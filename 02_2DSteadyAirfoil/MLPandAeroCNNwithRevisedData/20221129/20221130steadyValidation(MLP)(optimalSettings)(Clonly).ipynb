{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of the steady-state simulation - Case 1: MLP with Optimal settings\n",
    "## Optimal Settings are like below:\n",
    "# 1. Train/Validation/Test dataset ratio = 0.7/0.2/0.1\n",
    "# 2. Cd scaling -> replaced as normalization for both Cl and Cd\n",
    "# 3. Seperate the ML models into the two models, a model only for Cl and the other for Cd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining parameters and hyperparameters of the model\n",
    "\n",
    "n_units=128 # Number of units in the hidden layer of the MLP network\n",
    "input_size = 100 + 3 # Size of input for the network (100 coefficients and 3 other parameters, AoA, h, beta)\n",
    "lr = 1e-04 # Learning rate of the network\n",
    "test_rate = 0.1 # Defines the ratio of test dataset\n",
    "val_rate = 0.2 # Defines the ratio of validation dataset\n",
    "n_data = 16 # Number of txt files from which the aerodynamic coefficients are extracted\n",
    "batch_size = 20 # Mini-batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6d84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing working directory\n",
    "\n",
    "main_directory = 'D:\\\\VAWT_data\\\\flap_steady\\\\flap_steady'\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb294db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic parameters\n",
    "\n",
    "c = 1 # Chord length\n",
    "h = np.array([0.01, 0.02, 0.03]) * c # Height of the Gurney flaps\n",
    "t = 0.02 * h # Thickness of the Gurney flaps\n",
    "alpha = np.linspace(0, 16, 9).reshape((9,1)) # Angles of attack\n",
    "beta = np.linspace(30, 90, 5).reshape((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18aaa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.reshape((-1,1))\n",
    "t = t.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9745480",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alpha = alpha.shape[0] # Number of the angles of attack\n",
    "n_beta = beta.shape[0] # Number of the Gurney flap inclination\n",
    "n_h = h.shape[0] # Number of the height of the Gurney flaps\n",
    "n_cases = n_data * n_alpha # Total number of cases(Number of geometries * Number of angles of attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d7f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Input dataset\n",
    "# Defining the angles of attack\n",
    "\n",
    "aa_ = np.zeros((n_cases,1))\n",
    "for i in range(0, n_data):\n",
    "    aa_[n_alpha*i:n_alpha*(i+1),:] = alpha[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5014fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = aa_ / np.max(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa96208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937cc8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 1)\n"
     ]
    }
   ],
   "source": [
    "# Defining beta, the Gurney flap inclination\n",
    "# In case of mere NACA0018, the bb in those indexes are considered as zero.\n",
    "beta_0 = np.zeros((n_alpha,1)) # Values for sheer NACA0018\n",
    "b_ = np.ones((n_alpha,1)) # Template for the inclination for a single h and single beta\n",
    "bb_imp = np.zeros((n_alpha*n_beta,1))\n",
    "\n",
    "for j in range(n_beta):\n",
    "    b_imp = b_ * beta[j]\n",
    "    bb_imp[n_alpha*j:n_alpha*(j+1),:] = b_imp[:,:]\n",
    "    \n",
    "bb_imp = bb_imp.reshape((-1,1))\n",
    "\n",
    "bb = np.vstack((beta_0, bb_imp, bb_imp, bb_imp))\n",
    "bb = bb / np.max(beta)\n",
    "    \n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6302058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Gurney flap height\n",
    "# In case of mere NACA0018, the hh in those indexes are considered as zero.\n",
    "\n",
    "hh = np.concatenate((np.zeros(n_alpha), h[0]*np.ones(n_beta*n_alpha), h[1]*np.ones(n_beta*n_alpha), h[2]*np.ones(n_beta*n_alpha)))\n",
    "hh = hh.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174336d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh / np.max(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a5737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the coordinates of NACA0018 (airfoil15)\n",
    "origin_coord = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\\\\airfoil15\"\n",
    "\n",
    "csv_file_name = origin_coord + '\\\\airfoilOut15.txt'\n",
    "data = pd.read_csv(csv_file_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41daf0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_coord = data.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd4c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_coord = baseline_coord.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba48669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 100)\n"
     ]
    }
   ],
   "source": [
    "airfoil_coord = np.repeat(standard_coord, n_cases, axis=0)\n",
    "print(airfoil_coord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "492ab857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows mean the number of points at the Gurney flap\n",
    "# and the columns mean the number of the cases\n",
    "flap_left = np.zeros((15,5))\n",
    "flap_right = np.zeros((15,5))\n",
    "\n",
    "for i in range(n_h):\n",
    "    # Defining coordinates of the flaps with respect to beta=90 degree.\n",
    "    yLeft = np.linspace(-h[i]/5, -h[i], 5).reshape((-1,1))\n",
    "    yRight = np.linspace(-h[i]/5, -h[i], 5).reshape((-1,1))\n",
    "    xLeft = 0.5*np.ones((5,1)) - 0.02*h[i]\n",
    "    xRight = 0.5*np.ones((5,1))\n",
    "    \n",
    "    for j in range(n_beta):\n",
    "        betaValue = beta[j]\n",
    "        \n",
    "        # Rotating transformation\n",
    "        rotateTransf = np.array([[np.cos(90-betaValue), -np.sin(90-betaValue)],\n",
    "                                 [np.sin(90-betaValue), np.cos(90-betaValue)]])\n",
    "        rotateTransf = rotateTransf.reshape((2,2))\n",
    "        \n",
    "        LeftImp = np.hstack((xLeft-0.5, yLeft))\n",
    "        RightImp = np.hstack((xRight-0.5, yRight))\n",
    "        \n",
    "        rotatedFlapLeft = rotateTransf @ LeftImp.T # shape: 2*5 (x-coordinates on first row, y-coordinates on second row)\n",
    "        rotatedFlapRight = rotateTransf @ RightImp.T\n",
    "        \n",
    "        # All we need is the y-coordinates of the flaps\n",
    "        flap_left[5*i+j,:] = rotatedFlapLeft[1,:]\n",
    "        flap_right[5*i+j,:] = rotatedFlapRight[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "790fb777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 10)\n"
     ]
    }
   ],
   "source": [
    "# Combining y-coordinates from the left and the right side of the flaps\n",
    "flap_coords = np.hstack((flap_left, np.flip(flap_right, axis=1)))\n",
    "print(flap_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66f6855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 10)\n"
     ]
    }
   ],
   "source": [
    "# Placing the flap_coords into total coordinate variable\n",
    "# Total coordinate = Airfoil coordinates + flap coordinates\n",
    "flap_coords2 = np.zeros((n_cases, 10))\n",
    "for i in range(n_alpha, n_cases):\n",
    "    flap_coords2[i,:] = flap_coords[i%15,:]\n",
    "    \n",
    "print(flap_coords2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8323888f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 110)\n"
     ]
    }
   ],
   "source": [
    "total_coords = np.hstack((airfoil_coord, flap_coords2))\n",
    "print(total_coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d72e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.hstack((aa, hh, bb, total_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b41130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating output dataset - Cl and Cd\n",
    "files_orig = os.listdir(main_directory)\n",
    "files_target = [file for file in files_orig if file.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4c62765",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame()\n",
    "for file in files_target:\n",
    "    data = pd.read_table(file, header=None)\n",
    "    target_df = pd.concat([target_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ac849035",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_orig = target_df.iloc[:,4].values # Cd values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b2f4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = (cl_orig-np.min(cl_orig))/(np.max(cl_orig)-np.min(cl_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93bba2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cl.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7444ef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all, x_test, y_all, y_test = train_test_split(x, y, test_size=test_rate, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e090320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_all, y_all, test_size=val_rate/(1-test_rate), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1bbc2f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 113)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e00d21f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82d60c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.Input(shape=(3+total_coords.shape[1]))\n",
    "\n",
    "x_fc1 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc1')(input_data)\n",
    "x_fc2 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc2')(x_fc1)\n",
    "x_fc3 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc3')(x_fc2)\n",
    "x_fc4 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc4')(x_fc3)\n",
    "x_fc5 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc5')(x_fc4)\n",
    "\n",
    "output_data = tf.keras.layers.Dense(units=1, activation='linear', name='outputLayer')(x_fc5)\n",
    "# MLP(FC layer)-based\n",
    "model = tf.keras.Model(input_data, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 113)]             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               14592     \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " fc4 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " fc5 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,769\n",
      "Trainable params: 80,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b234f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20221130\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "134e54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = model_directory + \"\\\\20221130steadyValidation_MLP_val_\"+str(val_rate) + \"_test\"+str(test_rate)+ \"_\" + str(n_units) +\"units_ClOptimalSettings_checkpoint.h5\"\n",
    "\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(ckpt_name, monitor=\"val_loss\", mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1000, min_delta=6e-7,\n",
    "                                      restore_best_weights=True, verbose=1)\n",
    "rp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=200, factor=0.5,\n",
    "                                          min_delta = 1e-09, min_lr=1e-06, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4cc904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = len(x_train)//batch_size\n",
    "VALIDATION_STEPS = len(x_val)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/5 [=====>........................] - ETA: 5s - loss: 0.3085 - rmse: 0.5554\n",
      "Epoch 1: val_loss improved from inf to 0.38847, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 2s 56ms/step - loss: 0.3961 - rmse: 0.6294 - val_loss: 0.3885 - val_rmse: 0.6233 - lr: 1.0000e-04\n",
      "Epoch 2/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4761 - rmse: 0.6900\n",
      "Epoch 2: val_loss improved from 0.38847 to 0.34462, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3527 - rmse: 0.5939 - val_loss: 0.3446 - val_rmse: 0.5870 - lr: 1.0000e-04\n",
      "Epoch 3/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2918 - rmse: 0.5402\n",
      "Epoch 3: val_loss improved from 0.34462 to 0.29810, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3088 - rmse: 0.5557 - val_loss: 0.2981 - val_rmse: 0.5460 - lr: 1.0000e-04\n",
      "Epoch 4/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2142 - rmse: 0.4628\n",
      "Epoch 4: val_loss improved from 0.29810 to 0.25248, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2633 - rmse: 0.5131 - val_loss: 0.2525 - val_rmse: 0.5025 - lr: 1.0000e-04\n",
      "Epoch 5/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2446 - rmse: 0.4946\n",
      "Epoch 5: val_loss improved from 0.25248 to 0.20722, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2211 - rmse: 0.4702 - val_loss: 0.2072 - val_rmse: 0.4552 - lr: 1.0000e-04\n",
      "Epoch 6/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1248 - rmse: 0.3533\n",
      "Epoch 6: val_loss improved from 0.20722 to 0.16269, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1780 - rmse: 0.4219 - val_loss: 0.1627 - val_rmse: 0.4033 - lr: 1.0000e-04\n",
      "Epoch 7/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1783 - rmse: 0.4222\n",
      "Epoch 7: val_loss improved from 0.16269 to 0.12003, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1378 - rmse: 0.3712 - val_loss: 0.1200 - val_rmse: 0.3465 - lr: 1.0000e-04\n",
      "Epoch 8/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0841 - rmse: 0.2900\n",
      "Epoch 8: val_loss improved from 0.12003 to 0.08264, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1006 - rmse: 0.3172 - val_loss: 0.0826 - val_rmse: 0.2875 - lr: 1.0000e-04\n",
      "Epoch 9/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0939 - rmse: 0.3065\n",
      "Epoch 9: val_loss improved from 0.08264 to 0.05365, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0723 - rmse: 0.2689 - val_loss: 0.0537 - val_rmse: 0.2316 - lr: 1.0000e-04\n",
      "Epoch 10/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0486 - rmse: 0.2204\n",
      "Epoch 10: val_loss improved from 0.05365 to 0.03622, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0514 - rmse: 0.2267 - val_loss: 0.0362 - val_rmse: 0.1903 - lr: 1.0000e-04\n",
      "Epoch 11/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0431 - rmse: 0.2075\n",
      "Epoch 11: val_loss improved from 0.03622 to 0.02902, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0423 - rmse: 0.2058 - val_loss: 0.0290 - val_rmse: 0.1704 - lr: 1.0000e-04\n",
      "Epoch 12/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0262 - rmse: 0.1620\n",
      "Epoch 12: val_loss improved from 0.02902 to 0.02690, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0400 - rmse: 0.2001 - val_loss: 0.0269 - val_rmse: 0.1640 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0300 - rmse: 0.1731\n",
      "Epoch 13: val_loss improved from 0.02690 to 0.02529, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0389 - rmse: 0.1973 - val_loss: 0.0253 - val_rmse: 0.1590 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0541 - rmse: 0.2326\n",
      "Epoch 14: val_loss improved from 0.02529 to 0.02333, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0364 - rmse: 0.1907 - val_loss: 0.0233 - val_rmse: 0.1527 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0191 - rmse: 0.1381\n",
      "Epoch 15: val_loss improved from 0.02333 to 0.02199, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0320 - rmse: 0.1788 - val_loss: 0.0220 - val_rmse: 0.1483 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0221 - rmse: 0.1486\n",
      "Epoch 16: val_loss improved from 0.02199 to 0.02117, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0290 - rmse: 0.1704 - val_loss: 0.0212 - val_rmse: 0.1455 - lr: 1.0000e-04\n",
      "Epoch 17/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0260 - rmse: 0.1612\n",
      "Epoch 17: val_loss improved from 0.02117 to 0.01995, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0266 - rmse: 0.1632 - val_loss: 0.0200 - val_rmse: 0.1413 - lr: 1.0000e-04\n",
      "Epoch 18/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0216 - rmse: 0.1470\n",
      "Epoch 18: val_loss improved from 0.01995 to 0.01794, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0238 - rmse: 0.1543 - val_loss: 0.0179 - val_rmse: 0.1339 - lr: 1.0000e-04\n",
      "Epoch 19/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0249 - rmse: 0.1579\n",
      "Epoch 19: val_loss improved from 0.01794 to 0.01597, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0211 - rmse: 0.1453 - val_loss: 0.0160 - val_rmse: 0.1264 - lr: 1.0000e-04\n",
      "Epoch 20/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0136 - rmse: 0.1167\n",
      "Epoch 20: val_loss improved from 0.01597 to 0.01421, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0187 - rmse: 0.1366 - val_loss: 0.0142 - val_rmse: 0.1192 - lr: 1.0000e-04\n",
      "Epoch 21/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0135 - rmse: 0.1163\n",
      "Epoch 21: val_loss improved from 0.01421 to 0.01287, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0166 - rmse: 0.1288 - val_loss: 0.0129 - val_rmse: 0.1135 - lr: 1.0000e-04\n",
      "Epoch 22/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0116 - rmse: 0.1079\n",
      "Epoch 22: val_loss improved from 0.01287 to 0.01203, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0149 - rmse: 0.1222 - val_loss: 0.0120 - val_rmse: 0.1097 - lr: 1.0000e-04\n",
      "Epoch 23/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0098 - rmse: 0.0991\n",
      "Epoch 23: val_loss improved from 0.01203 to 0.01170, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0137 - rmse: 0.1172 - val_loss: 0.0117 - val_rmse: 0.1082 - lr: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0218 - rmse: 0.1475\n",
      "Epoch 24: val_loss improved from 0.01170 to 0.01136, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0127 - rmse: 0.1127 - val_loss: 0.0114 - val_rmse: 0.1066 - lr: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0096 - rmse: 0.0982\n",
      "Epoch 25: val_loss improved from 0.01136 to 0.01079, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0118 - rmse: 0.1086 - val_loss: 0.0108 - val_rmse: 0.1039 - lr: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0102 - rmse: 0.1008\n",
      "Epoch 26: val_loss improved from 0.01079 to 0.01052, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0114 - rmse: 0.1067 - val_loss: 0.0105 - val_rmse: 0.1026 - lr: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0092 - rmse: 0.0960\n",
      "Epoch 27: val_loss did not improve from 0.01052\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0110 - rmse: 0.1047 - val_loss: 0.0108 - val_rmse: 0.1040 - lr: 1.0000e-04\n",
      "Epoch 28/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0075 - rmse: 0.0868\n",
      "Epoch 28: val_loss improved from 0.01052 to 0.01031, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0106 - rmse: 0.1028 - val_loss: 0.0103 - val_rmse: 0.1015 - lr: 1.0000e-04\n",
      "Epoch 29/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0131 - rmse: 0.1147\n",
      "Epoch 29: val_loss did not improve from 0.01031\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0103 - rmse: 0.1013 - val_loss: 0.0105 - val_rmse: 0.1027 - lr: 1.0000e-04\n",
      "Epoch 30/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0086 - rmse: 0.0929\n",
      "Epoch 30: val_loss improved from 0.01031 to 0.01001, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0101 - rmse: 0.1006 - val_loss: 0.0100 - val_rmse: 0.1001 - lr: 1.0000e-04\n",
      "Epoch 31/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0078 - rmse: 0.0884\n",
      "Epoch 31: val_loss did not improve from 0.01001\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0097 - rmse: 0.0985 - val_loss: 0.0100 - val_rmse: 0.1002 - lr: 1.0000e-04\n",
      "Epoch 32/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0057 - rmse: 0.0755\n",
      "Epoch 32: val_loss did not improve from 0.01001\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0095 - rmse: 0.0975 - val_loss: 0.0101 - val_rmse: 0.1003 - lr: 1.0000e-04\n",
      "Epoch 33/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0106 - rmse: 0.1029\n",
      "Epoch 33: val_loss improved from 0.01001 to 0.00993, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0094 - rmse: 0.0967 - val_loss: 0.0099 - val_rmse: 0.0997 - lr: 1.0000e-04\n",
      "Epoch 34/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0044 - rmse: 0.0666\n",
      "Epoch 34: val_loss improved from 0.00993 to 0.00959, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0094 - rmse: 0.0968 - val_loss: 0.0096 - val_rmse: 0.0979 - lr: 1.0000e-04\n",
      "Epoch 35/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0034 - rmse: 0.0587\n",
      "Epoch 35: val_loss did not improve from 0.00959\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0090 - rmse: 0.0951 - val_loss: 0.0097 - val_rmse: 0.0984 - lr: 1.0000e-04\n",
      "Epoch 36/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0126 - rmse: 0.1123\n",
      "Epoch 36: val_loss did not improve from 0.00959\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0090 - rmse: 0.0948 - val_loss: 0.0096 - val_rmse: 0.0982 - lr: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0067 - rmse: 0.0819\n",
      "Epoch 37: val_loss improved from 0.00959 to 0.00947, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0089 - rmse: 0.0945 - val_loss: 0.0095 - val_rmse: 0.0973 - lr: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0052 - rmse: 0.0720\n",
      "Epoch 38: val_loss improved from 0.00947 to 0.00915, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0088 - rmse: 0.0937 - val_loss: 0.0091 - val_rmse: 0.0957 - lr: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0086 - rmse: 0.0928\n",
      "Epoch 39: val_loss improved from 0.00915 to 0.00897, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0088 - rmse: 0.0938 - val_loss: 0.0090 - val_rmse: 0.0947 - lr: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0188 - rmse: 0.1372\n",
      "Epoch 40: val_loss did not improve from 0.00897\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0087 - rmse: 0.0935 - val_loss: 0.0093 - val_rmse: 0.0966 - lr: 1.0000e-04\n",
      "Epoch 41/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0054 - rmse: 0.0737\n",
      "Epoch 41: val_loss did not improve from 0.00897\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0086 - rmse: 0.0928 - val_loss: 0.0090 - val_rmse: 0.0951 - lr: 1.0000e-04\n",
      "Epoch 42/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0059 - rmse: 0.0767\n",
      "Epoch 42: val_loss improved from 0.00897 to 0.00883, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0085 - rmse: 0.0923 - val_loss: 0.0088 - val_rmse: 0.0940 - lr: 1.0000e-04\n",
      "Epoch 43/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0073 - rmse: 0.0855\n",
      "Epoch 43: val_loss improved from 0.00883 to 0.00863, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0085 - rmse: 0.0923 - val_loss: 0.0086 - val_rmse: 0.0929 - lr: 1.0000e-04\n",
      "Epoch 44/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0063 - rmse: 0.0797\n",
      "Epoch 44: val_loss did not improve from 0.00863\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0085 - rmse: 0.0920 - val_loss: 0.0088 - val_rmse: 0.0936 - lr: 1.0000e-04\n",
      "Epoch 45/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0037 - rmse: 0.0609\n",
      "Epoch 45: val_loss improved from 0.00863 to 0.00850, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0084 - rmse: 0.0916 - val_loss: 0.0085 - val_rmse: 0.0922 - lr: 1.0000e-04\n",
      "Epoch 46/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - rmse: 0.0442\n",
      "Epoch 46: val_loss improved from 0.00850 to 0.00840, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0083 - rmse: 0.0912 - val_loss: 0.0084 - val_rmse: 0.0917 - lr: 1.0000e-04\n",
      "Epoch 47/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0086 - rmse: 0.0928\n",
      "Epoch 47: val_loss did not improve from 0.00840\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0083 - rmse: 0.0910 - val_loss: 0.0085 - val_rmse: 0.0921 - lr: 1.0000e-04\n",
      "Epoch 48/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0081 - rmse: 0.0902\n",
      "Epoch 48: val_loss improved from 0.00840 to 0.00812, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0082 - rmse: 0.0906 - val_loss: 0.0081 - val_rmse: 0.0901 - lr: 1.0000e-04\n",
      "Epoch 49/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0066 - rmse: 0.0813\n",
      "Epoch 49: val_loss did not improve from 0.00812\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0082 - rmse: 0.0908 - val_loss: 0.0083 - val_rmse: 0.0908 - lr: 1.0000e-04\n",
      "Epoch 50/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0148 - rmse: 0.1215\n",
      "Epoch 50: val_loss improved from 0.00812 to 0.00790, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0080 - rmse: 0.0897 - val_loss: 0.0079 - val_rmse: 0.0889 - lr: 1.0000e-04\n",
      "Epoch 51/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0064 - rmse: 0.0798\n",
      "Epoch 51: val_loss improved from 0.00790 to 0.00766, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0080 - rmse: 0.0892 - val_loss: 0.0077 - val_rmse: 0.0875 - lr: 1.0000e-04\n",
      "Epoch 52/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0122 - rmse: 0.1106\n",
      "Epoch 52: val_loss did not improve from 0.00766\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0079 - rmse: 0.0891 - val_loss: 0.0078 - val_rmse: 0.0882 - lr: 1.0000e-04\n",
      "Epoch 53/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0051 - rmse: 0.0713\n",
      "Epoch 53: val_loss improved from 0.00766 to 0.00759, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0079 - rmse: 0.0886 - val_loss: 0.0076 - val_rmse: 0.0871 - lr: 1.0000e-04\n",
      "Epoch 54/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0044 - rmse: 0.0661\n",
      "Epoch 54: val_loss improved from 0.00759 to 0.00736, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0078 - rmse: 0.0883 - val_loss: 0.0074 - val_rmse: 0.0858 - lr: 1.0000e-04\n",
      "Epoch 55/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0102 - rmse: 0.1009\n",
      "Epoch 55: val_loss improved from 0.00736 to 0.00733, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0077 - rmse: 0.0879 - val_loss: 0.0073 - val_rmse: 0.0856 - lr: 1.0000e-04\n",
      "Epoch 56/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0142 - rmse: 0.1191\n",
      "Epoch 56: val_loss did not improve from 0.00733\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0078 - rmse: 0.0882 - val_loss: 0.0074 - val_rmse: 0.0857 - lr: 1.0000e-04\n",
      "Epoch 57/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0030 - rmse: 0.0544\n",
      "Epoch 57: val_loss improved from 0.00733 to 0.00680, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0078 - rmse: 0.0883 - val_loss: 0.0068 - val_rmse: 0.0825 - lr: 1.0000e-04\n",
      "Epoch 58/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - rmse: 0.0347\n",
      "Epoch 58: val_loss did not improve from 0.00680\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0077 - rmse: 0.0875 - val_loss: 0.0070 - val_rmse: 0.0838 - lr: 1.0000e-04\n",
      "Epoch 59/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0134 - rmse: 0.1157\n",
      "Epoch 59: val_loss did not improve from 0.00680\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0076 - rmse: 0.0872 - val_loss: 0.0072 - val_rmse: 0.0849 - lr: 1.0000e-04\n",
      "Epoch 60/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0092 - rmse: 0.0960\n",
      "Epoch 60: val_loss did not improve from 0.00680\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0075 - rmse: 0.0866 - val_loss: 0.0068 - val_rmse: 0.0826 - lr: 1.0000e-04\n",
      "Epoch 61/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0040 - rmse: 0.0635\n",
      "Epoch 61: val_loss improved from 0.00680 to 0.00654, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0075 - rmse: 0.0866 - val_loss: 0.0065 - val_rmse: 0.0809 - lr: 1.0000e-04\n",
      "Epoch 62/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0053 - rmse: 0.0730\n",
      "Epoch 62: val_loss did not improve from 0.00654\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0075 - rmse: 0.0864 - val_loss: 0.0066 - val_rmse: 0.0813 - lr: 1.0000e-04\n",
      "Epoch 63/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0050 - rmse: 0.0704\n",
      "Epoch 63: val_loss did not improve from 0.00654\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0075 - rmse: 0.0863 - val_loss: 0.0072 - val_rmse: 0.0847 - lr: 1.0000e-04\n",
      "Epoch 64/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - rmse: 0.0571\n",
      "Epoch 64: val_loss did not improve from 0.00654\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0074 - rmse: 0.0860 - val_loss: 0.0066 - val_rmse: 0.0809 - lr: 1.0000e-04\n",
      "Epoch 65/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0017 - rmse: 0.0416\n",
      "Epoch 65: val_loss improved from 0.00654 to 0.00634, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0074 - rmse: 0.0859 - val_loss: 0.0063 - val_rmse: 0.0796 - lr: 1.0000e-04\n",
      "Epoch 66/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0070 - rmse: 0.0840\n",
      "Epoch 66: val_loss did not improve from 0.00634\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0073 - rmse: 0.0856 - val_loss: 0.0066 - val_rmse: 0.0812 - lr: 1.0000e-04\n",
      "Epoch 67/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0025 - rmse: 0.0498\n",
      "Epoch 67: val_loss improved from 0.00634 to 0.00629, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0073 - rmse: 0.0853 - val_loss: 0.0063 - val_rmse: 0.0793 - lr: 1.0000e-04\n",
      "Epoch 68/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0101 - rmse: 0.1003\n",
      "Epoch 68: val_loss did not improve from 0.00629\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0072 - rmse: 0.0848 - val_loss: 0.0064 - val_rmse: 0.0803 - lr: 1.0000e-04\n",
      "Epoch 69/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0046 - rmse: 0.0679\n",
      "Epoch 69: val_loss improved from 0.00629 to 0.00628, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0071 - rmse: 0.0844 - val_loss: 0.0063 - val_rmse: 0.0792 - lr: 1.0000e-04\n",
      "Epoch 70/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0106 - rmse: 0.1027\n",
      "Epoch 70: val_loss improved from 0.00628 to 0.00623, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0071 - rmse: 0.0841 - val_loss: 0.0062 - val_rmse: 0.0789 - lr: 1.0000e-04\n",
      "Epoch 71/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0054 - rmse: 0.0738\n",
      "Epoch 71: val_loss improved from 0.00623 to 0.00604, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0071 - rmse: 0.0841 - val_loss: 0.0060 - val_rmse: 0.0777 - lr: 1.0000e-04\n",
      "Epoch 72/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0124 - rmse: 0.1115\n",
      "Epoch 72: val_loss did not improve from 0.00604\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0071 - rmse: 0.0841 - val_loss: 0.0063 - val_rmse: 0.0796 - lr: 1.0000e-04\n",
      "Epoch 73/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0051 - rmse: 0.0716\n",
      "Epoch 73: val_loss did not improve from 0.00604\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0070 - rmse: 0.0834 - val_loss: 0.0061 - val_rmse: 0.0779 - lr: 1.0000e-04\n",
      "Epoch 74/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0134 - rmse: 0.1158\n",
      "Epoch 74: val_loss improved from 0.00604 to 0.00592, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0069 - rmse: 0.0831 - val_loss: 0.0059 - val_rmse: 0.0770 - lr: 1.0000e-04\n",
      "Epoch 75/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0110 - rmse: 0.1047\n",
      "Epoch 75: val_loss did not improve from 0.00592\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0069 - rmse: 0.0829 - val_loss: 0.0060 - val_rmse: 0.0774 - lr: 1.0000e-04\n",
      "Epoch 76/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0073 - rmse: 0.0852\n",
      "Epoch 76: val_loss did not improve from 0.00592\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0069 - rmse: 0.0829 - val_loss: 0.0060 - val_rmse: 0.0774 - lr: 1.0000e-04\n",
      "Epoch 77/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0062 - rmse: 0.0785\n",
      "Epoch 77: val_loss did not improve from 0.00592\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0069 - rmse: 0.0829 - val_loss: 0.0061 - val_rmse: 0.0778 - lr: 1.0000e-04\n",
      "Epoch 78/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0100 - rmse: 0.0998\n",
      "Epoch 78: val_loss improved from 0.00592 to 0.00582, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0067 - rmse: 0.0821 - val_loss: 0.0058 - val_rmse: 0.0763 - lr: 1.0000e-04\n",
      "Epoch 79/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0101 - rmse: 0.1004\n",
      "Epoch 79: val_loss improved from 0.00582 to 0.00571, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0067 - rmse: 0.0820 - val_loss: 0.0057 - val_rmse: 0.0756 - lr: 1.0000e-04\n",
      "Epoch 80/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0124 - rmse: 0.1112\n",
      "Epoch 80: val_loss did not improve from 0.00571\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0067 - rmse: 0.0820 - val_loss: 0.0059 - val_rmse: 0.0768 - lr: 1.0000e-04\n",
      "Epoch 81/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0075 - rmse: 0.0863\n",
      "Epoch 81: val_loss improved from 0.00571 to 0.00569, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0067 - rmse: 0.0816 - val_loss: 0.0057 - val_rmse: 0.0754 - lr: 1.0000e-04\n",
      "Epoch 82/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0065 - rmse: 0.0807\n",
      "Epoch 82: val_loss did not improve from 0.00569\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0067 - rmse: 0.0817 - val_loss: 0.0057 - val_rmse: 0.0758 - lr: 1.0000e-04\n",
      "Epoch 83/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0041 - rmse: 0.0637\n",
      "Epoch 83: val_loss improved from 0.00569 to 0.00555, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0069 - rmse: 0.0829 - val_loss: 0.0056 - val_rmse: 0.0745 - lr: 1.0000e-04\n",
      "Epoch 84/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0173 - rmse: 0.1316\n",
      "Epoch 84: val_loss did not improve from 0.00555\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0068 - rmse: 0.0823 - val_loss: 0.0060 - val_rmse: 0.0774 - lr: 1.0000e-04\n",
      "Epoch 85/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0038 - rmse: 0.0616\n",
      "Epoch 85: val_loss improved from 0.00555 to 0.00549, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0065 - rmse: 0.0809 - val_loss: 0.0055 - val_rmse: 0.0741 - lr: 1.0000e-04\n",
      "Epoch 86/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0037 - rmse: 0.0609\n",
      "Epoch 86: val_loss improved from 0.00549 to 0.00537, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0068 - rmse: 0.0823 - val_loss: 0.0054 - val_rmse: 0.0733 - lr: 1.0000e-04\n",
      "Epoch 87/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0145 - rmse: 0.1203\n",
      "Epoch 87: val_loss did not improve from 0.00537\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0066 - rmse: 0.0813 - val_loss: 0.0061 - val_rmse: 0.0780 - lr: 1.0000e-04\n",
      "Epoch 88/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0027 - rmse: 0.0524\n",
      "Epoch 88: val_loss did not improve from 0.00537\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0064 - rmse: 0.0802 - val_loss: 0.0054 - val_rmse: 0.0735 - lr: 1.0000e-04\n",
      "Epoch 89/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0048 - rmse: 0.0693\n",
      "Epoch 89: val_loss improved from 0.00537 to 0.00528, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0065 - rmse: 0.0807 - val_loss: 0.0053 - val_rmse: 0.0727 - lr: 1.0000e-04\n",
      "Epoch 90/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0130 - rmse: 0.1141\n",
      "Epoch 90: val_loss did not improve from 0.00528\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0066 - rmse: 0.0811 - val_loss: 0.0057 - val_rmse: 0.0758 - lr: 1.0000e-04\n",
      "Epoch 91/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0129 - rmse: 0.1134\n",
      "Epoch 91: val_loss improved from 0.00528 to 0.00518, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0062 - rmse: 0.0790 - val_loss: 0.0052 - val_rmse: 0.0719 - lr: 1.0000e-04\n",
      "Epoch 92/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0019 - rmse: 0.0436\n",
      "Epoch 92: val_loss improved from 0.00518 to 0.00513, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0064 - rmse: 0.0799 - val_loss: 0.0051 - val_rmse: 0.0716 - lr: 1.0000e-04\n",
      "Epoch 93/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0045 - rmse: 0.0667\n",
      "Epoch 93: val_loss did not improve from 0.00513\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0064 - rmse: 0.0802 - val_loss: 0.0058 - val_rmse: 0.0760 - lr: 1.0000e-04\n",
      "Epoch 94/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0068 - rmse: 0.0824\n",
      "Epoch 94: val_loss improved from 0.00513 to 0.00510, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0063 - rmse: 0.0792 - val_loss: 0.0051 - val_rmse: 0.0714 - lr: 1.0000e-04\n",
      "Epoch 95/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0152 - rmse: 0.1231\n",
      "Epoch 95: val_loss did not improve from 0.00510\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0062 - rmse: 0.0785 - val_loss: 0.0052 - val_rmse: 0.0723 - lr: 1.0000e-04\n",
      "Epoch 96/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0052 - rmse: 0.0722\n",
      "Epoch 96: val_loss did not improve from 0.00510\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0062 - rmse: 0.0785 - val_loss: 0.0054 - val_rmse: 0.0731 - lr: 1.0000e-04\n",
      "Epoch 97/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0024 - rmse: 0.0492\n",
      "Epoch 97: val_loss improved from 0.00510 to 0.00499, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0063 - rmse: 0.0795 - val_loss: 0.0050 - val_rmse: 0.0706 - lr: 1.0000e-04\n",
      "Epoch 98/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0026 - rmse: 0.0510\n",
      "Epoch 98: val_loss did not improve from 0.00499\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0061 - rmse: 0.0782 - val_loss: 0.0056 - val_rmse: 0.0750 - lr: 1.0000e-04\n",
      "Epoch 99/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0079 - rmse: 0.0887\n",
      "Epoch 99: val_loss did not improve from 0.00499\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0062 - rmse: 0.0786 - val_loss: 0.0052 - val_rmse: 0.0723 - lr: 1.0000e-04\n",
      "Epoch 100/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0113 - rmse: 0.1063\n",
      "Epoch 100: val_loss improved from 0.00499 to 0.00490, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0059 - rmse: 0.0769 - val_loss: 0.0049 - val_rmse: 0.0700 - lr: 1.0000e-04\n",
      "Epoch 101/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0039 - rmse: 0.0625\n",
      "Epoch 101: val_loss did not improve from 0.00490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0060 - rmse: 0.0776 - val_loss: 0.0050 - val_rmse: 0.0708 - lr: 1.0000e-04\n",
      "Epoch 102/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0021 - rmse: 0.0457\n",
      "Epoch 102: val_loss did not improve from 0.00490\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0059 - rmse: 0.0767 - val_loss: 0.0051 - val_rmse: 0.0717 - lr: 1.0000e-04\n",
      "Epoch 103/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0095 - rmse: 0.0972\n",
      "Epoch 103: val_loss did not improve from 0.00490\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0060 - rmse: 0.0772 - val_loss: 0.0053 - val_rmse: 0.0730 - lr: 1.0000e-04\n",
      "Epoch 104/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - rmse: 0.0574\n",
      "Epoch 104: val_loss improved from 0.00490 to 0.00478, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0059 - rmse: 0.0768 - val_loss: 0.0048 - val_rmse: 0.0691 - lr: 1.0000e-04\n",
      "Epoch 105/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0089 - rmse: 0.0943\n",
      "Epoch 105: val_loss did not improve from 0.00478\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0059 - rmse: 0.0766 - val_loss: 0.0049 - val_rmse: 0.0701 - lr: 1.0000e-04\n",
      "Epoch 106/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - rmse: 0.0576\n",
      "Epoch 106: val_loss did not improve from 0.00478\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0057 - rmse: 0.0758 - val_loss: 0.0053 - val_rmse: 0.0725 - lr: 1.0000e-04\n",
      "Epoch 107/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0032 - rmse: 0.0567\n",
      "Epoch 107: val_loss did not improve from 0.00478\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0057 - rmse: 0.0757 - val_loss: 0.0049 - val_rmse: 0.0699 - lr: 1.0000e-04\n",
      "Epoch 108/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0057 - rmse: 0.0752\n",
      "Epoch 108: val_loss improved from 0.00478 to 0.00474, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0057 - rmse: 0.0752 - val_loss: 0.0047 - val_rmse: 0.0688 - lr: 1.0000e-04\n",
      "Epoch 109/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0104 - rmse: 0.1020\n",
      "Epoch 109: val_loss did not improve from 0.00474\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0057 - rmse: 0.0755 - val_loss: 0.0049 - val_rmse: 0.0700 - lr: 1.0000e-04\n",
      "Epoch 110/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0040 - rmse: 0.0635\n",
      "Epoch 110: val_loss improved from 0.00474 to 0.00473, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0056 - rmse: 0.0751 - val_loss: 0.0047 - val_rmse: 0.0688 - lr: 1.0000e-04\n",
      "Epoch 111/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0038 - rmse: 0.0619\n",
      "Epoch 111: val_loss did not improve from 0.00473\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0056 - rmse: 0.0749 - val_loss: 0.0049 - val_rmse: 0.0700 - lr: 1.0000e-04\n",
      "Epoch 112/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0025 - rmse: 0.0497\n",
      "Epoch 112: val_loss improved from 0.00473 to 0.00463, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0057 - rmse: 0.0753 - val_loss: 0.0046 - val_rmse: 0.0680 - lr: 1.0000e-04\n",
      "Epoch 113/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0339\n",
      "Epoch 113: val_loss did not improve from 0.00463\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0055 - rmse: 0.0743 - val_loss: 0.0048 - val_rmse: 0.0694 - lr: 1.0000e-04\n",
      "Epoch 114/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0050 - rmse: 0.0708\n",
      "Epoch 114: val_loss did not improve from 0.00463\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0055 - rmse: 0.0740 - val_loss: 0.0048 - val_rmse: 0.0690 - lr: 1.0000e-04\n",
      "Epoch 115/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0032 - rmse: 0.0569\n",
      "Epoch 115: val_loss did not improve from 0.00463\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0055 - rmse: 0.0741 - val_loss: 0.0047 - val_rmse: 0.0688 - lr: 1.0000e-04\n",
      "Epoch 116/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0037 - rmse: 0.0608\n",
      "Epoch 116: val_loss improved from 0.00463 to 0.00449, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0054 - rmse: 0.0736 - val_loss: 0.0045 - val_rmse: 0.0670 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0058 - rmse: 0.0761\n",
      "Epoch 117: val_loss did not improve from 0.00449\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0054 - rmse: 0.0735 - val_loss: 0.0048 - val_rmse: 0.0696 - lr: 1.0000e-04\n",
      "Epoch 118/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0098 - rmse: 0.0991\n",
      "Epoch 118: val_loss did not improve from 0.00449\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0054 - rmse: 0.0732 - val_loss: 0.0046 - val_rmse: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 119/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0018 - rmse: 0.0425\n",
      "Epoch 119: val_loss improved from 0.00449 to 0.00439, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0054 - rmse: 0.0738 - val_loss: 0.0044 - val_rmse: 0.0663 - lr: 1.0000e-04\n",
      "Epoch 120/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0140 - rmse: 0.1182\n",
      "Epoch 120: val_loss did not improve from 0.00439\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0055 - rmse: 0.0740 - val_loss: 0.0048 - val_rmse: 0.0696 - lr: 1.0000e-04\n",
      "Epoch 121/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0050 - rmse: 0.0706\n",
      "Epoch 121: val_loss improved from 0.00439 to 0.00435, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0053 - rmse: 0.0726 - val_loss: 0.0043 - val_rmse: 0.0659 - lr: 1.0000e-04\n",
      "Epoch 122/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - rmse: 0.0474\n",
      "Epoch 122: val_loss did not improve from 0.00435\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0052 - rmse: 0.0723 - val_loss: 0.0045 - val_rmse: 0.0672 - lr: 1.0000e-04\n",
      "Epoch 123/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0086 - rmse: 0.0929\n",
      "Epoch 123: val_loss did not improve from 0.00435\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0053 - rmse: 0.0728 - val_loss: 0.0045 - val_rmse: 0.0670 - lr: 1.0000e-04\n",
      "Epoch 124/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0055 - rmse: 0.0741\n",
      "Epoch 124: val_loss improved from 0.00435 to 0.00424, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0054 - rmse: 0.0733 - val_loss: 0.0042 - val_rmse: 0.0651 - lr: 1.0000e-04\n",
      "Epoch 125/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0112 - rmse: 0.1057\n",
      "Epoch 125: val_loss did not improve from 0.00424\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0056 - rmse: 0.0749 - val_loss: 0.0049 - val_rmse: 0.0703 - lr: 1.0000e-04\n",
      "Epoch 126/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - rmse: 0.0446\n",
      "Epoch 126: val_loss improved from 0.00424 to 0.00419, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0051 - rmse: 0.0713 - val_loss: 0.0042 - val_rmse: 0.0647 - lr: 1.0000e-04\n",
      "Epoch 127/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0068 - rmse: 0.0823\n",
      "Epoch 127: val_loss did not improve from 0.00419\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0051 - rmse: 0.0715 - val_loss: 0.0044 - val_rmse: 0.0660 - lr: 1.0000e-04\n",
      "Epoch 128/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0052 - rmse: 0.0721\n",
      "Epoch 128: val_loss did not improve from 0.00419\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0050 - rmse: 0.0705 - val_loss: 0.0043 - val_rmse: 0.0657 - lr: 1.0000e-04\n",
      "Epoch 129/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0035 - rmse: 0.0588\n",
      "Epoch 129: val_loss did not improve from 0.00419\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0050 - rmse: 0.0704 - val_loss: 0.0043 - val_rmse: 0.0657 - lr: 1.0000e-04\n",
      "Epoch 130/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0032 - rmse: 0.0565\n",
      "Epoch 130: val_loss improved from 0.00419 to 0.00412, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0050 - rmse: 0.0705 - val_loss: 0.0041 - val_rmse: 0.0642 - lr: 1.0000e-04\n",
      "Epoch 131/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0123 - rmse: 0.1109\n",
      "Epoch 131: val_loss did not improve from 0.00412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0049 - rmse: 0.0703 - val_loss: 0.0044 - val_rmse: 0.0661 - lr: 1.0000e-04\n",
      "Epoch 132/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0045 - rmse: 0.0669\n",
      "Epoch 132: val_loss did not improve from 0.00412\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0048 - rmse: 0.0695 - val_loss: 0.0042 - val_rmse: 0.0644 - lr: 1.0000e-04\n",
      "Epoch 133/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - rmse: 0.0380\n",
      "Epoch 133: val_loss improved from 0.00412 to 0.00402, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0050 - rmse: 0.0707 - val_loss: 0.0040 - val_rmse: 0.0634 - lr: 1.0000e-04\n",
      "Epoch 134/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0043 - rmse: 0.0654\n",
      "Epoch 134: val_loss did not improve from 0.00402\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0047 - rmse: 0.0685 - val_loss: 0.0044 - val_rmse: 0.0663 - lr: 1.0000e-04\n",
      "Epoch 135/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0084 - rmse: 0.0914\n",
      "Epoch 135: val_loss did not improve from 0.00402\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - rmse: 0.0688 - val_loss: 0.0040 - val_rmse: 0.0635 - lr: 1.0000e-04\n",
      "Epoch 136/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0050 - rmse: 0.0706\n",
      "Epoch 136: val_loss did not improve from 0.00402\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0047 - rmse: 0.0688 - val_loss: 0.0041 - val_rmse: 0.0637 - lr: 1.0000e-04\n",
      "Epoch 137/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0115 - rmse: 0.1074\n",
      "Epoch 137: val_loss improved from 0.00402 to 0.00397, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0047 - rmse: 0.0685 - val_loss: 0.0040 - val_rmse: 0.0630 - lr: 1.0000e-04\n",
      "Epoch 138/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0077 - rmse: 0.0878\n",
      "Epoch 138: val_loss improved from 0.00397 to 0.00395, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0046 - rmse: 0.0675 - val_loss: 0.0039 - val_rmse: 0.0628 - lr: 1.0000e-04\n",
      "Epoch 139/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0070 - rmse: 0.0838\n",
      "Epoch 139: val_loss improved from 0.00395 to 0.00391, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0045 - rmse: 0.0674 - val_loss: 0.0039 - val_rmse: 0.0625 - lr: 1.0000e-04\n",
      "Epoch 140/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0084 - rmse: 0.0919\n",
      "Epoch 140: val_loss improved from 0.00391 to 0.00388, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0045 - rmse: 0.0670 - val_loss: 0.0039 - val_rmse: 0.0623 - lr: 1.0000e-04\n",
      "Epoch 141/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.9944e-04 - rmse: 0.0316\n",
      "Epoch 141: val_loss improved from 0.00388 to 0.00378, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0047 - rmse: 0.0684 - val_loss: 0.0038 - val_rmse: 0.0615 - lr: 1.0000e-04\n",
      "Epoch 142/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0013 - rmse: 0.0357\n",
      "Epoch 142: val_loss did not improve from 0.00378\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0045 - rmse: 0.0669 - val_loss: 0.0043 - val_rmse: 0.0654 - lr: 1.0000e-04\n",
      "Epoch 143/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0032 - rmse: 0.0569\n",
      "Epoch 143: val_loss did not improve from 0.00378\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0045 - rmse: 0.0668 - val_loss: 0.0038 - val_rmse: 0.0616 - lr: 1.0000e-04\n",
      "Epoch 144/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0019 - rmse: 0.0437\n",
      "Epoch 144: val_loss improved from 0.00378 to 0.00378, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0044 - rmse: 0.0666 - val_loss: 0.0038 - val_rmse: 0.0615 - lr: 1.0000e-04\n",
      "Epoch 145/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0110 - rmse: 0.1051\n",
      "Epoch 145: val_loss did not improve from 0.00378\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0046 - rmse: 0.0676 - val_loss: 0.0040 - val_rmse: 0.0636 - lr: 1.0000e-04\n",
      "Epoch 146/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0028 - rmse: 0.0529\n",
      "Epoch 146: val_loss improved from 0.00378 to 0.00363, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0043 - rmse: 0.0659 - val_loss: 0.0036 - val_rmse: 0.0603 - lr: 1.0000e-04\n",
      "Epoch 147/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0034 - rmse: 0.0579\n",
      "Epoch 147: val_loss did not improve from 0.00363\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0043 - rmse: 0.0656 - val_loss: 0.0038 - val_rmse: 0.0620 - lr: 1.0000e-04\n",
      "Epoch 148/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0054 - rmse: 0.0738\n",
      "Epoch 148: val_loss improved from 0.00363 to 0.00361, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0043 - rmse: 0.0656 - val_loss: 0.0036 - val_rmse: 0.0601 - lr: 1.0000e-04\n",
      "Epoch 149/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0056 - rmse: 0.0748\n",
      "Epoch 149: val_loss improved from 0.00361 to 0.00361, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0042 - rmse: 0.0647 - val_loss: 0.0036 - val_rmse: 0.0601 - lr: 1.0000e-04\n",
      "Epoch 150/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0056 - rmse: 0.0747\n",
      "Epoch 150: val_loss improved from 0.00361 to 0.00357, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0042 - rmse: 0.0645 - val_loss: 0.0036 - val_rmse: 0.0598 - lr: 1.0000e-04\n",
      "Epoch 151/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0061 - rmse: 0.0784\n",
      "Epoch 151: val_loss did not improve from 0.00357\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0042 - rmse: 0.0651 - val_loss: 0.0037 - val_rmse: 0.0611 - lr: 1.0000e-04\n",
      "Epoch 152/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0042 - rmse: 0.0646\n",
      "Epoch 152: val_loss improved from 0.00357 to 0.00350, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0040 - rmse: 0.0629 - val_loss: 0.0035 - val_rmse: 0.0591 - lr: 1.0000e-04\n",
      "Epoch 153/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0018 - rmse: 0.0428\n",
      "Epoch 153: val_loss improved from 0.00350 to 0.00349, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0041 - rmse: 0.0639 - val_loss: 0.0035 - val_rmse: 0.0591 - lr: 1.0000e-04\n",
      "Epoch 154/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0050 - rmse: 0.0708\n",
      "Epoch 154: val_loss did not improve from 0.00349\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0041 - rmse: 0.0637 - val_loss: 0.0036 - val_rmse: 0.0600 - lr: 1.0000e-04\n",
      "Epoch 155/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0019 - rmse: 0.0435\n",
      "Epoch 155: val_loss improved from 0.00349 to 0.00342, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0042 - rmse: 0.0651 - val_loss: 0.0034 - val_rmse: 0.0585 - lr: 1.0000e-04\n",
      "Epoch 156/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - rmse: 0.0375\n",
      "Epoch 156: val_loss did not improve from 0.00342\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0039 - rmse: 0.0623 - val_loss: 0.0038 - val_rmse: 0.0613 - lr: 1.0000e-04\n",
      "Epoch 157/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0066 - rmse: 0.0813\n",
      "Epoch 157: val_loss did not improve from 0.00342\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0040 - rmse: 0.0630 - val_loss: 0.0034 - val_rmse: 0.0586 - lr: 1.0000e-04\n",
      "Epoch 158/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - rmse: 0.0380\n",
      "Epoch 158: val_loss did not improve from 0.00342\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0040 - rmse: 0.0630 - val_loss: 0.0034 - val_rmse: 0.0585 - lr: 1.0000e-04\n",
      "Epoch 159/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6709e-04 - rmse: 0.0192\n",
      "Epoch 159: val_loss did not improve from 0.00342\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0041 - rmse: 0.0638 - val_loss: 0.0036 - val_rmse: 0.0600 - lr: 1.0000e-04\n",
      "Epoch 160/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0065 - rmse: 0.0807\n",
      "Epoch 160: val_loss improved from 0.00342 to 0.00338, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0039 - rmse: 0.0621 - val_loss: 0.0034 - val_rmse: 0.0581 - lr: 1.0000e-04\n",
      "Epoch 161/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0015 - rmse: 0.0393\n",
      "Epoch 161: val_loss did not improve from 0.00338\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0038 - rmse: 0.0616 - val_loss: 0.0036 - val_rmse: 0.0598 - lr: 1.0000e-04\n",
      "Epoch 162/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0030 - rmse: 0.0544\n",
      "Epoch 162: val_loss improved from 0.00338 to 0.00328, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0037 - rmse: 0.0612 - val_loss: 0.0033 - val_rmse: 0.0573 - lr: 1.0000e-04\n",
      "Epoch 163/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0021 - rmse: 0.0459\n",
      "Epoch 163: val_loss improved from 0.00328 to 0.00327, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0037 - rmse: 0.0605 - val_loss: 0.0033 - val_rmse: 0.0572 - lr: 1.0000e-04\n",
      "Epoch 164/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0075 - rmse: 0.0865\n",
      "Epoch 164: val_loss did not improve from 0.00327\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0038 - rmse: 0.0618 - val_loss: 0.0035 - val_rmse: 0.0588 - lr: 1.0000e-04\n",
      "Epoch 165/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0010 - rmse: 0.0318\n",
      "Epoch 165: val_loss improved from 0.00327 to 0.00326, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0038 - rmse: 0.0618 - val_loss: 0.0033 - val_rmse: 0.0571 - lr: 1.0000e-04\n",
      "Epoch 166/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0072 - rmse: 0.0850\n",
      "Epoch 166: val_loss did not improve from 0.00326\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0035 - rmse: 0.0592 - val_loss: 0.0034 - val_rmse: 0.0587 - lr: 1.0000e-04\n",
      "Epoch 167/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0026 - rmse: 0.0510\n",
      "Epoch 167: val_loss improved from 0.00326 to 0.00321, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0036 - rmse: 0.0598 - val_loss: 0.0032 - val_rmse: 0.0567 - lr: 1.0000e-04\n",
      "Epoch 168/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0018 - rmse: 0.0430\n",
      "Epoch 168: val_loss improved from 0.00321 to 0.00318, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0035 - rmse: 0.0590 - val_loss: 0.0032 - val_rmse: 0.0564 - lr: 1.0000e-04\n",
      "Epoch 169/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0078 - rmse: 0.0883\n",
      "Epoch 169: val_loss improved from 0.00318 to 0.00317, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0034 - rmse: 0.0586 - val_loss: 0.0032 - val_rmse: 0.0563 - lr: 1.0000e-04\n",
      "Epoch 170/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - rmse: 0.0448\n",
      "Epoch 170: val_loss improved from 0.00317 to 0.00310, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0036 - rmse: 0.0599 - val_loss: 0.0031 - val_rmse: 0.0556 - lr: 1.0000e-04\n",
      "Epoch 171/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0084 - rmse: 0.0917\n",
      "Epoch 171: val_loss did not improve from 0.00310\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0038 - rmse: 0.0613 - val_loss: 0.0032 - val_rmse: 0.0569 - lr: 1.0000e-04\n",
      "Epoch 172/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0045 - rmse: 0.0671\n",
      "Epoch 172: val_loss did not improve from 0.00310\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0037 - rmse: 0.0611 - val_loss: 0.0031 - val_rmse: 0.0560 - lr: 1.0000e-04\n",
      "Epoch 173/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0018 - rmse: 0.0426\n",
      "Epoch 173: val_loss did not improve from 0.00310\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0034 - rmse: 0.0586 - val_loss: 0.0035 - val_rmse: 0.0591 - lr: 1.0000e-04\n",
      "Epoch 174/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0046 - rmse: 0.0681\n",
      "Epoch 174: val_loss did not improve from 0.00310\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0033 - rmse: 0.0572 - val_loss: 0.0032 - val_rmse: 0.0565 - lr: 1.0000e-04\n",
      "Epoch 175/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - rmse: 0.0470\n",
      "Epoch 175: val_loss improved from 0.00310 to 0.00308, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0034 - rmse: 0.0580 - val_loss: 0.0031 - val_rmse: 0.0555 - lr: 1.0000e-04\n",
      "Epoch 176/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0029 - rmse: 0.0538\n",
      "Epoch 176: val_loss did not improve from 0.00308\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0032 - rmse: 0.0562 - val_loss: 0.0031 - val_rmse: 0.0557 - lr: 1.0000e-04\n",
      "Epoch 177/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0013 - rmse: 0.0355\n",
      "Epoch 177: val_loss improved from 0.00308 to 0.00295, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0035 - rmse: 0.0589 - val_loss: 0.0030 - val_rmse: 0.0543 - lr: 1.0000e-04\n",
      "Epoch 178/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0031 - rmse: 0.0557\n",
      "Epoch 178: val_loss did not improve from 0.00295\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0032 - rmse: 0.0564 - val_loss: 0.0033 - val_rmse: 0.0572 - lr: 1.0000e-04\n",
      "Epoch 179/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0029 - rmse: 0.0538\n",
      "Epoch 179: val_loss did not improve from 0.00295\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0031 - rmse: 0.0553 - val_loss: 0.0030 - val_rmse: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 180/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - rmse: 0.0343\n",
      "Epoch 180: val_loss did not improve from 0.00295\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0032 - rmse: 0.0563 - val_loss: 0.0031 - val_rmse: 0.0554 - lr: 1.0000e-04\n",
      "Epoch 181/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0021 - rmse: 0.0460\n",
      "Epoch 181: val_loss improved from 0.00295 to 0.00287, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0033 - rmse: 0.0577 - val_loss: 0.0029 - val_rmse: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 182/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8932e-04 - rmse: 0.0281\n",
      "Epoch 182: val_loss did not improve from 0.00287\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - rmse: 0.0548 - val_loss: 0.0031 - val_rmse: 0.0554 - lr: 1.0000e-04\n",
      "Epoch 183/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0052 - rmse: 0.0723\n",
      "Epoch 183: val_loss did not improve from 0.00287\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - rmse: 0.0545 - val_loss: 0.0030 - val_rmse: 0.0546 - lr: 1.0000e-04\n",
      "Epoch 184/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0077 - rmse: 0.0879\n",
      "Epoch 184: val_loss did not improve from 0.00287\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0030 - rmse: 0.0545 - val_loss: 0.0029 - val_rmse: 0.0543 - lr: 1.0000e-04\n",
      "Epoch 185/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - rmse: 0.0375\n",
      "Epoch 185: val_loss improved from 0.00287 to 0.00284, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0029 - rmse: 0.0535 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 186/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0016 - rmse: 0.0394\n",
      "Epoch 186: val_loss improved from 0.00284 to 0.00278, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0029 - rmse: 0.0534 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 187/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0469e-04 - rmse: 0.0246\n",
      "Epoch 187: val_loss did not improve from 0.00278\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0028 - rmse: 0.0526 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 188/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0013 - rmse: 0.0363\n",
      "Epoch 188: val_loss did not improve from 0.00278\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0028 - rmse: 0.0528 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 189/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0044 - rmse: 0.0667\n",
      "Epoch 189: val_loss did not improve from 0.00278\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - rmse: 0.0523 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 190/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0025 - rmse: 0.0502\n",
      "Epoch 190: val_loss did not improve from 0.00278\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0029 - rmse: 0.0538 - val_loss: 0.0028 - val_rmse: 0.0529 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0032 - rmse: 0.0569\n",
      "Epoch 191: val_loss improved from 0.00278 to 0.00270, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0028 - rmse: 0.0529 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 192/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0023 - rmse: 0.0482\n",
      "Epoch 192: val_loss did not improve from 0.00270\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0026 - rmse: 0.0511 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 193/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - rmse: 0.0470\n",
      "Epoch 193: val_loss did not improve from 0.00270\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0026 - rmse: 0.0509 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 194/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0019 - rmse: 0.0440\n",
      "Epoch 194: val_loss did not improve from 0.00270\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0027 - rmse: 0.0515 - val_loss: 0.0028 - val_rmse: 0.0529 - lr: 1.0000e-04\n",
      "Epoch 195/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0041 - rmse: 0.0643\n",
      "Epoch 195: val_loss improved from 0.00270 to 0.00265, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0025 - rmse: 0.0502 - val_loss: 0.0026 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 196/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0040 - rmse: 0.0632\n",
      "Epoch 196: val_loss improved from 0.00265 to 0.00260, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0025 - rmse: 0.0499 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 197/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0015 - rmse: 0.0384\n",
      "Epoch 197: val_loss improved from 0.00260 to 0.00253, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - rmse: 0.0501 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 198/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0021 - rmse: 0.0459\n",
      "Epoch 198: val_loss did not improve from 0.00253\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0026 - rmse: 0.0509 - val_loss: 0.0026 - val_rmse: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 199/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4049e-04 - rmse: 0.0290\n",
      "Epoch 199: val_loss improved from 0.00253 to 0.00252, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0026 - rmse: 0.0509 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 200/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0026 - rmse: 0.0514\n",
      "Epoch 200: val_loss did not improve from 0.00252\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0024 - rmse: 0.0489 - val_loss: 0.0026 - val_rmse: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 201/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0039 - rmse: 0.0628\n",
      "Epoch 201: val_loss did not improve from 0.00252\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0023 - rmse: 0.0484 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 202/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0048 - rmse: 0.0693\n",
      "Epoch 202: val_loss improved from 0.00252 to 0.00251, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0023 - rmse: 0.0482 - val_loss: 0.0025 - val_rmse: 0.0501 - lr: 1.0000e-04\n",
      "Epoch 203/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0030 - rmse: 0.0552\n",
      "Epoch 203: val_loss improved from 0.00251 to 0.00240, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0023 - rmse: 0.0476 - val_loss: 0.0024 - val_rmse: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 204/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0054 - rmse: 0.0733\n",
      "Epoch 204: val_loss improved from 0.00240 to 0.00240, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0024 - rmse: 0.0491 - val_loss: 0.0024 - val_rmse: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 205/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0045 - rmse: 0.0668\n",
      "Epoch 205: val_loss improved from 0.00240 to 0.00236, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0022 - rmse: 0.0469 - val_loss: 0.0024 - val_rmse: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 206/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0023 - rmse: 0.0478\n",
      "Epoch 206: val_loss improved from 0.00236 to 0.00232, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0022 - rmse: 0.0468 - val_loss: 0.0023 - val_rmse: 0.0482 - lr: 1.0000e-04\n",
      "Epoch 207/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0326\n",
      "Epoch 207: val_loss improved from 0.00232 to 0.00232, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0021 - rmse: 0.0463 - val_loss: 0.0023 - val_rmse: 0.0482 - lr: 1.0000e-04\n",
      "Epoch 208/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - rmse: 0.0448\n",
      "Epoch 208: val_loss did not improve from 0.00232\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0021 - rmse: 0.0461 - val_loss: 0.0024 - val_rmse: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 209/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0044 - rmse: 0.0664\n",
      "Epoch 209: val_loss improved from 0.00232 to 0.00230, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0021 - rmse: 0.0457 - val_loss: 0.0023 - val_rmse: 0.0479 - lr: 1.0000e-04\n",
      "Epoch 210/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - rmse: 0.0464\n",
      "Epoch 210: val_loss improved from 0.00230 to 0.00224, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0021 - rmse: 0.0458 - val_loss: 0.0022 - val_rmse: 0.0474 - lr: 1.0000e-04\n",
      "Epoch 211/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0015 - rmse: 0.0392\n",
      "Epoch 211: val_loss did not improve from 0.00224\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - rmse: 0.0455 - val_loss: 0.0023 - val_rmse: 0.0478 - lr: 1.0000e-04\n",
      "Epoch 212/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0023 - rmse: 0.0480\n",
      "Epoch 212: val_loss did not improve from 0.00224\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0020 - rmse: 0.0452 - val_loss: 0.0022 - val_rmse: 0.0474 - lr: 1.0000e-04\n",
      "Epoch 213/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0027 - rmse: 0.0516\n",
      "Epoch 213: val_loss improved from 0.00224 to 0.00220, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0021 - rmse: 0.0454 - val_loss: 0.0022 - val_rmse: 0.0469 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0017 - rmse: 0.0417\n",
      "Epoch 214: val_loss improved from 0.00220 to 0.00214, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0020 - rmse: 0.0445 - val_loss: 0.0021 - val_rmse: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 215/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0044 - rmse: 0.0663\n",
      "Epoch 215: val_loss did not improve from 0.00214\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - rmse: 0.0459 - val_loss: 0.0022 - val_rmse: 0.0466 - lr: 1.0000e-04\n",
      "Epoch 216/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0026 - rmse: 0.0512\n",
      "Epoch 216: val_loss improved from 0.00214 to 0.00210, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0020 - rmse: 0.0443 - val_loss: 0.0021 - val_rmse: 0.0458 - lr: 1.0000e-04\n",
      "Epoch 217/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - rmse: 0.0470\n",
      "Epoch 217: val_loss improved from 0.00210 to 0.00209, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0019 - rmse: 0.0432 - val_loss: 0.0021 - val_rmse: 0.0457 - lr: 1.0000e-04\n",
      "Epoch 218/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - rmse: 0.0575\n",
      "Epoch 218: val_loss improved from 0.00209 to 0.00205, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0019 - rmse: 0.0433 - val_loss: 0.0021 - val_rmse: 0.0453 - lr: 1.0000e-04\n",
      "Epoch 219/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3852e-04 - rmse: 0.0306\n",
      "Epoch 219: val_loss improved from 0.00205 to 0.00204, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0019 - rmse: 0.0430 - val_loss: 0.0020 - val_rmse: 0.0452 - lr: 1.0000e-04\n",
      "Epoch 220/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0014 - rmse: 0.0372\n",
      "Epoch 220: val_loss improved from 0.00204 to 0.00199, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0019 - rmse: 0.0435 - val_loss: 0.0020 - val_rmse: 0.0446 - lr: 1.0000e-04\n",
      "Epoch 221/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0027 - rmse: 0.0522\n",
      "Epoch 221: val_loss improved from 0.00199 to 0.00196, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0017 - rmse: 0.0417 - val_loss: 0.0020 - val_rmse: 0.0443 - lr: 1.0000e-04\n",
      "Epoch 222/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0335\n",
      "Epoch 222: val_loss improved from 0.00196 to 0.00189, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0018 - rmse: 0.0419 - val_loss: 0.0019 - val_rmse: 0.0434 - lr: 1.0000e-04\n",
      "Epoch 223/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - rmse: 0.0346\n",
      "Epoch 223: val_loss did not improve from 0.00189\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0016 - rmse: 0.0405 - val_loss: 0.0019 - val_rmse: 0.0438 - lr: 1.0000e-04\n",
      "Epoch 224/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0033 - rmse: 0.0576\n",
      "Epoch 224: val_loss did not improve from 0.00189\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0017 - rmse: 0.0412 - val_loss: 0.0019 - val_rmse: 0.0440 - lr: 1.0000e-04\n",
      "Epoch 225/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0010 - rmse: 0.0318\n",
      "Epoch 225: val_loss improved from 0.00189 to 0.00183, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0016 - rmse: 0.0405 - val_loss: 0.0018 - val_rmse: 0.0428 - lr: 1.0000e-04\n",
      "Epoch 226/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1860e-04 - rmse: 0.0286\n",
      "Epoch 226: val_loss improved from 0.00183 to 0.00183, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0016 - rmse: 0.0400 - val_loss: 0.0018 - val_rmse: 0.0427 - lr: 1.0000e-04\n",
      "Epoch 227/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3132e-04 - rmse: 0.0305\n",
      "Epoch 227: val_loss improved from 0.00183 to 0.00179, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0016 - rmse: 0.0399 - val_loss: 0.0018 - val_rmse: 0.0423 - lr: 1.0000e-04\n",
      "Epoch 228/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0026 - rmse: 0.0511\n",
      "Epoch 228: val_loss did not improve from 0.00179\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0015 - rmse: 0.0391 - val_loss: 0.0018 - val_rmse: 0.0427 - lr: 1.0000e-04\n",
      "Epoch 229/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0023 - rmse: 0.0476\n",
      "Epoch 229: val_loss improved from 0.00179 to 0.00176, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0016 - rmse: 0.0396 - val_loss: 0.0018 - val_rmse: 0.0420 - lr: 1.0000e-04\n",
      "Epoch 230/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6413e-04 - rmse: 0.0215\n",
      "Epoch 230: val_loss improved from 0.00176 to 0.00175, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0015 - rmse: 0.0392 - val_loss: 0.0018 - val_rmse: 0.0418 - lr: 1.0000e-04\n",
      "Epoch 231/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0840e-04 - rmse: 0.0202\n",
      "Epoch 231: val_loss improved from 0.00175 to 0.00167, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0016 - rmse: 0.0400 - val_loss: 0.0017 - val_rmse: 0.0409 - lr: 1.0000e-04\n",
      "Epoch 232/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8522e-04 - rmse: 0.0196\n",
      "Epoch 232: val_loss improved from 0.00167 to 0.00166, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0017 - rmse: 0.0410 - val_loss: 0.0017 - val_rmse: 0.0408 - lr: 1.0000e-04\n",
      "Epoch 233/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0330\n",
      "Epoch 233: val_loss improved from 0.00166 to 0.00165, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0017 - rmse: 0.0407 - val_loss: 0.0016 - val_rmse: 0.0406 - lr: 1.0000e-04\n",
      "Epoch 234/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0015 - rmse: 0.0390\n",
      "Epoch 234: val_loss did not improve from 0.00165\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0014 - rmse: 0.0378 - val_loss: 0.0017 - val_rmse: 0.0409 - lr: 1.0000e-04\n",
      "Epoch 235/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0019 - rmse: 0.0436\n",
      "Epoch 235: val_loss did not improve from 0.00165\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - rmse: 0.0374 - val_loss: 0.0017 - val_rmse: 0.0408 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5188e-04 - rmse: 0.0235\n",
      "Epoch 236: val_loss did not improve from 0.00165\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0014 - rmse: 0.0375 - val_loss: 0.0017 - val_rmse: 0.0406 - lr: 1.0000e-04\n",
      "Epoch 237/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6554e-04 - rmse: 0.0191\n",
      "Epoch 237: val_loss improved from 0.00165 to 0.00155, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0014 - rmse: 0.0378 - val_loss: 0.0015 - val_rmse: 0.0393 - lr: 1.0000e-04\n",
      "Epoch 238/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6101e-04 - rmse: 0.0257\n",
      "Epoch 238: val_loss did not improve from 0.00155\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0013 - rmse: 0.0362 - val_loss: 0.0016 - val_rmse: 0.0398 - lr: 1.0000e-04\n",
      "Epoch 239/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0022 - rmse: 0.0471\n",
      "Epoch 239: val_loss did not improve from 0.00155\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0013 - rmse: 0.0361 - val_loss: 0.0016 - val_rmse: 0.0398 - lr: 1.0000e-04\n",
      "Epoch 240/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8181e-04 - rmse: 0.0261\n",
      "Epoch 240: val_loss improved from 0.00155 to 0.00151, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0013 - rmse: 0.0358 - val_loss: 0.0015 - val_rmse: 0.0388 - lr: 1.0000e-04\n",
      "Epoch 241/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0330\n",
      "Epoch 241: val_loss improved from 0.00151 to 0.00148, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0013 - rmse: 0.0366 - val_loss: 0.0015 - val_rmse: 0.0385 - lr: 1.0000e-04\n",
      "Epoch 242/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0017 - rmse: 0.0408\n",
      "Epoch 242: val_loss improved from 0.00148 to 0.00142, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0013 - rmse: 0.0358 - val_loss: 0.0014 - val_rmse: 0.0377 - lr: 1.0000e-04\n",
      "Epoch 243/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1905e-04 - rmse: 0.0268\n",
      "Epoch 243: val_loss did not improve from 0.00142\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - rmse: 0.0342 - val_loss: 0.0014 - val_rmse: 0.0381 - lr: 1.0000e-04\n",
      "Epoch 244/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8378e-04 - rmse: 0.0168\n",
      "Epoch 244: val_loss did not improve from 0.00142\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - rmse: 0.0338 - val_loss: 0.0015 - val_rmse: 0.0387 - lr: 1.0000e-04\n",
      "Epoch 245/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1941e-04 - rmse: 0.0303\n",
      "Epoch 245: val_loss improved from 0.00142 to 0.00142, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0011 - rmse: 0.0332 - val_loss: 0.0014 - val_rmse: 0.0377 - lr: 1.0000e-04\n",
      "Epoch 246/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4213e-04 - rmse: 0.0290\n",
      "Epoch 246: val_loss improved from 0.00142 to 0.00139, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0012 - rmse: 0.0346 - val_loss: 0.0014 - val_rmse: 0.0373 - lr: 1.0000e-04\n",
      "Epoch 247/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0325\n",
      "Epoch 247: val_loss did not improve from 0.00139\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0011 - rmse: 0.0334 - val_loss: 0.0014 - val_rmse: 0.0380 - lr: 1.0000e-04\n",
      "Epoch 248/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3145e-04 - rmse: 0.0251\n",
      "Epoch 248: val_loss did not improve from 0.00139\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0012 - rmse: 0.0343 - val_loss: 0.0014 - val_rmse: 0.0379 - lr: 1.0000e-04\n",
      "Epoch 249/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8853e-04 - rmse: 0.0281\n",
      "Epoch 249: val_loss improved from 0.00139 to 0.00136, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0011 - rmse: 0.0325 - val_loss: 0.0014 - val_rmse: 0.0369 - lr: 1.0000e-04\n",
      "Epoch 250/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7950e-04 - rmse: 0.0313\n",
      "Epoch 250: val_loss improved from 0.00136 to 0.00132, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - rmse: 0.0331 - val_loss: 0.0013 - val_rmse: 0.0363 - lr: 1.0000e-04\n",
      "Epoch 251/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0338\n",
      "Epoch 251: val_loss improved from 0.00132 to 0.00129, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - rmse: 0.0330 - val_loss: 0.0013 - val_rmse: 0.0359 - lr: 1.0000e-04\n",
      "Epoch 252/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0602e-04 - rmse: 0.0301\n",
      "Epoch 252: val_loss did not improve from 0.00129\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.0010 - rmse: 0.0319 - val_loss: 0.0013 - val_rmse: 0.0361 - lr: 1.0000e-04\n",
      "Epoch 253/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0169e-04 - rmse: 0.0265\n",
      "Epoch 253: val_loss improved from 0.00129 to 0.00126, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0010 - rmse: 0.0318 - val_loss: 0.0013 - val_rmse: 0.0355 - lr: 1.0000e-04\n",
      "Epoch 254/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0020 - rmse: 0.0444\n",
      "Epoch 254: val_loss improved from 0.00126 to 0.00123, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0010 - rmse: 0.0316 - val_loss: 0.0012 - val_rmse: 0.0350 - lr: 1.0000e-04\n",
      "Epoch 255/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0851e-04 - rmse: 0.0144\n",
      "Epoch 255: val_loss improved from 0.00123 to 0.00119, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5298e-04 - rmse: 0.0309 - val_loss: 0.0012 - val_rmse: 0.0345 - lr: 1.0000e-04\n",
      "Epoch 256/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0018 - rmse: 0.0419\n",
      "Epoch 256: val_loss improved from 0.00119 to 0.00114, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8752e-04 - rmse: 0.0314 - val_loss: 0.0011 - val_rmse: 0.0337 - lr: 1.0000e-04\n",
      "Epoch 257/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1655e-04 - rmse: 0.0204\n",
      "Epoch 257: val_loss did not improve from 0.00114\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9578e-04 - rmse: 0.0316 - val_loss: 0.0011 - val_rmse: 0.0338 - lr: 1.0000e-04\n",
      "Epoch 258/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9458e-04 - rmse: 0.0244\n",
      "Epoch 258: val_loss did not improve from 0.00114\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8640e-04 - rmse: 0.0298 - val_loss: 0.0012 - val_rmse: 0.0343 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9201e-04 - rmse: 0.0243\n",
      "Epoch 259: val_loss did not improve from 0.00114\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4409e-04 - rmse: 0.0291 - val_loss: 0.0012 - val_rmse: 0.0340 - lr: 1.0000e-04\n",
      "Epoch 260/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0775e-04 - rmse: 0.0202\n",
      "Epoch 260: val_loss improved from 0.00114 to 0.00113, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5301e-04 - rmse: 0.0292 - val_loss: 0.0011 - val_rmse: 0.0336 - lr: 1.0000e-04\n",
      "Epoch 261/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3146e-04 - rmse: 0.0208\n",
      "Epoch 261: val_loss improved from 0.00113 to 0.00107, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.8948e-04 - rmse: 0.0298 - val_loss: 0.0011 - val_rmse: 0.0327 - lr: 1.0000e-04\n",
      "Epoch 262/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - rmse: 0.0344\n",
      "Epoch 262: val_loss improved from 0.00107 to 0.00106, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.8437e-04 - rmse: 0.0297 - val_loss: 0.0011 - val_rmse: 0.0326 - lr: 1.0000e-04\n",
      "Epoch 263/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3854e-04 - rmse: 0.0232\n",
      "Epoch 263: val_loss improved from 0.00106 to 0.00102, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.1803e-04 - rmse: 0.0286 - val_loss: 0.0010 - val_rmse: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 264/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0015 - rmse: 0.0387\n",
      "Epoch 264: val_loss did not improve from 0.00102\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6585e-04 - rmse: 0.0294 - val_loss: 0.0011 - val_rmse: 0.0325 - lr: 1.0000e-04\n",
      "Epoch 265/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9415e-04 - rmse: 0.0244\n",
      "Epoch 265: val_loss did not improve from 0.00102\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3313e-04 - rmse: 0.0305 - val_loss: 0.0010 - val_rmse: 0.0320 - lr: 1.0000e-04\n",
      "Epoch 266/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0056e-04 - rmse: 0.0245\n",
      "Epoch 266: val_loss did not improve from 0.00102\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7075e-04 - rmse: 0.0295 - val_loss: 0.0011 - val_rmse: 0.0331 - lr: 1.0000e-04\n",
      "Epoch 267/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9241e-04 - rmse: 0.0243\n",
      "Epoch 267: val_loss did not improve from 0.00102\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5117e-04 - rmse: 0.0292 - val_loss: 0.0010 - val_rmse: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 268/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - rmse: 0.0345\n",
      "Epoch 268: val_loss improved from 0.00102 to 0.00100, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4014e-04 - rmse: 0.0290 - val_loss: 9.9642e-04 - val_rmse: 0.0316 - lr: 1.0000e-04\n",
      "Epoch 269/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2220e-04 - rmse: 0.0229\n",
      "Epoch 269: val_loss improved from 0.00100 to 0.00097, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6729e-04 - rmse: 0.0311 - val_loss: 9.6754e-04 - val_rmse: 0.0311 - lr: 1.0000e-04\n",
      "Epoch 270/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9055e-04 - rmse: 0.0221\n",
      "Epoch 270: val_loss did not improve from 0.00097\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3960e-04 - rmse: 0.0307 - val_loss: 0.0011 - val_rmse: 0.0325 - lr: 1.0000e-04\n",
      "Epoch 271/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4329e-04 - rmse: 0.0185\n",
      "Epoch 271: val_loss improved from 0.00097 to 0.00095, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9379e-04 - rmse: 0.0282 - val_loss: 9.5356e-04 - val_rmse: 0.0309 - lr: 1.0000e-04\n",
      "Epoch 272/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3806e-04 - rmse: 0.0209\n",
      "Epoch 272: val_loss improved from 0.00095 to 0.00091, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3415e-04 - rmse: 0.0271 - val_loss: 9.1232e-04 - val_rmse: 0.0302 - lr: 1.0000e-04\n",
      "Epoch 273/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6131e-04 - rmse: 0.0237\n",
      "Epoch 273: val_loss did not improve from 0.00091\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1929e-04 - rmse: 0.0268 - val_loss: 9.6998e-04 - val_rmse: 0.0311 - lr: 1.0000e-04\n",
      "Epoch 274/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8412e-04 - rmse: 0.0220\n",
      "Epoch 274: val_loss did not improve from 0.00091\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3562e-04 - rmse: 0.0271 - val_loss: 9.4616e-04 - val_rmse: 0.0308 - lr: 1.0000e-04\n",
      "Epoch 275/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1344e-04 - rmse: 0.0302\n",
      "Epoch 275: val_loss improved from 0.00091 to 0.00085, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.1861e-04 - rmse: 0.0268 - val_loss: 8.5357e-04 - val_rmse: 0.0292 - lr: 1.0000e-04\n",
      "Epoch 276/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6023e-04 - rmse: 0.0190\n",
      "Epoch 276: val_loss improved from 0.00085 to 0.00083, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2854e-04 - rmse: 0.0251 - val_loss: 8.2903e-04 - val_rmse: 0.0288 - lr: 1.0000e-04\n",
      "Epoch 277/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2987e-04 - rmse: 0.0207\n",
      "Epoch 277: val_loss improved from 0.00083 to 0.00082, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8037e-04 - rmse: 0.0241 - val_loss: 8.2032e-04 - val_rmse: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 278/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2059e-04 - rmse: 0.0205\n",
      "Epoch 278: val_loss did not improve from 0.00082\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6851e-04 - rmse: 0.0238 - val_loss: 8.4433e-04 - val_rmse: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 279/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8082e-04 - rmse: 0.0168\n",
      "Epoch 279: val_loss did not improve from 0.00082\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2032e-04 - rmse: 0.0249 - val_loss: 8.7364e-04 - val_rmse: 0.0296 - lr: 1.0000e-04\n",
      "Epoch 280/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9720e-04 - rmse: 0.0300\n",
      "Epoch 280: val_loss improved from 0.00082 to 0.00081, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.2872e-04 - rmse: 0.0230 - val_loss: 8.0676e-04 - val_rmse: 0.0284 - lr: 1.0000e-04\n",
      "Epoch 281/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0011 - rmse: 0.0328\n",
      "Epoch 281: val_loss improved from 0.00081 to 0.00079, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6639e-04 - rmse: 0.0238 - val_loss: 7.8941e-04 - val_rmse: 0.0281 - lr: 1.0000e-04\n",
      "Epoch 282/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0013 - rmse: 0.0355\n",
      "Epoch 282: val_loss did not improve from 0.00079\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4486e-04 - rmse: 0.0233 - val_loss: 8.0510e-04 - val_rmse: 0.0284 - lr: 1.0000e-04\n",
      "Epoch 283/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2578e-04 - rmse: 0.0180\n",
      "Epoch 283: val_loss improved from 0.00079 to 0.00077, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.2781e-04 - rmse: 0.0230 - val_loss: 7.6591e-04 - val_rmse: 0.0277 - lr: 1.0000e-04\n",
      "Epoch 284/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2112e-04 - rmse: 0.0179\n",
      "Epoch 284: val_loss improved from 0.00077 to 0.00072, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7817e-04 - rmse: 0.0219 - val_loss: 7.2037e-04 - val_rmse: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 285/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7600e-04 - rmse: 0.0218\n",
      "Epoch 285: val_loss improved from 0.00072 to 0.00072, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8918e-04 - rmse: 0.0221 - val_loss: 7.1936e-04 - val_rmse: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 286/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8323e-04 - rmse: 0.0242\n",
      "Epoch 286: val_loss improved from 0.00072 to 0.00071, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.7596e-04 - rmse: 0.0218 - val_loss: 7.0544e-04 - val_rmse: 0.0266 - lr: 1.0000e-04\n",
      "Epoch 287/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0359e-04 - rmse: 0.0201\n",
      "Epoch 287: val_loss did not improve from 0.00071\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7454e-04 - rmse: 0.0218 - val_loss: 7.1759e-04 - val_rmse: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 288/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5993e-04 - rmse: 0.0214\n",
      "Epoch 288: val_loss did not improve from 0.00071\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4239e-04 - rmse: 0.0233 - val_loss: 7.1855e-04 - val_rmse: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 289/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0012 - rmse: 0.0343\n",
      "Epoch 289: val_loss did not improve from 0.00071\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0052e-04 - rmse: 0.0224 - val_loss: 7.2196e-04 - val_rmse: 0.0269 - lr: 1.0000e-04\n",
      "Epoch 290/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2146e-04 - rmse: 0.0110\n",
      "Epoch 290: val_loss improved from 0.00071 to 0.00067, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.9662e-04 - rmse: 0.0223 - val_loss: 6.7120e-04 - val_rmse: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 291/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5202e-04 - rmse: 0.0123\n",
      "Epoch 291: val_loss did not improve from 0.00067\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2904e-04 - rmse: 0.0207 - val_loss: 6.8059e-04 - val_rmse: 0.0261 - lr: 1.0000e-04\n",
      "Epoch 292/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9759e-04 - rmse: 0.0300\n",
      "Epoch 292: val_loss improved from 0.00067 to 0.00064, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.4399e-04 - rmse: 0.0211 - val_loss: 6.4445e-04 - val_rmse: 0.0254 - lr: 1.0000e-04\n",
      "Epoch 293/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3650e-04 - rmse: 0.0154\n",
      "Epoch 293: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1286e-04 - rmse: 0.0203 - val_loss: 6.5040e-04 - val_rmse: 0.0255 - lr: 1.0000e-04\n",
      "Epoch 294/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1078e-04 - rmse: 0.0247\n",
      "Epoch 294: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4949e-04 - rmse: 0.0212 - val_loss: 6.6888e-04 - val_rmse: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 295/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4411e-04 - rmse: 0.0233\n",
      "Epoch 295: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3417e-04 - rmse: 0.0208 - val_loss: 7.0667e-04 - val_rmse: 0.0266 - lr: 1.0000e-04\n",
      "Epoch 296/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2086e-04 - rmse: 0.0149\n",
      "Epoch 296: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0668e-04 - rmse: 0.0225 - val_loss: 7.1678e-04 - val_rmse: 0.0268 - lr: 1.0000e-04\n",
      "Epoch 297/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6519e-04 - rmse: 0.0191\n",
      "Epoch 297: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9864e-04 - rmse: 0.0200 - val_loss: 6.5407e-04 - val_rmse: 0.0256 - lr: 1.0000e-04\n",
      "Epoch 298/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7953e-04 - rmse: 0.0167\n",
      "Epoch 298: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9176e-04 - rmse: 0.0198 - val_loss: 6.9397e-04 - val_rmse: 0.0263 - lr: 1.0000e-04\n",
      "Epoch 299/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6519e-04 - rmse: 0.0129\n",
      "Epoch 299: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9678e-04 - rmse: 0.0199 - val_loss: 6.6602e-04 - val_rmse: 0.0258 - lr: 1.0000e-04\n",
      "Epoch 300/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7815e-04 - rmse: 0.0219\n",
      "Epoch 300: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9633e-04 - rmse: 0.0199 - val_loss: 7.2520e-04 - val_rmse: 0.0269 - lr: 1.0000e-04\n",
      "Epoch 301/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0737e-04 - rmse: 0.0246\n",
      "Epoch 301: val_loss did not improve from 0.00064\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9846e-04 - rmse: 0.0200 - val_loss: 6.5762e-04 - val_rmse: 0.0256 - lr: 1.0000e-04\n",
      "Epoch 302/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3007e-04 - rmse: 0.0152\n",
      "Epoch 302: val_loss improved from 0.00064 to 0.00057, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.7383e-04 - rmse: 0.0193 - val_loss: 5.7292e-04 - val_rmse: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 303/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7650e-04 - rmse: 0.0133\n",
      "Epoch 303: val_loss did not improve from 0.00057\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2037e-04 - rmse: 0.0179 - val_loss: 5.7752e-04 - val_rmse: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 304/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0148e-04 - rmse: 0.0142\n",
      "Epoch 304: val_loss did not improve from 0.00057\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5014e-04 - rmse: 0.0187 - val_loss: 5.9007e-04 - val_rmse: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 305/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4718e-04 - rmse: 0.0157\n",
      "Epoch 305: val_loss did not improve from 0.00057\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3849e-04 - rmse: 0.0184 - val_loss: 5.7669e-04 - val_rmse: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 306/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3050e-04 - rmse: 0.0182\n",
      "Epoch 306: val_loss improved from 0.00057 to 0.00057, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1686e-04 - rmse: 0.0178 - val_loss: 5.6629e-04 - val_rmse: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 307/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3624e-04 - rmse: 0.0154\n",
      "Epoch 307: val_loss did not improve from 0.00057\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6276e-04 - rmse: 0.0190 - val_loss: 5.6675e-04 - val_rmse: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 308/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5766e-04 - rmse: 0.0126\n",
      "Epoch 308: val_loss improved from 0.00057 to 0.00055, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.3409e-04 - rmse: 0.0183 - val_loss: 5.5086e-04 - val_rmse: 0.0235 - lr: 1.0000e-04\n",
      "Epoch 309/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9724e-05 - rmse: 0.0095\n",
      "Epoch 309: val_loss did not improve from 0.00055\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5293e-04 - rmse: 0.0188 - val_loss: 6.1419e-04 - val_rmse: 0.0248 - lr: 1.0000e-04\n",
      "Epoch 310/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9460e-04 - rmse: 0.0199\n",
      "Epoch 310: val_loss did not improve from 0.00055\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6297e-04 - rmse: 0.0191 - val_loss: 5.9061e-04 - val_rmse: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 311/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0993e-04 - rmse: 0.0202\n",
      "Epoch 311: val_loss improved from 0.00055 to 0.00053, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.5450e-04 - rmse: 0.0188 - val_loss: 5.3408e-04 - val_rmse: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 312/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6707e-04 - rmse: 0.0216\n",
      "Epoch 312: val_loss improved from 0.00053 to 0.00052, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2016e-04 - rmse: 0.0179 - val_loss: 5.2186e-04 - val_rmse: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 313/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1869e-04 - rmse: 0.0109\n",
      "Epoch 313: val_loss did not improve from 0.00052\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8501e-04 - rmse: 0.0169 - val_loss: 5.3781e-04 - val_rmse: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 314/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7035e-04 - rmse: 0.0239\n",
      "Epoch 314: val_loss improved from 0.00052 to 0.00050, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.7212e-04 - rmse: 0.0165 - val_loss: 5.0069e-04 - val_rmse: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 315/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5818e-04 - rmse: 0.0126\n",
      "Epoch 315: val_loss did not improve from 0.00050\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6090e-04 - rmse: 0.0162 - val_loss: 5.0343e-04 - val_rmse: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 316/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2353e-04 - rmse: 0.0150\n",
      "Epoch 316: val_loss improved from 0.00050 to 0.00050, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6915e-04 - rmse: 0.0164 - val_loss: 4.9753e-04 - val_rmse: 0.0223 - lr: 1.0000e-04\n",
      "Epoch 317/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1373e-04 - rmse: 0.0107\n",
      "Epoch 317: val_loss improved from 0.00050 to 0.00049, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4258e-04 - rmse: 0.0156 - val_loss: 4.9142e-04 - val_rmse: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 318/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1632e-05 - rmse: 0.0079\n",
      "Epoch 318: val_loss did not improve from 0.00049\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3064e-04 - rmse: 0.0152 - val_loss: 4.9253e-04 - val_rmse: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 319/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3825e-05 - rmse: 0.0092\n",
      "Epoch 319: val_loss improved from 0.00049 to 0.00049, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.2446e-04 - rmse: 0.0150 - val_loss: 4.8821e-04 - val_rmse: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 320/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1429e-04 - rmse: 0.0204\n",
      "Epoch 320: val_loss improved from 0.00049 to 0.00047, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.2821e-04 - rmse: 0.0151 - val_loss: 4.6560e-04 - val_rmse: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 321/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6852e-05 - rmse: 0.0082\n",
      "Epoch 321: val_loss improved from 0.00047 to 0.00046, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1992e-04 - rmse: 0.0148 - val_loss: 4.5779e-04 - val_rmse: 0.0214 - lr: 1.0000e-04\n",
      "Epoch 322/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2708e-04 - rmse: 0.0151\n",
      "Epoch 322: val_loss did not improve from 0.00046\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3737e-04 - rmse: 0.0154 - val_loss: 4.7275e-04 - val_rmse: 0.0217 - lr: 1.0000e-04\n",
      "Epoch 323/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1362e-04 - rmse: 0.0107\n",
      "Epoch 323: val_loss improved from 0.00046 to 0.00045, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4144e-04 - rmse: 0.0155 - val_loss: 4.5461e-04 - val_rmse: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 324/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9379e-04 - rmse: 0.0222\n",
      "Epoch 324: val_loss improved from 0.00045 to 0.00044, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.4797e-04 - rmse: 0.0157 - val_loss: 4.4255e-04 - val_rmse: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 325/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6293e-04 - rmse: 0.0128\n",
      "Epoch 325: val_loss improved from 0.00044 to 0.00043, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.0835e-04 - rmse: 0.0144 - val_loss: 4.3381e-04 - val_rmse: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 326/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0618e-05 - rmse: 0.0095\n",
      "Epoch 326: val_loss did not improve from 0.00043\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0127e-04 - rmse: 0.0142 - val_loss: 4.4228e-04 - val_rmse: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 327/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9884e-04 - rmse: 0.0141\n",
      "Epoch 327: val_loss improved from 0.00043 to 0.00043, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 2.0744e-04 - rmse: 0.0144 - val_loss: 4.2637e-04 - val_rmse: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 328/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2624e-04 - rmse: 0.0181\n",
      "Epoch 328: val_loss did not improve from 0.00043\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0385e-04 - rmse: 0.0143 - val_loss: 4.5184e-04 - val_rmse: 0.0213 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6337e-04 - rmse: 0.0162\n",
      "Epoch 329: val_loss did not improve from 0.00043\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0880e-04 - rmse: 0.0144 - val_loss: 4.3914e-04 - val_rmse: 0.0210 - lr: 1.0000e-04\n",
      "Epoch 330/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2528e-05 - rmse: 0.0091\n",
      "Epoch 330: val_loss improved from 0.00043 to 0.00042, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8463e-04 - rmse: 0.0136 - val_loss: 4.2357e-04 - val_rmse: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 331/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5622e-04 - rmse: 0.0125\n",
      "Epoch 331: val_loss improved from 0.00042 to 0.00041, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.0596e-04 - rmse: 0.0144 - val_loss: 4.1336e-04 - val_rmse: 0.0203 - lr: 1.0000e-04\n",
      "Epoch 332/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3592e-04 - rmse: 0.0154\n",
      "Epoch 332: val_loss did not improve from 0.00041\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8218e-04 - rmse: 0.0135 - val_loss: 4.3539e-04 - val_rmse: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 333/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0789e-04 - rmse: 0.0104\n",
      "Epoch 333: val_loss improved from 0.00041 to 0.00041, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1341e-04 - rmse: 0.0146 - val_loss: 4.0682e-04 - val_rmse: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 334/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9041e-04 - rmse: 0.0138\n",
      "Epoch 334: val_loss improved from 0.00041 to 0.00040, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.8370e-04 - rmse: 0.0136 - val_loss: 4.0284e-04 - val_rmse: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 335/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1474e-04 - rmse: 0.0107\n",
      "Epoch 335: val_loss did not improve from 0.00040\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8372e-04 - rmse: 0.0136 - val_loss: 4.0662e-04 - val_rmse: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 336/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7260e-05 - rmse: 0.0069\n",
      "Epoch 336: val_loss did not improve from 0.00040\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8918e-04 - rmse: 0.0138 - val_loss: 4.1231e-04 - val_rmse: 0.0203 - lr: 1.0000e-04\n",
      "Epoch 337/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9596e-04 - rmse: 0.0199\n",
      "Epoch 337: val_loss did not improve from 0.00040\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9123e-04 - rmse: 0.0138 - val_loss: 4.2718e-04 - val_rmse: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 338/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8232e-05 - rmse: 0.0099\n",
      "Epoch 338: val_loss improved from 0.00040 to 0.00040, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1345e-04 - rmse: 0.0146 - val_loss: 4.0121e-04 - val_rmse: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 339/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0897e-05 - rmse: 0.0078\n",
      "Epoch 339: val_loss did not improve from 0.00040\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6434e-04 - rmse: 0.0128 - val_loss: 4.5371e-04 - val_rmse: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 340/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3569e-05 - rmse: 0.0091\n",
      "Epoch 340: val_loss did not improve from 0.00040\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8581e-04 - rmse: 0.0136 - val_loss: 4.0852e-04 - val_rmse: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 341/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4476e-04 - rmse: 0.0156\n",
      "Epoch 341: val_loss improved from 0.00040 to 0.00039, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.9696e-04 - rmse: 0.0140 - val_loss: 3.9033e-04 - val_rmse: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 342/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5203e-04 - rmse: 0.0123\n",
      "Epoch 342: val_loss improved from 0.00039 to 0.00038, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6521e-04 - rmse: 0.0129 - val_loss: 3.7888e-04 - val_rmse: 0.0195 - lr: 1.0000e-04\n",
      "Epoch 343/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1617e-04 - rmse: 0.0108\n",
      "Epoch 343: val_loss did not improve from 0.00038\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6045e-04 - rmse: 0.0127 - val_loss: 3.9072e-04 - val_rmse: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 344/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4694e-04 - rmse: 0.0121\n",
      "Epoch 344: val_loss improved from 0.00038 to 0.00037, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5625e-04 - rmse: 0.0125 - val_loss: 3.7214e-04 - val_rmse: 0.0193 - lr: 1.0000e-04\n",
      "Epoch 345/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5388e-04 - rmse: 0.0159\n",
      "Epoch 345: val_loss improved from 0.00037 to 0.00037, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4378e-04 - rmse: 0.0120 - val_loss: 3.6825e-04 - val_rmse: 0.0192 - lr: 1.0000e-04\n",
      "Epoch 346/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4925e-05 - rmse: 0.0087\n",
      "Epoch 346: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4442e-04 - rmse: 0.0120 - val_loss: 3.7822e-04 - val_rmse: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 347/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2844e-04 - rmse: 0.0151\n",
      "Epoch 347: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9776e-04 - rmse: 0.0141 - val_loss: 4.2035e-04 - val_rmse: 0.0205 - lr: 1.0000e-04\n",
      "Epoch 348/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2673e-04 - rmse: 0.0113\n",
      "Epoch 348: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7897e-04 - rmse: 0.0134 - val_loss: 4.4363e-04 - val_rmse: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 349/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8667e-04 - rmse: 0.0169\n",
      "Epoch 349: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5739e-04 - rmse: 0.0125 - val_loss: 3.9713e-04 - val_rmse: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 350/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9097e-04 - rmse: 0.0138\n",
      "Epoch 350: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5471e-04 - rmse: 0.0124 - val_loss: 4.6631e-04 - val_rmse: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 351/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8442e-04 - rmse: 0.0136\n",
      "Epoch 351: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5878e-04 - rmse: 0.0126 - val_loss: 4.2374e-04 - val_rmse: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 352/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2252e-04 - rmse: 0.0149\n",
      "Epoch 352: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6261e-04 - rmse: 0.0128 - val_loss: 4.7418e-04 - val_rmse: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 353/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5481e-04 - rmse: 0.0124\n",
      "Epoch 353: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8854e-04 - rmse: 0.0137 - val_loss: 4.8505e-04 - val_rmse: 0.0220 - lr: 1.0000e-04\n",
      "Epoch 354/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8940e-04 - rmse: 0.0138\n",
      "Epoch 354: val_loss did not improve from 0.00037\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8576e-04 - rmse: 0.0136 - val_loss: 4.3342e-04 - val_rmse: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 355/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3519e-04 - rmse: 0.0153\n",
      "Epoch 355: val_loss improved from 0.00037 to 0.00036, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.8717e-04 - rmse: 0.0137 - val_loss: 3.6465e-04 - val_rmse: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 356/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4732e-04 - rmse: 0.0157\n",
      "Epoch 356: val_loss improved from 0.00036 to 0.00032, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8658e-04 - rmse: 0.0137 - val_loss: 3.2282e-04 - val_rmse: 0.0180 - lr: 1.0000e-04\n",
      "Epoch 357/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3048e-04 - rmse: 0.0114\n",
      "Epoch 357: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4917e-04 - rmse: 0.0122 - val_loss: 3.4359e-04 - val_rmse: 0.0185 - lr: 1.0000e-04\n",
      "Epoch 358/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1247e-05 - rmse: 0.0090\n",
      "Epoch 358: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5078e-04 - rmse: 0.0123 - val_loss: 3.4931e-04 - val_rmse: 0.0187 - lr: 1.0000e-04\n",
      "Epoch 359/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8376e-05 - rmse: 0.0094\n",
      "Epoch 359: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5464e-04 - rmse: 0.0124 - val_loss: 4.1004e-04 - val_rmse: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 360/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9920e-04 - rmse: 0.0141\n",
      "Epoch 360: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6457e-04 - rmse: 0.0128 - val_loss: 3.4353e-04 - val_rmse: 0.0185 - lr: 1.0000e-04\n",
      "Epoch 361/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0742e-04 - rmse: 0.0104\n",
      "Epoch 361: val_loss improved from 0.00032 to 0.00032, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5685e-04 - rmse: 0.0125 - val_loss: 3.1889e-04 - val_rmse: 0.0179 - lr: 1.0000e-04\n",
      "Epoch 362/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0870e-04 - rmse: 0.0104\n",
      "Epoch 362: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4179e-04 - rmse: 0.0119 - val_loss: 3.4346e-04 - val_rmse: 0.0185 - lr: 1.0000e-04\n",
      "Epoch 363/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1597e-04 - rmse: 0.0147\n",
      "Epoch 363: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3436e-04 - rmse: 0.0116 - val_loss: 3.4782e-04 - val_rmse: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 364/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4308e-05 - rmse: 0.0080\n",
      "Epoch 364: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4660e-04 - rmse: 0.0121 - val_loss: 3.9434e-04 - val_rmse: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 365/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8453e-05 - rmse: 0.0099\n",
      "Epoch 365: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3491e-04 - rmse: 0.0116 - val_loss: 3.4472e-04 - val_rmse: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 366/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8036e-05 - rmse: 0.0082\n",
      "Epoch 366: val_loss did not improve from 0.00032\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0624e-04 - rmse: 0.0103 - val_loss: 3.3268e-04 - val_rmse: 0.0182 - lr: 1.0000e-04\n",
      "Epoch 367/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3205e-04 - rmse: 0.0115\n",
      "Epoch 367: val_loss improved from 0.00032 to 0.00031, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.1817e-04 - rmse: 0.0109 - val_loss: 3.1099e-04 - val_rmse: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 368/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3364e-05 - rmse: 0.0086\n",
      "Epoch 368: val_loss improved from 0.00031 to 0.00030, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0885e-04 - rmse: 0.0104 - val_loss: 3.0036e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 369/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1485e-04 - rmse: 0.0107\n",
      "Epoch 369: val_loss improved from 0.00030 to 0.00030, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.0794e-04 - rmse: 0.0104 - val_loss: 2.9942e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 370/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5492e-05 - rmse: 0.0081\n",
      "Epoch 370: val_loss did not improve from 0.00030\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0691e-04 - rmse: 0.0103 - val_loss: 3.0449e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 371/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6483e-05 - rmse: 0.0082\n",
      "Epoch 371: val_loss did not improve from 0.00030\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1508e-04 - rmse: 0.0107 - val_loss: 3.0198e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 372/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0104e-05 - rmse: 0.0063\n",
      "Epoch 372: val_loss improved from 0.00030 to 0.00029, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3237e-05 - rmse: 0.0097 - val_loss: 2.9017e-04 - val_rmse: 0.0170 - lr: 1.0000e-04\n",
      "Epoch 373/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6626e-04 - rmse: 0.0129\n",
      "Epoch 373: val_loss did not improve from 0.00029\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0985e-04 - rmse: 0.0105 - val_loss: 3.0898e-04 - val_rmse: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 374/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9405e-05 - rmse: 0.0089\n",
      "Epoch 374: val_loss did not improve from 0.00029\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0320e-04 - rmse: 0.0102 - val_loss: 3.0341e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 375/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5061e-05 - rmse: 0.0097\n",
      "Epoch 375: val_loss improved from 0.00029 to 0.00028, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.0031e-04 - rmse: 0.0100 - val_loss: 2.7665e-04 - val_rmse: 0.0166 - lr: 1.0000e-04\n",
      "Epoch 376/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2187e-05 - rmse: 0.0085\n",
      "Epoch 376: val_loss improved from 0.00028 to 0.00028, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0568e-05 - rmse: 0.0095 - val_loss: 2.7606e-04 - val_rmse: 0.0166 - lr: 1.0000e-04\n",
      "Epoch 377/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5556e-05 - rmse: 0.0075\n",
      "Epoch 377: val_loss improved from 0.00028 to 0.00027, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4663e-05 - rmse: 0.0092 - val_loss: 2.6849e-04 - val_rmse: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 378/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2751e-04 - rmse: 0.0113\n",
      "Epoch 378: val_loss did not improve from 0.00027\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8632e-05 - rmse: 0.0094 - val_loss: 2.8703e-04 - val_rmse: 0.0169 - lr: 1.0000e-04\n",
      "Epoch 379/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5550e-05 - rmse: 0.0098\n",
      "Epoch 379: val_loss did not improve from 0.00027\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2414e-05 - rmse: 0.0096 - val_loss: 2.9869e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 380/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7146e-05 - rmse: 0.0069\n",
      "Epoch 380: val_loss did not improve from 0.00027\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0916e-04 - rmse: 0.0104 - val_loss: 3.1099e-04 - val_rmse: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 381/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2754e-04 - rmse: 0.0113\n",
      "Epoch 381: val_loss did not improve from 0.00027\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0897e-05 - rmse: 0.0095 - val_loss: 2.8193e-04 - val_rmse: 0.0168 - lr: 1.0000e-04\n",
      "Epoch 382/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6157e-05 - rmse: 0.0051\n",
      "Epoch 382: val_loss improved from 0.00027 to 0.00027, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9529e-05 - rmse: 0.0100 - val_loss: 2.6730e-04 - val_rmse: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 383/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7282e-05 - rmse: 0.0076\n",
      "Epoch 383: val_loss improved from 0.00027 to 0.00027, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0263e-04 - rmse: 0.0101 - val_loss: 2.6603e-04 - val_rmse: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 384/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2287e-04 - rmse: 0.0111\n",
      "Epoch 384: val_loss improved from 0.00027 to 0.00026, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3212e-05 - rmse: 0.0091 - val_loss: 2.6202e-04 - val_rmse: 0.0162 - lr: 1.0000e-04\n",
      "Epoch 385/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8955e-05 - rmse: 0.0062\n",
      "Epoch 385: val_loss did not improve from 0.00026\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3147e-05 - rmse: 0.0091 - val_loss: 2.6205e-04 - val_rmse: 0.0162 - lr: 1.0000e-04\n",
      "Epoch 386/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3388e-05 - rmse: 0.0058\n",
      "Epoch 386: val_loss did not improve from 0.00026\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.7123e-05 - rmse: 0.0088 - val_loss: 2.6483e-04 - val_rmse: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 387/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6582e-05 - rmse: 0.0075\n",
      "Epoch 387: val_loss did not improve from 0.00026\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.9953e-05 - rmse: 0.0095 - val_loss: 2.6494e-04 - val_rmse: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 388/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9683e-04 - rmse: 0.0140\n",
      "Epoch 388: val_loss improved from 0.00026 to 0.00026, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4891e-05 - rmse: 0.0087 - val_loss: 2.5908e-04 - val_rmse: 0.0161 - lr: 1.0000e-04\n",
      "Epoch 389/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3753e-05 - rmse: 0.0080\n",
      "Epoch 389: val_loss improved from 0.00026 to 0.00025, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6713e-05 - rmse: 0.0088 - val_loss: 2.4787e-04 - val_rmse: 0.0157 - lr: 1.0000e-04\n",
      "Epoch 390/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4440e-05 - rmse: 0.0067\n",
      "Epoch 390: val_loss improved from 0.00025 to 0.00024, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9312e-05 - rmse: 0.0083 - val_loss: 2.4145e-04 - val_rmse: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 391/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5165e-05 - rmse: 0.0059\n",
      "Epoch 391: val_loss did not improve from 0.00024\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.8752e-05 - rmse: 0.0083 - val_loss: 2.4388e-04 - val_rmse: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 392/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7967e-05 - rmse: 0.0062\n",
      "Epoch 392: val_loss did not improve from 0.00024\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.0661e-05 - rmse: 0.0084 - val_loss: 2.4944e-04 - val_rmse: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 393/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3549e-05 - rmse: 0.0058\n",
      "Epoch 393: val_loss did not improve from 0.00024\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2189e-05 - rmse: 0.0085 - val_loss: 2.4971e-04 - val_rmse: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 394/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3590e-04 - rmse: 0.0117\n",
      "Epoch 394: val_loss did not improve from 0.00024\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.5205e-05 - rmse: 0.0087 - val_loss: 2.6123e-04 - val_rmse: 0.0162 - lr: 1.0000e-04\n",
      "Epoch 395/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0033e-04 - rmse: 0.0100\n",
      "Epoch 395: val_loss did not improve from 0.00024\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4707e-05 - rmse: 0.0086 - val_loss: 2.7200e-04 - val_rmse: 0.0165 - lr: 1.0000e-04\n",
      "Epoch 396/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4754e-05 - rmse: 0.0080\n",
      "Epoch 396: val_loss did not improve from 0.00024\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7351e-05 - rmse: 0.0099 - val_loss: 2.6710e-04 - val_rmse: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 397/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6024e-05 - rmse: 0.0075\n",
      "Epoch 397: val_loss improved from 0.00024 to 0.00023, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2277e-05 - rmse: 0.0096 - val_loss: 2.2691e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 398/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4262e-05 - rmse: 0.0074\n",
      "Epoch 398: val_loss improved from 0.00023 to 0.00022, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.4092e-05 - rmse: 0.0086 - val_loss: 2.2290e-04 - val_rmse: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 399/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0323e-05 - rmse: 0.0071\n",
      "Epoch 399: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9991e-05 - rmse: 0.0084 - val_loss: 2.2707e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 400/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7153e-05 - rmse: 0.0082\n",
      "Epoch 400: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.3835e-05 - rmse: 0.0080 - val_loss: 2.2427e-04 - val_rmse: 0.0150 - lr: 1.0000e-04\n",
      "Epoch 401/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9805e-05 - rmse: 0.0055\n",
      "Epoch 401: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.3921e-05 - rmse: 0.0080 - val_loss: 2.2962e-04 - val_rmse: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 402/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2455e-05 - rmse: 0.0065\n",
      "Epoch 402: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2255e-05 - rmse: 0.0079 - val_loss: 2.2980e-04 - val_rmse: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 403/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0329e-05 - rmse: 0.0064\n",
      "Epoch 403: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8740e-05 - rmse: 0.0077 - val_loss: 2.3368e-04 - val_rmse: 0.0153 - lr: 1.0000e-04\n",
      "Epoch 404/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7986e-05 - rmse: 0.0069\n",
      "Epoch 404: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5417e-05 - rmse: 0.0081 - val_loss: 2.2721e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 405/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1599e-04 - rmse: 0.0108\n",
      "Epoch 405: val_loss improved from 0.00022 to 0.00022, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.2635e-05 - rmse: 0.0079 - val_loss: 2.2123e-04 - val_rmse: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 406/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2863e-05 - rmse: 0.0096\n",
      "Epoch 406: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9651e-05 - rmse: 0.0083 - val_loss: 2.3492e-04 - val_rmse: 0.0153 - lr: 1.0000e-04\n",
      "Epoch 407/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2914e-04 - rmse: 0.0114\n",
      "Epoch 407: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6772e-05 - rmse: 0.0088 - val_loss: 2.3190e-04 - val_rmse: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 408/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6060e-05 - rmse: 0.0075\n",
      "Epoch 408: val_loss did not improve from 0.00022\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0215e-05 - rmse: 0.0084 - val_loss: 2.4978e-04 - val_rmse: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 409/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0825e-05 - rmse: 0.0090\n",
      "Epoch 409: val_loss improved from 0.00022 to 0.00022, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9406e-05 - rmse: 0.0083 - val_loss: 2.2095e-04 - val_rmse: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 410/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8039e-05 - rmse: 0.0094\n",
      "Epoch 410: val_loss improved from 0.00022 to 0.00022, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.0089e-05 - rmse: 0.0071 - val_loss: 2.1876e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 411/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2201e-05 - rmse: 0.0047\n",
      "Epoch 411: val_loss improved from 0.00022 to 0.00021, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1351e-05 - rmse: 0.0072 - val_loss: 2.1176e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 412/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4511e-05 - rmse: 0.0067\n",
      "Epoch 412: val_loss improved from 0.00021 to 0.00021, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.0553e-05 - rmse: 0.0071 - val_loss: 2.0842e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 413/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3468e-05 - rmse: 0.0066\n",
      "Epoch 413: val_loss improved from 0.00021 to 0.00021, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.9161e-05 - rmse: 0.0070 - val_loss: 2.0658e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 414/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8742e-05 - rmse: 0.0043\n",
      "Epoch 414: val_loss did not improve from 0.00021\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2668e-05 - rmse: 0.0073 - val_loss: 2.1227e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 415/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9476e-05 - rmse: 0.0063\n",
      "Epoch 415: val_loss improved from 0.00021 to 0.00020, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7027e-05 - rmse: 0.0076 - val_loss: 2.0239e-04 - val_rmse: 0.0142 - lr: 1.0000e-04\n",
      "Epoch 416/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8292e-05 - rmse: 0.0053\n",
      "Epoch 416: val_loss did not improve from 0.00020\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9093e-05 - rmse: 0.0070 - val_loss: 2.0360e-04 - val_rmse: 0.0143 - lr: 1.0000e-04\n",
      "Epoch 417/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6314e-05 - rmse: 0.0068\n",
      "Epoch 417: val_loss did not improve from 0.00020\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4433e-05 - rmse: 0.0067 - val_loss: 2.0607e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 418/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9647e-05 - rmse: 0.0070\n",
      "Epoch 418: val_loss did not improve from 0.00020\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2977e-05 - rmse: 0.0073 - val_loss: 2.1609e-04 - val_rmse: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 419/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6933e-05 - rmse: 0.0052\n",
      "Epoch 419: val_loss did not improve from 0.00020\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.9958e-05 - rmse: 0.0071 - val_loss: 2.2742e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 420/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2911e-05 - rmse: 0.0066\n",
      "Epoch 420: val_loss did not improve from 0.00020\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7930e-05 - rmse: 0.0076 - val_loss: 2.1906e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 421/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5415e-05 - rmse: 0.0067\n",
      "Epoch 421: val_loss improved from 0.00020 to 0.00020, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3479e-05 - rmse: 0.0073 - val_loss: 2.0147e-04 - val_rmse: 0.0142 - lr: 1.0000e-04\n",
      "Epoch 422/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4589e-05 - rmse: 0.0059\n",
      "Epoch 422: val_loss did not improve from 0.00020\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5712e-05 - rmse: 0.0075 - val_loss: 2.0617e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 423/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0562e-05 - rmse: 0.0095\n",
      "Epoch 423: val_loss improved from 0.00020 to 0.00019, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.9867e-05 - rmse: 0.0071 - val_loss: 1.9236e-04 - val_rmse: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 424/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9462e-05 - rmse: 0.0044\n",
      "Epoch 424: val_loss did not improve from 0.00019\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.5415e-05 - rmse: 0.0067 - val_loss: 1.9270e-04 - val_rmse: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 425/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5696e-05 - rmse: 0.0081\n",
      "Epoch 425: val_loss did not improve from 0.00019\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7807e-05 - rmse: 0.0069 - val_loss: 1.9898e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 426/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0901e-05 - rmse: 0.0056\n",
      "Epoch 426: val_loss did not improve from 0.00019\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2170e-05 - rmse: 0.0072 - val_loss: 2.0933e-04 - val_rmse: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 427/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1988e-05 - rmse: 0.0065\n",
      "Epoch 427: val_loss did not improve from 0.00019\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5223e-05 - rmse: 0.0074 - val_loss: 2.0398e-04 - val_rmse: 0.0143 - lr: 1.0000e-04\n",
      "Epoch 428/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5000e-05 - rmse: 0.0050\n",
      "Epoch 428: val_loss did not improve from 0.00019\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4999e-05 - rmse: 0.0074 - val_loss: 1.9988e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 429/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3576e-05 - rmse: 0.0049\n",
      "Epoch 429: val_loss did not improve from 0.00019\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.6979e-05 - rmse: 0.0069 - val_loss: 2.0112e-04 - val_rmse: 0.0142 - lr: 1.0000e-04\n",
      "Epoch 430/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2986e-05 - rmse: 0.0048\n",
      "Epoch 430: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.9418e-05 - rmse: 0.0070 - val_loss: 1.9010e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 431/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8513e-05 - rmse: 0.0043\n",
      "Epoch 431: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.6381e-05 - rmse: 0.0060 - val_loss: 1.8950e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 432/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7317e-05 - rmse: 0.0061\n",
      "Epoch 432: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.1992e-05 - rmse: 0.0065 - val_loss: 1.8586e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 433/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9628e-05 - rmse: 0.0077\n",
      "Epoch 433: val_loss improved from 0.00019 to 0.00018, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9225e-05 - rmse: 0.0063 - val_loss: 1.8308e-04 - val_rmse: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 434/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1177e-05 - rmse: 0.0046\n",
      "Epoch 434: val_loss did not improve from 0.00018\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4781e-05 - rmse: 0.0059 - val_loss: 1.8652e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 435/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0960e-05 - rmse: 0.0056\n",
      "Epoch 435: val_loss did not improve from 0.00018\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6755e-05 - rmse: 0.0061 - val_loss: 1.8549e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 436/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1243e-05 - rmse: 0.0046\n",
      "Epoch 436: val_loss did not improve from 0.00018\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7017e-05 - rmse: 0.0061 - val_loss: 1.8425e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 437/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3807e-05 - rmse: 0.0049\n",
      "Epoch 437: val_loss did not improve from 0.00018\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.9492e-05 - rmse: 0.0063 - val_loss: 1.8906e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 438/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4335e-05 - rmse: 0.0067\n",
      "Epoch 438: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.4085e-05 - rmse: 0.0058 - val_loss: 1.7923e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 439/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3250e-05 - rmse: 0.0080\n",
      "Epoch 439: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.3547e-05 - rmse: 0.0058 - val_loss: 1.7918e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 440/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1642e-05 - rmse: 0.0072\n",
      "Epoch 440: val_loss improved from 0.00018 to 0.00017, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.3475e-05 - rmse: 0.0058 - val_loss: 1.6972e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 441/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8165e-05 - rmse: 0.0053\n",
      "Epoch 441: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5338e-05 - rmse: 0.0059 - val_loss: 1.7479e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 442/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3428e-05 - rmse: 0.0048\n",
      "Epoch 442: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0356e-05 - rmse: 0.0064 - val_loss: 1.9168e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 443/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2744e-05 - rmse: 0.0048\n",
      "Epoch 443: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6095e-05 - rmse: 0.0060 - val_loss: 2.0719e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 444/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0465e-05 - rmse: 0.0090\n",
      "Epoch 444: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3109e-05 - rmse: 0.0073 - val_loss: 1.8565e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 445/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6249e-05 - rmse: 0.0040\n",
      "Epoch 445: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5310e-05 - rmse: 0.0067 - val_loss: 1.9010e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 446/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9116e-05 - rmse: 0.0089\n",
      "Epoch 446: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9712e-05 - rmse: 0.0063 - val_loss: 1.7082e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 447/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3949e-05 - rmse: 0.0049\n",
      "Epoch 447: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4908e-05 - rmse: 0.0059 - val_loss: 1.7979e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 448/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8341e-05 - rmse: 0.0062\n",
      "Epoch 448: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1954e-05 - rmse: 0.0065 - val_loss: 1.8101e-04 - val_rmse: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 449/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8585e-05 - rmse: 0.0062\n",
      "Epoch 449: val_loss did not improve from 0.00017\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4953e-05 - rmse: 0.0059 - val_loss: 1.8881e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 450/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9323e-05 - rmse: 0.0054\n",
      "Epoch 450: val_loss improved from 0.00017 to 0.00016, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.3040e-05 - rmse: 0.0066 - val_loss: 1.6343e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 451/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4846e-05 - rmse: 0.0059\n",
      "Epoch 451: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1171e-05 - rmse: 0.0056 - val_loss: 1.5930e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 452/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6979e-05 - rmse: 0.0052\n",
      "Epoch 452: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8815e-05 - rmse: 0.0054 - val_loss: 1.7974e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 453/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7494e-05 - rmse: 0.0069\n",
      "Epoch 453: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0434e-05 - rmse: 0.0055 - val_loss: 1.7842e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 454/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0617e-05 - rmse: 0.0071\n",
      "Epoch 454: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7382e-05 - rmse: 0.0061 - val_loss: 1.7655e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 455/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5451e-05 - rmse: 0.0050\n",
      "Epoch 455: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0283e-05 - rmse: 0.0055 - val_loss: 1.7360e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 456/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6170e-05 - rmse: 0.0040\n",
      "Epoch 456: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8620e-05 - rmse: 0.0053 - val_loss: 1.6805e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 457/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2126e-05 - rmse: 0.0065\n",
      "Epoch 457: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6156e-05 - rmse: 0.0051 - val_loss: 1.7834e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 458/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4927e-05 - rmse: 0.0059\n",
      "Epoch 458: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.1008e-05 - rmse: 0.0056 - val_loss: 1.6836e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 459/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5381e-05 - rmse: 0.0067\n",
      "Epoch 459: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9964e-05 - rmse: 0.0055 - val_loss: 1.7206e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 460/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9637e-05 - rmse: 0.0044\n",
      "Epoch 460: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1693e-05 - rmse: 0.0056 - val_loss: 1.7640e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 461/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6724e-05 - rmse: 0.0052\n",
      "Epoch 461: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3135e-05 - rmse: 0.0058 - val_loss: 2.1345e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 462/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5249e-04 - rmse: 0.0123\n",
      "Epoch 462: val_loss did not improve from 0.00016\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9628e-05 - rmse: 0.0070 - val_loss: 1.6530e-04 - val_rmse: 0.0129 - lr: 1.0000e-04\n",
      "Epoch 463/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9551e-05 - rmse: 0.0044\n",
      "Epoch 463: val_loss improved from 0.00016 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8008e-05 - rmse: 0.0062 - val_loss: 1.5496e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 464/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0290e-05 - rmse: 0.0055\n",
      "Epoch 464: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9265e-05 - rmse: 0.0054 - val_loss: 1.5746e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 465/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0853e-05 - rmse: 0.0033\n",
      "Epoch 465: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5163e-05 - rmse: 0.0050 - val_loss: 1.6346e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 466/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3156e-05 - rmse: 0.0066\n",
      "Epoch 466: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.4805e-05 - rmse: 0.0050 - val_loss: 1.6065e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 467/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8271e-05 - rmse: 0.0062\n",
      "Epoch 467: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3197e-05 - rmse: 0.0048 - val_loss: 1.5957e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 468/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3920e-05 - rmse: 0.0037\n",
      "Epoch 468: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1987e-05 - rmse: 0.0047 - val_loss: 1.6060e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 469/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4768e-05 - rmse: 0.0050\n",
      "Epoch 469: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5297e-05 - rmse: 0.0050 - val_loss: 1.6011e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 470/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1557e-05 - rmse: 0.0046\n",
      "Epoch 470: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9977e-05 - rmse: 0.0055 - val_loss: 1.5786e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 471/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5320e-05 - rmse: 0.0050\n",
      "Epoch 471: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3706e-05 - rmse: 0.0049 - val_loss: 1.6220e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 472/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0692e-05 - rmse: 0.0084\n",
      "Epoch 472: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5693e-05 - rmse: 0.0051 - val_loss: 1.6132e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 473/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2496e-05 - rmse: 0.0047\n",
      "Epoch 473: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5993e-05 - rmse: 0.0051 - val_loss: 1.6180e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 474/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2454e-05 - rmse: 0.0035\n",
      "Epoch 474: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2385e-05 - rmse: 0.0047 - val_loss: 1.6119e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 475/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9753e-05 - rmse: 0.0044\n",
      "Epoch 475: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3300e-05 - rmse: 0.0048 - val_loss: 1.6384e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 476/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5300e-05 - rmse: 0.0059\n",
      "Epoch 476: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5673e-05 - rmse: 0.0051 - val_loss: 1.5643e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0617e-05 - rmse: 0.0045\n",
      "Epoch 477: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1937e-05 - rmse: 0.0047 - val_loss: 1.5307e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 478/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9588e-05 - rmse: 0.0054\n",
      "Epoch 478: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0314e-05 - rmse: 0.0045 - val_loss: 1.5549e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 479/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7054e-05 - rmse: 0.0041\n",
      "Epoch 479: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0141e-05 - rmse: 0.0045 - val_loss: 1.5054e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 480/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8161e-06 - rmse: 0.0030\n",
      "Epoch 480: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0841e-05 - rmse: 0.0046 - val_loss: 1.5647e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 481/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7873e-06 - rmse: 0.0024\n",
      "Epoch 481: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.8074e-05 - rmse: 0.0043 - val_loss: 1.5724e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 482/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0123e-05 - rmse: 0.0055\n",
      "Epoch 482: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1760e-05 - rmse: 0.0047 - val_loss: 1.6919e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 483/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5833e-05 - rmse: 0.0040\n",
      "Epoch 483: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0024e-05 - rmse: 0.0045 - val_loss: 1.5240e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 484/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4633e-05 - rmse: 0.0038\n",
      "Epoch 484: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9980e-05 - rmse: 0.0045 - val_loss: 1.5095e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 485/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8210e-05 - rmse: 0.0043\n",
      "Epoch 485: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1917e-05 - rmse: 0.0047 - val_loss: 1.4955e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 486/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0698e-06 - rmse: 0.0025\n",
      "Epoch 486: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.9154e-05 - rmse: 0.0044 - val_loss: 1.4923e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 487/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4092e-05 - rmse: 0.0038\n",
      "Epoch 487: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8899e-05 - rmse: 0.0043 - val_loss: 1.6158e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 488/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5570e-05 - rmse: 0.0039\n",
      "Epoch 488: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9797e-05 - rmse: 0.0044 - val_loss: 1.6220e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 489/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6051e-05 - rmse: 0.0040\n",
      "Epoch 489: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2297e-05 - rmse: 0.0047 - val_loss: 1.5772e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 490/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2639e-05 - rmse: 0.0048\n",
      "Epoch 490: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5773e-05 - rmse: 0.0051 - val_loss: 1.8005e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 491/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1873e-05 - rmse: 0.0056\n",
      "Epoch 491: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1860e-05 - rmse: 0.0056 - val_loss: 1.5221e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 492/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0191e-05 - rmse: 0.0055\n",
      "Epoch 492: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8965e-05 - rmse: 0.0044 - val_loss: 1.5287e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 493/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1422e-05 - rmse: 0.0046\n",
      "Epoch 493: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4920e-05 - rmse: 0.0050 - val_loss: 1.8272e-04 - val_rmse: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 494/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3704e-05 - rmse: 0.0066\n",
      "Epoch 494: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0417e-05 - rmse: 0.0055 - val_loss: 1.5072e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 495/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3772e-05 - rmse: 0.0037\n",
      "Epoch 495: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9058e-05 - rmse: 0.0044 - val_loss: 1.6064e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 496/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7309e-05 - rmse: 0.0052\n",
      "Epoch 496: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9086e-05 - rmse: 0.0044 - val_loss: 1.5666e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 497/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3258e-06 - rmse: 0.0029\n",
      "Epoch 497: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6608e-05 - rmse: 0.0041 - val_loss: 1.5208e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 498/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0624e-05 - rmse: 0.0033\n",
      "Epoch 498: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6908e-05 - rmse: 0.0041 - val_loss: 1.5413e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 499/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1123e-05 - rmse: 0.0033\n",
      "Epoch 499: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8548e-05 - rmse: 0.0043 - val_loss: 1.5561e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 500/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1960e-05 - rmse: 0.0035\n",
      "Epoch 500: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7892e-05 - rmse: 0.0042 - val_loss: 1.5828e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 501/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.9295e-06 - rmse: 0.0032\n",
      "Epoch 501: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0365e-05 - rmse: 0.0045 - val_loss: 1.5456e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 502/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7846e-05 - rmse: 0.0042\n",
      "Epoch 502: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8742e-05 - rmse: 0.0043 - val_loss: 1.4776e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6467e-06 - rmse: 0.0029\n",
      "Epoch 503: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5744e-05 - rmse: 0.0040 - val_loss: 1.5301e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 504/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9115e-06 - rmse: 0.0022\n",
      "Epoch 504: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7872e-05 - rmse: 0.0042 - val_loss: 1.5610e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 505/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0761e-05 - rmse: 0.0033\n",
      "Epoch 505: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5144e-05 - rmse: 0.0039 - val_loss: 1.5080e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 506/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1274e-06 - rmse: 0.0030\n",
      "Epoch 506: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6426e-05 - rmse: 0.0041 - val_loss: 1.5479e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 507/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9181e-05 - rmse: 0.0044\n",
      "Epoch 507: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.6672e-05 - rmse: 0.0041 - val_loss: 1.4551e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 508/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1761e-05 - rmse: 0.0034\n",
      "Epoch 508: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7115e-05 - rmse: 0.0041 - val_loss: 1.4695e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 509/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1108e-05 - rmse: 0.0033\n",
      "Epoch 509: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5386e-05 - rmse: 0.0039 - val_loss: 1.5448e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 510/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1474e-05 - rmse: 0.0056\n",
      "Epoch 510: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3033e-05 - rmse: 0.0036 - val_loss: 1.5528e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 511/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3010e-06 - rmse: 0.0029\n",
      "Epoch 511: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5279e-05 - rmse: 0.0039 - val_loss: 1.5682e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 512/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0586e-05 - rmse: 0.0033\n",
      "Epoch 512: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6231e-05 - rmse: 0.0040 - val_loss: 1.4801e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 513/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7215e-05 - rmse: 0.0041\n",
      "Epoch 513: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8615e-05 - rmse: 0.0043 - val_loss: 1.5245e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 514/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3240e-05 - rmse: 0.0036\n",
      "Epoch 514: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5317e-05 - rmse: 0.0039 - val_loss: 1.7083e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 515/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6900e-05 - rmse: 0.0061\n",
      "Epoch 515: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0781e-05 - rmse: 0.0046 - val_loss: 1.5684e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 516/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6882e-05 - rmse: 0.0041\n",
      "Epoch 516: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9208e-05 - rmse: 0.0044 - val_loss: 1.5945e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 517/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3814e-05 - rmse: 0.0037\n",
      "Epoch 517: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3025e-05 - rmse: 0.0048 - val_loss: 1.5247e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 518/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3478e-05 - rmse: 0.0048\n",
      "Epoch 518: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7900e-05 - rmse: 0.0042 - val_loss: 1.5823e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 519/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1103e-05 - rmse: 0.0046\n",
      "Epoch 519: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4179e-05 - rmse: 0.0038 - val_loss: 1.4746e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 520/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9860e-06 - rmse: 0.0024\n",
      "Epoch 520: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3232e-05 - rmse: 0.0036 - val_loss: 1.4970e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 521/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9318e-05 - rmse: 0.0044\n",
      "Epoch 521: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4172e-05 - rmse: 0.0038 - val_loss: 1.4911e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 522/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3449e-05 - rmse: 0.0037\n",
      "Epoch 522: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3483e-05 - rmse: 0.0037 - val_loss: 1.4865e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 523/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2483e-06 - rmse: 0.0027\n",
      "Epoch 523: val_loss did not improve from 0.00015\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1411e-05 - rmse: 0.0034 - val_loss: 1.4555e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 524/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8173e-06 - rmse: 0.0031\n",
      "Epoch 524: val_loss improved from 0.00015 to 0.00014, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1985e-05 - rmse: 0.0035 - val_loss: 1.4491e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 525/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2608e-05 - rmse: 0.0036\n",
      "Epoch 525: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3824e-05 - rmse: 0.0037 - val_loss: 1.4751e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 526/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0214e-05 - rmse: 0.0032\n",
      "Epoch 526: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2993e-05 - rmse: 0.0036 - val_loss: 1.4650e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 527/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2148e-06 - rmse: 0.0027\n",
      "Epoch 527: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0480e-05 - rmse: 0.0032 - val_loss: 1.4556e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 528/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5120e-06 - rmse: 0.0026\n",
      "Epoch 528: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0002e-05 - rmse: 0.0032 - val_loss: 1.4522e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 529/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4267e-06 - rmse: 0.0023\n",
      "Epoch 529: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0443e-05 - rmse: 0.0032 - val_loss: 1.4565e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 530/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4634e-06 - rmse: 0.0023\n",
      "Epoch 530: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2303e-05 - rmse: 0.0035 - val_loss: 1.5792e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 531/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5083e-05 - rmse: 0.0039\n",
      "Epoch 531: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4870e-05 - rmse: 0.0039 - val_loss: 1.4735e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 532/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3864e-06 - rmse: 0.0029\n",
      "Epoch 532: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2012e-05 - rmse: 0.0035 - val_loss: 1.5445e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 533/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2500e-05 - rmse: 0.0047\n",
      "Epoch 533: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.9029e-05 - rmse: 0.0044 - val_loss: 1.4075e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 534/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9982e-06 - rmse: 0.0030\n",
      "Epoch 534: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2364e-05 - rmse: 0.0035 - val_loss: 1.5627e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 535/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0151e-05 - rmse: 0.0063\n",
      "Epoch 535: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4836e-05 - rmse: 0.0039 - val_loss: 1.4413e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 536/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3670e-05 - rmse: 0.0049\n",
      "Epoch 536: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1589e-05 - rmse: 0.0034 - val_loss: 1.4624e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 537/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2156e-06 - rmse: 0.0029\n",
      "Epoch 537: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0391e-05 - rmse: 0.0032 - val_loss: 1.4146e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 538/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4560e-06 - rmse: 0.0025\n",
      "Epoch 538: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0155e-05 - rmse: 0.0032 - val_loss: 1.4099e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 539/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9697e-06 - rmse: 0.0030\n",
      "Epoch 539: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.1335e-05 - rmse: 0.0034 - val_loss: 1.3902e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 540/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2532e-06 - rmse: 0.0030\n",
      "Epoch 540: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4193e-05 - rmse: 0.0038 - val_loss: 1.4304e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 541/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1711e-05 - rmse: 0.0034\n",
      "Epoch 541: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5042e-05 - rmse: 0.0039 - val_loss: 1.5779e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 542/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4861e-05 - rmse: 0.0059\n",
      "Epoch 542: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3962e-05 - rmse: 0.0049 - val_loss: 1.7123e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 543/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1878e-05 - rmse: 0.0065\n",
      "Epoch 543: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.1018e-05 - rmse: 0.0046 - val_loss: 1.3610e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 544/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6683e-05 - rmse: 0.0041\n",
      "Epoch 544: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6339e-05 - rmse: 0.0040 - val_loss: 1.4162e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 545/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0317e-05 - rmse: 0.0045\n",
      "Epoch 545: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6382e-05 - rmse: 0.0040 - val_loss: 1.3765e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 546/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4371e-05 - rmse: 0.0038\n",
      "Epoch 546: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7521e-05 - rmse: 0.0042 - val_loss: 1.5956e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 547/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4137e-05 - rmse: 0.0038\n",
      "Epoch 547: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6276e-05 - rmse: 0.0040 - val_loss: 1.4242e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 548/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4186e-06 - rmse: 0.0023\n",
      "Epoch 548: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2258e-05 - rmse: 0.0035 - val_loss: 1.4971e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 549/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3721e-05 - rmse: 0.0037\n",
      "Epoch 549: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.3872e-05 - rmse: 0.0037 - val_loss: 1.3544e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 550/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7078e-06 - rmse: 0.0024\n",
      "Epoch 550: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3034e-05 - rmse: 0.0036 - val_loss: 1.4545e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 551/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2219e-05 - rmse: 0.0047\n",
      "Epoch 551: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3464e-05 - rmse: 0.0037 - val_loss: 1.4555e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 552/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3343e-06 - rmse: 0.0023\n",
      "Epoch 552: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3981e-05 - rmse: 0.0037 - val_loss: 1.7270e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 553/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5523e-05 - rmse: 0.0051\n",
      "Epoch 553: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7675e-05 - rmse: 0.0053 - val_loss: 1.4470e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 554/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0707e-05 - rmse: 0.0033\n",
      "Epoch 554: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7263e-05 - rmse: 0.0042 - val_loss: 1.4031e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 555/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0638e-06 - rmse: 0.0018\n",
      "Epoch 555: val_loss did not improve from 0.00014\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1469e-05 - rmse: 0.0034 - val_loss: 1.4106e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 556/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3154e-06 - rmse: 0.0029\n",
      "Epoch 556: val_loss improved from 0.00014 to 0.00013, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0026e-05 - rmse: 0.0032 - val_loss: 1.3226e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 557/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6984e-05 - rmse: 0.0041\n",
      "Epoch 557: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1524e-06 - rmse: 0.0030 - val_loss: 1.3750e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 558/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8979e-06 - rmse: 0.0026\n",
      "Epoch 558: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4487e-06 - rmse: 0.0027 - val_loss: 1.3993e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 559/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3817e-06 - rmse: 0.0027\n",
      "Epoch 559: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2457e-06 - rmse: 0.0030 - val_loss: 1.3963e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 560/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0226e-05 - rmse: 0.0032\n",
      "Epoch 560: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1281e-06 - rmse: 0.0027 - val_loss: 1.3843e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 561/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9460e-06 - rmse: 0.0024\n",
      "Epoch 561: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0456e-06 - rmse: 0.0028 - val_loss: 1.4596e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 562/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4619e-06 - rmse: 0.0025\n",
      "Epoch 562: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3162e-06 - rmse: 0.0029 - val_loss: 1.3874e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 563/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5346e-06 - rmse: 0.0024\n",
      "Epoch 563: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9963e-06 - rmse: 0.0030 - val_loss: 1.3369e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 564/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4824e-06 - rmse: 0.0023\n",
      "Epoch 564: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0250e-05 - rmse: 0.0032 - val_loss: 1.3114e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 565/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2922e-06 - rmse: 0.0018\n",
      "Epoch 565: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0127e-05 - rmse: 0.0032 - val_loss: 1.3299e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 566/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0811e-05 - rmse: 0.0033\n",
      "Epoch 566: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0714e-05 - rmse: 0.0033 - val_loss: 1.3285e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 567/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2338e-06 - rmse: 0.0030\n",
      "Epoch 567: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2670e-06 - rmse: 0.0029 - val_loss: 1.3670e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 568/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3114e-06 - rmse: 0.0025\n",
      "Epoch 568: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.8980e-06 - rmse: 0.0028 - val_loss: 1.4791e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 569/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4265e-05 - rmse: 0.0038\n",
      "Epoch 569: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7164e-06 - rmse: 0.0030 - val_loss: 1.4131e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 570/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3619e-06 - rmse: 0.0031\n",
      "Epoch 570: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8023e-06 - rmse: 0.0030 - val_loss: 1.3518e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 571/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1325e-06 - rmse: 0.0029\n",
      "Epoch 571: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3244e-06 - rmse: 0.0029 - val_loss: 1.3384e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 572/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4369e-06 - rmse: 0.0031\n",
      "Epoch 572: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2346e-06 - rmse: 0.0027 - val_loss: 1.4071e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 573/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3716e-05 - rmse: 0.0037\n",
      "Epoch 573: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4136e-06 - rmse: 0.0029 - val_loss: 1.4177e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 574/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3196e-06 - rmse: 0.0025\n",
      "Epoch 574: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1241e-06 - rmse: 0.0029 - val_loss: 1.4358e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 575/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4216e-06 - rmse: 0.0023\n",
      "Epoch 575: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0596e-05 - rmse: 0.0033 - val_loss: 1.4050e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 576/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1361e-05 - rmse: 0.0034\n",
      "Epoch 576: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4527e-06 - rmse: 0.0029 - val_loss: 1.3717e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 577/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8369e-06 - rmse: 0.0022\n",
      "Epoch 577: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7831e-06 - rmse: 0.0030 - val_loss: 1.3975e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 578/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1757e-06 - rmse: 0.0023\n",
      "Epoch 578: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0354e-06 - rmse: 0.0027 - val_loss: 1.4165e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 579/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7807e-06 - rmse: 0.0030\n",
      "Epoch 579: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3257e-05 - rmse: 0.0036 - val_loss: 1.3788e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 580/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0956e-05 - rmse: 0.0033\n",
      "Epoch 580: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0818e-05 - rmse: 0.0033 - val_loss: 1.4650e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 581/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3479e-05 - rmse: 0.0037\n",
      "Epoch 581: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9173e-05 - rmse: 0.0044 - val_loss: 1.4924e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 582/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5810e-05 - rmse: 0.0040\n",
      "Epoch 582: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8928e-05 - rmse: 0.0044 - val_loss: 1.4671e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 583/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5204e-06 - rmse: 0.0029\n",
      "Epoch 583: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0357e-05 - rmse: 0.0032 - val_loss: 1.4599e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 584/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6072e-05 - rmse: 0.0040\n",
      "Epoch 584: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1785e-05 - rmse: 0.0034 - val_loss: 1.5060e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 585/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1956e-05 - rmse: 0.0035\n",
      "Epoch 585: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0013e-05 - rmse: 0.0032 - val_loss: 1.4565e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 586/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9429e-05 - rmse: 0.0044\n",
      "Epoch 586: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2497e-05 - rmse: 0.0035 - val_loss: 1.3761e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 587/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1378e-05 - rmse: 0.0034\n",
      "Epoch 587: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.0021e-05 - rmse: 0.0032 - val_loss: 1.2995e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 588/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8947e-06 - rmse: 0.0020\n",
      "Epoch 588: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5838e-06 - rmse: 0.0031 - val_loss: 1.3850e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 589/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2007e-05 - rmse: 0.0035\n",
      "Epoch 589: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1289e-05 - rmse: 0.0034 - val_loss: 1.4160e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 590/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3144e-06 - rmse: 0.0029\n",
      "Epoch 590: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5837e-05 - rmse: 0.0040 - val_loss: 1.4104e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 591/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4924e-05 - rmse: 0.0039\n",
      "Epoch 591: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5212e-05 - rmse: 0.0039 - val_loss: 1.5120e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 592/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8044e-05 - rmse: 0.0053\n",
      "Epoch 592: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.8672e-05 - rmse: 0.0043 - val_loss: 1.2790e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 593/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3447e-06 - rmse: 0.0021\n",
      "Epoch 593: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0675e-05 - rmse: 0.0033 - val_loss: 1.3447e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 594/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9963e-06 - rmse: 0.0024\n",
      "Epoch 594: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2122e-06 - rmse: 0.0029 - val_loss: 1.2715e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 595/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7450e-06 - rmse: 0.0031\n",
      "Epoch 595: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0041e-05 - rmse: 0.0032 - val_loss: 1.3169e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 596/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2382e-05 - rmse: 0.0035\n",
      "Epoch 596: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9358e-06 - rmse: 0.0028 - val_loss: 1.3269e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 597/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9277e-06 - rmse: 0.0026\n",
      "Epoch 597: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7281e-06 - rmse: 0.0024 - val_loss: 1.3472e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 598/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4412e-06 - rmse: 0.0027\n",
      "Epoch 598: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2758e-06 - rmse: 0.0023 - val_loss: 1.3744e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 599/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2038e-06 - rmse: 0.0030\n",
      "Epoch 599: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5191e-06 - rmse: 0.0026 - val_loss: 1.3950e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 600/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8645e-06 - rmse: 0.0026\n",
      "Epoch 600: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0661e-06 - rmse: 0.0027 - val_loss: 1.3211e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 601/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3407e-06 - rmse: 0.0021\n",
      "Epoch 601: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0743e-06 - rmse: 0.0025 - val_loss: 1.3114e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 602/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3164e-06 - rmse: 0.0025\n",
      "Epoch 602: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1635e-06 - rmse: 0.0027 - val_loss: 1.3072e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 603/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0968e-06 - rmse: 0.0023\n",
      "Epoch 603: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.7268e-06 - rmse: 0.0028 - val_loss: 1.3338e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 604/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4390e-06 - rmse: 0.0025\n",
      "Epoch 604: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8266e-06 - rmse: 0.0026 - val_loss: 1.3566e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 605/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8901e-06 - rmse: 0.0031\n",
      "Epoch 605: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5863e-06 - rmse: 0.0024 - val_loss: 1.3604e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 606/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9412e-06 - rmse: 0.0020\n",
      "Epoch 606: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5695e-06 - rmse: 0.0021 - val_loss: 1.3155e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 607/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0021e-06 - rmse: 0.0022\n",
      "Epoch 607: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9748e-06 - rmse: 0.0022 - val_loss: 1.3207e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 608/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6145e-06 - rmse: 0.0019\n",
      "Epoch 608: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7362e-06 - rmse: 0.0024 - val_loss: 1.3496e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 609/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4092e-06 - rmse: 0.0021\n",
      "Epoch 609: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.8620e-06 - rmse: 0.0020 - val_loss: 1.3001e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 610/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7779e-06 - rmse: 0.0026\n",
      "Epoch 610: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7638e-06 - rmse: 0.0019 - val_loss: 1.2847e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7078e-06 - rmse: 0.0024\n",
      "Epoch 611: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8699e-06 - rmse: 0.0020 - val_loss: 1.3076e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 612/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5551e-06 - rmse: 0.0021\n",
      "Epoch 612: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0383e-06 - rmse: 0.0020 - val_loss: 1.3347e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 613/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0350e-06 - rmse: 0.0025\n",
      "Epoch 613: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2454e-06 - rmse: 0.0021 - val_loss: 1.2980e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 614/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2496e-06 - rmse: 0.0018\n",
      "Epoch 614: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0010e-06 - rmse: 0.0020 - val_loss: 1.2807e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 615/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1922e-06 - rmse: 0.0020\n",
      "Epoch 615: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.7870e-06 - rmse: 0.0019 - val_loss: 1.2763e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 616/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8898e-06 - rmse: 0.0022\n",
      "Epoch 616: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1984e-06 - rmse: 0.0018 - val_loss: 1.2952e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 617/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1059e-06 - rmse: 0.0018\n",
      "Epoch 617: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3609e-06 - rmse: 0.0025 - val_loss: 1.3150e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 618/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3491e-06 - rmse: 0.0018\n",
      "Epoch 618: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6877e-06 - rmse: 0.0022 - val_loss: 1.3087e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 619/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9322e-06 - rmse: 0.0026\n",
      "Epoch 619: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4981e-06 - rmse: 0.0021 - val_loss: 1.3095e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 620/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1468e-06 - rmse: 0.0020\n",
      "Epoch 620: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8968e-06 - rmse: 0.0020 - val_loss: 1.3104e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 621/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7720e-06 - rmse: 0.0026\n",
      "Epoch 621: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.6596e-06 - rmse: 0.0022 - val_loss: 1.3023e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 622/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4570e-06 - rmse: 0.0016\n",
      "Epoch 622: val_loss did not improve from 0.00013\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7051e-06 - rmse: 0.0019 - val_loss: 1.2931e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 623/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8878e-06 - rmse: 0.0022\n",
      "Epoch 623: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 4.3194e-06 - rmse: 0.0021 - val_loss: 1.2686e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 624/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6185e-06 - rmse: 0.0021\n",
      "Epoch 624: val_loss improved from 0.00013 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.0626e-06 - rmse: 0.0020 - val_loss: 1.2467e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 625/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6792e-06 - rmse: 0.0016\n",
      "Epoch 625: val_loss improved from 0.00012 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9739e-06 - rmse: 0.0022 - val_loss: 1.2411e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 626/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8264e-06 - rmse: 0.0020\n",
      "Epoch 626: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4374e-06 - rmse: 0.0019 - val_loss: 1.2687e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 627/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4581e-06 - rmse: 0.0016\n",
      "Epoch 627: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7288e-06 - rmse: 0.0017 - val_loss: 1.2818e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 628/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6175e-06 - rmse: 0.0019\n",
      "Epoch 628: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3540e-06 - rmse: 0.0018 - val_loss: 1.2652e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 629/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1190e-06 - rmse: 0.0015\n",
      "Epoch 629: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2982e-06 - rmse: 0.0018 - val_loss: 1.2694e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 630/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2873e-06 - rmse: 0.0015\n",
      "Epoch 630: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4371e-06 - rmse: 0.0019 - val_loss: 1.2660e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 631/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0360e-06 - rmse: 0.0010\n",
      "Epoch 631: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0868e-06 - rmse: 0.0020 - val_loss: 1.2693e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 632/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3677e-06 - rmse: 0.0015\n",
      "Epoch 632: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2192e-06 - rmse: 0.0023 - val_loss: 1.3013e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 633/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4122e-06 - rmse: 0.0027\n",
      "Epoch 633: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0157e-06 - rmse: 0.0025 - val_loss: 1.2685e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 634/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0394e-06 - rmse: 0.0025\n",
      "Epoch 634: val_loss improved from 0.00012 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6413e-06 - rmse: 0.0024 - val_loss: 1.1978e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 635/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6599e-06 - rmse: 0.0016\n",
      "Epoch 635: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3671e-06 - rmse: 0.0021 - val_loss: 1.2589e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 636/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8441e-06 - rmse: 0.0022\n",
      "Epoch 636: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1859e-06 - rmse: 0.0020 - val_loss: 1.2651e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 637/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1465e-06 - rmse: 0.0018\n",
      "Epoch 637: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6764e-06 - rmse: 0.0016 - val_loss: 1.3282e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 638/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9671e-06 - rmse: 0.0014\n",
      "Epoch 638: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0908e-06 - rmse: 0.0020 - val_loss: 1.3453e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 639/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0085e-06 - rmse: 0.0022\n",
      "Epoch 639: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8294e-06 - rmse: 0.0020 - val_loss: 1.2937e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 640/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9422e-06 - rmse: 0.0014\n",
      "Epoch 640: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8892e-06 - rmse: 0.0017 - val_loss: 1.2556e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 641/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2427e-06 - rmse: 0.0023\n",
      "Epoch 641: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8835e-06 - rmse: 0.0017 - val_loss: 1.2522e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 642/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1882e-06 - rmse: 0.0015\n",
      "Epoch 642: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4351e-06 - rmse: 0.0016 - val_loss: 1.2649e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 643/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2099e-06 - rmse: 0.0011\n",
      "Epoch 643: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2524e-06 - rmse: 0.0018 - val_loss: 1.2685e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 644/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0479e-06 - rmse: 0.0014\n",
      "Epoch 644: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4447e-06 - rmse: 0.0016 - val_loss: 1.2561e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 645/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4648e-06 - rmse: 0.0016\n",
      "Epoch 645: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0270e-06 - rmse: 0.0017 - val_loss: 1.2670e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 646/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0604e-06 - rmse: 0.0020\n",
      "Epoch 646: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1146e-06 - rmse: 0.0018 - val_loss: 1.2593e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 647/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5291e-06 - rmse: 0.0016\n",
      "Epoch 647: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8920e-06 - rmse: 0.0020 - val_loss: 1.2996e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 648/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0774e-06 - rmse: 0.0018\n",
      "Epoch 648: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4694e-06 - rmse: 0.0023 - val_loss: 1.3580e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 649/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9438e-06 - rmse: 0.0026\n",
      "Epoch 649: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6850e-06 - rmse: 0.0022 - val_loss: 1.3432e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 650/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0986e-06 - rmse: 0.0018\n",
      "Epoch 650: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7636e-06 - rmse: 0.0024 - val_loss: 1.2795e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 651/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7663e-06 - rmse: 0.0013\n",
      "Epoch 651: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0904e-06 - rmse: 0.0023 - val_loss: 1.2672e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 652/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2873e-06 - rmse: 0.0011\n",
      "Epoch 652: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9423e-06 - rmse: 0.0024 - val_loss: 1.2719e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 653/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4715e-06 - rmse: 0.0029\n",
      "Epoch 653: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4897e-06 - rmse: 0.0023 - val_loss: 1.2644e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 654/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8926e-06 - rmse: 0.0026\n",
      "Epoch 654: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.0534e-06 - rmse: 0.0022 - val_loss: 1.2374e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 655/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5284e-06 - rmse: 0.0021\n",
      "Epoch 655: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5957e-06 - rmse: 0.0019 - val_loss: 1.2953e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 656/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9648e-06 - rmse: 0.0022\n",
      "Epoch 656: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5868e-06 - rmse: 0.0019 - val_loss: 1.2508e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 657/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2317e-06 - rmse: 0.0023\n",
      "Epoch 657: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6963e-06 - rmse: 0.0022 - val_loss: 1.3017e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 658/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2766e-06 - rmse: 0.0025\n",
      "Epoch 658: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8100e-06 - rmse: 0.0022 - val_loss: 1.2574e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 659/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7692e-06 - rmse: 0.0017\n",
      "Epoch 659: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4737e-06 - rmse: 0.0021 - val_loss: 1.2458e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 660/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5382e-06 - rmse: 0.0021\n",
      "Epoch 660: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4852e-06 - rmse: 0.0016 - val_loss: 1.2158e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 661/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7066e-06 - rmse: 0.0016\n",
      "Epoch 661: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8976e-06 - rmse: 0.0017 - val_loss: 1.2428e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 662/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8798e-06 - rmse: 0.0014\n",
      "Epoch 662: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2495e-06 - rmse: 0.0015 - val_loss: 1.2224e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 663/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3547e-06 - rmse: 0.0012\n",
      "Epoch 663: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9915e-06 - rmse: 0.0014 - val_loss: 1.2200e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 664/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7378e-06 - rmse: 0.0013\n",
      "Epoch 664: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2075e-06 - rmse: 0.0015 - val_loss: 1.2263e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 665/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3271e-06 - rmse: 0.0012\n",
      "Epoch 665: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4399e-06 - rmse: 0.0016 - val_loss: 1.2482e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 666/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8082e-06 - rmse: 0.0013\n",
      "Epoch 666: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1418e-06 - rmse: 0.0015 - val_loss: 1.2501e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 667/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9991e-06 - rmse: 0.0014\n",
      "Epoch 667: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8687e-06 - rmse: 0.0014 - val_loss: 1.2306e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 668/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3368e-06 - rmse: 0.0015\n",
      "Epoch 668: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0529e-06 - rmse: 0.0014 - val_loss: 1.2165e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 669/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1394e-06 - rmse: 0.0015\n",
      "Epoch 669: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4160e-06 - rmse: 0.0016 - val_loss: 1.2307e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 670/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1850e-06 - rmse: 0.0011\n",
      "Epoch 670: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6650e-06 - rmse: 0.0013 - val_loss: 1.2095e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 671/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6703e-06 - rmse: 0.0013\n",
      "Epoch 671: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1271e-06 - rmse: 0.0015 - val_loss: 1.2015e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 672/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5094e-06 - rmse: 0.0016\n",
      "Epoch 672: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8709e-06 - rmse: 0.0014 - val_loss: 1.2012e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 673/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4927e-06 - rmse: 0.0012\n",
      "Epoch 673: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9959e-06 - rmse: 0.0014 - val_loss: 1.2125e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 674/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9649e-06 - rmse: 0.0017\n",
      "Epoch 674: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9791e-06 - rmse: 0.0017 - val_loss: 1.2153e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 675/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4577e-06 - rmse: 0.0012\n",
      "Epoch 675: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.6791e-06 - rmse: 0.0022 - val_loss: 1.2194e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 676/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1667e-06 - rmse: 0.0027\n",
      "Epoch 676: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4482e-06 - rmse: 0.0021 - val_loss: 1.2394e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 677/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9273e-06 - rmse: 0.0024\n",
      "Epoch 677: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4966e-06 - rmse: 0.0019 - val_loss: 1.2297e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 678/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0728e-06 - rmse: 0.0018\n",
      "Epoch 678: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8998e-06 - rmse: 0.0017 - val_loss: 1.2294e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 679/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1745e-06 - rmse: 0.0015\n",
      "Epoch 679: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8551e-06 - rmse: 0.0014 - val_loss: 1.2632e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 680/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4225e-06 - rmse: 0.0019\n",
      "Epoch 680: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7247e-06 - rmse: 0.0017 - val_loss: 1.2530e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 681/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1236e-06 - rmse: 0.0011\n",
      "Epoch 681: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3100e-06 - rmse: 0.0015 - val_loss: 1.2202e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 682/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2811e-06 - rmse: 0.0015\n",
      "Epoch 682: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9129e-06 - rmse: 0.0014 - val_loss: 1.2126e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 683/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5065e-06 - rmse: 0.0012\n",
      "Epoch 683: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5012e-06 - rmse: 0.0012 - val_loss: 1.2188e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 684/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8298e-07 - rmse: 9.9145e-04\n",
      "Epoch 684: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7355e-06 - rmse: 0.0013 - val_loss: 1.2484e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 685/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0638e-07 - rmse: 8.9799e-04\n",
      "Epoch 685: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4831e-06 - rmse: 0.0012 - val_loss: 1.2311e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 686/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4553e-06 - rmse: 0.0012\n",
      "Epoch 686: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6848e-06 - rmse: 0.0013 - val_loss: 1.2294e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 687/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4375e-06 - rmse: 0.0012\n",
      "Epoch 687: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6194e-06 - rmse: 0.0013 - val_loss: 1.2294e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 688/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3783e-06 - rmse: 0.0012\n",
      "Epoch 688: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6254e-06 - rmse: 0.0013 - val_loss: 1.2188e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 689/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3632e-06 - rmse: 0.0012\n",
      "Epoch 689: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5996e-06 - rmse: 0.0013 - val_loss: 1.2056e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 690/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4260e-06 - rmse: 0.0012\n",
      "Epoch 690: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4155e-06 - rmse: 0.0012 - val_loss: 1.2453e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 691/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7381e-07 - rmse: 8.2086e-04\n",
      "Epoch 691: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3122e-06 - rmse: 0.0011 - val_loss: 1.2389e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 692/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1629e-06 - rmse: 0.0011\n",
      "Epoch 692: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3055e-06 - rmse: 0.0011 - val_loss: 1.2221e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 693/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1467e-06 - rmse: 0.0011\n",
      "Epoch 693: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6443e-06 - rmse: 0.0013 - val_loss: 1.2301e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 694/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7813e-06 - rmse: 0.0013\n",
      "Epoch 694: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6019e-06 - rmse: 0.0013 - val_loss: 1.2209e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 695/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7910e-06 - rmse: 0.0013\n",
      "Epoch 695: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8079e-06 - rmse: 0.0013 - val_loss: 1.2244e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 696/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1961e-06 - rmse: 0.0011\n",
      "Epoch 696: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4571e-06 - rmse: 0.0012 - val_loss: 1.1982e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 697/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8392e-07 - rmse: 9.4017e-04\n",
      "Epoch 697: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2384e-06 - rmse: 0.0011 - val_loss: 1.2014e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 698/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4520e-06 - rmse: 0.0012\n",
      "Epoch 698: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2511e-06 - rmse: 0.0011 - val_loss: 1.2029e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 699/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1448e-06 - rmse: 0.0015\n",
      "Epoch 699: val_loss improved from 0.00012 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1.4565e-06 - rmse: 0.0012 - val_loss: 1.1921e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 700/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2094e-06 - rmse: 0.0011\n",
      "Epoch 700: val_loss improved from 0.00012 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.6347e-06 - rmse: 0.0013 - val_loss: 1.1904e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 701/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2588e-06 - rmse: 0.0011\n",
      "Epoch 701: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3553e-06 - rmse: 0.0015 - val_loss: 1.2117e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 702/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6878e-06 - rmse: 0.0019\n",
      "Epoch 702: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0752e-06 - rmse: 0.0014 - val_loss: 1.1946e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 703/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7646e-06 - rmse: 0.0013\n",
      "Epoch 703: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2140e-06 - rmse: 0.0011 - val_loss: 1.2136e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 704/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1143e-06 - rmse: 0.0011\n",
      "Epoch 704: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1505e-06 - rmse: 0.0011 - val_loss: 1.2132e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 705/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6670e-06 - rmse: 0.0013\n",
      "Epoch 705: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1301e-06 - rmse: 0.0011 - val_loss: 1.2210e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 706/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3925e-07 - rmse: 9.6915e-04\n",
      "Epoch 706: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1964e-06 - rmse: 0.0011 - val_loss: 1.2086e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 707/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4370e-06 - rmse: 0.0012\n",
      "Epoch 707: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4041e-06 - rmse: 0.0012 - val_loss: 1.2080e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 708/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2191e-06 - rmse: 0.0015\n",
      "Epoch 708: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9874e-06 - rmse: 0.0014 - val_loss: 1.2217e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 709/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7172e-06 - rmse: 0.0013\n",
      "Epoch 709: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6550e-06 - rmse: 0.0013 - val_loss: 1.2071e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 710/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3724e-06 - rmse: 0.0012\n",
      "Epoch 710: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8674e-06 - rmse: 0.0014 - val_loss: 1.2180e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 711/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7773e-07 - rmse: 9.3687e-04\n",
      "Epoch 711: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1029e-06 - rmse: 0.0018 - val_loss: 1.1908e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 712/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3384e-06 - rmse: 0.0012\n",
      "Epoch 712: val_loss improved from 0.00012 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3978e-06 - rmse: 0.0015 - val_loss: 1.1809e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 713/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6461e-06 - rmse: 0.0016\n",
      "Epoch 713: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4080e-06 - rmse: 0.0018 - val_loss: 1.2182e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 714/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1918e-06 - rmse: 0.0011\n",
      "Epoch 714: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8987e-06 - rmse: 0.0014 - val_loss: 1.2089e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 715/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1315e-06 - rmse: 0.0011\n",
      "Epoch 715: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3092e-06 - rmse: 0.0011 - val_loss: 1.1943e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 716/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3470e-07 - rmse: 7.3123e-04\n",
      "Epoch 716: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3098e-06 - rmse: 0.0011 - val_loss: 1.1892e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 717/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2174e-07 - rmse: 8.4955e-04\n",
      "Epoch 717: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0003e-06 - rmse: 0.0010 - val_loss: 1.1949e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 718/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5886e-07 - rmse: 9.7921e-04\n",
      "Epoch 718: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2688e-06 - rmse: 0.0011 - val_loss: 1.2260e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 719/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3900e-06 - rmse: 0.0012\n",
      "Epoch 719: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1018e-06 - rmse: 0.0014 - val_loss: 1.2021e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5731e-06 - rmse: 0.0013\n",
      "Epoch 720: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2976e-06 - rmse: 0.0011 - val_loss: 1.1977e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 721/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6961e-06 - rmse: 0.0013\n",
      "Epoch 721: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2523e-06 - rmse: 0.0011 - val_loss: 1.2084e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 722/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0239e-06 - rmse: 0.0017\n",
      "Epoch 722: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9546e-06 - rmse: 0.0014 - val_loss: 1.2240e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 723/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7005e-06 - rmse: 0.0019\n",
      "Epoch 723: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7597e-06 - rmse: 0.0017 - val_loss: 1.1996e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 724/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6960e-06 - rmse: 0.0024\n",
      "Epoch 724: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8162e-06 - rmse: 0.0017 - val_loss: 1.2227e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 725/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5772e-06 - rmse: 0.0013\n",
      "Epoch 725: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8146e-06 - rmse: 0.0013 - val_loss: 1.2303e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 726/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8518e-06 - rmse: 0.0014\n",
      "Epoch 726: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3522e-06 - rmse: 0.0015 - val_loss: 1.1856e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 727/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1431e-06 - rmse: 0.0011\n",
      "Epoch 727: val_loss improved from 0.00012 to 0.00012, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.3920e-06 - rmse: 0.0018 - val_loss: 1.1535e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 728/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1323e-06 - rmse: 0.0018\n",
      "Epoch 728: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6506e-06 - rmse: 0.0019 - val_loss: 1.1579e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 729/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5599e-06 - rmse: 0.0016\n",
      "Epoch 729: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6392e-06 - rmse: 0.0016 - val_loss: 1.1914e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 730/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0785e-06 - rmse: 0.0010\n",
      "Epoch 730: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7323e-06 - rmse: 0.0013 - val_loss: 1.1929e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 731/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8161e-07 - rmse: 8.8409e-04\n",
      "Epoch 731: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2148e-06 - rmse: 0.0011 - val_loss: 1.1558e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 732/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6368e-07 - rmse: 9.8167e-04\n",
      "Epoch 732: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2880e-06 - rmse: 0.0011 - val_loss: 1.1570e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 733/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2897e-07 - rmse: 9.6383e-04\n",
      "Epoch 733: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3425e-06 - rmse: 0.0012 - val_loss: 1.1918e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 734/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6902e-06 - rmse: 0.0013\n",
      "Epoch 734: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0887e-06 - rmse: 0.0010 - val_loss: 1.2040e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 735/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0087e-06 - rmse: 0.0010\n",
      "Epoch 735: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1395e-06 - rmse: 0.0011 - val_loss: 1.1817e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 736/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4829e-07 - rmse: 9.2103e-04\n",
      "Epoch 736: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1253e-06 - rmse: 0.0011 - val_loss: 1.1751e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 737/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3675e-06 - rmse: 0.0012\n",
      "Epoch 737: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5391e-06 - rmse: 0.0012 - val_loss: 1.1978e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 738/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6362e-07 - rmse: 9.8164e-04\n",
      "Epoch 738: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1598e-06 - rmse: 0.0011 - val_loss: 1.1959e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 739/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5568e-07 - rmse: 8.6930e-04\n",
      "Epoch 739: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5331e-07 - rmse: 9.7638e-04 - val_loss: 1.1872e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 740/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3983e-06 - rmse: 0.0012\n",
      "Epoch 740: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5886e-06 - rmse: 0.0013 - val_loss: 1.1796e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 741/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3419e-07 - rmse: 7.9636e-04\n",
      "Epoch 741: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2909e-06 - rmse: 0.0011 - val_loss: 1.1615e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 742/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7104e-06 - rmse: 0.0013\n",
      "Epoch 742: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3587e-06 - rmse: 0.0012 - val_loss: 1.1727e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 743/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0512e-06 - rmse: 0.0010\n",
      "Epoch 743: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0336e-06 - rmse: 0.0010 - val_loss: 1.1857e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 744/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7928e-07 - rmse: 6.9230e-04\n",
      "Epoch 744: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0354e-06 - rmse: 0.0010 - val_loss: 1.1856e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 745/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4538e-07 - rmse: 6.6737e-04\n",
      "Epoch 745: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5938e-06 - rmse: 0.0013 - val_loss: 1.1892e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 746/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7754e-07 - rmse: 6.9104e-04\n",
      "Epoch 746: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8963e-06 - rmse: 0.0014 - val_loss: 1.1907e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 747/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1296e-06 - rmse: 0.0015\n",
      "Epoch 747: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3635e-06 - rmse: 0.0015 - val_loss: 1.2005e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 748/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7182e-06 - rmse: 0.0013\n",
      "Epoch 748: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1741e-06 - rmse: 0.0015 - val_loss: 1.1855e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 749/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0611e-07 - rmse: 9.5190e-04\n",
      "Epoch 749: val_loss did not improve from 0.00012\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0721e-06 - rmse: 0.0014 - val_loss: 1.1906e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 750/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0773e-07 - rmse: 9.5275e-04\n",
      "Epoch 750: val_loss improved from 0.00012 to 0.00011, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.1785e-06 - rmse: 0.0015 - val_loss: 1.1307e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 751/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5670e-06 - rmse: 0.0013\n",
      "Epoch 751: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1346e-06 - rmse: 0.0015 - val_loss: 1.1309e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 752/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3526e-06 - rmse: 0.0012\n",
      "Epoch 752: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3019e-06 - rmse: 0.0015 - val_loss: 1.1355e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 753/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6776e-07 - rmse: 8.7622e-04\n",
      "Epoch 753: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1925e-06 - rmse: 0.0015 - val_loss: 1.2035e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 754/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7642e-06 - rmse: 0.0024\n",
      "Epoch 754: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1942e-06 - rmse: 0.0027 - val_loss: 1.1911e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 755/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6774e-06 - rmse: 0.0019\n",
      "Epoch 755: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4257e-05 - rmse: 0.0038 - val_loss: 1.3807e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 756/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1440e-05 - rmse: 0.0034\n",
      "Epoch 756: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4990e-05 - rmse: 0.0039 - val_loss: 1.3943e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 757/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7164e-06 - rmse: 0.0024\n",
      "Epoch 757: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9143e-05 - rmse: 0.0044 - val_loss: 1.4624e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 758/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2122e-05 - rmse: 0.0035\n",
      "Epoch 758: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9443e-05 - rmse: 0.0044 - val_loss: 1.3095e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 759/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1137e-05 - rmse: 0.0033\n",
      "Epoch 759: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1974e-05 - rmse: 0.0047 - val_loss: 1.2864e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 760/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9518e-05 - rmse: 0.0044\n",
      "Epoch 760: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4717e-05 - rmse: 0.0050 - val_loss: 1.4668e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 761/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7395e-05 - rmse: 0.0052\n",
      "Epoch 761: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6407e-05 - rmse: 0.0051 - val_loss: 1.4217e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 762/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7724e-05 - rmse: 0.0042\n",
      "Epoch 762: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2866e-05 - rmse: 0.0036 - val_loss: 1.4699e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 763/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0250e-05 - rmse: 0.0032\n",
      "Epoch 763: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1565e-05 - rmse: 0.0034 - val_loss: 1.3242e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 764/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4546e-05 - rmse: 0.0038\n",
      "Epoch 764: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1423e-06 - rmse: 0.0029 - val_loss: 1.1759e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 765/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0355e-06 - rmse: 0.0020\n",
      "Epoch 765: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5484e-06 - rmse: 0.0024 - val_loss: 1.2025e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 766/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7746e-06 - rmse: 0.0022\n",
      "Epoch 766: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4495e-06 - rmse: 0.0023 - val_loss: 1.3287e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 767/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8424e-06 - rmse: 0.0028\n",
      "Epoch 767: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9545e-06 - rmse: 0.0024 - val_loss: 1.3050e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 768/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5991e-06 - rmse: 0.0021\n",
      "Epoch 768: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1571e-06 - rmse: 0.0018 - val_loss: 1.1752e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 769/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8968e-06 - rmse: 0.0017\n",
      "Epoch 769: val_loss improved from 0.00011 to 0.00011, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.0828e-06 - rmse: 0.0018 - val_loss: 1.1304e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 770/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6862e-06 - rmse: 0.0016\n",
      "Epoch 770: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9230e-06 - rmse: 0.0014 - val_loss: 1.1677e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 771/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2843e-07 - rmse: 9.1018e-04\n",
      "Epoch 771: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5168e-06 - rmse: 0.0012 - val_loss: 1.2225e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 772/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1134e-06 - rmse: 0.0011\n",
      "Epoch 772: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6410e-06 - rmse: 0.0013 - val_loss: 1.2575e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 773/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8280e-07 - rmse: 8.2631e-04\n",
      "Epoch 773: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0099e-06 - rmse: 0.0010 - val_loss: 1.2101e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 774/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9727e-06 - rmse: 0.0014\n",
      "Epoch 774: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6655e-06 - rmse: 0.0013 - val_loss: 1.1489e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 775/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8266e-06 - rmse: 0.0014\n",
      "Epoch 775: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3306e-06 - rmse: 0.0012 - val_loss: 1.1571e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 776/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8191e-06 - rmse: 0.0013\n",
      "Epoch 776: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0772e-06 - rmse: 0.0010 - val_loss: 1.1950e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 777/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2375e-06 - rmse: 0.0011\n",
      "Epoch 777: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.1817e-06 - rmse: 0.0011 - val_loss: 1.2099e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 778/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3307e-07 - rmse: 8.5620e-04\n",
      "Epoch 778: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0459e-06 - rmse: 0.0010 - val_loss: 1.1606e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 779/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1044e-07 - rmse: 9.0024e-04\n",
      "Epoch 779: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3936e-06 - rmse: 0.0012 - val_loss: 1.1417e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 780/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8415e-06 - rmse: 0.0014\n",
      "Epoch 780: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8634e-06 - rmse: 0.0014 - val_loss: 1.1620e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6738e-06 - rmse: 0.0013\n",
      "Epoch 781: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2154e-06 - rmse: 0.0011 - val_loss: 1.1802e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 782/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4426e-07 - rmse: 6.6653e-04\n",
      "Epoch 782: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0075e-06 - rmse: 0.0010 - val_loss: 1.2042e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 783/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4069e-07 - rmse: 8.0043e-04\n",
      "Epoch 783: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1645e-06 - rmse: 0.0011 - val_loss: 1.2126e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 784/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8440e-07 - rmse: 9.4043e-04\n",
      "Epoch 784: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6864e-06 - rmse: 0.0013 - val_loss: 1.1826e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 785/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4431e-07 - rmse: 8.6273e-04\n",
      "Epoch 785: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8440e-06 - rmse: 0.0014 - val_loss: 1.1630e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 786/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8737e-07 - rmse: 9.4200e-04\n",
      "Epoch 786: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3131e-06 - rmse: 0.0015 - val_loss: 1.1967e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 787/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3864e-06 - rmse: 0.0012\n",
      "Epoch 787: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0207e-06 - rmse: 0.0014 - val_loss: 1.1728e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 788/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1472e-06 - rmse: 0.0015\n",
      "Epoch 788: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7530e-06 - rmse: 0.0013 - val_loss: 1.1587e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 789/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8010e-06 - rmse: 0.0017\n",
      "Epoch 789: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7192e-06 - rmse: 0.0016 - val_loss: 1.1896e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 790/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7501e-06 - rmse: 0.0022\n",
      "Epoch 790: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5726e-06 - rmse: 0.0016 - val_loss: 1.1688e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 791/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9472e-06 - rmse: 0.0017\n",
      "Epoch 791: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3191e-06 - rmse: 0.0015 - val_loss: 1.1620e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 792/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1241e-06 - rmse: 0.0011\n",
      "Epoch 792: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4665e-06 - rmse: 0.0016 - val_loss: 1.1423e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 793/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1706e-06 - rmse: 0.0011\n",
      "Epoch 793: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3288e-06 - rmse: 0.0015 - val_loss: 1.2004e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 794/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0448e-06 - rmse: 0.0010\n",
      "Epoch 794: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9263e-06 - rmse: 0.0017 - val_loss: 1.2676e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 795/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5610e-06 - rmse: 0.0016\n",
      "Epoch 795: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6387e-06 - rmse: 0.0019 - val_loss: 1.2603e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 796/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3234e-05 - rmse: 0.0036\n",
      "Epoch 796: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7759e-06 - rmse: 0.0024 - val_loss: 1.2581e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 797/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5435e-06 - rmse: 0.0026\n",
      "Epoch 797: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7162e-06 - rmse: 0.0019 - val_loss: 1.2046e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 798/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4940e-06 - rmse: 0.0021\n",
      "Epoch 798: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5508e-06 - rmse: 0.0019 - val_loss: 1.2447e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 799/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4909e-06 - rmse: 0.0012\n",
      "Epoch 799: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9518e-06 - rmse: 0.0022 - val_loss: 1.2300e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 800/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0370e-05 - rmse: 0.0032\n",
      "Epoch 800: val_loss improved from 0.00011 to 0.00011, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7325e-06 - rmse: 0.0024 - val_loss: 1.0702e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 801/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6494e-06 - rmse: 0.0019\n",
      "Epoch 801: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1726e-06 - rmse: 0.0020 - val_loss: 1.0894e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 802/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7868e-06 - rmse: 0.0019\n",
      "Epoch 802: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1718e-06 - rmse: 0.0015 - val_loss: 1.1762e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 803/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5700e-06 - rmse: 0.0016\n",
      "Epoch 803: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3209e-06 - rmse: 0.0015 - val_loss: 1.2145e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 804/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9019e-06 - rmse: 0.0014\n",
      "Epoch 804: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2561e-06 - rmse: 0.0011 - val_loss: 1.1841e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 805/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5633e-06 - rmse: 0.0013\n",
      "Epoch 805: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1932e-06 - rmse: 0.0011 - val_loss: 1.1427e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 806/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0699e-07 - rmse: 8.4083e-04\n",
      "Epoch 806: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1378e-06 - rmse: 0.0011 - val_loss: 1.2062e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 807/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7979e-07 - rmse: 9.3797e-04\n",
      "Epoch 807: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0295e-06 - rmse: 0.0010 - val_loss: 1.2057e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 808/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0629e-07 - rmse: 8.9794e-04\n",
      "Epoch 808: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3400e-07 - rmse: 9.1324e-04 - val_loss: 1.1760e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 809/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2028e-06 - rmse: 0.0011\n",
      "Epoch 809: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1353e-06 - rmse: 0.0011 - val_loss: 1.1425e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 810/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3629e-07 - rmse: 9.6762e-04\n",
      "Epoch 810: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0277e-06 - rmse: 0.0010 - val_loss: 1.1566e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 811/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.0552e-07 - rmse: 9.5159e-04\n",
      "Epoch 811: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0505e-06 - rmse: 0.0010 - val_loss: 1.1750e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 812/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3715e-07 - rmse: 6.6117e-04\n",
      "Epoch 812: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.7004e-07 - rmse: 8.7752e-04 - val_loss: 1.2003e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 813/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9188e-07 - rmse: 8.8988e-04\n",
      "Epoch 813: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3640e-06 - rmse: 0.0012 - val_loss: 1.2102e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 814/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4287e-06 - rmse: 0.0012\n",
      "Epoch 814: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3271e-06 - rmse: 0.0012 - val_loss: 1.1943e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 815/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1136e-07 - rmse: 7.1510e-04\n",
      "Epoch 815: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1246e-06 - rmse: 0.0011 - val_loss: 1.1685e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 816/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7890e-06 - rmse: 0.0013\n",
      "Epoch 816: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2983e-06 - rmse: 0.0015 - val_loss: 1.1922e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 817/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7617e-06 - rmse: 0.0013\n",
      "Epoch 817: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5076e-06 - rmse: 0.0019 - val_loss: 1.2703e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 818/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6541e-06 - rmse: 0.0026\n",
      "Epoch 818: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5125e-06 - rmse: 0.0023 - val_loss: 1.2411e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 819/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2812e-06 - rmse: 0.0015\n",
      "Epoch 819: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4729e-06 - rmse: 0.0021 - val_loss: 1.1750e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 820/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0966e-06 - rmse: 0.0010\n",
      "Epoch 820: val_loss improved from 0.00011 to 0.00011, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.7322e-06 - rmse: 0.0017 - val_loss: 1.0644e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 821/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4702e-06 - rmse: 0.0012\n",
      "Epoch 821: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2445e-06 - rmse: 0.0015 - val_loss: 1.0819e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 822/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5993e-06 - rmse: 0.0013\n",
      "Epoch 822: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7380e-06 - rmse: 0.0013 - val_loss: 1.1640e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 823/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1312e-06 - rmse: 0.0011\n",
      "Epoch 823: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0775e-06 - rmse: 0.0010 - val_loss: 1.2128e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 824/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9966e-07 - rmse: 9.4850e-04\n",
      "Epoch 824: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1417e-06 - rmse: 0.0011 - val_loss: 1.1866e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 825/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9643e-06 - rmse: 0.0014\n",
      "Epoch 825: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1726e-06 - rmse: 0.0011 - val_loss: 1.1012e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 826/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8761e-07 - rmse: 8.2922e-04\n",
      "Epoch 826: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2157e-06 - rmse: 0.0011 - val_loss: 1.1028e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 827/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1276e-06 - rmse: 0.0011\n",
      "Epoch 827: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2589e-06 - rmse: 0.0011 - val_loss: 1.1229e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 828/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0679e-07 - rmse: 8.9821e-04\n",
      "Epoch 828: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0697e-06 - rmse: 0.0010 - val_loss: 1.1241e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 829/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0733e-06 - rmse: 0.0010\n",
      "Epoch 829: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.4177e-07 - rmse: 9.7045e-04 - val_loss: 1.1315e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 830/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1836e-07 - rmse: 6.4680e-04\n",
      "Epoch 830: val_loss did not improve from 0.00011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2859e-06 - rmse: 0.0011 - val_loss: 1.1338e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 831/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1864e-07 - rmse: 9.0479e-04\n",
      "Epoch 831: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0401e-06 - rmse: 0.0014 - val_loss: 1.1403e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 832/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1143e-06 - rmse: 0.0020\n",
      "Epoch 832: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8371e-06 - rmse: 0.0017 - val_loss: 1.1262e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 833/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3987e-07 - rmse: 7.9992e-04\n",
      "Epoch 833: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4830e-06 - rmse: 0.0012 - val_loss: 1.2056e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 834/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5657e-07 - rmse: 9.7805e-04\n",
      "Epoch 834: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7978e-06 - rmse: 0.0013 - val_loss: 1.2247e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 835/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3057e-06 - rmse: 0.0015\n",
      "Epoch 835: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0863e-06 - rmse: 0.0014 - val_loss: 1.1369e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 836/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6109e-06 - rmse: 0.0016\n",
      "Epoch 836: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4513e-06 - rmse: 0.0012 - val_loss: 1.0698e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 837/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8360e-06 - rmse: 0.0014\n",
      "Epoch 837: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1184e-06 - rmse: 0.0011 - val_loss: 1.0887e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 838/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5012e-07 - rmse: 6.7091e-04\n",
      "Epoch 838: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2191e-06 - rmse: 0.0011 - val_loss: 1.1521e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 839/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6086e-07 - rmse: 9.8023e-04\n",
      "Epoch 839: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0710e-06 - rmse: 0.0010 - val_loss: 1.0977e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 840/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7918e-07 - rmse: 6.9222e-04\n",
      "Epoch 840: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2528e-06 - rmse: 0.0011 - val_loss: 1.1164e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 841/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4689e-06 - rmse: 0.0016\n",
      "Epoch 841: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8866e-06 - rmse: 0.0014 - val_loss: 1.1010e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 842/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0010e-06 - rmse: 0.0010\n",
      "Epoch 842: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5126e-06 - rmse: 0.0012 - val_loss: 1.1476e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 843/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6570e-07 - rmse: 8.1590e-04\n",
      "Epoch 843: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2743e-06 - rmse: 0.0011 - val_loss: 1.1597e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 844/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5497e-06 - rmse: 0.0024\n",
      "Epoch 844: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0032e-06 - rmse: 0.0017 - val_loss: 1.1192e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 845/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5432e-06 - rmse: 0.0012\n",
      "Epoch 845: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5194e-06 - rmse: 0.0012 - val_loss: 1.1711e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 846/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0633e-07 - rmse: 8.9796e-04\n",
      "Epoch 846: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9847e-06 - rmse: 0.0014 - val_loss: 1.1517e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 847/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8103e-06 - rmse: 0.0013\n",
      "Epoch 847: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9377e-06 - rmse: 0.0017 - val_loss: 1.1008e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 848/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2701e-06 - rmse: 0.0018\n",
      "Epoch 848: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9621e-06 - rmse: 0.0017 - val_loss: 1.1639e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 849/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4507e-06 - rmse: 0.0016\n",
      "Epoch 849: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0645e-06 - rmse: 0.0020 - val_loss: 1.1597e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 850/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2159e-06 - rmse: 0.0018\n",
      "Epoch 850: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2824e-06 - rmse: 0.0015 - val_loss: 1.1327e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 851/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9930e-06 - rmse: 0.0017\n",
      "Epoch 851: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0464e-06 - rmse: 0.0017 - val_loss: 1.0709e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 852/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1591e-07 - rmse: 8.4612e-04\n",
      "Epoch 852: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8131e-06 - rmse: 0.0013 - val_loss: 1.1154e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 853/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0057e-06 - rmse: 0.0014\n",
      "Epoch 853: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3578e-06 - rmse: 0.0018 - val_loss: 1.1556e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 854/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7963e-06 - rmse: 0.0019\n",
      "Epoch 854: val_loss improved from 0.00011 to 0.00011, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.2834e-06 - rmse: 0.0015 - val_loss: 1.0518e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 855/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5967e-06 - rmse: 0.0013\n",
      "Epoch 855: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7870e-06 - rmse: 0.0013 - val_loss: 1.0887e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 856/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5437e-06 - rmse: 0.0012\n",
      "Epoch 856: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8494e-06 - rmse: 0.0014 - val_loss: 1.1718e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 857/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3348e-06 - rmse: 0.0021\n",
      "Epoch 857: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5349e-06 - rmse: 0.0016 - val_loss: 1.1898e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 858/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5457e-06 - rmse: 0.0012\n",
      "Epoch 858: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3543e-06 - rmse: 0.0012 - val_loss: 1.1342e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 859/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1674e-07 - rmse: 6.4555e-04\n",
      "Epoch 859: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3371e-06 - rmse: 0.0012 - val_loss: 1.0947e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 860/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0493e-06 - rmse: 0.0010\n",
      "Epoch 860: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1239e-06 - rmse: 0.0011 - val_loss: 1.1141e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 861/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6508e-07 - rmse: 7.5172e-04\n",
      "Epoch 861: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6551e-06 - rmse: 0.0013 - val_loss: 1.1739e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 862/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8005e-07 - rmse: 8.8320e-04\n",
      "Epoch 862: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0371e-06 - rmse: 0.0010 - val_loss: 1.1423e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 863/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6751e-07 - rmse: 6.0623e-04\n",
      "Epoch 863: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.0058e-07 - rmse: 7.7497e-04 - val_loss: 1.1021e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 864/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2059e-07 - rmse: 9.0586e-04\n",
      "Epoch 864: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4761e-07 - rmse: 8.6464e-04 - val_loss: 1.1139e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 865/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8053e-07 - rmse: 6.9321e-04\n",
      "Epoch 865: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4795e-07 - rmse: 7.4024e-04 - val_loss: 1.1373e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 866/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7815e-08 - rmse: 3.1275e-04\n",
      "Epoch 866: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.7891e-07 - rmse: 8.2396e-04 - val_loss: 1.1374e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 867/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1889e-07 - rmse: 8.4787e-04\n",
      "Epoch 867: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1959e-07 - rmse: 8.4828e-04 - val_loss: 1.1135e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 868/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3522e-07 - rmse: 5.7898e-04\n",
      "Epoch 868: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2064e-06 - rmse: 0.0011 - val_loss: 1.1481e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 869/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1631e-06 - rmse: 0.0011\n",
      "Epoch 869: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4358e-06 - rmse: 0.0012 - val_loss: 1.1506e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 870/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5150e-06 - rmse: 0.0016\n",
      "Epoch 870: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0902e-06 - rmse: 0.0014 - val_loss: 1.0913e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 871/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6963e-07 - rmse: 8.1831e-04\n",
      "Epoch 871: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4649e-06 - rmse: 0.0012 - val_loss: 1.0993e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 872/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8049e-06 - rmse: 0.0013\n",
      "Epoch 872: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6053e-06 - rmse: 0.0013 - val_loss: 1.1500e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 873/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7979e-06 - rmse: 0.0019\n",
      "Epoch 873: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3311e-06 - rmse: 0.0015 - val_loss: 1.1626e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 874/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7835e-06 - rmse: 0.0013\n",
      "Epoch 874: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7995e-06 - rmse: 0.0017 - val_loss: 1.1425e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 875/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0478e-06 - rmse: 0.0014\n",
      "Epoch 875: val_loss did not improve from 0.00011\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5539e-06 - rmse: 0.0026 - val_loss: 1.1373e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 876/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0466e-05 - rmse: 0.0032\n",
      "Epoch 876: val_loss improved from 0.00011 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9923e-06 - rmse: 0.0028 - val_loss: 9.8161e-05 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 877/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9776e-06 - rmse: 0.0014\n",
      "Epoch 877: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8924e-06 - rmse: 0.0024 - val_loss: 1.0922e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 878/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5732e-06 - rmse: 0.0016\n",
      "Epoch 878: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4232e-06 - rmse: 0.0023 - val_loss: 1.2404e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 879/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1848e-06 - rmse: 0.0029\n",
      "Epoch 879: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7753e-06 - rmse: 0.0022 - val_loss: 1.2225e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 880/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6627e-06 - rmse: 0.0016\n",
      "Epoch 880: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0559e-06 - rmse: 0.0017 - val_loss: 1.0761e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 881/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8131e-06 - rmse: 0.0020\n",
      "Epoch 881: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3505e-06 - rmse: 0.0015 - val_loss: 1.1059e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 882/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5026e-07 - rmse: 5.9182e-04\n",
      "Epoch 882: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3332e-06 - rmse: 0.0012 - val_loss: 1.1539e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 883/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1991e-07 - rmse: 7.8734e-04\n",
      "Epoch 883: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5958e-06 - rmse: 0.0016 - val_loss: 1.2032e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 884/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9617e-06 - rmse: 0.0022\n",
      "Epoch 884: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9874e-06 - rmse: 0.0020 - val_loss: 1.1610e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 885/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8721e-06 - rmse: 0.0017\n",
      "Epoch 885: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1264e-06 - rmse: 0.0018 - val_loss: 1.1113e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0141e-06 - rmse: 0.0014\n",
      "Epoch 886: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3413e-06 - rmse: 0.0015 - val_loss: 1.2162e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 887/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7705e-06 - rmse: 0.0017\n",
      "Epoch 887: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8445e-06 - rmse: 0.0017 - val_loss: 1.2746e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 888/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4031e-06 - rmse: 0.0016\n",
      "Epoch 888: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0477e-06 - rmse: 0.0028 - val_loss: 1.3648e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 889/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0753e-05 - rmse: 0.0055\n",
      "Epoch 889: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2824e-05 - rmse: 0.0048 - val_loss: 1.2393e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 890/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2194e-05 - rmse: 0.0035\n",
      "Epoch 890: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4699e-05 - rmse: 0.0038 - val_loss: 1.3496e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 891/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2957e-05 - rmse: 0.0057\n",
      "Epoch 891: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4759e-05 - rmse: 0.0038 - val_loss: 1.2595e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 892/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0279e-06 - rmse: 0.0020\n",
      "Epoch 892: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8031e-06 - rmse: 0.0026 - val_loss: 1.2540e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 893/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2579e-06 - rmse: 0.0027\n",
      "Epoch 893: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.3880e-06 - rmse: 0.0027 - val_loss: 9.9270e-05 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 894/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5054e-06 - rmse: 0.0016\n",
      "Epoch 894: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7369e-06 - rmse: 0.0017 - val_loss: 1.0151e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 895/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4252e-06 - rmse: 0.0016\n",
      "Epoch 895: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9809e-06 - rmse: 0.0014 - val_loss: 1.1271e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 896/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5492e-06 - rmse: 0.0019\n",
      "Epoch 896: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5628e-06 - rmse: 0.0019 - val_loss: 1.0866e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 897/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1819e-06 - rmse: 0.0020\n",
      "Epoch 897: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1901e-06 - rmse: 0.0023 - val_loss: 1.0282e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 898/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6818e-06 - rmse: 0.0022\n",
      "Epoch 898: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.4430e-06 - rmse: 0.0019 - val_loss: 1.0275e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 899/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2278e-06 - rmse: 0.0021\n",
      "Epoch 899: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5752e-06 - rmse: 0.0021 - val_loss: 1.1110e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 900/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6605e-06 - rmse: 0.0019\n",
      "Epoch 900: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3961e-06 - rmse: 0.0015 - val_loss: 1.1074e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 901/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0330e-06 - rmse: 0.0014\n",
      "Epoch 901: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4133e-06 - rmse: 0.0025 - val_loss: 1.0406e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 902/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4186e-06 - rmse: 0.0016\n",
      "Epoch 902: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5572e-06 - rmse: 0.0021 - val_loss: 1.1613e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 903/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5051e-06 - rmse: 0.0027\n",
      "Epoch 903: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7003e-06 - rmse: 0.0026 - val_loss: 1.1612e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 904/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6343e-06 - rmse: 0.0022\n",
      "Epoch 904: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.2150e-06 - rmse: 0.0023 - val_loss: 1.1417e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 905/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0777e-06 - rmse: 0.0020\n",
      "Epoch 905: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5168e-06 - rmse: 0.0021 - val_loss: 1.2157e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 906/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3866e-05 - rmse: 0.0049\n",
      "Epoch 906: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0304e-05 - rmse: 0.0032 - val_loss: 1.1145e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 907/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7896e-06 - rmse: 0.0026\n",
      "Epoch 907: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5802e-06 - rmse: 0.0029 - val_loss: 1.2111e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 908/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0601e-05 - rmse: 0.0033\n",
      "Epoch 908: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3207e-06 - rmse: 0.0029 - val_loss: 1.0390e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 909/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5986e-06 - rmse: 0.0019\n",
      "Epoch 909: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4547e-06 - rmse: 0.0029 - val_loss: 1.0870e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 910/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2382e-05 - rmse: 0.0035\n",
      "Epoch 910: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0933e-05 - rmse: 0.0033 - val_loss: 1.1810e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 911/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4685e-05 - rmse: 0.0038\n",
      "Epoch 911: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5510e-06 - rmse: 0.0029 - val_loss: 1.2245e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 912/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3983e-05 - rmse: 0.0037\n",
      "Epoch 912: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2921e-05 - rmse: 0.0036 - val_loss: 1.0528e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 913/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2886e-05 - rmse: 0.0036\n",
      "Epoch 913: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6064e-05 - rmse: 0.0040 - val_loss: 1.1459e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 914/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5824e-05 - rmse: 0.0040\n",
      "Epoch 914: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3124e-05 - rmse: 0.0048 - val_loss: 1.7499e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 915/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5676e-05 - rmse: 0.0068\n",
      "Epoch 915: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9419e-05 - rmse: 0.0054 - val_loss: 2.0281e-04 - val_rmse: 0.0142 - lr: 1.0000e-04\n",
      "Epoch 916/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3693e-05 - rmse: 0.0086\n",
      "Epoch 916: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7613e-05 - rmse: 0.0069 - val_loss: 1.0278e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 917/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7567e-06 - rmse: 0.0030\n",
      "Epoch 917: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0174e-05 - rmse: 0.0032 - val_loss: 1.3153e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 918/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1944e-05 - rmse: 0.0035\n",
      "Epoch 918: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2392e-05 - rmse: 0.0035 - val_loss: 1.5899e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 919/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0739e-05 - rmse: 0.0033\n",
      "Epoch 919: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0331e-06 - rmse: 0.0028 - val_loss: 1.3942e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 920/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3042e-06 - rmse: 0.0029\n",
      "Epoch 920: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2027e-05 - rmse: 0.0035 - val_loss: 1.1593e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 921/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3468e-05 - rmse: 0.0037\n",
      "Epoch 921: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8078e-05 - rmse: 0.0043 - val_loss: 1.0556e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 922/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4772e-06 - rmse: 0.0027\n",
      "Epoch 922: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5165e-05 - rmse: 0.0039 - val_loss: 1.3210e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 923/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3686e-05 - rmse: 0.0058\n",
      "Epoch 923: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6936e-05 - rmse: 0.0052 - val_loss: 1.4660e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 924/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8694e-05 - rmse: 0.0054\n",
      "Epoch 924: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5671e-05 - rmse: 0.0068 - val_loss: 1.0061e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 925/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4601e-06 - rmse: 0.0029\n",
      "Epoch 925: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3306e-05 - rmse: 0.0058 - val_loss: 1.1570e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 926/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0898e-05 - rmse: 0.0046\n",
      "Epoch 926: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.3917e-05 - rmse: 0.0058 - val_loss: 1.4718e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 927/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2075e-05 - rmse: 0.0057\n",
      "Epoch 927: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0449e-05 - rmse: 0.0078 - val_loss: 1.2621e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 928/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5766e-05 - rmse: 0.0051\n",
      "Epoch 928: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3374e-05 - rmse: 0.0080 - val_loss: 1.7391e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 929/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5597e-05 - rmse: 0.0068\n",
      "Epoch 929: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1834e-04 - rmse: 0.0109 - val_loss: 1.9009e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 930/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9329e-05 - rmse: 0.0095\n",
      "Epoch 930: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1979e-04 - rmse: 0.0109 - val_loss: 1.6048e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 931/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0410e-04 - rmse: 0.0102\n",
      "Epoch 931: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1092e-04 - rmse: 0.0105 - val_loss: 1.5434e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 932/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6734e-05 - rmse: 0.0061\n",
      "Epoch 932: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2701e-05 - rmse: 0.0096 - val_loss: 1.1095e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 933/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8669e-05 - rmse: 0.0054\n",
      "Epoch 933: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8750e-05 - rmse: 0.0070 - val_loss: 1.2216e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 934/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6548e-05 - rmse: 0.0082\n",
      "Epoch 934: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1184e-05 - rmse: 0.0056 - val_loss: 1.2723e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 935/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3461e-05 - rmse: 0.0086\n",
      "Epoch 935: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0129e-05 - rmse: 0.0055 - val_loss: 1.2405e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 936/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1754e-05 - rmse: 0.0047\n",
      "Epoch 936: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6073e-05 - rmse: 0.0040 - val_loss: 1.1362e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 937/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1859e-05 - rmse: 0.0034\n",
      "Epoch 937: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1183e-05 - rmse: 0.0033 - val_loss: 1.0525e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 938/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3545e-06 - rmse: 0.0018\n",
      "Epoch 938: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9350e-06 - rmse: 0.0024 - val_loss: 1.1086e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 939/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2237e-05 - rmse: 0.0035\n",
      "Epoch 939: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9856e-06 - rmse: 0.0026 - val_loss: 1.1031e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 940/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4921e-06 - rmse: 0.0031\n",
      "Epoch 940: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.6233e-06 - rmse: 0.0022 - val_loss: 1.1286e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 941/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8135e-06 - rmse: 0.0022\n",
      "Epoch 941: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6378e-06 - rmse: 0.0022 - val_loss: 1.1814e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 942/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5901e-06 - rmse: 0.0024\n",
      "Epoch 942: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9589e-06 - rmse: 0.0020 - val_loss: 1.2359e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 943/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7222e-06 - rmse: 0.0026\n",
      "Epoch 943: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0217e-06 - rmse: 0.0020 - val_loss: 1.1512e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 944/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8207e-06 - rmse: 0.0013\n",
      "Epoch 944: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2389e-06 - rmse: 0.0015 - val_loss: 1.1033e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 945/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4748e-06 - rmse: 0.0023\n",
      "Epoch 945: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5541e-06 - rmse: 0.0019 - val_loss: 1.1045e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 946/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4186e-06 - rmse: 0.0021\n",
      "Epoch 946: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3563e-06 - rmse: 0.0021 - val_loss: 1.1466e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 947/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1469e-07 - rmse: 9.5639e-04\n",
      "Epoch 947: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.1944e-06 - rmse: 0.0018 - val_loss: 1.1976e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 948/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6917e-06 - rmse: 0.0016\n",
      "Epoch 948: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2850e-06 - rmse: 0.0015 - val_loss: 1.1434e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 949/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4429e-06 - rmse: 0.0012\n",
      "Epoch 949: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5284e-06 - rmse: 0.0012 - val_loss: 1.0920e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 950/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6980e-06 - rmse: 0.0013\n",
      "Epoch 950: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0141e-06 - rmse: 0.0014 - val_loss: 1.1262e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 951/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6043e-06 - rmse: 0.0016\n",
      "Epoch 951: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3112e-06 - rmse: 0.0015 - val_loss: 1.1622e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 952/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7489e-06 - rmse: 0.0017\n",
      "Epoch 952: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9081e-06 - rmse: 0.0014 - val_loss: 1.1182e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 953/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5722e-07 - rmse: 9.7837e-04\n",
      "Epoch 953: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2743e-06 - rmse: 0.0011 - val_loss: 1.0856e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 954/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5727e-07 - rmse: 8.7021e-04\n",
      "Epoch 954: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0569e-06 - rmse: 0.0010 - val_loss: 1.1156e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 955/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3853e-07 - rmse: 7.9908e-04\n",
      "Epoch 955: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0950e-06 - rmse: 0.0010 - val_loss: 1.1154e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 956/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8237e-06 - rmse: 0.0014\n",
      "Epoch 956: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2940e-06 - rmse: 0.0011 - val_loss: 1.1155e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 957/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0950e-06 - rmse: 0.0010\n",
      "Epoch 957: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3211e-07 - rmse: 9.6546e-04 - val_loss: 1.1267e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 958/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6758e-07 - rmse: 8.1706e-04\n",
      "Epoch 958: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0735e-07 - rmse: 8.9853e-04 - val_loss: 1.1272e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 959/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3276e-06 - rmse: 0.0012\n",
      "Epoch 959: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6066e-07 - rmse: 8.7216e-04 - val_loss: 1.1098e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 960/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7184e-07 - rmse: 8.7855e-04\n",
      "Epoch 960: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6511e-07 - rmse: 7.5174e-04 - val_loss: 1.1298e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 961/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4677e-07 - rmse: 5.8887e-04\n",
      "Epoch 961: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5152e-07 - rmse: 8.6690e-04 - val_loss: 1.1420e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 962/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7508e-07 - rmse: 9.8746e-04\n",
      "Epoch 962: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2678e-06 - rmse: 0.0011 - val_loss: 1.1272e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 963/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7126e-06 - rmse: 0.0013\n",
      "Epoch 963: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5026e-06 - rmse: 0.0016 - val_loss: 1.1426e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 964/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9507e-06 - rmse: 0.0017\n",
      "Epoch 964: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8976e-06 - rmse: 0.0014 - val_loss: 1.1080e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 965/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2322e-06 - rmse: 0.0011\n",
      "Epoch 965: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.6210e-07 - rmse: 9.8087e-04 - val_loss: 1.0938e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 966/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5459e-07 - rmse: 9.2444e-04\n",
      "Epoch 966: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0223e-06 - rmse: 0.0010 - val_loss: 1.0802e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 967/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4479e-07 - rmse: 7.3810e-04\n",
      "Epoch 967: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1454e-07 - rmse: 9.5631e-04 - val_loss: 1.1324e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 968/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8303e-06 - rmse: 0.0014\n",
      "Epoch 968: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4672e-06 - rmse: 0.0016 - val_loss: 1.1578e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 969/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9002e-06 - rmse: 0.0026\n",
      "Epoch 969: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.0988e-06 - rmse: 0.0023 - val_loss: 1.1298e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1439e-06 - rmse: 0.0015\n",
      "Epoch 970: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2444e-06 - rmse: 0.0018 - val_loss: 1.1047e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 971/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1888e-06 - rmse: 0.0015\n",
      "Epoch 971: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0139e-06 - rmse: 0.0014 - val_loss: 1.0534e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 972/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8565e-07 - rmse: 9.9280e-04\n",
      "Epoch 972: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0306e-06 - rmse: 0.0014 - val_loss: 1.0755e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 973/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1737e-06 - rmse: 0.0011\n",
      "Epoch 973: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1005e-06 - rmse: 0.0014 - val_loss: 1.1343e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 974/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3451e-06 - rmse: 0.0021\n",
      "Epoch 974: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9868e-06 - rmse: 0.0017 - val_loss: 1.1249e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 975/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0098e-06 - rmse: 0.0017\n",
      "Epoch 975: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9895e-06 - rmse: 0.0017 - val_loss: 1.1220e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 976/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5115e-06 - rmse: 0.0016\n",
      "Epoch 976: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5033e-06 - rmse: 0.0016 - val_loss: 1.1382e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 977/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6774e-06 - rmse: 0.0016\n",
      "Epoch 977: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0243e-06 - rmse: 0.0017 - val_loss: 1.0972e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 978/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9739e-06 - rmse: 0.0020\n",
      "Epoch 978: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9654e-06 - rmse: 0.0022 - val_loss: 1.0649e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 979/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7032e-06 - rmse: 0.0028\n",
      "Epoch 979: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.9267e-06 - rmse: 0.0022 - val_loss: 1.0877e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 980/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1680e-05 - rmse: 0.0034\n",
      "Epoch 980: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2855e-05 - rmse: 0.0036 - val_loss: 1.1266e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 981/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8521e-06 - rmse: 0.0017\n",
      "Epoch 981: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7687e-06 - rmse: 0.0026 - val_loss: 1.0810e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 982/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4057e-06 - rmse: 0.0027\n",
      "Epoch 982: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1500e-05 - rmse: 0.0034 - val_loss: 1.2384e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 983/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1467e-05 - rmse: 0.0046\n",
      "Epoch 983: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9436e-05 - rmse: 0.0044 - val_loss: 1.0884e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 984/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6588e-06 - rmse: 0.0029\n",
      "Epoch 984: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4871e-06 - rmse: 0.0027 - val_loss: 1.1477e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 985/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5894e-06 - rmse: 0.0019\n",
      "Epoch 985: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4882e-06 - rmse: 0.0023 - val_loss: 1.2580e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 986/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6472e-06 - rmse: 0.0019\n",
      "Epoch 986: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4299e-06 - rmse: 0.0019 - val_loss: 1.1815e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 987/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0484e-06 - rmse: 0.0020\n",
      "Epoch 987: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0606e-06 - rmse: 0.0014 - val_loss: 1.1125e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 988/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8130e-06 - rmse: 0.0013\n",
      "Epoch 988: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2061e-06 - rmse: 0.0015 - val_loss: 1.1766e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 989/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6774e-06 - rmse: 0.0013\n",
      "Epoch 989: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0242e-06 - rmse: 0.0014 - val_loss: 1.1983e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 990/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7160e-06 - rmse: 0.0016\n",
      "Epoch 990: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1471e-06 - rmse: 0.0023 - val_loss: 1.1559e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 991/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6652e-06 - rmse: 0.0031\n",
      "Epoch 991: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3666e-06 - rmse: 0.0023 - val_loss: 1.0652e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 992/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8491e-06 - rmse: 0.0014\n",
      "Epoch 992: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6962e-06 - rmse: 0.0019 - val_loss: 1.1283e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 993/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6473e-06 - rmse: 0.0024\n",
      "Epoch 993: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8303e-06 - rmse: 0.0020 - val_loss: 1.1246e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 994/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1648e-06 - rmse: 0.0015\n",
      "Epoch 994: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2218e-06 - rmse: 0.0015 - val_loss: 1.1290e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 995/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9146e-06 - rmse: 0.0014\n",
      "Epoch 995: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9156e-06 - rmse: 0.0014 - val_loss: 1.1825e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 996/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4502e-06 - rmse: 0.0021\n",
      "Epoch 996: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5822e-06 - rmse: 0.0016 - val_loss: 1.1114e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 997/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5810e-07 - rmse: 9.2634e-04\n",
      "Epoch 997: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2473e-06 - rmse: 0.0011 - val_loss: 1.1265e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 998/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5523e-06 - rmse: 0.0012\n",
      "Epoch 998: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.4832e-07 - rmse: 8.6505e-04 - val_loss: 1.0754e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 999/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5799e-07 - rmse: 5.9832e-04\n",
      "Epoch 999: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6503e-07 - rmse: 6.8193e-04 - val_loss: 1.0510e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 1000/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4432e-07 - rmse: 9.7176e-04\n",
      "Epoch 1000: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0509e-06 - rmse: 0.0010 - val_loss: 1.0751e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1001/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0009e-07 - rmse: 7.0717e-04\n",
      "Epoch 1001: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.8905e-07 - rmse: 8.8828e-04 - val_loss: 1.1232e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 1002/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8244e-07 - rmse: 6.1842e-04\n",
      "Epoch 1002: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6709e-07 - rmse: 9.3117e-04 - val_loss: 1.1031e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1003/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1618e-07 - rmse: 4.6495e-04\n",
      "Epoch 1003: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6914e-07 - rmse: 6.0757e-04 - val_loss: 1.0799e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1004/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8224e-07 - rmse: 4.2689e-04\n",
      "Epoch 1004: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0066e-07 - rmse: 7.0757e-04 - val_loss: 1.0857e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1005/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2746e-07 - rmse: 7.2627e-04\n",
      "Epoch 1005: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9128e-07 - rmse: 7.6895e-04 - val_loss: 1.1158e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 1006/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0923e-06 - rmse: 0.0010\n",
      "Epoch 1006: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6505e-07 - rmse: 9.3008e-04 - val_loss: 1.0844e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1007/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3863e-07 - rmse: 6.6229e-04\n",
      "Epoch 1007: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8723e-07 - rmse: 7.6631e-04 - val_loss: 1.0892e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1008/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9558e-07 - rmse: 8.3401e-04\n",
      "Epoch 1008: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.7361e-07 - rmse: 8.7955e-04 - val_loss: 1.0921e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1009/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6475e-07 - rmse: 9.2992e-04\n",
      "Epoch 1009: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4667e-07 - rmse: 9.2015e-04 - val_loss: 1.0789e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1010/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5592e-07 - rmse: 9.7771e-04\n",
      "Epoch 1010: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3000e-07 - rmse: 8.5440e-04 - val_loss: 1.0667e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 1011/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5925e-07 - rmse: 7.4783e-04\n",
      "Epoch 1011: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3082e-07 - rmse: 7.9424e-04 - val_loss: 1.0585e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 1012/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5547e-07 - rmse: 6.7489e-04\n",
      "Epoch 1012: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1572e-06 - rmse: 0.0011 - val_loss: 1.1412e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1013/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9320e-06 - rmse: 0.0017\n",
      "Epoch 1013: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4856e-06 - rmse: 0.0012 - val_loss: 1.1340e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 1014/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4311e-07 - rmse: 6.6567e-04\n",
      "Epoch 1014: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5336e-06 - rmse: 0.0012 - val_loss: 1.1433e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1015/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1153e-06 - rmse: 0.0018\n",
      "Epoch 1015: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9607e-06 - rmse: 0.0014 - val_loss: 1.0896e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1016/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2665e-06 - rmse: 0.0011\n",
      "Epoch 1016: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9671e-06 - rmse: 0.0017 - val_loss: 1.1536e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1017/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2262e-06 - rmse: 0.0021\n",
      "Epoch 1017: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1519e-06 - rmse: 0.0018 - val_loss: 1.1207e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 1018/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2418e-06 - rmse: 0.0021\n",
      "Epoch 1018: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9914e-06 - rmse: 0.0017 - val_loss: 1.1106e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1019/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8682e-06 - rmse: 0.0017\n",
      "Epoch 1019: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4362e-06 - rmse: 0.0016 - val_loss: 1.0964e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1020/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4079e-06 - rmse: 0.0012\n",
      "Epoch 1020: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5593e-06 - rmse: 0.0012 - val_loss: 1.1696e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 1021/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5657e-06 - rmse: 0.0019\n",
      "Epoch 1021: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5431e-06 - rmse: 0.0016 - val_loss: 1.0924e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1022/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5772e-06 - rmse: 0.0013\n",
      "Epoch 1022: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2981e-06 - rmse: 0.0011 - val_loss: 1.1366e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1023/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6787e-07 - rmse: 8.1723e-04\n",
      "Epoch 1023: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2828e-06 - rmse: 0.0011 - val_loss: 1.1223e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 1024/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6644e-07 - rmse: 8.1636e-04\n",
      "Epoch 1024: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0701e-06 - rmse: 0.0010 - val_loss: 1.1027e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1025/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5489e-07 - rmse: 6.7445e-04\n",
      "Epoch 1025: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6914e-07 - rmse: 6.8494e-04 - val_loss: 1.1125e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5606e-07 - rmse: 7.4569e-04\n",
      "Epoch 1026: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2964e-06 - rmse: 0.0011 - val_loss: 1.0870e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1027/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8294e-07 - rmse: 7.6351e-04\n",
      "Epoch 1027: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.5999e-07 - rmse: 9.7979e-04 - val_loss: 1.1469e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1028/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8467e-07 - rmse: 9.9230e-04\n",
      "Epoch 1028: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2740e-06 - rmse: 0.0011 - val_loss: 1.1501e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1029/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8206e-06 - rmse: 0.0013\n",
      "Epoch 1029: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0840e-06 - rmse: 0.0014 - val_loss: 1.0973e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1030/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7119e-06 - rmse: 0.0013\n",
      "Epoch 1030: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8902e-06 - rmse: 0.0014 - val_loss: 1.0678e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 1031/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6826e-06 - rmse: 0.0016\n",
      "Epoch 1031: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1302e-06 - rmse: 0.0015 - val_loss: 1.0725e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1032/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2109e-06 - rmse: 0.0011\n",
      "Epoch 1032: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4361e-06 - rmse: 0.0016 - val_loss: 1.1485e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1033/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3922e-06 - rmse: 0.0018\n",
      "Epoch 1033: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4968e-06 - rmse: 0.0016 - val_loss: 1.1347e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1034/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6028e-06 - rmse: 0.0013\n",
      "Epoch 1034: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1955e-06 - rmse: 0.0020 - val_loss: 1.0861e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1035/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8540e-06 - rmse: 0.0026\n",
      "Epoch 1035: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8869e-06 - rmse: 0.0020 - val_loss: 1.0352e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 1036/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9255e-06 - rmse: 0.0020\n",
      "Epoch 1036: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5232e-06 - rmse: 0.0016 - val_loss: 1.0871e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1037/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0734e-06 - rmse: 0.0010\n",
      "Epoch 1037: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1584e-06 - rmse: 0.0015 - val_loss: 1.1890e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 1038/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8549e-06 - rmse: 0.0017\n",
      "Epoch 1038: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1182e-06 - rmse: 0.0015 - val_loss: 1.1396e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1039/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0374e-06 - rmse: 0.0014\n",
      "Epoch 1039: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1680e-06 - rmse: 0.0011 - val_loss: 1.0901e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 1040/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7356e-07 - rmse: 8.2071e-04\n",
      "Epoch 1040: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6767e-06 - rmse: 0.0013 - val_loss: 1.1183e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 1041/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8429e-06 - rmse: 0.0014\n",
      "Epoch 1041: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7448e-06 - rmse: 0.0017 - val_loss: 1.1827e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 1042/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5076e-06 - rmse: 0.0012\n",
      "Epoch 1042: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2296e-06 - rmse: 0.0015 - val_loss: 1.1367e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 1043/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9822e-06 - rmse: 0.0014\n",
      "Epoch 1043: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1545e-06 - rmse: 0.0020 - val_loss: 1.0599e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 1044/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5576e-06 - rmse: 0.0012\n",
      "Epoch 1044: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3264e-06 - rmse: 0.0023 - val_loss: 1.0948e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1045/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3766e-06 - rmse: 0.0027\n",
      "Epoch 1045: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2678e-06 - rmse: 0.0027 - val_loss: 1.0257e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 1046/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1672e-06 - rmse: 0.0011\n",
      "Epoch 1046: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0876e-06 - rmse: 0.0023 - val_loss: 1.1844e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 1047/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6290e-06 - rmse: 0.0024\n",
      "Epoch 1047: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2592e-06 - rmse: 0.0027 - val_loss: 1.3268e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 1048/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2701e-05 - rmse: 0.0036\n",
      "Epoch 1048: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2573e-05 - rmse: 0.0035 - val_loss: 1.2074e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 1049/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4953e-06 - rmse: 0.0025\n",
      "Epoch 1049: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2103e-05 - rmse: 0.0035 - val_loss: 1.1112e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 1050/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6301e-06 - rmse: 0.0024\n",
      "Epoch 1050: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3774e-06 - rmse: 0.0027 - val_loss: 1.2181e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 1051/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6664e-06 - rmse: 0.0028\n",
      "Epoch 1051: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7236e-05 - rmse: 0.0042 - val_loss: 1.1658e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 1052/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8681e-06 - rmse: 0.0031\n",
      "Epoch 1052: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6054e-05 - rmse: 0.0040 - val_loss: 2.0612e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 1053/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8988e-05 - rmse: 0.0083\n",
      "Epoch 1053: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6505e-05 - rmse: 0.0068 - val_loss: 1.4199e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1054/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5254e-05 - rmse: 0.0050\n",
      "Epoch 1054: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6956e-05 - rmse: 0.0061 - val_loss: 1.5675e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 1055/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0372e-05 - rmse: 0.0055\n",
      "Epoch 1055: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9146e-05 - rmse: 0.0054 - val_loss: 1.3688e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 1056/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9368e-05 - rmse: 0.0054\n",
      "Epoch 1056: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6817e-05 - rmse: 0.0061 - val_loss: 1.8151e-04 - val_rmse: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 1057/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3636e-05 - rmse: 0.0097\n",
      "Epoch 1057: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5501e-05 - rmse: 0.0081 - val_loss: 1.2731e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 1058/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3362e-05 - rmse: 0.0048\n",
      "Epoch 1058: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6956e-05 - rmse: 0.0082 - val_loss: 2.9153e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 1059/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9312e-04 - rmse: 0.0139\n",
      "Epoch 1059: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2929e-04 - rmse: 0.0114 - val_loss: 2.5385e-04 - val_rmse: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 1060/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3909e-04 - rmse: 0.0118\n",
      "Epoch 1060: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6651e-04 - rmse: 0.0129 - val_loss: 6.1956e-04 - val_rmse: 0.0249 - lr: 1.0000e-04\n",
      "Epoch 1061/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3359e-04 - rmse: 0.0208\n",
      "Epoch 1061: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6373e-04 - rmse: 0.0162 - val_loss: 3.2064e-04 - val_rmse: 0.0179 - lr: 1.0000e-04\n",
      "Epoch 1062/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9502e-04 - rmse: 0.0140\n",
      "Epoch 1062: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2940e-04 - rmse: 0.0151 - val_loss: 1.2064e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 1063/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5234e-05 - rmse: 0.0074\n",
      "Epoch 1063: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7653e-04 - rmse: 0.0133 - val_loss: 2.3828e-04 - val_rmse: 0.0154 - lr: 1.0000e-04\n",
      "Epoch 1064/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0148e-04 - rmse: 0.0101\n",
      "Epoch 1064: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7909e-04 - rmse: 0.0134 - val_loss: 1.9745e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 1065/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0369e-04 - rmse: 0.0102\n",
      "Epoch 1065: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2309e-04 - rmse: 0.0111 - val_loss: 1.3225e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 1066/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0328e-04 - rmse: 0.0102\n",
      "Epoch 1066: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6290e-05 - rmse: 0.0093 - val_loss: 1.3841e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 1067/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0127e-05 - rmse: 0.0078\n",
      "Epoch 1067: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6884e-05 - rmse: 0.0093 - val_loss: 1.7564e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 1068/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6856e-05 - rmse: 0.0093\n",
      "Epoch 1068: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1021e-04 - rmse: 0.0105 - val_loss: 2.1852e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 1069/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5752e-05 - rmse: 0.0075\n",
      "Epoch 1069: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0508e-04 - rmse: 0.0103 - val_loss: 1.6522e-04 - val_rmse: 0.0129 - lr: 1.0000e-04\n",
      "Epoch 1070/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0606e-04 - rmse: 0.0103\n",
      "Epoch 1070: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0469e-05 - rmse: 0.0090 - val_loss: 1.5452e-04 - val_rmse: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 1071/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8824e-05 - rmse: 0.0054\n",
      "Epoch 1071: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1623e-04 - rmse: 0.0108 - val_loss: 2.2956e-04 - val_rmse: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 1072/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4082e-04 - rmse: 0.0119\n",
      "Epoch 1072: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2425e-04 - rmse: 0.0111 - val_loss: 2.6694e-04 - val_rmse: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 1073/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0684e-04 - rmse: 0.0144\n",
      "Epoch 1073: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2270e-04 - rmse: 0.0111 - val_loss: 1.8864e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 1074/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0063e-04 - rmse: 0.0100\n",
      "Epoch 1074: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0209e-05 - rmse: 0.0090 - val_loss: 1.8938e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 1075/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1495e-05 - rmse: 0.0064\n",
      "Epoch 1075: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.6564e-05 - rmse: 0.0068 - val_loss: 2.2776e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 1076/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4201e-04 - rmse: 0.0119\n",
      "Epoch 1076: val_loss did not improve from 0.00010\n",
      "\n",
      "Epoch 1076: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1162e-05 - rmse: 0.0078 - val_loss: 3.4539e-04 - val_rmse: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 1077/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7253e-04 - rmse: 0.0131\n",
      "Epoch 1077: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0080e-04 - rmse: 0.0100 - val_loss: 1.8394e-04 - val_rmse: 0.0136 - lr: 5.0000e-05\n",
      "Epoch 1078/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5873e-05 - rmse: 0.0087\n",
      "Epoch 1078: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5832e-05 - rmse: 0.0081 - val_loss: 2.0310e-04 - val_rmse: 0.0143 - lr: 5.0000e-05\n",
      "Epoch 1079/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6726e-05 - rmse: 0.0075\n",
      "Epoch 1079: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9014e-05 - rmse: 0.0070 - val_loss: 1.7277e-04 - val_rmse: 0.0131 - lr: 5.0000e-05\n",
      "Epoch 1080/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8883e-05 - rmse: 0.0043\n",
      "Epoch 1080: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.0801e-05 - rmse: 0.0071 - val_loss: 1.9729e-04 - val_rmse: 0.0140 - lr: 5.0000e-05\n",
      "Epoch 1081/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9931e-05 - rmse: 0.0077\n",
      "Epoch 1081: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3608e-05 - rmse: 0.0091 - val_loss: 1.9944e-04 - val_rmse: 0.0141 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1082/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3828e-05 - rmse: 0.0080\n",
      "Epoch 1082: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7046e-05 - rmse: 0.0069 - val_loss: 1.1824e-04 - val_rmse: 0.0109 - lr: 5.0000e-05\n",
      "Epoch 1083/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8827e-05 - rmse: 0.0043\n",
      "Epoch 1083: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3339e-05 - rmse: 0.0048 - val_loss: 1.2661e-04 - val_rmse: 0.0113 - lr: 5.0000e-05\n",
      "Epoch 1084/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5351e-05 - rmse: 0.0039\n",
      "Epoch 1084: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5525e-05 - rmse: 0.0060 - val_loss: 1.4881e-04 - val_rmse: 0.0122 - lr: 5.0000e-05\n",
      "Epoch 1085/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2490e-05 - rmse: 0.0057\n",
      "Epoch 1085: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8654e-05 - rmse: 0.0043 - val_loss: 1.2269e-04 - val_rmse: 0.0111 - lr: 5.0000e-05\n",
      "Epoch 1086/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1500e-06 - rmse: 0.0027\n",
      "Epoch 1086: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3855e-05 - rmse: 0.0037 - val_loss: 1.3463e-04 - val_rmse: 0.0116 - lr: 5.0000e-05\n",
      "Epoch 1087/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9204e-05 - rmse: 0.0044\n",
      "Epoch 1087: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4495e-05 - rmse: 0.0038 - val_loss: 1.2779e-04 - val_rmse: 0.0113 - lr: 5.0000e-05\n",
      "Epoch 1088/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6514e-05 - rmse: 0.0041\n",
      "Epoch 1088: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5764e-05 - rmse: 0.0040 - val_loss: 1.0348e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1089/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5031e-06 - rmse: 0.0021\n",
      "Epoch 1089: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2312e-05 - rmse: 0.0035 - val_loss: 1.0769e-04 - val_rmse: 0.0104 - lr: 5.0000e-05\n",
      "Epoch 1090/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4539e-06 - rmse: 0.0025\n",
      "Epoch 1090: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0636e-06 - rmse: 0.0028 - val_loss: 1.0779e-04 - val_rmse: 0.0104 - lr: 5.0000e-05\n",
      "Epoch 1091/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9724e-06 - rmse: 0.0028\n",
      "Epoch 1091: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2222e-06 - rmse: 0.0023 - val_loss: 1.0966e-04 - val_rmse: 0.0105 - lr: 5.0000e-05\n",
      "Epoch 1092/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4854e-06 - rmse: 0.0016\n",
      "Epoch 1092: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0112e-06 - rmse: 0.0020 - val_loss: 1.1271e-04 - val_rmse: 0.0106 - lr: 5.0000e-05\n",
      "Epoch 1093/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7879e-06 - rmse: 0.0019\n",
      "Epoch 1093: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8526e-06 - rmse: 0.0020 - val_loss: 1.0870e-04 - val_rmse: 0.0104 - lr: 5.0000e-05\n",
      "Epoch 1094/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1310e-06 - rmse: 0.0018\n",
      "Epoch 1094: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6847e-06 - rmse: 0.0019 - val_loss: 1.0441e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1095/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0064e-06 - rmse: 0.0014\n",
      "Epoch 1095: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6629e-06 - rmse: 0.0019 - val_loss: 1.0506e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1096/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5367e-06 - rmse: 0.0019\n",
      "Epoch 1096: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0024e-06 - rmse: 0.0017 - val_loss: 1.0332e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1097/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4702e-06 - rmse: 0.0023\n",
      "Epoch 1097: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2330e-06 - rmse: 0.0018 - val_loss: 1.0320e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1098/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9662e-06 - rmse: 0.0014\n",
      "Epoch 1098: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7667e-06 - rmse: 0.0017 - val_loss: 1.0457e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1099/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8016e-06 - rmse: 0.0019\n",
      "Epoch 1099: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9198e-06 - rmse: 0.0017 - val_loss: 1.0335e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1100/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0709e-06 - rmse: 0.0010\n",
      "Epoch 1100: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2847e-06 - rmse: 0.0015 - val_loss: 1.0406e-04 - val_rmse: 0.0102 - lr: 5.0000e-05\n",
      "Epoch 1101/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3599e-06 - rmse: 0.0015\n",
      "Epoch 1101: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2911e-06 - rmse: 0.0015 - val_loss: 1.0119e-04 - val_rmse: 0.0101 - lr: 5.0000e-05\n",
      "Epoch 1102/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9999e-06 - rmse: 0.0014\n",
      "Epoch 1102: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6590e-06 - rmse: 0.0013 - val_loss: 1.0080e-04 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1103/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2916e-06 - rmse: 0.0011\n",
      "Epoch 1103: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3606e-06 - rmse: 0.0012 - val_loss: 1.0157e-04 - val_rmse: 0.0101 - lr: 5.0000e-05\n",
      "Epoch 1104/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5805e-07 - rmse: 9.7880e-04\n",
      "Epoch 1104: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1885e-06 - rmse: 0.0015 - val_loss: 1.0188e-04 - val_rmse: 0.0101 - lr: 5.0000e-05\n",
      "Epoch 1105/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6717e-06 - rmse: 0.0016\n",
      "Epoch 1105: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6159e-06 - rmse: 0.0013 - val_loss: 9.8375e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1106/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8800e-06 - rmse: 0.0014\n",
      "Epoch 1106: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3433e-06 - rmse: 0.0012 - val_loss: 1.0015e-04 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1107/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9202e-06 - rmse: 0.0017\n",
      "Epoch 1107: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6379e-06 - rmse: 0.0013 - val_loss: 9.8381e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1108/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3868e-07 - rmse: 8.5947e-04\n",
      "Epoch 1108: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3527e-06 - rmse: 0.0012 - val_loss: 9.7834e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1109/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5457e-06 - rmse: 0.0012\n",
      "Epoch 1109: val_loss did not improve from 0.00010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0953e-06 - rmse: 0.0010 - val_loss: 9.8967e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1110/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4078e-07 - rmse: 9.1694e-04\n",
      "Epoch 1110: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0787e-06 - rmse: 0.0010 - val_loss: 9.9299e-05 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1111/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3846e-07 - rmse: 7.9904e-04\n",
      "Epoch 1111: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1514e-06 - rmse: 0.0011 - val_loss: 9.9536e-05 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1112/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4004e-06 - rmse: 0.0012\n",
      "Epoch 1112: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2506e-06 - rmse: 0.0011 - val_loss: 9.6730e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1113/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3771e-06 - rmse: 0.0012\n",
      "Epoch 1113: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4338e-06 - rmse: 0.0012 - val_loss: 9.8980e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1114/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1959e-06 - rmse: 0.0011\n",
      "Epoch 1114: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6449e-06 - rmse: 0.0013 - val_loss: 9.9324e-05 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1115/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1414e-06 - rmse: 0.0015\n",
      "Epoch 1115: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6947e-06 - rmse: 0.0013 - val_loss: 9.8398e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1116/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6301e-06 - rmse: 0.0013\n",
      "Epoch 1116: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0671e-06 - rmse: 0.0014 - val_loss: 1.0156e-04 - val_rmse: 0.0101 - lr: 5.0000e-05\n",
      "Epoch 1117/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3853e-06 - rmse: 0.0015\n",
      "Epoch 1117: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0920e-06 - rmse: 0.0014 - val_loss: 9.8071e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1118/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2685e-07 - rmse: 8.5256e-04\n",
      "Epoch 1118: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7746e-06 - rmse: 0.0013 - val_loss: 9.7716e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1119/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6774e-06 - rmse: 0.0013\n",
      "Epoch 1119: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4923e-06 - rmse: 0.0012 - val_loss: 9.8241e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1120/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9112e-07 - rmse: 7.6884e-04\n",
      "Epoch 1120: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2924e-06 - rmse: 0.0011 - val_loss: 9.9900e-05 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1121/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0729e-06 - rmse: 0.0014\n",
      "Epoch 1121: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8434e-06 - rmse: 0.0014 - val_loss: 9.9181e-05 - val_rmse: 0.0100 - lr: 5.0000e-05\n",
      "Epoch 1122/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0589e-06 - rmse: 0.0014\n",
      "Epoch 1122: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6509e-06 - rmse: 0.0013 - val_loss: 9.8543e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1123/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3113e-07 - rmse: 7.2879e-04\n",
      "Epoch 1123: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9280e-07 - rmse: 9.4488e-04 - val_loss: 9.7546e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1124/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0721e-07 - rmse: 5.5426e-04\n",
      "Epoch 1124: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2752e-07 - rmse: 7.9216e-04 - val_loss: 9.8280e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1125/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5448e-07 - rmse: 9.2438e-04\n",
      "Epoch 1125: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1870e-07 - rmse: 8.4776e-04 - val_loss: 9.6231e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1126/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5901e-07 - rmse: 7.4767e-04\n",
      "Epoch 1126: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2821e-07 - rmse: 7.9260e-04 - val_loss: 9.6829e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1127/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2400e-07 - rmse: 7.2388e-04\n",
      "Epoch 1127: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2834e-07 - rmse: 7.9268e-04 - val_loss: 9.7641e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1128/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2404e-07 - rmse: 6.5119e-04\n",
      "Epoch 1128: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6688e-07 - rmse: 8.1663e-04 - val_loss: 9.6750e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1129/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6035e-07 - rmse: 8.1262e-04\n",
      "Epoch 1129: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8208e-07 - rmse: 7.6294e-04 - val_loss: 9.7161e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1130/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1014e-07 - rmse: 9.0008e-04\n",
      "Epoch 1130: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2088e-07 - rmse: 7.8796e-04 - val_loss: 9.7323e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1131/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8454e-07 - rmse: 6.9609e-04\n",
      "Epoch 1131: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3819e-07 - rmse: 7.3361e-04 - val_loss: 9.7185e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1132/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4742e-07 - rmse: 9.2055e-04\n",
      "Epoch 1132: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1766e-07 - rmse: 7.1949e-04 - val_loss: 9.6604e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1133/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0356e-07 - rmse: 7.7689e-04\n",
      "Epoch 1133: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4319e-07 - rmse: 6.6572e-04 - val_loss: 9.6966e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1134/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8872e-07 - rmse: 7.6728e-04\n",
      "Epoch 1134: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1377e-07 - rmse: 7.8343e-04 - val_loss: 9.6217e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1135/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4406e-07 - rmse: 7.3760e-04\n",
      "Epoch 1135: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7615e-07 - rmse: 8.2228e-04 - val_loss: 9.6132e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1136/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5960e-07 - rmse: 5.0951e-04\n",
      "Epoch 1136: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9103e-07 - rmse: 8.3128e-04 - val_loss: 9.7029e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1137/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5333e-07 - rmse: 8.6794e-04\n",
      "Epoch 1137: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6509e-07 - rmse: 8.1553e-04 - val_loss: 9.6434e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1138/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3120e-07 - rmse: 7.2884e-04\n",
      "Epoch 1138: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2709e-07 - rmse: 7.2601e-04 - val_loss: 9.6251e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1139/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3557e-06 - rmse: 0.0012\n",
      "Epoch 1139: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 7.1264e-07 - rmse: 8.4418e-04 - val_loss: 9.5948e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1140/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1065e-07 - rmse: 9.0036e-04\n",
      "Epoch 1140: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9872e-07 - rmse: 7.7377e-04 - val_loss: 9.5589e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1141/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6798e-07 - rmse: 4.0985e-04\n",
      "Epoch 1141: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2289e-07 - rmse: 6.5030e-04 - val_loss: 9.5557e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1142/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1841e-07 - rmse: 5.6428e-04\n",
      "Epoch 1142: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.9092e-07 - rmse: 7.0066e-04 - val_loss: 9.5641e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1143/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2672e-07 - rmse: 4.7615e-04\n",
      "Epoch 1143: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.9467e-07 - rmse: 7.7115e-04 - val_loss: 9.6840e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1144/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1726e-07 - rmse: 9.5773e-04\n",
      "Epoch 1144: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6666e-07 - rmse: 7.5277e-04 - val_loss: 9.6632e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1145/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2333e-07 - rmse: 7.2342e-04\n",
      "Epoch 1145: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3903e-07 - rmse: 6.6259e-04 - val_loss: 9.6362e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1146/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2716e-07 - rmse: 5.7197e-04\n",
      "Epoch 1146: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5313e-07 - rmse: 6.7315e-04 - val_loss: 9.5569e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1147/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2664e-07 - rmse: 7.9161e-04\n",
      "Epoch 1147: val_loss improved from 0.00010 to 0.00010, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6780e-07 - rmse: 6.0646e-04 - val_loss: 9.5218e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1148/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9529e-07 - rmse: 7.0377e-04\n",
      "Epoch 1148: val_loss did not improve from 0.00010\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7403e-07 - rmse: 6.1158e-04 - val_loss: 9.5474e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1149/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2831e-07 - rmse: 5.7298e-04\n",
      "Epoch 1149: val_loss improved from 0.00010 to 0.00009, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9313e-07 - rmse: 6.2700e-04 - val_loss: 9.4992e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1150/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5889e-07 - rmse: 5.0881e-04\n",
      "Epoch 1150: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1663e-07 - rmse: 6.4547e-04 - val_loss: 9.5682e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1151/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7671e-07 - rmse: 6.1377e-04\n",
      "Epoch 1151: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2775e-07 - rmse: 6.5403e-04 - val_loss: 9.5389e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1152/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1297e-07 - rmse: 8.4438e-04\n",
      "Epoch 1152: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3034e-07 - rmse: 7.2824e-04 - val_loss: 9.6317e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1153/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0368e-07 - rmse: 7.0970e-04\n",
      "Epoch 1153: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2545e-07 - rmse: 9.6200e-04 - val_loss: 9.7292e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1154/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0440e-06 - rmse: 0.0010\n",
      "Epoch 1154: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.1768e-07 - rmse: 9.0426e-04 - val_loss: 9.6595e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1155/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5426e-07 - rmse: 9.7686e-04\n",
      "Epoch 1155: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.4464e-07 - rmse: 8.6292e-04 - val_loss: 9.5335e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1156/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3309e-07 - rmse: 5.7714e-04\n",
      "Epoch 1156: val_loss improved from 0.00009 to 0.00009, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0913e-07 - rmse: 8.4210e-04 - val_loss: 9.4396e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1157/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3161e-07 - rmse: 6.5697e-04\n",
      "Epoch 1157: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7616e-07 - rmse: 6.1332e-04 - val_loss: 9.4733e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1158/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9740e-07 - rmse: 5.4534e-04\n",
      "Epoch 1158: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1341e-07 - rmse: 5.5983e-04 - val_loss: 9.5026e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1159/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8628e-07 - rmse: 4.3160e-04\n",
      "Epoch 1159: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1000e-07 - rmse: 5.5677e-04 - val_loss: 9.5293e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1160/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4748e-07 - rmse: 6.6894e-04\n",
      "Epoch 1160: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1209e-07 - rmse: 6.4195e-04 - val_loss: 9.5387e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1161/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0251e-07 - rmse: 4.5001e-04\n",
      "Epoch 1161: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1101e-07 - rmse: 5.5769e-04 - val_loss: 9.5916e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1162/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1040e-07 - rmse: 5.5714e-04\n",
      "Epoch 1162: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0850e-07 - rmse: 6.3914e-04 - val_loss: 9.5536e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1163/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6476e-07 - rmse: 5.1455e-04\n",
      "Epoch 1163: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.0950e-07 - rmse: 6.3992e-04 - val_loss: 9.5798e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1164/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5878e-07 - rmse: 6.7733e-04\n",
      "Epoch 1164: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4488e-07 - rmse: 6.6699e-04 - val_loss: 9.6110e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1165/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5074e-07 - rmse: 5.9223e-04\n",
      "Epoch 1165: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9749e-07 - rmse: 6.3047e-04 - val_loss: 9.6913e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1166/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8849e-07 - rmse: 6.9892e-04\n",
      "Epoch 1166: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5887e-07 - rmse: 7.4758e-04 - val_loss: 9.4806e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1167/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1340e-07 - rmse: 4.6195e-04\n",
      "Epoch 1167: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1103e-07 - rmse: 7.8169e-04 - val_loss: 9.4847e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1168/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3896e-07 - rmse: 7.3414e-04\n",
      "Epoch 1168: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2681e-07 - rmse: 5.7168e-04 - val_loss: 9.5197e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1169/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0944e-07 - rmse: 5.5627e-04\n",
      "Epoch 1169: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2351e-07 - rmse: 5.6878e-04 - val_loss: 9.5502e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1170/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1433e-07 - rmse: 4.6296e-04\n",
      "Epoch 1170: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2512e-07 - rmse: 5.7019e-04 - val_loss: 9.5487e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1171/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4502e-07 - rmse: 4.9500e-04\n",
      "Epoch 1171: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.0534e-07 - rmse: 5.5258e-04 - val_loss: 9.5182e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1172/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3560e-07 - rmse: 4.8539e-04\n",
      "Epoch 1172: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2829e-07 - rmse: 5.7296e-04 - val_loss: 9.5022e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1173/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8397e-07 - rmse: 6.9568e-04\n",
      "Epoch 1173: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4169e-07 - rmse: 5.8454e-04 - val_loss: 9.5425e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1174/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3304e-07 - rmse: 5.7710e-04\n",
      "Epoch 1174: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5299e-07 - rmse: 5.0298e-04 - val_loss: 9.5639e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1175/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5867e-07 - rmse: 3.9834e-04\n",
      "Epoch 1175: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4782e-07 - rmse: 4.9781e-04 - val_loss: 9.5440e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1176/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6794e-07 - rmse: 5.1763e-04\n",
      "Epoch 1176: val_loss improved from 0.00009 to 0.00009, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3900e-07 - rmse: 4.8887e-04 - val_loss: 9.4336e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1177/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9089e-07 - rmse: 5.3934e-04\n",
      "Epoch 1177: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2021e-07 - rmse: 5.6587e-04 - val_loss: 9.4422e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1178/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2644e-07 - rmse: 4.7585e-04\n",
      "Epoch 1178: val_loss improved from 0.00009 to 0.00009, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.0746e-07 - rmse: 4.5548e-04 - val_loss: 9.4271e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1179/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1692e-07 - rmse: 5.6296e-04\n",
      "Epoch 1179: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6639e-07 - rmse: 5.1613e-04 - val_loss: 9.4875e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1180/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2225e-07 - rmse: 4.7144e-04\n",
      "Epoch 1180: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0542e-07 - rmse: 7.1093e-04 - val_loss: 9.4938e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1181/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5672e-07 - rmse: 5.9726e-04\n",
      "Epoch 1181: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.8485e-07 - rmse: 6.2037e-04 - val_loss: 9.4732e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1182/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2361e-07 - rmse: 7.8969e-04\n",
      "Epoch 1182: val_loss improved from 0.00009 to 0.00009, saving model to D:\\TrainedModels\\20221130\\20221130steadyValidation_MLP_val_0.2_test0.1_128units_ClOptimalSettings_checkpoint.h5\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5074e-07 - rmse: 6.7137e-04 - val_loss: 9.4091e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1183/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1709e-07 - rmse: 4.6593e-04\n",
      "Epoch 1183: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7540e-07 - rmse: 5.2478e-04 - val_loss: 9.4523e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1184/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4637e-07 - rmse: 6.6811e-04\n",
      "Epoch 1184: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 3.2950e-07 - rmse: 5.7402e-04 - val_loss: 9.5185e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1185/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4992e-07 - rmse: 4.9992e-04\n",
      "Epoch 1185: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3082e-07 - rmse: 4.8043e-04 - val_loss: 9.5406e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1186/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0647e-07 - rmse: 4.5439e-04\n",
      "Epoch 1186: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1191e-07 - rmse: 4.6034e-04 - val_loss: 9.5620e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1187/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9698e-07 - rmse: 4.4382e-04\n",
      "Epoch 1187: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1336e-07 - rmse: 4.6190e-04 - val_loss: 9.5495e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1188/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5951e-07 - rmse: 3.9938e-04\n",
      "Epoch 1188: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5277e-07 - rmse: 5.0276e-04 - val_loss: 9.5355e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1189/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7236e-07 - rmse: 5.2188e-04\n",
      "Epoch 1189: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4950e-07 - rmse: 4.9950e-04 - val_loss: 9.5183e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1190/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8885e-07 - rmse: 4.3457e-04\n",
      "Epoch 1190: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6310e-07 - rmse: 5.1293e-04 - val_loss: 9.5175e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1191/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8249e-07 - rmse: 4.2719e-04\n",
      "Epoch 1191: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9787e-07 - rmse: 4.4483e-04 - val_loss: 9.4781e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1192/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3814e-07 - rmse: 3.7167e-04\n",
      "Epoch 1192: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1979e-07 - rmse: 4.6882e-04 - val_loss: 9.5172e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1193/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6896e-07 - rmse: 4.1104e-04\n",
      "Epoch 1193: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0165e-07 - rmse: 4.4905e-04 - val_loss: 9.5594e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1194/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9689e-07 - rmse: 5.4488e-04\n",
      "Epoch 1194: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9337e-07 - rmse: 4.3974e-04 - val_loss: 9.5543e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1195/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0494e-07 - rmse: 3.2395e-04\n",
      "Epoch 1195: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3506e-07 - rmse: 4.8483e-04 - val_loss: 9.5456e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1196/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8989e-07 - rmse: 4.3576e-04\n",
      "Epoch 1196: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7107e-07 - rmse: 4.1361e-04 - val_loss: 9.5996e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1197/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6242e-08 - rmse: 3.1023e-04\n",
      "Epoch 1197: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5358e-07 - rmse: 3.9190e-04 - val_loss: 9.5705e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1198/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4004e-07 - rmse: 3.7421e-04\n",
      "Epoch 1198: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6610e-07 - rmse: 4.0755e-04 - val_loss: 9.5570e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1199/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5432e-07 - rmse: 3.9284e-04\n",
      "Epoch 1199: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5769e-07 - rmse: 3.9710e-04 - val_loss: 9.5442e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1200/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5983e-07 - rmse: 5.0973e-04\n",
      "Epoch 1200: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6999e-07 - rmse: 4.1229e-04 - val_loss: 9.5299e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1201/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6496e-08 - rmse: 3.1064e-04\n",
      "Epoch 1201: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0811e-07 - rmse: 4.5619e-04 - val_loss: 9.5487e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1202/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4947e-07 - rmse: 3.8662e-04\n",
      "Epoch 1202: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2706e-07 - rmse: 4.7651e-04 - val_loss: 9.5542e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1203/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2217e-07 - rmse: 4.7135e-04\n",
      "Epoch 1203: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9883e-07 - rmse: 4.4591e-04 - val_loss: 9.5180e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1204/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2366e-07 - rmse: 3.5165e-04\n",
      "Epoch 1204: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0821e-07 - rmse: 4.5630e-04 - val_loss: 9.4828e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1205/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6556e-07 - rmse: 4.0689e-04\n",
      "Epoch 1205: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9326e-07 - rmse: 4.3961e-04 - val_loss: 9.5279e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1206/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5298e-07 - rmse: 5.0297e-04\n",
      "Epoch 1206: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7752e-07 - rmse: 4.2134e-04 - val_loss: 9.5714e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1207/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4995e-07 - rmse: 3.8723e-04\n",
      "Epoch 1207: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6271e-07 - rmse: 4.0337e-04 - val_loss: 9.5772e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1208/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9951e-08 - rmse: 2.4485e-04\n",
      "Epoch 1208: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5457e-07 - rmse: 3.9315e-04 - val_loss: 9.6099e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1209/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0598e-07 - rmse: 3.2554e-04\n",
      "Epoch 1209: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9228e-07 - rmse: 4.3849e-04 - val_loss: 9.6167e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1210/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3211e-07 - rmse: 3.6347e-04\n",
      "Epoch 1210: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9395e-07 - rmse: 4.4040e-04 - val_loss: 9.5684e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1211/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6549e-07 - rmse: 4.0681e-04\n",
      "Epoch 1211: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6906e-07 - rmse: 4.1117e-04 - val_loss: 9.5428e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1212/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5503e-07 - rmse: 3.9374e-04\n",
      "Epoch 1212: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5051e-07 - rmse: 3.8796e-04 - val_loss: 9.6068e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1213/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7427e-07 - rmse: 4.1746e-04\n",
      "Epoch 1213: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5680e-07 - rmse: 3.9598e-04 - val_loss: 9.6063e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1214/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6526e-07 - rmse: 4.0652e-04\n",
      "Epoch 1214: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4562e-07 - rmse: 3.8160e-04 - val_loss: 9.6206e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1215/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2974e-07 - rmse: 3.6019e-04\n",
      "Epoch 1215: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4900e-07 - rmse: 3.8601e-04 - val_loss: 9.5784e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1216/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6767e-08 - rmse: 2.9456e-04\n",
      "Epoch 1216: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2599e-07 - rmse: 3.5495e-04 - val_loss: 9.6040e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1217/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1499e-07 - rmse: 3.3910e-04\n",
      "Epoch 1217: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4704e-07 - rmse: 3.8346e-04 - val_loss: 9.5500e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1218/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1032e-07 - rmse: 3.3214e-04\n",
      "Epoch 1218: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2148e-07 - rmse: 3.4855e-04 - val_loss: 9.5186e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1219/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7694e-08 - rmse: 2.6018e-04\n",
      "Epoch 1219: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4826e-07 - rmse: 3.8505e-04 - val_loss: 9.5505e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1220/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1023e-07 - rmse: 4.5851e-04\n",
      "Epoch 1220: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3930e-07 - rmse: 3.7323e-04 - val_loss: 9.5948e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1221/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5579e-07 - rmse: 3.9470e-04\n",
      "Epoch 1221: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5863e-07 - rmse: 3.9829e-04 - val_loss: 9.6637e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1222/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4759e-08 - rmse: 2.7342e-04\n",
      "Epoch 1222: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3452e-07 - rmse: 3.6677e-04 - val_loss: 9.6600e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1223/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4705e-08 - rmse: 2.7332e-04\n",
      "Epoch 1223: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5585e-07 - rmse: 3.9478e-04 - val_loss: 9.6474e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1224/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4000e-08 - rmse: 2.3238e-04\n",
      "Epoch 1224: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1065e-07 - rmse: 3.3264e-04 - val_loss: 9.6172e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1225/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1307e-07 - rmse: 4.6160e-04\n",
      "Epoch 1225: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3928e-07 - rmse: 3.7320e-04 - val_loss: 9.6412e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1226/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7698e-07 - rmse: 4.2069e-04\n",
      "Epoch 1226: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6672e-07 - rmse: 4.0831e-04 - val_loss: 9.6177e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1227/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5855e-07 - rmse: 3.9818e-04\n",
      "Epoch 1227: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6452e-07 - rmse: 4.0561e-04 - val_loss: 9.5773e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1228/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0603e-07 - rmse: 4.5391e-04\n",
      "Epoch 1228: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4335e-07 - rmse: 3.7861e-04 - val_loss: 9.5953e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1229/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.9770e-08 - rmse: 3.1586e-04\n",
      "Epoch 1229: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2938e-07 - rmse: 3.5969e-04 - val_loss: 9.6648e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1230/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2944e-07 - rmse: 3.5978e-04\n",
      "Epoch 1230: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3407e-07 - rmse: 3.6616e-04 - val_loss: 9.6337e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1231/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5579e-07 - rmse: 3.9470e-04\n",
      "Epoch 1231: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9151e-07 - rmse: 4.3761e-04 - val_loss: 9.6554e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1232/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1186e-07 - rmse: 4.6028e-04\n",
      "Epoch 1232: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8855e-07 - rmse: 5.3717e-04 - val_loss: 9.6736e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1233/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4355e-07 - rmse: 3.7888e-04\n",
      "Epoch 1233: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0904e-07 - rmse: 4.5721e-04 - val_loss: 9.6550e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1234/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5450e-08 - rmse: 2.5583e-04\n",
      "Epoch 1234: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1109e-07 - rmse: 3.3331e-04 - val_loss: 9.6402e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1235/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4604e-07 - rmse: 3.8215e-04\n",
      "Epoch 1235: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1515e-07 - rmse: 3.3933e-04 - val_loss: 9.5938e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1236/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4590e-07 - rmse: 3.8197e-04\n",
      "Epoch 1236: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0672e-07 - rmse: 3.2668e-04 - val_loss: 9.6174e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1237/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0910e-07 - rmse: 5.5597e-04\n",
      "Epoch 1237: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5894e-07 - rmse: 3.9867e-04 - val_loss: 9.6464e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1238/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6272e-07 - rmse: 4.0339e-04\n",
      "Epoch 1238: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7882e-07 - rmse: 4.2287e-04 - val_loss: 9.6646e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1239/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5366e-08 - rmse: 3.0881e-04\n",
      "Epoch 1239: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6838e-07 - rmse: 4.1034e-04 - val_loss: 9.7107e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1240/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4611e-07 - rmse: 3.8225e-04\n",
      "Epoch 1240: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4890e-07 - rmse: 4.9890e-04 - val_loss: 9.6731e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1241/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4676e-07 - rmse: 7.3943e-04\n",
      "Epoch 1241: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2396e-07 - rmse: 5.6918e-04 - val_loss: 9.5690e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1242/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7468e-07 - rmse: 6.1211e-04\n",
      "Epoch 1242: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2791e-07 - rmse: 4.7740e-04 - val_loss: 9.5094e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1243/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0533e-07 - rmse: 3.2454e-04\n",
      "Epoch 1243: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2273e-07 - rmse: 3.5033e-04 - val_loss: 9.6093e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1244/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9082e-07 - rmse: 5.3928e-04\n",
      "Epoch 1244: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7556e-07 - rmse: 4.1899e-04 - val_loss: 9.5872e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1245/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4639e-07 - rmse: 3.8261e-04\n",
      "Epoch 1245: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3340e-07 - rmse: 3.6523e-04 - val_loss: 9.5919e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1246/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1453e-07 - rmse: 3.3842e-04\n",
      "Epoch 1246: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3472e-07 - rmse: 3.6704e-04 - val_loss: 9.6886e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1247/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1990e-07 - rmse: 3.4626e-04\n",
      "Epoch 1247: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2014e-07 - rmse: 3.4661e-04 - val_loss: 9.7035e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1248/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5353e-08 - rmse: 2.5564e-04\n",
      "Epoch 1248: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0463e-07 - rmse: 3.2347e-04 - val_loss: 9.6285e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1249/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1515e-08 - rmse: 2.8551e-04\n",
      "Epoch 1249: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0292e-07 - rmse: 3.2081e-04 - val_loss: 9.6453e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1250/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6084e-07 - rmse: 4.0105e-04\n",
      "Epoch 1250: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2494e-07 - rmse: 3.5347e-04 - val_loss: 9.6672e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1251/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0124e-07 - rmse: 3.1818e-04\n",
      "Epoch 1251: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1393e-07 - rmse: 3.3754e-04 - val_loss: 9.7191e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1252/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0756e-07 - rmse: 3.2796e-04\n",
      "Epoch 1252: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0516e-07 - rmse: 3.2429e-04 - val_loss: 9.6607e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1253/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6258e-08 - rmse: 3.1026e-04\n",
      "Epoch 1253: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1492e-07 - rmse: 4.6360e-04 - val_loss: 9.5565e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1254/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9887e-07 - rmse: 4.4594e-04\n",
      "Epoch 1254: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7484e-07 - rmse: 4.1814e-04 - val_loss: 9.4676e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1255/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8638e-07 - rmse: 6.2159e-04\n",
      "Epoch 1255: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1648e-07 - rmse: 4.6528e-04 - val_loss: 9.4644e-05 - val_rmse: 0.0097 - lr: 5.0000e-05\n",
      "Epoch 1256/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2142e-07 - rmse: 4.7056e-04\n",
      "Epoch 1256: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6541e-07 - rmse: 4.0670e-04 - val_loss: 9.6148e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1257/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7352e-08 - rmse: 3.1201e-04\n",
      "Epoch 1257: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7582e-07 - rmse: 4.1931e-04 - val_loss: 9.7352e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1258/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8371e-08 - rmse: 2.7995e-04\n",
      "Epoch 1258: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2628e-07 - rmse: 3.5535e-04 - val_loss: 9.6205e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1259/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1623e-08 - rmse: 3.0269e-04\n",
      "Epoch 1259: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3027e-08 - rmse: 3.0500e-04 - val_loss: 9.6220e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1260/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3552e-08 - rmse: 2.7120e-04\n",
      "Epoch 1260: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1107e-07 - rmse: 3.3327e-04 - val_loss: 9.6219e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1261/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3511e-07 - rmse: 3.6757e-04\n",
      "Epoch 1261: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2343e-07 - rmse: 3.5133e-04 - val_loss: 9.6383e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1262/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6229e-07 - rmse: 4.0286e-04\n",
      "Epoch 1262: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1176e-07 - rmse: 3.3431e-04 - val_loss: 9.6780e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1263/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5102e-08 - rmse: 3.0839e-04\n",
      "Epoch 1263: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7715e-08 - rmse: 2.9617e-04 - val_loss: 9.7351e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1264/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8532e-08 - rmse: 2.9754e-04\n",
      "Epoch 1264: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1924e-07 - rmse: 3.4531e-04 - val_loss: 9.7203e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1265/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3614e-07 - rmse: 3.6897e-04\n",
      "Epoch 1265: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3270e-07 - rmse: 3.6427e-04 - val_loss: 9.6578e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1266/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3303e-08 - rmse: 2.0809e-04\n",
      "Epoch 1266: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2479e-07 - rmse: 3.5326e-04 - val_loss: 9.6719e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1267/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1650e-08 - rmse: 2.4829e-04\n",
      "Epoch 1267: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0305e-07 - rmse: 3.2101e-04 - val_loss: 9.6627e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1268/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9898e-08 - rmse: 2.2338e-04\n",
      "Epoch 1268: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.8745e-08 - rmse: 2.9790e-04 - val_loss: 9.6762e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1269/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7655e-08 - rmse: 2.6011e-04\n",
      "Epoch 1269: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0384e-07 - rmse: 3.2225e-04 - val_loss: 9.6530e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1270/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3884e-07 - rmse: 3.7261e-04\n",
      "Epoch 1270: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9683e-08 - rmse: 3.1573e-04 - val_loss: 9.6568e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1271/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1915e-07 - rmse: 3.4518e-04\n",
      "Epoch 1271: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.9281e-08 - rmse: 3.1509e-04 - val_loss: 9.6269e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1272/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7993e-08 - rmse: 1.9492e-04\n",
      "Epoch 1272: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0059e-07 - rmse: 3.1715e-04 - val_loss: 9.6155e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1273/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0806e-07 - rmse: 3.2873e-04\n",
      "Epoch 1273: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1736e-07 - rmse: 3.4259e-04 - val_loss: 9.5885e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1274/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0121e-08 - rmse: 2.0030e-04\n",
      "Epoch 1274: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1093e-07 - rmse: 3.3306e-04 - val_loss: 9.5409e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1275/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0688e-07 - rmse: 3.2692e-04\n",
      "Epoch 1275: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3138e-07 - rmse: 3.6246e-04 - val_loss: 9.5862e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1276/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5805e-07 - rmse: 5.0799e-04\n",
      "Epoch 1276: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1806e-07 - rmse: 3.4359e-04 - val_loss: 9.7097e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1277/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3120e-08 - rmse: 2.5124e-04\n",
      "Epoch 1277: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0472e-07 - rmse: 3.2361e-04 - val_loss: 9.6844e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1278/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2978e-08 - rmse: 2.7014e-04\n",
      "Epoch 1278: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4207e-08 - rmse: 2.9018e-04 - val_loss: 9.6063e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1279/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2577e-08 - rmse: 2.8736e-04\n",
      "Epoch 1279: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9253e-08 - rmse: 2.6316e-04 - val_loss: 9.5787e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1280/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0304e-07 - rmse: 3.2100e-04\n",
      "Epoch 1280: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3890e-08 - rmse: 2.5276e-04 - val_loss: 9.6066e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1281/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6109e-08 - rmse: 1.9002e-04\n",
      "Epoch 1281: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.4734e-08 - rmse: 2.5443e-04 - val_loss: 9.6695e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1282/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7369e-08 - rmse: 2.5955e-04\n",
      "Epoch 1282: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7160e-08 - rmse: 2.5915e-04 - val_loss: 9.6977e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1283/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4730e-08 - rmse: 1.8636e-04\n",
      "Epoch 1283: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8891e-08 - rmse: 2.8087e-04 - val_loss: 9.6239e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1284/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7978e-08 - rmse: 1.6727e-04\n",
      "Epoch 1284: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2041e-08 - rmse: 2.4908e-04 - val_loss: 9.6196e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1285/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6484e-08 - rmse: 2.3766e-04\n",
      "Epoch 1285: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8989e-08 - rmse: 2.9831e-04 - val_loss: 9.6515e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1286/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2057e-07 - rmse: 3.4724e-04\n",
      "Epoch 1286: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6082e-08 - rmse: 2.5706e-04 - val_loss: 9.6535e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1287/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.2703e-08 - rmse: 2.2957e-04\n",
      "Epoch 1287: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9114e-08 - rmse: 2.8127e-04 - val_loss: 9.6651e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1288/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4836e-07 - rmse: 3.8518e-04\n",
      "Epoch 1288: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6557e-08 - rmse: 2.7669e-04 - val_loss: 9.7277e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1289/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4754e-08 - rmse: 2.3400e-04\n",
      "Epoch 1289: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6186e-08 - rmse: 2.5727e-04 - val_loss: 9.7367e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1290/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9865e-08 - rmse: 2.4467e-04\n",
      "Epoch 1290: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0789e-08 - rmse: 2.8423e-04 - val_loss: 9.7246e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1291/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2810e-07 - rmse: 4.7760e-04\n",
      "Epoch 1291: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2477e-07 - rmse: 3.5323e-04 - val_loss: 9.7046e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1292/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0301e-07 - rmse: 3.2095e-04\n",
      "Epoch 1292: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7520e-08 - rmse: 3.1228e-04 - val_loss: 9.6847e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1293/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0086e-07 - rmse: 4.4818e-04\n",
      "Epoch 1293: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8248e-08 - rmse: 3.1345e-04 - val_loss: 9.7290e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1294/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8644e-08 - rmse: 2.4216e-04\n",
      "Epoch 1294: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0512e-08 - rmse: 3.0085e-04 - val_loss: 9.7882e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1295/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3457e-08 - rmse: 2.3121e-04\n",
      "Epoch 1295: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8670e-08 - rmse: 2.8048e-04 - val_loss: 9.7789e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1296/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4941e-08 - rmse: 2.9145e-04\n",
      "Epoch 1296: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6743e-08 - rmse: 2.7703e-04 - val_loss: 9.6944e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1297/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4878e-08 - rmse: 2.9134e-04\n",
      "Epoch 1297: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1716e-07 - rmse: 3.4229e-04 - val_loss: 9.6011e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1298/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4635e-08 - rmse: 2.9092e-04\n",
      "Epoch 1298: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3369e-07 - rmse: 3.6563e-04 - val_loss: 9.6243e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1299/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4084e-07 - rmse: 3.7528e-04\n",
      "Epoch 1299: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0690e-07 - rmse: 3.2695e-04 - val_loss: 9.6818e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1300/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2415e-07 - rmse: 3.5234e-04\n",
      "Epoch 1300: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0182e-07 - rmse: 3.1910e-04 - val_loss: 9.7391e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1301/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6531e-07 - rmse: 4.0658e-04\n",
      "Epoch 1301: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8279e-08 - rmse: 2.9712e-04 - val_loss: 9.7727e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1302/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9284e-08 - rmse: 1.7112e-04\n",
      "Epoch 1302: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0017e-08 - rmse: 3.0003e-04 - val_loss: 9.7886e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1303/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1015e-07 - rmse: 3.3189e-04\n",
      "Epoch 1303: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8165e-08 - rmse: 2.9693e-04 - val_loss: 9.7682e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1304/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9371e-08 - rmse: 2.8173e-04\n",
      "Epoch 1304: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.3572e-08 - rmse: 2.8909e-04 - val_loss: 9.6931e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1305/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2507e-08 - rmse: 2.0617e-04\n",
      "Epoch 1305: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2012e-08 - rmse: 3.0333e-04 - val_loss: 9.6205e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1306/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8342e-08 - rmse: 2.9722e-04\n",
      "Epoch 1306: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4265e-08 - rmse: 2.5350e-04 - val_loss: 9.6417e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1307/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9128e-08 - rmse: 2.2165e-04\n",
      "Epoch 1307: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4321e-08 - rmse: 2.7262e-04 - val_loss: 9.6621e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1308/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2820e-07 - rmse: 3.5805e-04\n",
      "Epoch 1308: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3231e-08 - rmse: 2.5146e-04 - val_loss: 9.7109e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1309/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1580e-08 - rmse: 1.4690e-04\n",
      "Epoch 1309: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7449e-08 - rmse: 2.3968e-04 - val_loss: 9.7220e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1310/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5281e-08 - rmse: 1.5900e-04\n",
      "Epoch 1310: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7879e-08 - rmse: 2.4058e-04 - val_loss: 9.7467e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1311/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5573e-08 - rmse: 2.9253e-04\n",
      "Epoch 1311: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2947e-08 - rmse: 2.8801e-04 - val_loss: 9.7404e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1312/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6163e-07 - rmse: 4.0203e-04\n",
      "Epoch 1312: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8253e-08 - rmse: 2.7974e-04 - val_loss: 9.7198e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1313/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7792e-08 - rmse: 2.7891e-04\n",
      "Epoch 1313: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7305e-08 - rmse: 2.5943e-04 - val_loss: 9.7328e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1314/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3839e-08 - rmse: 2.5266e-04\n",
      "Epoch 1314: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4736e-08 - rmse: 2.3396e-04 - val_loss: 9.7173e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1315/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4096e-08 - rmse: 1.8465e-04\n",
      "Epoch 1315: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8175e-08 - rmse: 2.4119e-04 - val_loss: 9.7173e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1316/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7830e-08 - rmse: 2.7898e-04\n",
      "Epoch 1316: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8915e-08 - rmse: 2.8092e-04 - val_loss: 9.6457e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1317/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5667e-07 - rmse: 3.9582e-04\n",
      "Epoch 1317: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5477e-07 - rmse: 3.9341e-04 - val_loss: 9.6906e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1318/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1766e-07 - rmse: 3.4302e-04\n",
      "Epoch 1318: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1739e-07 - rmse: 3.4262e-04 - val_loss: 9.7182e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1319/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9266e-07 - rmse: 5.4098e-04\n",
      "Epoch 1319: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4909e-07 - rmse: 3.8612e-04 - val_loss: 9.7490e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1320/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3671e-07 - rmse: 3.6974e-04\n",
      "Epoch 1320: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1327e-07 - rmse: 3.3655e-04 - val_loss: 9.7018e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1321/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3743e-08 - rmse: 2.3183e-04\n",
      "Epoch 1321: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7677e-08 - rmse: 2.6015e-04 - val_loss: 9.7172e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1322/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9796e-08 - rmse: 1.9949e-04\n",
      "Epoch 1322: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5475e-08 - rmse: 2.9236e-04 - val_loss: 9.7147e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1323/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0174e-08 - rmse: 1.4204e-04\n",
      "Epoch 1323: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2651e-08 - rmse: 2.8749e-04 - val_loss: 9.7321e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1324/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8328e-08 - rmse: 2.6140e-04\n",
      "Epoch 1324: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7577e-08 - rmse: 3.1237e-04 - val_loss: 9.7408e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1325/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5646e-08 - rmse: 2.1365e-04\n",
      "Epoch 1325: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8707e-08 - rmse: 2.8055e-04 - val_loss: 9.7206e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1326/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6289e-08 - rmse: 2.7621e-04\n",
      "Epoch 1326: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8566e-08 - rmse: 2.8030e-04 - val_loss: 9.7154e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1327/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7939e-08 - rmse: 2.7918e-04\n",
      "Epoch 1327: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.9234e-08 - rmse: 3.1501e-04 - val_loss: 9.7003e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1328/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3409e-08 - rmse: 1.8278e-04\n",
      "Epoch 1328: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3874e-08 - rmse: 2.7180e-04 - val_loss: 9.7640e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1329/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2197e-07 - rmse: 3.4924e-04\n",
      "Epoch 1329: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3626e-07 - rmse: 3.6914e-04 - val_loss: 9.7329e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1330/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2619e-07 - rmse: 3.5523e-04\n",
      "Epoch 1330: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6188e-07 - rmse: 4.0235e-04 - val_loss: 9.7101e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1331/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4756e-07 - rmse: 3.8413e-04\n",
      "Epoch 1331: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5123e-07 - rmse: 3.8889e-04 - val_loss: 9.7566e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1332/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7753e-07 - rmse: 4.2134e-04\n",
      "Epoch 1332: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1844e-07 - rmse: 4.6737e-04 - val_loss: 9.7836e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1333/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9642e-07 - rmse: 4.4319e-04\n",
      "Epoch 1333: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5086e-07 - rmse: 3.8840e-04 - val_loss: 9.7904e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1334/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0024e-07 - rmse: 8.3680e-04\n",
      "Epoch 1334: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.1442e-07 - rmse: 5.6073e-04 - val_loss: 9.7596e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1335/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5916e-07 - rmse: 3.9895e-04\n",
      "Epoch 1335: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.8892e-07 - rmse: 4.3465e-04 - val_loss: 9.6003e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1336/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2171e-07 - rmse: 4.7086e-04\n",
      "Epoch 1336: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9220e-07 - rmse: 4.3841e-04 - val_loss: 9.6512e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1337/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8008e-07 - rmse: 5.2923e-04\n",
      "Epoch 1337: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2778e-07 - rmse: 4.7726e-04 - val_loss: 9.6907e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1338/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2156e-07 - rmse: 6.4928e-04\n",
      "Epoch 1338: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6464e-07 - rmse: 5.1443e-04 - val_loss: 9.8199e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1339/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8893e-08 - rmse: 2.8088e-04\n",
      "Epoch 1339: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6989e-07 - rmse: 4.1218e-04 - val_loss: 9.7941e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1340/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3901e-08 - rmse: 2.3217e-04\n",
      "Epoch 1340: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9174e-07 - rmse: 4.3788e-04 - val_loss: 9.7145e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1341/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1916e-07 - rmse: 3.4520e-04\n",
      "Epoch 1341: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1259e-07 - rmse: 4.6108e-04 - val_loss: 9.6218e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1342/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8993e-08 - rmse: 2.9832e-04\n",
      "Epoch 1342: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3791e-07 - rmse: 4.8776e-04 - val_loss: 9.6667e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1343/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8364e-08 - rmse: 2.4159e-04\n",
      "Epoch 1343: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8901e-07 - rmse: 4.3475e-04 - val_loss: 9.6759e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1344/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6169e-07 - rmse: 4.0211e-04\n",
      "Epoch 1344: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9244e-07 - rmse: 4.3868e-04 - val_loss: 9.6354e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1345/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8279e-07 - rmse: 5.3178e-04\n",
      "Epoch 1345: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7360e-07 - rmse: 4.1665e-04 - val_loss: 9.6089e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1346/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5559e-07 - rmse: 5.0556e-04\n",
      "Epoch 1346: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6264e-07 - rmse: 4.0329e-04 - val_loss: 9.6186e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1347/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4726e-07 - rmse: 3.8375e-04\n",
      "Epoch 1347: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3903e-07 - rmse: 3.7287e-04 - val_loss: 9.7010e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1348/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2021e-07 - rmse: 3.4672e-04\n",
      "Epoch 1348: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4179e-07 - rmse: 3.7655e-04 - val_loss: 9.6661e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1349/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0215e-07 - rmse: 3.1961e-04\n",
      "Epoch 1349: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5228e-07 - rmse: 3.9024e-04 - val_loss: 9.7438e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1350/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3754e-07 - rmse: 3.7087e-04\n",
      "Epoch 1350: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6497e-07 - rmse: 4.0616e-04 - val_loss: 9.7128e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1351/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0802e-07 - rmse: 3.2866e-04\n",
      "Epoch 1351: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9704e-08 - rmse: 2.9951e-04 - val_loss: 9.7588e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1352/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1946e-07 - rmse: 4.6846e-04\n",
      "Epoch 1352: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4839e-07 - rmse: 3.8521e-04 - val_loss: 9.7695e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1353/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2053e-07 - rmse: 3.4718e-04\n",
      "Epoch 1353: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2522e-08 - rmse: 3.0417e-04 - val_loss: 9.7837e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1354/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1040e-07 - rmse: 3.3227e-04\n",
      "Epoch 1354: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0678e-07 - rmse: 3.2677e-04 - val_loss: 9.8711e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1355/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3490e-07 - rmse: 4.8467e-04\n",
      "Epoch 1355: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4465e-07 - rmse: 3.8033e-04 - val_loss: 9.7375e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1356/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8887e-08 - rmse: 2.6246e-04\n",
      "Epoch 1356: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3085e-07 - rmse: 3.6174e-04 - val_loss: 9.6674e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1357/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6485e-08 - rmse: 2.3767e-04\n",
      "Epoch 1357: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4175e-07 - rmse: 3.7650e-04 - val_loss: 9.7499e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1358/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3827e-08 - rmse: 2.8953e-04\n",
      "Epoch 1358: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9106e-07 - rmse: 4.3710e-04 - val_loss: 9.8725e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1359/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4677e-07 - rmse: 3.8310e-04\n",
      "Epoch 1359: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5801e-07 - rmse: 3.9751e-04 - val_loss: 9.6755e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1360/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1849e-08 - rmse: 3.0307e-04\n",
      "Epoch 1360: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1033e-07 - rmse: 3.3215e-04 - val_loss: 9.6560e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1361/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9937e-08 - rmse: 2.4482e-04\n",
      "Epoch 1361: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5582e-08 - rmse: 3.0916e-04 - val_loss: 9.6956e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1362/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7924e-08 - rmse: 2.4067e-04\n",
      "Epoch 1362: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4810e-08 - rmse: 2.7351e-04 - val_loss: 9.7370e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1363/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1386e-08 - rmse: 2.0344e-04\n",
      "Epoch 1363: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9860e-08 - rmse: 3.1601e-04 - val_loss: 9.7669e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1364/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5366e-08 - rmse: 3.0881e-04\n",
      "Epoch 1364: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5428e-08 - rmse: 2.7464e-04 - val_loss: 9.7107e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1365/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7848e-08 - rmse: 2.1874e-04\n",
      "Epoch 1365: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7235e-08 - rmse: 2.9536e-04 - val_loss: 9.6300e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1366/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4248e-08 - rmse: 1.5572e-04\n",
      "Epoch 1366: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3628e-08 - rmse: 2.8919e-04 - val_loss: 9.7238e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1367/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3529e-08 - rmse: 2.5205e-04\n",
      "Epoch 1367: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1652e-08 - rmse: 2.6768e-04 - val_loss: 9.7962e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1368/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5207e-08 - rmse: 2.7424e-04\n",
      "Epoch 1368: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3998e-08 - rmse: 2.7203e-04 - val_loss: 9.7843e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1369/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8920e-08 - rmse: 2.2118e-04\n",
      "Epoch 1369: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1852e-07 - rmse: 3.4427e-04 - val_loss: 9.8141e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1370/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4823e-08 - rmse: 3.0793e-04\n",
      "Epoch 1370: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6219e-07 - rmse: 4.0273e-04 - val_loss: 9.7007e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1371/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1834e-07 - rmse: 3.4400e-04\n",
      "Epoch 1371: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2238e-07 - rmse: 3.4983e-04 - val_loss: 9.6842e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1372/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5352e-08 - rmse: 2.3527e-04\n",
      "Epoch 1372: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.3741e-08 - rmse: 2.8938e-04 - val_loss: 9.7578e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1373/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8443e-08 - rmse: 2.6162e-04\n",
      "Epoch 1373: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9146e-08 - rmse: 2.9857e-04 - val_loss: 9.7160e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1374/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9958e-08 - rmse: 2.2351e-04\n",
      "Epoch 1374: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2910e-08 - rmse: 2.5082e-04 - val_loss: 9.7300e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1375/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6933e-08 - rmse: 3.1134e-04\n",
      "Epoch 1375: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5244e-08 - rmse: 2.3504e-04 - val_loss: 9.7074e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1376/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7134e-08 - rmse: 2.3903e-04\n",
      "Epoch 1376: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8287e-08 - rmse: 2.6132e-04 - val_loss: 9.6322e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1377/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7993e-08 - rmse: 2.6075e-04\n",
      "Epoch 1377: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5710e-08 - rmse: 2.3603e-04 - val_loss: 9.7278e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1378/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0878e-08 - rmse: 2.0218e-04\n",
      "Epoch 1378: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7791e-08 - rmse: 2.1861e-04 - val_loss: 9.7422e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1379/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4262e-08 - rmse: 2.7251e-04\n",
      "Epoch 1379: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4261e-08 - rmse: 2.1038e-04 - val_loss: 9.7691e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1380/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2612e-08 - rmse: 2.0643e-04\n",
      "Epoch 1380: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7260e-08 - rmse: 1.9303e-04 - val_loss: 9.7105e-05 - val_rmse: 0.0099 - lr: 5.0000e-05\n",
      "Epoch 1381/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7188e-08 - rmse: 2.1723e-04\n",
      "Epoch 1381: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7493e-08 - rmse: 2.1793e-04 - val_loss: 9.6225e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1382/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6731e-08 - rmse: 2.5832e-04\n",
      "Epoch 1382: val_loss did not improve from 0.00009\n",
      "\n",
      "Epoch 1382: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0264e-08 - rmse: 2.4549e-04 - val_loss: 9.6842e-05 - val_rmse: 0.0098 - lr: 5.0000e-05\n",
      "Epoch 1383/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7798e-08 - rmse: 3.1273e-04\n",
      "Epoch 1383: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1394e-08 - rmse: 2.8530e-04 - val_loss: 9.7612e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1384/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3520e-08 - rmse: 1.8308e-04\n",
      "Epoch 1384: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1702e-08 - rmse: 2.2738e-04 - val_loss: 9.7781e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1385/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0004e-07 - rmse: 3.1630e-04\n",
      "Epoch 1385: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5734e-08 - rmse: 2.7520e-04 - val_loss: 9.7171e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1386/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1345e-08 - rmse: 1.4610e-04\n",
      "Epoch 1386: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4911e-08 - rmse: 1.8684e-04 - val_loss: 9.6919e-05 - val_rmse: 0.0098 - lr: 2.5000e-05\n",
      "Epoch 1387/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3681e-08 - rmse: 1.1697e-04\n",
      "Epoch 1387: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7728e-08 - rmse: 1.6652e-04 - val_loss: 9.7028e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1388/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8901e-09 - rmse: 9.4287e-05\n",
      "Epoch 1388: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7345e-08 - rmse: 1.6536e-04 - val_loss: 9.6970e-05 - val_rmse: 0.0098 - lr: 2.5000e-05\n",
      "Epoch 1389/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7050e-08 - rmse: 1.6447e-04\n",
      "Epoch 1389: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8966e-08 - rmse: 1.7019e-04 - val_loss: 9.7462e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1390/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2745e-08 - rmse: 1.1290e-04\n",
      "Epoch 1390: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9261e-08 - rmse: 1.7106e-04 - val_loss: 9.7141e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1391/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0171e-08 - rmse: 2.0043e-04\n",
      "Epoch 1391: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6294e-08 - rmse: 1.6215e-04 - val_loss: 9.7360e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1392/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1111e-09 - rmse: 7.1492e-05\n",
      "Epoch 1392: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7207e-08 - rmse: 1.6495e-04 - val_loss: 9.7627e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1393/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3826e-08 - rmse: 1.8392e-04\n",
      "Epoch 1393: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1071e-08 - rmse: 1.7627e-04 - val_loss: 9.6915e-05 - val_rmse: 0.0098 - lr: 2.5000e-05\n",
      "Epoch 1394/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8905e-08 - rmse: 1.9724e-04\n",
      "Epoch 1394: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5263e-08 - rmse: 1.5894e-04 - val_loss: 9.6959e-05 - val_rmse: 0.0098 - lr: 2.5000e-05\n",
      "Epoch 1395/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5416e-08 - rmse: 1.2416e-04\n",
      "Epoch 1395: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6820e-08 - rmse: 1.6377e-04 - val_loss: 9.7368e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1396/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4856e-09 - rmse: 9.7394e-05\n",
      "Epoch 1396: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3828e-08 - rmse: 1.5436e-04 - val_loss: 9.7518e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1397/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4470e-08 - rmse: 1.2029e-04\n",
      "Epoch 1397: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2945e-08 - rmse: 1.5148e-04 - val_loss: 9.7417e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1398/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0955e-08 - rmse: 1.7594e-04\n",
      "Epoch 1398: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2613e-08 - rmse: 1.5038e-04 - val_loss: 9.7105e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1399/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5463e-08 - rmse: 1.5957e-04\n",
      "Epoch 1399: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7564e-08 - rmse: 1.6603e-04 - val_loss: 9.7191e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1400/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8727e-08 - rmse: 1.3685e-04\n",
      "Epoch 1400: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3192e-08 - rmse: 1.5229e-04 - val_loss: 9.7142e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1401/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2490e-09 - rmse: 8.5141e-05\n",
      "Epoch 1401: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3109e-08 - rmse: 1.5202e-04 - val_loss: 9.7472e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1402/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2428e-08 - rmse: 1.4976e-04\n",
      "Epoch 1402: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2663e-08 - rmse: 1.5054e-04 - val_loss: 9.7382e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1403/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6799e-09 - rmse: 9.3166e-05\n",
      "Epoch 1403: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0899e-08 - rmse: 1.4456e-04 - val_loss: 9.7102e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1404/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.6128e-09 - rmse: 9.8045e-05\n",
      "Epoch 1404: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4872e-08 - rmse: 1.5771e-04 - val_loss: 9.7493e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1405/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3962e-08 - rmse: 1.1816e-04\n",
      "Epoch 1405: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9488e-08 - rmse: 1.7172e-04 - val_loss: 9.7053e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1406/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3182e-08 - rmse: 1.8216e-04\n",
      "Epoch 1406: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8295e-08 - rmse: 1.9569e-04 - val_loss: 9.7249e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1407/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4061e-08 - rmse: 2.0991e-04\n",
      "Epoch 1407: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7610e-08 - rmse: 1.9393e-04 - val_loss: 9.7328e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1408/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8285e-09 - rmse: 7.6345e-05\n",
      "Epoch 1408: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8796e-08 - rmse: 1.9697e-04 - val_loss: 9.7645e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1409/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1053e-08 - rmse: 2.6656e-04\n",
      "Epoch 1409: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.8149e-08 - rmse: 1.9532e-04 - val_loss: 9.7500e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1410/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0118e-08 - rmse: 1.7355e-04\n",
      "Epoch 1410: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1340e-08 - rmse: 1.4608e-04 - val_loss: 9.7234e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1411/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2423e-08 - rmse: 1.1146e-04\n",
      "Epoch 1411: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5554e-08 - rmse: 1.5986e-04 - val_loss: 9.7249e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1412/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3781e-09 - rmse: 9.6841e-05\n",
      "Epoch 1412: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2343e-08 - rmse: 1.4947e-04 - val_loss: 9.7403e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1413/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6270e-08 - rmse: 1.2756e-04\n",
      "Epoch 1413: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2831e-08 - rmse: 1.5110e-04 - val_loss: 9.7539e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1414/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5171e-08 - rmse: 1.2317e-04\n",
      "Epoch 1414: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1892e-08 - rmse: 1.4796e-04 - val_loss: 9.7346e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1415/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2675e-08 - rmse: 1.5058e-04\n",
      "Epoch 1415: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5055e-08 - rmse: 1.5829e-04 - val_loss: 9.7419e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1416/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4149e-08 - rmse: 2.3270e-04\n",
      "Epoch 1416: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2653e-08 - rmse: 1.5051e-04 - val_loss: 9.7429e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1417/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5075e-08 - rmse: 1.5835e-04\n",
      "Epoch 1417: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2965e-08 - rmse: 1.5154e-04 - val_loss: 9.7563e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1418/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4578e-08 - rmse: 1.5677e-04\n",
      "Epoch 1418: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3857e-08 - rmse: 1.5446e-04 - val_loss: 9.7430e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1419/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6704e-08 - rmse: 1.2924e-04\n",
      "Epoch 1419: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6483e-08 - rmse: 1.6274e-04 - val_loss: 9.7391e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1420/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3481e-08 - rmse: 1.8298e-04\n",
      "Epoch 1420: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7780e-08 - rmse: 1.9437e-04 - val_loss: 9.7394e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1421/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5982e-08 - rmse: 1.8969e-04\n",
      "Epoch 1421: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2182e-08 - rmse: 1.7939e-04 - val_loss: 9.7589e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1422/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0611e-08 - rmse: 1.4357e-04\n",
      "Epoch 1422: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2507e-08 - rmse: 1.8030e-04 - val_loss: 9.7669e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1423/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0556e-08 - rmse: 1.0274e-04\n",
      "Epoch 1423: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.3860e-08 - rmse: 1.5447e-04 - val_loss: 9.7595e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1424/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6758e-09 - rmse: 8.7611e-05\n",
      "Epoch 1424: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6733e-08 - rmse: 1.6350e-04 - val_loss: 9.7505e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1425/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8500e-08 - rmse: 1.6882e-04\n",
      "Epoch 1425: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.6294e-08 - rmse: 1.6215e-04 - val_loss: 9.7309e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1426/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7411e-08 - rmse: 2.1774e-04\n",
      "Epoch 1426: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5380e-08 - rmse: 1.8810e-04 - val_loss: 9.7719e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1427/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6550e-08 - rmse: 2.1575e-04\n",
      "Epoch 1427: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7374e-08 - rmse: 1.9332e-04 - val_loss: 9.7987e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1428/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1249e-08 - rmse: 1.7677e-04\n",
      "Epoch 1428: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7949e-08 - rmse: 1.6718e-04 - val_loss: 9.7522e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1429/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8831e-08 - rmse: 1.6980e-04\n",
      "Epoch 1429: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2441e-08 - rmse: 1.8011e-04 - val_loss: 9.7530e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1430/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5584e-08 - rmse: 1.8864e-04\n",
      "Epoch 1430: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6732e-08 - rmse: 1.6350e-04 - val_loss: 9.7342e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1431/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3149e-08 - rmse: 1.8207e-04\n",
      "Epoch 1431: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.8308e-08 - rmse: 1.6825e-04 - val_loss: 9.7373e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1432/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0271e-09 - rmse: 8.9594e-05\n",
      "Epoch 1432: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2028e-08 - rmse: 1.4842e-04 - val_loss: 9.7488e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1433/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8391e-08 - rmse: 1.6850e-04\n",
      "Epoch 1433: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9809e-08 - rmse: 1.4074e-04 - val_loss: 9.7773e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1434/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5535e-08 - rmse: 1.8851e-04\n",
      "Epoch 1434: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2572e-08 - rmse: 1.5024e-04 - val_loss: 9.7823e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1435/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.6849e-09 - rmse: 8.1761e-05\n",
      "Epoch 1435: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4358e-08 - rmse: 1.5607e-04 - val_loss: 9.7512e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1436/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6755e-08 - rmse: 1.6357e-04\n",
      "Epoch 1436: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6883e-08 - rmse: 1.6396e-04 - val_loss: 9.7694e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1437/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7566e-08 - rmse: 1.6603e-04\n",
      "Epoch 1437: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0116e-08 - rmse: 1.4183e-04 - val_loss: 9.7691e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1438/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8969e-09 - rmse: 8.3048e-05\n",
      "Epoch 1438: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.8733e-08 - rmse: 1.3687e-04 - val_loss: 9.7660e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1439/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5263e-08 - rmse: 1.8779e-04\n",
      "Epoch 1439: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2862e-08 - rmse: 1.5120e-04 - val_loss: 9.7766e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1440/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4395e-08 - rmse: 1.5619e-04\n",
      "Epoch 1440: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3076e-08 - rmse: 1.5191e-04 - val_loss: 9.7606e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1441/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1906e-08 - rmse: 1.0911e-04\n",
      "Epoch 1441: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7474e-08 - rmse: 1.6575e-04 - val_loss: 9.7095e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1442/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7499e-08 - rmse: 2.1794e-04\n",
      "Epoch 1442: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8880e-08 - rmse: 1.6994e-04 - val_loss: 9.7610e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1443/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9928e-08 - rmse: 1.7300e-04\n",
      "Epoch 1443: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6346e-08 - rmse: 1.6231e-04 - val_loss: 9.7851e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1444/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5230e-08 - rmse: 1.8770e-04\n",
      "Epoch 1444: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0074e-08 - rmse: 1.7342e-04 - val_loss: 9.7677e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1445/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7036e-08 - rmse: 2.3882e-04\n",
      "Epoch 1445: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2687e-08 - rmse: 1.8080e-04 - val_loss: 9.7558e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1446/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3866e-08 - rmse: 2.3209e-04\n",
      "Epoch 1446: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2986e-08 - rmse: 1.8162e-04 - val_loss: 9.7483e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1447/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2589e-08 - rmse: 1.1220e-04\n",
      "Epoch 1447: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7532e-08 - rmse: 1.6593e-04 - val_loss: 9.7198e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1448/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3554e-09 - rmse: 7.9721e-05\n",
      "Epoch 1448: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1050e-08 - rmse: 1.4508e-04 - val_loss: 9.7055e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1449/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1088e-08 - rmse: 1.4522e-04\n",
      "Epoch 1449: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7950e-08 - rmse: 1.6718e-04 - val_loss: 9.7625e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1450/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4687e-08 - rmse: 1.2119e-04\n",
      "Epoch 1450: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7082e-08 - rmse: 1.6457e-04 - val_loss: 9.7637e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1451/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0759e-08 - rmse: 2.0189e-04\n",
      "Epoch 1451: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7347e-08 - rmse: 1.6537e-04 - val_loss: 9.7737e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1452/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8120e-08 - rmse: 1.3461e-04\n",
      "Epoch 1452: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.9359e-08 - rmse: 1.7134e-04 - val_loss: 9.7667e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1453/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4834e-09 - rmse: 8.0519e-05\n",
      "Epoch 1453: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7882e-08 - rmse: 1.6698e-04 - val_loss: 9.7704e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1454/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8558e-08 - rmse: 2.2036e-04\n",
      "Epoch 1454: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.8175e-08 - rmse: 1.6785e-04 - val_loss: 9.7773e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1455/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1296e-08 - rmse: 1.0628e-04\n",
      "Epoch 1455: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6861e-08 - rmse: 1.6389e-04 - val_loss: 9.7914e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1456/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8366e-08 - rmse: 1.3552e-04\n",
      "Epoch 1456: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3986e-08 - rmse: 1.5488e-04 - val_loss: 9.7924e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1457/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7743e-08 - rmse: 1.3320e-04\n",
      "Epoch 1457: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2338e-08 - rmse: 1.4946e-04 - val_loss: 9.7648e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1458/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1545e-09 - rmse: 5.6165e-05\n",
      "Epoch 1458: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4085e-08 - rmse: 1.5519e-04 - val_loss: 9.7523e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1459/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9091e-08 - rmse: 1.9771e-04\n",
      "Epoch 1459: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3231e-08 - rmse: 1.5242e-04 - val_loss: 9.7488e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1460/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8320e-09 - rmse: 9.3979e-05\n",
      "Epoch 1460: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5367e-08 - rmse: 1.5927e-04 - val_loss: 9.7656e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1461/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8215e-08 - rmse: 1.3496e-04\n",
      "Epoch 1461: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0474e-08 - rmse: 1.4309e-04 - val_loss: 9.7842e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1462/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5233e-08 - rmse: 1.2342e-04\n",
      "Epoch 1462: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1823e-08 - rmse: 1.4773e-04 - val_loss: 9.7955e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1463/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3198e-08 - rmse: 1.5231e-04\n",
      "Epoch 1463: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0167e-08 - rmse: 1.4201e-04 - val_loss: 9.7746e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1464/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2116e-08 - rmse: 2.0522e-04\n",
      "Epoch 1464: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3991e-08 - rmse: 1.5489e-04 - val_loss: 9.7451e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1465/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9508e-08 - rmse: 1.7178e-04\n",
      "Epoch 1465: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3186e-08 - rmse: 1.5227e-04 - val_loss: 9.7349e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1466/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3581e-08 - rmse: 1.1654e-04\n",
      "Epoch 1466: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1804e-08 - rmse: 1.4766e-04 - val_loss: 9.7646e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1467/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1133e-08 - rmse: 1.7645e-04\n",
      "Epoch 1467: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3896e-08 - rmse: 1.5458e-04 - val_loss: 9.7737e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1468/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0071e-08 - rmse: 1.4167e-04\n",
      "Epoch 1468: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2661e-08 - rmse: 1.5054e-04 - val_loss: 9.8084e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1469/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7793e-08 - rmse: 1.9440e-04\n",
      "Epoch 1469: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6037e-08 - rmse: 1.6136e-04 - val_loss: 9.8061e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1470/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6604e-08 - rmse: 1.9132e-04\n",
      "Epoch 1470: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5328e-08 - rmse: 1.5915e-04 - val_loss: 9.7711e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1471/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7892e-08 - rmse: 1.3376e-04\n",
      "Epoch 1471: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9081e-08 - rmse: 1.3813e-04 - val_loss: 9.7883e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1472/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2221e-08 - rmse: 1.4907e-04\n",
      "Epoch 1472: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9618e-08 - rmse: 1.4006e-04 - val_loss: 9.7872e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1473/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2961e-08 - rmse: 2.0727e-04\n",
      "Epoch 1473: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1034e-08 - rmse: 1.4503e-04 - val_loss: 9.7751e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1474/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2605e-09 - rmse: 5.7101e-05\n",
      "Epoch 1474: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7815e-08 - rmse: 1.3347e-04 - val_loss: 9.7614e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1475/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6872e-08 - rmse: 1.2989e-04\n",
      "Epoch 1475: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9773e-08 - rmse: 1.4062e-04 - val_loss: 9.7663e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1476/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5585e-08 - rmse: 1.2484e-04\n",
      "Epoch 1476: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5954e-08 - rmse: 1.6110e-04 - val_loss: 9.7475e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1477/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7657e-09 - rmse: 8.8123e-05\n",
      "Epoch 1477: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5520e-08 - rmse: 1.5975e-04 - val_loss: 9.7965e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1478/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3981e-08 - rmse: 1.8434e-04\n",
      "Epoch 1478: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7527e-08 - rmse: 1.6591e-04 - val_loss: 9.7879e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1479/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6404e-08 - rmse: 1.2808e-04\n",
      "Epoch 1479: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5906e-08 - rmse: 1.6095e-04 - val_loss: 9.7803e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1480/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1167e-08 - rmse: 1.0567e-04\n",
      "Epoch 1480: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0608e-08 - rmse: 1.4356e-04 - val_loss: 9.7792e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1481/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7158e-08 - rmse: 1.3099e-04\n",
      "Epoch 1481: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1432e-08 - rmse: 1.4640e-04 - val_loss: 9.7894e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1482/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3533e-08 - rmse: 1.8312e-04\n",
      "Epoch 1482: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1683e-08 - rmse: 1.4725e-04 - val_loss: 9.8025e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1483/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 8.6282e-09 - rmse: 9.2888e-05\n",
      "Epoch 1483: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9250e-08 - rmse: 1.3875e-04 - val_loss: 9.7840e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1484/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1976e-08 - rmse: 1.0944e-04\n",
      "Epoch 1484: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8256e-08 - rmse: 1.3512e-04 - val_loss: 9.7765e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1485/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7474e-08 - rmse: 1.3219e-04\n",
      "Epoch 1485: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8976e-08 - rmse: 1.3775e-04 - val_loss: 9.7832e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1486/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2522e-08 - rmse: 1.1190e-04\n",
      "Epoch 1486: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1689e-08 - rmse: 1.4727e-04 - val_loss: 9.7638e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1487/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1709e-08 - rmse: 1.4734e-04\n",
      "Epoch 1487: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8761e-08 - rmse: 1.3697e-04 - val_loss: 9.7737e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1488/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9777e-08 - rmse: 1.7256e-04\n",
      "Epoch 1488: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6929e-08 - rmse: 1.3011e-04 - val_loss: 9.7886e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1489/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1278e-09 - rmse: 9.5540e-05\n",
      "Epoch 1489: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8449e-08 - rmse: 1.3583e-04 - val_loss: 9.8072e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1490/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2492e-08 - rmse: 1.4997e-04\n",
      "Epoch 1490: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5590e-08 - rmse: 1.5997e-04 - val_loss: 9.8217e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1491/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8826e-08 - rmse: 1.6978e-04\n",
      "Epoch 1491: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4604e-08 - rmse: 1.8602e-04 - val_loss: 9.7999e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1492/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8229e-08 - rmse: 1.3502e-04\n",
      "Epoch 1492: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4693e-08 - rmse: 1.8626e-04 - val_loss: 9.7865e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1493/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7147e-08 - rmse: 1.9273e-04\n",
      "Epoch 1493: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2834e-08 - rmse: 1.8120e-04 - val_loss: 9.7545e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1494/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1373e-08 - rmse: 2.4774e-04\n",
      "Epoch 1494: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0644e-08 - rmse: 1.7505e-04 - val_loss: 9.7755e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1495/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4014e-08 - rmse: 1.8443e-04\n",
      "Epoch 1495: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.6201e-08 - rmse: 1.9027e-04 - val_loss: 9.8321e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1496/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1472e-08 - rmse: 2.6734e-04\n",
      "Epoch 1496: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0095e-08 - rmse: 2.0024e-04 - val_loss: 9.8127e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1497/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2249e-08 - rmse: 1.1067e-04\n",
      "Epoch 1497: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5964e-08 - rmse: 1.8964e-04 - val_loss: 9.8065e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1498/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1410e-08 - rmse: 2.2674e-04\n",
      "Epoch 1498: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0374e-08 - rmse: 1.7428e-04 - val_loss: 9.7929e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1499/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1053e-08 - rmse: 1.0513e-04\n",
      "Epoch 1499: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.4458e-08 - rmse: 1.8563e-04 - val_loss: 9.7901e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1500/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2379e-08 - rmse: 2.0586e-04\n",
      "Epoch 1500: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.0027e-08 - rmse: 1.7328e-04 - val_loss: 9.7968e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1501/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6852e-08 - rmse: 1.6387e-04\n",
      "Epoch 1501: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1031e-08 - rmse: 1.7616e-04 - val_loss: 9.8097e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1502/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0167e-08 - rmse: 1.7369e-04\n",
      "Epoch 1502: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2161e-08 - rmse: 1.7933e-04 - val_loss: 9.8256e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1503/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1798e-08 - rmse: 2.2759e-04\n",
      "Epoch 1503: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6110e-08 - rmse: 1.6158e-04 - val_loss: 9.7867e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1504/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4323e-08 - rmse: 2.1053e-04\n",
      "Epoch 1504: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0428e-08 - rmse: 1.4293e-04 - val_loss: 9.7625e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1505/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9094e-08 - rmse: 1.3818e-04\n",
      "Epoch 1505: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8917e-08 - rmse: 1.7005e-04 - val_loss: 9.7478e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1506/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1935e-08 - rmse: 1.4810e-04\n",
      "Epoch 1506: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.1990e-08 - rmse: 1.7886e-04 - val_loss: 9.8067e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1507/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5037e-08 - rmse: 1.2263e-04\n",
      "Epoch 1507: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1043e-08 - rmse: 1.4506e-04 - val_loss: 9.8382e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1508/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1274e-08 - rmse: 1.4586e-04\n",
      "Epoch 1508: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9871e-08 - rmse: 1.4096e-04 - val_loss: 9.8184e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1509/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4096e-08 - rmse: 1.1873e-04\n",
      "Epoch 1509: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9914e-08 - rmse: 1.4112e-04 - val_loss: 9.7833e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1510/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4003e-09 - rmse: 8.6025e-05\n",
      "Epoch 1510: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6851e-08 - rmse: 1.2981e-04 - val_loss: 9.7893e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1511/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4899e-09 - rmse: 4.9899e-05\n",
      "Epoch 1511: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1168e-08 - rmse: 1.4549e-04 - val_loss: 9.7985e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1512/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6341e-09 - rmse: 7.5060e-05\n",
      "Epoch 1512: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8338e-08 - rmse: 1.3542e-04 - val_loss: 9.8209e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1513/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5680e-08 - rmse: 1.2522e-04\n",
      "Epoch 1513: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0588e-08 - rmse: 1.4349e-04 - val_loss: 9.7704e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1514/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1606e-08 - rmse: 1.4699e-04\n",
      "Epoch 1514: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1314e-08 - rmse: 1.4599e-04 - val_loss: 9.8053e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1515/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1499e-09 - rmse: 6.4420e-05\n",
      "Epoch 1515: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7451e-08 - rmse: 1.3210e-04 - val_loss: 9.8018e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1516/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6685e-08 - rmse: 1.6335e-04\n",
      "Epoch 1516: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7128e-08 - rmse: 1.3087e-04 - val_loss: 9.8062e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1517/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2575e-09 - rmse: 5.7074e-05\n",
      "Epoch 1517: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4581e-08 - rmse: 1.2075e-04 - val_loss: 9.7860e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1518/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2569e-09 - rmse: 9.0867e-05\n",
      "Epoch 1518: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1309e-08 - rmse: 1.4598e-04 - val_loss: 9.7990e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1519/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0705e-08 - rmse: 1.4389e-04\n",
      "Epoch 1519: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9037e-08 - rmse: 1.7040e-04 - val_loss: 9.8137e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1520/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8340e-08 - rmse: 1.9581e-04\n",
      "Epoch 1520: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1101e-08 - rmse: 2.0273e-04 - val_loss: 9.8215e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1521/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7175e-08 - rmse: 1.3105e-04\n",
      "Epoch 1521: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9282e-08 - rmse: 2.2200e-04 - val_loss: 9.8632e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1522/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1458e-08 - rmse: 1.7736e-04\n",
      "Epoch 1522: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6674e-08 - rmse: 1.9150e-04 - val_loss: 9.8311e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1523/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.0591e-09 - rmse: 7.7840e-05\n",
      "Epoch 1523: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7511e-08 - rmse: 1.6586e-04 - val_loss: 9.7962e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1524/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4648e-08 - rmse: 1.5700e-04\n",
      "Epoch 1524: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8700e-08 - rmse: 1.6941e-04 - val_loss: 9.7766e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1525/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6610e-08 - rmse: 1.2888e-04\n",
      "Epoch 1525: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1885e-08 - rmse: 1.4794e-04 - val_loss: 9.7975e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1526/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7024e-08 - rmse: 1.6439e-04\n",
      "Epoch 1526: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4400e-08 - rmse: 1.5620e-04 - val_loss: 9.7920e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1527/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6738e-08 - rmse: 1.2938e-04\n",
      "Epoch 1527: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1907e-08 - rmse: 1.4801e-04 - val_loss: 9.7908e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1528/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5801e-08 - rmse: 1.6063e-04\n",
      "Epoch 1528: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1334e-08 - rmse: 2.0331e-04 - val_loss: 9.8082e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1529/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6519e-08 - rmse: 2.1568e-04\n",
      "Epoch 1529: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1076e-08 - rmse: 2.2600e-04 - val_loss: 9.7900e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1530/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5578e-08 - rmse: 2.3575e-04\n",
      "Epoch 1530: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9727e-08 - rmse: 2.2300e-04 - val_loss: 9.7450e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1531/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0346e-07 - rmse: 3.2166e-04\n",
      "Epoch 1531: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.7071e-08 - rmse: 2.1696e-04 - val_loss: 9.8022e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1532/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3945e-08 - rmse: 1.8424e-04\n",
      "Epoch 1532: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3979e-08 - rmse: 1.8433e-04 - val_loss: 9.8370e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1533/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3094e-08 - rmse: 1.8192e-04\n",
      "Epoch 1533: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8951e-08 - rmse: 1.7015e-04 - val_loss: 9.8627e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1534/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4131e-08 - rmse: 2.3266e-04\n",
      "Epoch 1534: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4169e-08 - rmse: 2.1016e-04 - val_loss: 9.8270e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1535/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2073e-08 - rmse: 1.4857e-04\n",
      "Epoch 1535: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3537e-08 - rmse: 1.8313e-04 - val_loss: 9.8052e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1536/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1904e-08 - rmse: 1.7862e-04\n",
      "Epoch 1536: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.9117e-08 - rmse: 1.9778e-04 - val_loss: 9.7775e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1537/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2479e-08 - rmse: 2.0610e-04\n",
      "Epoch 1537: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.5140e-08 - rmse: 2.1246e-04 - val_loss: 9.7814e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1538/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5825e-08 - rmse: 1.6070e-04\n",
      "Epoch 1538: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0767e-08 - rmse: 1.7541e-04 - val_loss: 9.8076e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1539/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1102e-08 - rmse: 1.7636e-04\n",
      "Epoch 1539: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2134e-08 - rmse: 1.7926e-04 - val_loss: 9.8509e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1540/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8266e-08 - rmse: 1.6813e-04\n",
      "Epoch 1540: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7346e-08 - rmse: 1.6537e-04 - val_loss: 9.8012e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1541/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2671e-08 - rmse: 1.1257e-04\n",
      "Epoch 1541: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0515e-08 - rmse: 1.7468e-04 - val_loss: 9.7901e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1542/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1377e-08 - rmse: 1.0666e-04\n",
      "Epoch 1542: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2704e-08 - rmse: 1.5068e-04 - val_loss: 9.7465e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1543/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3270e-08 - rmse: 1.1519e-04\n",
      "Epoch 1543: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6057e-08 - rmse: 1.6142e-04 - val_loss: 9.8014e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1544/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5691e-09 - rmse: 9.2569e-05\n",
      "Epoch 1544: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8873e-08 - rmse: 1.6992e-04 - val_loss: 9.7864e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1545/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7066e-08 - rmse: 1.6452e-04\n",
      "Epoch 1545: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9103e-08 - rmse: 1.7060e-04 - val_loss: 9.8031e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1546/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6908e-08 - rmse: 1.3003e-04\n",
      "Epoch 1546: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7473e-08 - rmse: 1.9358e-04 - val_loss: 9.8081e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1547/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1828e-08 - rmse: 1.7840e-04\n",
      "Epoch 1547: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6077e-08 - rmse: 2.3681e-04 - val_loss: 9.8704e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1548/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0425e-08 - rmse: 2.0106e-04\n",
      "Epoch 1548: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0767e-08 - rmse: 2.2532e-04 - val_loss: 9.7905e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1549/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5603e-08 - rmse: 2.3580e-04\n",
      "Epoch 1549: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2444e-08 - rmse: 1.8012e-04 - val_loss: 9.7935e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1550/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9018e-08 - rmse: 1.3791e-04\n",
      "Epoch 1550: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.2943e-08 - rmse: 2.0723e-04 - val_loss: 9.7540e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1551/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0258e-08 - rmse: 2.0064e-04\n",
      "Epoch 1551: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8519e-08 - rmse: 2.2027e-04 - val_loss: 9.7916e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1552/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7980e-08 - rmse: 1.6727e-04\n",
      "Epoch 1552: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.3777e-08 - rmse: 2.0923e-04 - val_loss: 9.7908e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1553/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5177e-08 - rmse: 2.5530e-04\n",
      "Epoch 1553: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1125e-08 - rmse: 2.0279e-04 - val_loss: 9.7830e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1554/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3663e-09 - rmse: 9.6780e-05\n",
      "Epoch 1554: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3696e-08 - rmse: 2.3172e-04 - val_loss: 9.7945e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1555/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3581e-08 - rmse: 1.8325e-04\n",
      "Epoch 1555: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.6374e-08 - rmse: 2.3743e-04 - val_loss: 9.8030e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1556/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0849e-08 - rmse: 1.7564e-04\n",
      "Epoch 1556: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.6984e-08 - rmse: 1.9231e-04 - val_loss: 9.8005e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1557/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5487e-08 - rmse: 1.2445e-04\n",
      "Epoch 1557: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.3334e-08 - rmse: 2.0817e-04 - val_loss: 9.7887e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1558/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8864e-08 - rmse: 1.3735e-04\n",
      "Epoch 1558: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.1964e-08 - rmse: 2.0485e-04 - val_loss: 9.8240e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1559/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5002e-08 - rmse: 1.8709e-04\n",
      "Epoch 1559: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5149e-08 - rmse: 1.8748e-04 - val_loss: 9.7984e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1560/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.0022e-09 - rmse: 8.3679e-05\n",
      "Epoch 1560: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0507e-08 - rmse: 2.0126e-04 - val_loss: 9.7794e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1561/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5473e-09 - rmse: 9.2452e-05\n",
      "Epoch 1561: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.3031e-08 - rmse: 1.8174e-04 - val_loss: 9.8115e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1562/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6288e-08 - rmse: 1.2763e-04\n",
      "Epoch 1562: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.1272e-08 - rmse: 1.7684e-04 - val_loss: 9.8699e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1563/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1725e-08 - rmse: 1.7811e-04\n",
      "Epoch 1563: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4580e-08 - rmse: 1.5678e-04 - val_loss: 9.8766e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1564/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9188e-08 - rmse: 1.3852e-04\n",
      "Epoch 1564: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.7105e-08 - rmse: 1.6463e-04 - val_loss: 9.8176e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1565/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0387e-08 - rmse: 1.0192e-04\n",
      "Epoch 1565: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1229e-08 - rmse: 1.4570e-04 - val_loss: 9.7771e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1566/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4462e-08 - rmse: 2.1086e-04\n",
      "Epoch 1566: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1210e-08 - rmse: 1.4564e-04 - val_loss: 9.8232e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1567/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4968e-08 - rmse: 1.2235e-04\n",
      "Epoch 1567: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6627e-08 - rmse: 1.2894e-04 - val_loss: 9.8012e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1568/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0675e-08 - rmse: 1.7514e-04\n",
      "Epoch 1568: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4887e-08 - rmse: 1.2201e-04 - val_loss: 9.8234e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1569/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1656e-08 - rmse: 1.0796e-04\n",
      "Epoch 1569: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6475e-08 - rmse: 1.2835e-04 - val_loss: 9.8385e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1570/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0374e-08 - rmse: 1.4274e-04\n",
      "Epoch 1570: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6942e-08 - rmse: 1.3016e-04 - val_loss: 9.8523e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1571/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5510e-08 - rmse: 1.5972e-04\n",
      "Epoch 1571: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9579e-08 - rmse: 1.3992e-04 - val_loss: 9.8429e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1572/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8005e-08 - rmse: 2.1910e-04\n",
      "Epoch 1572: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2526e-08 - rmse: 1.5009e-04 - val_loss: 9.8780e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1573/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7053e-08 - rmse: 1.6448e-04\n",
      "Epoch 1573: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1505e-08 - rmse: 1.4665e-04 - val_loss: 9.8788e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1574/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5514e-09 - rmse: 8.0941e-05\n",
      "Epoch 1574: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1507e-08 - rmse: 1.4665e-04 - val_loss: 9.8759e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1575/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8362e-08 - rmse: 1.6841e-04\n",
      "Epoch 1575: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8290e-08 - rmse: 1.6820e-04 - val_loss: 9.8131e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1576/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5573e-09 - rmse: 6.7508e-05\n",
      "Epoch 1576: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.4759e-08 - rmse: 2.1156e-04 - val_loss: 9.7855e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1577/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3917e-08 - rmse: 1.5465e-04\n",
      "Epoch 1577: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6378e-08 - rmse: 2.3744e-04 - val_loss: 9.8578e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1578/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4623e-08 - rmse: 1.2093e-04\n",
      "Epoch 1578: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.0450e-08 - rmse: 2.0112e-04 - val_loss: 9.8509e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1579/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3096e-08 - rmse: 1.8192e-04\n",
      "Epoch 1579: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4418e-08 - rmse: 1.5626e-04 - val_loss: 9.8020e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1580/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4105e-08 - rmse: 1.8467e-04\n",
      "Epoch 1580: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4548e-08 - rmse: 1.5668e-04 - val_loss: 9.8395e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1581/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5713e-08 - rmse: 1.8898e-04\n",
      "Epoch 1581: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2953e-08 - rmse: 1.5150e-04 - val_loss: 9.8338e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1582/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2116e-08 - rmse: 1.7921e-04\n",
      "Epoch 1582: val_loss did not improve from 0.00009\n",
      "\n",
      "Epoch 1582: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3634e-08 - rmse: 1.5373e-04 - val_loss: 9.7594e-05 - val_rmse: 0.0099 - lr: 2.5000e-05\n",
      "Epoch 1583/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8080e-09 - rmse: 7.6210e-05\n",
      "Epoch 1583: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6934e-08 - rmse: 1.3013e-04 - val_loss: 9.7527e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1584/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4553e-08 - rmse: 1.8588e-04\n",
      "Epoch 1584: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6345e-08 - rmse: 1.2785e-04 - val_loss: 9.8133e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1585/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1750e-08 - rmse: 1.0840e-04\n",
      "Epoch 1585: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5354e-08 - rmse: 1.2391e-04 - val_loss: 9.8094e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1586/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6654e-08 - rmse: 1.6326e-04\n",
      "Epoch 1586: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7165e-08 - rmse: 1.3101e-04 - val_loss: 9.7930e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1587/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4139e-08 - rmse: 1.5537e-04\n",
      "Epoch 1587: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6751e-08 - rmse: 1.2943e-04 - val_loss: 9.8418e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1588/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6023e-08 - rmse: 2.1453e-04\n",
      "Epoch 1588: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7793e-08 - rmse: 1.3339e-04 - val_loss: 9.8351e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1589/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1623e-09 - rmse: 9.5720e-05\n",
      "Epoch 1589: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4494e-08 - rmse: 1.2039e-04 - val_loss: 9.7934e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1590/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1614e-09 - rmse: 6.4509e-05\n",
      "Epoch 1590: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2963e-08 - rmse: 1.1386e-04 - val_loss: 9.7925e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1591/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0014e-08 - rmse: 1.0007e-04\n",
      "Epoch 1591: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2934e-08 - rmse: 1.1373e-04 - val_loss: 9.8156e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1592/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2490e-09 - rmse: 6.5185e-05\n",
      "Epoch 1592: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1621e-08 - rmse: 1.0780e-04 - val_loss: 9.8026e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1593/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4587e-08 - rmse: 1.2078e-04\n",
      "Epoch 1593: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1543e-08 - rmse: 1.0744e-04 - val_loss: 9.8347e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1594/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7095e-09 - rmse: 7.5561e-05\n",
      "Epoch 1594: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1817e-08 - rmse: 1.0871e-04 - val_loss: 9.8026e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1595/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7877e-08 - rmse: 1.3371e-04\n",
      "Epoch 1595: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1613e-08 - rmse: 1.0776e-04 - val_loss: 9.8170e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1596/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0631e-08 - rmse: 1.0311e-04\n",
      "Epoch 1596: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2574e-08 - rmse: 1.1213e-04 - val_loss: 9.8453e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1597/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1280e-08 - rmse: 1.7686e-04\n",
      "Epoch 1597: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5570e-08 - rmse: 1.2478e-04 - val_loss: 9.8574e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1598/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4781e-08 - rmse: 1.2158e-04\n",
      "Epoch 1598: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2579e-08 - rmse: 1.1216e-04 - val_loss: 9.8055e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1599/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2600e-08 - rmse: 1.1225e-04\n",
      "Epoch 1599: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1393e-08 - rmse: 1.0674e-04 - val_loss: 9.8195e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1600/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3236e-08 - rmse: 1.1505e-04\n",
      "Epoch 1600: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1568e-08 - rmse: 1.0756e-04 - val_loss: 9.8218e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1601/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2977e-08 - rmse: 1.1392e-04\n",
      "Epoch 1601: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3249e-08 - rmse: 1.1510e-04 - val_loss: 9.8165e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1602/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3533e-08 - rmse: 1.1633e-04\n",
      "Epoch 1602: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3632e-08 - rmse: 1.1675e-04 - val_loss: 9.8367e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1603/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0211e-08 - rmse: 1.4217e-04\n",
      "Epoch 1603: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4982e-08 - rmse: 1.2240e-04 - val_loss: 9.8726e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1604/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6232e-08 - rmse: 1.2740e-04\n",
      "Epoch 1604: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.7605e-08 - rmse: 1.3268e-04 - val_loss: 9.8104e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1605/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0211e-08 - rmse: 1.0105e-04\n",
      "Epoch 1605: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4109e-08 - rmse: 1.1878e-04 - val_loss: 9.8189e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1606/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2534e-09 - rmse: 8.5167e-05\n",
      "Epoch 1606: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4026e-08 - rmse: 1.1843e-04 - val_loss: 9.8553e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1607/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.4707e-09 - rmse: 9.2036e-05\n",
      "Epoch 1607: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3626e-08 - rmse: 1.1673e-04 - val_loss: 9.8415e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1608/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6253e-09 - rmse: 8.7323e-05\n",
      "Epoch 1608: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4011e-08 - rmse: 1.1837e-04 - val_loss: 9.8008e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1609/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6893e-09 - rmse: 7.5427e-05\n",
      "Epoch 1609: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2006e-08 - rmse: 1.0957e-04 - val_loss: 9.8125e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1610/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0531e-08 - rmse: 1.4329e-04\n",
      "Epoch 1610: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1802e-08 - rmse: 1.0864e-04 - val_loss: 9.8322e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1611/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5860e-09 - rmse: 7.4739e-05\n",
      "Epoch 1611: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2166e-08 - rmse: 1.1030e-04 - val_loss: 9.8285e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1612/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1239e-08 - rmse: 1.4574e-04\n",
      "Epoch 1612: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0647e-08 - rmse: 1.0319e-04 - val_loss: 9.8251e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1613/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1804e-09 - rmse: 3.4357e-05\n",
      "Epoch 1613: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0671e-08 - rmse: 1.0330e-04 - val_loss: 9.8261e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1614/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7262e-09 - rmse: 6.1043e-05\n",
      "Epoch 1614: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1631e-08 - rmse: 1.0785e-04 - val_loss: 9.8305e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1615/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8925e-09 - rmse: 4.3503e-05\n",
      "Epoch 1615: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1172e-08 - rmse: 1.0570e-04 - val_loss: 9.8159e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1616/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5370e-09 - rmse: 5.0368e-05\n",
      "Epoch 1616: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3776e-08 - rmse: 1.1737e-04 - val_loss: 9.8277e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1617/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2030e-08 - rmse: 1.0968e-04\n",
      "Epoch 1617: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3119e-08 - rmse: 1.1454e-04 - val_loss: 9.8659e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1618/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5174e-09 - rmse: 9.2290e-05\n",
      "Epoch 1618: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3942e-08 - rmse: 1.1808e-04 - val_loss: 9.8596e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1619/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2635e-08 - rmse: 1.1241e-04\n",
      "Epoch 1619: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4114e-08 - rmse: 1.1880e-04 - val_loss: 9.8576e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1620/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5443e-08 - rmse: 1.2427e-04\n",
      "Epoch 1620: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2678e-08 - rmse: 1.1260e-04 - val_loss: 9.8632e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1621/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1938e-08 - rmse: 1.0926e-04\n",
      "Epoch 1621: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2042e-08 - rmse: 1.0974e-04 - val_loss: 9.8223e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1622/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2819e-08 - rmse: 1.8116e-04\n",
      "Epoch 1622: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1778e-08 - rmse: 1.0853e-04 - val_loss: 9.8205e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1623/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0777e-08 - rmse: 1.4414e-04\n",
      "Epoch 1623: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2635e-08 - rmse: 1.1241e-04 - val_loss: 9.8229e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1624/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4851e-09 - rmse: 5.9035e-05\n",
      "Epoch 1624: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3630e-08 - rmse: 1.1675e-04 - val_loss: 9.8717e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1625/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1168e-08 - rmse: 1.0568e-04\n",
      "Epoch 1625: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.0145e-08 - rmse: 1.4193e-04 - val_loss: 9.8100e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1626/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0521e-08 - rmse: 2.0130e-04\n",
      "Epoch 1626: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3185e-08 - rmse: 1.5227e-04 - val_loss: 9.8242e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1627/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3791e-09 - rmse: 7.9869e-05\n",
      "Epoch 1627: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4322e-08 - rmse: 1.1967e-04 - val_loss: 9.8415e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1628/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9854e-09 - rmse: 8.9361e-05\n",
      "Epoch 1628: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5973e-08 - rmse: 1.2638e-04 - val_loss: 9.8048e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1629/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.1775e-09 - rmse: 7.8597e-05\n",
      "Epoch 1629: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2474e-08 - rmse: 1.1169e-04 - val_loss: 9.8166e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1630/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1806e-09 - rmse: 9.0446e-05\n",
      "Epoch 1630: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1829e-08 - rmse: 1.0876e-04 - val_loss: 9.8224e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1631/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2105e-08 - rmse: 2.0520e-04\n",
      "Epoch 1631: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2715e-08 - rmse: 1.1276e-04 - val_loss: 9.8351e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1632/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0446e-08 - rmse: 1.0220e-04\n",
      "Epoch 1632: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2131e-08 - rmse: 1.1014e-04 - val_loss: 9.8461e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1633/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8463e-08 - rmse: 1.3588e-04\n",
      "Epoch 1633: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1059e-08 - rmse: 1.0516e-04 - val_loss: 9.8326e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1634/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7488e-08 - rmse: 1.3224e-04\n",
      "Epoch 1634: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0906e-08 - rmse: 1.0443e-04 - val_loss: 9.8714e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1635/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6888e-08 - rmse: 1.9206e-04\n",
      "Epoch 1635: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1440e-08 - rmse: 1.0696e-04 - val_loss: 9.8610e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1636/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4949e-09 - rmse: 4.9949e-05\n",
      "Epoch 1636: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.2267e-08 - rmse: 1.1076e-04 - val_loss: 9.8337e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1637/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3392e-09 - rmse: 9.6640e-05\n",
      "Epoch 1637: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3244e-08 - rmse: 1.1508e-04 - val_loss: 9.8211e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1638/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0178e-09 - rmse: 7.0836e-05\n",
      "Epoch 1638: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2939e-08 - rmse: 1.1375e-04 - val_loss: 9.8274e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1639/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2205e-09 - rmse: 5.6749e-05\n",
      "Epoch 1639: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2383e-08 - rmse: 1.1128e-04 - val_loss: 9.8681e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1640/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2465e-09 - rmse: 6.5165e-05\n",
      "Epoch 1640: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2651e-08 - rmse: 1.1248e-04 - val_loss: 9.8766e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1641/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2915e-08 - rmse: 1.5138e-04\n",
      "Epoch 1641: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4126e-08 - rmse: 1.1885e-04 - val_loss: 9.8353e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1642/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7741e-09 - rmse: 6.1434e-05\n",
      "Epoch 1642: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5402e-08 - rmse: 1.2411e-04 - val_loss: 9.8279e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1643/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5204e-08 - rmse: 1.2331e-04\n",
      "Epoch 1643: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5203e-08 - rmse: 1.2330e-04 - val_loss: 9.8355e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1644/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0315e-08 - rmse: 1.4253e-04\n",
      "Epoch 1644: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0887e-08 - rmse: 1.4452e-04 - val_loss: 9.8313e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1645/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8949e-08 - rmse: 1.3765e-04\n",
      "Epoch 1645: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6263e-08 - rmse: 1.2753e-04 - val_loss: 9.8585e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1646/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1725e-08 - rmse: 1.0828e-04\n",
      "Epoch 1646: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9650e-08 - rmse: 1.4018e-04 - val_loss: 9.8768e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1647/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9076e-08 - rmse: 1.3812e-04\n",
      "Epoch 1647: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3854e-08 - rmse: 1.5445e-04 - val_loss: 9.8327e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1648/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8758e-08 - rmse: 1.9687e-04\n",
      "Epoch 1648: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9538e-08 - rmse: 1.3978e-04 - val_loss: 9.8388e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1649/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1845e-08 - rmse: 1.4780e-04\n",
      "Epoch 1649: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7139e-08 - rmse: 1.3092e-04 - val_loss: 9.8565e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1650/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1169e-08 - rmse: 1.0569e-04\n",
      "Epoch 1650: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8154e-08 - rmse: 1.3474e-04 - val_loss: 9.8510e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1651/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3467e-09 - rmse: 6.5930e-05\n",
      "Epoch 1651: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4270e-08 - rmse: 1.1946e-04 - val_loss: 9.8414e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1652/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3307e-08 - rmse: 1.8250e-04\n",
      "Epoch 1652: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7056e-08 - rmse: 1.3060e-04 - val_loss: 9.8410e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1653/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2879e-08 - rmse: 1.1349e-04\n",
      "Epoch 1653: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4140e-08 - rmse: 1.1891e-04 - val_loss: 9.8296e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1654/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1895e-09 - rmse: 8.4791e-05\n",
      "Epoch 1654: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4305e-08 - rmse: 1.1960e-04 - val_loss: 9.8107e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1655/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1036e-09 - rmse: 8.4283e-05\n",
      "Epoch 1655: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5044e-08 - rmse: 1.2266e-04 - val_loss: 9.8741e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1656/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6436e-09 - rmse: 5.1416e-05\n",
      "Epoch 1656: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4452e-08 - rmse: 1.2022e-04 - val_loss: 9.8420e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1657/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3529e-08 - rmse: 1.1631e-04\n",
      "Epoch 1657: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3367e-08 - rmse: 1.1561e-04 - val_loss: 9.8605e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1658/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4524e-09 - rmse: 4.9522e-05\n",
      "Epoch 1658: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6235e-08 - rmse: 1.2741e-04 - val_loss: 9.9046e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1659/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4703e-08 - rmse: 1.8629e-04\n",
      "Epoch 1659: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8659e-08 - rmse: 1.3660e-04 - val_loss: 9.8800e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1660/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4587e-08 - rmse: 1.2078e-04\n",
      "Epoch 1660: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4823e-08 - rmse: 1.2175e-04 - val_loss: 9.8730e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1661/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2121e-08 - rmse: 1.7922e-04\n",
      "Epoch 1661: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4753e-08 - rmse: 1.2146e-04 - val_loss: 9.8551e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1662/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4059e-09 - rmse: 6.6377e-05\n",
      "Epoch 1662: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5574e-08 - rmse: 1.2480e-04 - val_loss: 9.7546e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1663/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6552e-08 - rmse: 1.9119e-04\n",
      "Epoch 1663: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7780e-08 - rmse: 1.3334e-04 - val_loss: 9.9109e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1664/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3268e-08 - rmse: 1.1519e-04\n",
      "Epoch 1664: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6191e-08 - rmse: 1.2724e-04 - val_loss: 9.8838e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1665/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1660e-08 - rmse: 1.0798e-04\n",
      "Epoch 1665: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0987e-08 - rmse: 1.4487e-04 - val_loss: 9.8751e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1666/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3212e-08 - rmse: 1.1494e-04\n",
      "Epoch 1666: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9583e-08 - rmse: 1.3994e-04 - val_loss: 9.8819e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1667/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.8177e-09 - rmse: 9.9084e-05\n",
      "Epoch 1667: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7519e-08 - rmse: 1.3236e-04 - val_loss: 9.8885e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1668/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3491e-09 - rmse: 8.5727e-05\n",
      "Epoch 1668: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3021e-08 - rmse: 1.1411e-04 - val_loss: 9.8719e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1669/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4287e-08 - rmse: 1.1953e-04\n",
      "Epoch 1669: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3246e-08 - rmse: 1.1509e-04 - val_loss: 9.8173e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1670/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5306e-09 - rmse: 7.4368e-05\n",
      "Epoch 1670: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7194e-08 - rmse: 1.3113e-04 - val_loss: 9.8638e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1671/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1434e-08 - rmse: 1.0693e-04\n",
      "Epoch 1671: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6781e-08 - rmse: 1.2954e-04 - val_loss: 9.8304e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1672/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5706e-08 - rmse: 1.6033e-04\n",
      "Epoch 1672: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0231e-08 - rmse: 1.4224e-04 - val_loss: 9.8198e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1673/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8016e-09 - rmse: 9.3817e-05\n",
      "Epoch 1673: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3007e-08 - rmse: 1.1405e-04 - val_loss: 9.7997e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1674/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0789e-08 - rmse: 1.4418e-04\n",
      "Epoch 1674: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1221e-08 - rmse: 1.4568e-04 - val_loss: 9.8027e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1675/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0910e-08 - rmse: 1.4460e-04\n",
      "Epoch 1675: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0486e-08 - rmse: 1.4313e-04 - val_loss: 9.8518e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1676/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3412e-09 - rmse: 9.1330e-05\n",
      "Epoch 1676: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.7363e-08 - rmse: 1.9329e-04 - val_loss: 9.8531e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1677/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9672e-08 - rmse: 1.4026e-04\n",
      "Epoch 1677: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.9372e-08 - rmse: 1.3918e-04 - val_loss: 9.9114e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1678/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0143e-08 - rmse: 1.4192e-04\n",
      "Epoch 1678: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5345e-08 - rmse: 1.2387e-04 - val_loss: 9.8711e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1679/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.9505e-09 - rmse: 8.9165e-05\n",
      "Epoch 1679: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6493e-08 - rmse: 1.2843e-04 - val_loss: 9.9011e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1680/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7798e-08 - rmse: 1.6673e-04\n",
      "Epoch 1680: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8839e-08 - rmse: 1.6982e-04 - val_loss: 9.9198e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1681/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1299e-08 - rmse: 2.0322e-04\n",
      "Epoch 1681: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6446e-08 - rmse: 1.6262e-04 - val_loss: 9.8318e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1682/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5239e-08 - rmse: 1.5887e-04\n",
      "Epoch 1682: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0317e-08 - rmse: 1.4254e-04 - val_loss: 9.8697e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1683/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8316e-08 - rmse: 1.3534e-04\n",
      "Epoch 1683: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9702e-08 - rmse: 1.4036e-04 - val_loss: 9.8475e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1684/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6295e-08 - rmse: 1.2765e-04\n",
      "Epoch 1684: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6586e-08 - rmse: 1.2879e-04 - val_loss: 9.9144e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1685/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9487e-08 - rmse: 2.2246e-04\n",
      "Epoch 1685: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.0062e-08 - rmse: 1.7338e-04 - val_loss: 9.9005e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1686/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7135e-08 - rmse: 1.3090e-04\n",
      "Epoch 1686: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7355e-08 - rmse: 1.6539e-04 - val_loss: 9.8327e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1687/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3638e-08 - rmse: 1.1678e-04\n",
      "Epoch 1687: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0938e-08 - rmse: 1.4470e-04 - val_loss: 9.8367e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1688/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7195e-08 - rmse: 1.6491e-04\n",
      "Epoch 1688: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.5993e-08 - rmse: 1.6122e-04 - val_loss: 9.8337e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1689/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5929e-08 - rmse: 1.2621e-04\n",
      "Epoch 1689: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7885e-08 - rmse: 1.6699e-04 - val_loss: 9.8705e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1690/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1457e-09 - rmse: 8.4532e-05\n",
      "Epoch 1690: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7542e-08 - rmse: 1.3245e-04 - val_loss: 9.8937e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1691/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7168e-08 - rmse: 1.9279e-04\n",
      "Epoch 1691: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0732e-08 - rmse: 1.4399e-04 - val_loss: 9.9166e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1692/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1686e-09 - rmse: 7.1893e-05\n",
      "Epoch 1692: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4039e-08 - rmse: 1.1849e-04 - val_loss: 9.8990e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1693/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2192e-08 - rmse: 1.1042e-04\n",
      "Epoch 1693: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4297e-08 - rmse: 1.1957e-04 - val_loss: 9.8520e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1694/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2064e-08 - rmse: 1.0984e-04\n",
      "Epoch 1694: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3981e-08 - rmse: 1.1824e-04 - val_loss: 9.8432e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1695/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7304e-08 - rmse: 1.3155e-04\n",
      "Epoch 1695: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7495e-08 - rmse: 1.3227e-04 - val_loss: 9.8560e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1696/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3483e-08 - rmse: 1.5324e-04\n",
      "Epoch 1696: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3289e-08 - rmse: 1.5261e-04 - val_loss: 9.8388e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1697/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7336e-08 - rmse: 1.6534e-04\n",
      "Epoch 1697: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9987e-08 - rmse: 1.4137e-04 - val_loss: 9.8875e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1698/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1745e-08 - rmse: 1.4746e-04\n",
      "Epoch 1698: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8692e-08 - rmse: 1.3672e-04 - val_loss: 9.8838e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1699/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0369e-08 - rmse: 1.0183e-04\n",
      "Epoch 1699: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5543e-08 - rmse: 1.2467e-04 - val_loss: 9.9392e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1700/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6148e-08 - rmse: 1.6170e-04\n",
      "Epoch 1700: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5592e-08 - rmse: 1.2487e-04 - val_loss: 9.9526e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1701/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9126e-08 - rmse: 1.9780e-04\n",
      "Epoch 1701: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.4253e-08 - rmse: 1.5573e-04 - val_loss: 9.8978e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1702/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2725e-08 - rmse: 2.5045e-04\n",
      "Epoch 1702: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6098e-08 - rmse: 1.6155e-04 - val_loss: 9.8262e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1703/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3606e-08 - rmse: 1.1664e-04\n",
      "Epoch 1703: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4726e-08 - rmse: 1.2135e-04 - val_loss: 9.8506e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1704/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0273e-09 - rmse: 7.0903e-05\n",
      "Epoch 1704: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5301e-08 - rmse: 1.2370e-04 - val_loss: 9.8764e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1705/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0978e-08 - rmse: 1.0478e-04\n",
      "Epoch 1705: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2620e-08 - rmse: 1.1234e-04 - val_loss: 9.9204e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1706/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3793e-09 - rmse: 6.6176e-05\n",
      "Epoch 1706: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0360e-08 - rmse: 1.0178e-04 - val_loss: 9.8405e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1707/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7002e-08 - rmse: 1.3039e-04\n",
      "Epoch 1707: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8427e-09 - rmse: 9.9211e-05 - val_loss: 9.8349e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1708/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3908e-08 - rmse: 1.1793e-04\n",
      "Epoch 1708: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1562e-08 - rmse: 1.0753e-04 - val_loss: 9.8495e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1709/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9506e-08 - rmse: 1.3966e-04\n",
      "Epoch 1709: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3349e-08 - rmse: 1.1554e-04 - val_loss: 9.8936e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1710/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6825e-09 - rmse: 8.7650e-05\n",
      "Epoch 1710: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3806e-08 - rmse: 1.5429e-04 - val_loss: 9.9319e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1711/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0907e-08 - rmse: 1.0444e-04\n",
      "Epoch 1711: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8081e-08 - rmse: 1.6757e-04 - val_loss: 9.8992e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1712/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5218e-09 - rmse: 5.9345e-05\n",
      "Epoch 1712: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.9698e-08 - rmse: 1.7233e-04 - val_loss: 9.8772e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1713/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7976e-08 - rmse: 1.3407e-04\n",
      "Epoch 1713: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9978e-08 - rmse: 1.4134e-04 - val_loss: 9.8580e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1714/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1363e-08 - rmse: 1.4616e-04\n",
      "Epoch 1714: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2999e-08 - rmse: 1.8166e-04 - val_loss: 9.8752e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1715/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5718e-08 - rmse: 1.2537e-04\n",
      "Epoch 1715: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9894e-08 - rmse: 1.4105e-04 - val_loss: 9.9159e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1716/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4271e-08 - rmse: 1.8512e-04\n",
      "Epoch 1716: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9848e-08 - rmse: 1.4088e-04 - val_loss: 9.8675e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1717/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9027e-09 - rmse: 5.3877e-05\n",
      "Epoch 1717: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7494e-08 - rmse: 1.3226e-04 - val_loss: 9.8555e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1718/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2808e-09 - rmse: 9.0999e-05\n",
      "Epoch 1718: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6920e-08 - rmse: 1.3008e-04 - val_loss: 9.8932e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1719/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6939e-08 - rmse: 1.3015e-04\n",
      "Epoch 1719: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2147e-08 - rmse: 1.1021e-04 - val_loss: 9.8902e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1720/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3233e-09 - rmse: 5.7648e-05\n",
      "Epoch 1720: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.3118e-08 - rmse: 1.1453e-04 - val_loss: 9.8443e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1721/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5447e-08 - rmse: 1.5952e-04\n",
      "Epoch 1721: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2270e-08 - rmse: 1.1077e-04 - val_loss: 9.8471e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1722/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8940e-09 - rmse: 4.3520e-05\n",
      "Epoch 1722: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2491e-08 - rmse: 1.1176e-04 - val_loss: 9.8793e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1723/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0753e-08 - rmse: 1.4406e-04\n",
      "Epoch 1723: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1617e-08 - rmse: 1.0778e-04 - val_loss: 9.8765e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1724/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3550e-09 - rmse: 6.5992e-05\n",
      "Epoch 1724: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0835e-08 - rmse: 1.0409e-04 - val_loss: 9.8616e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1725/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8369e-09 - rmse: 6.1943e-05\n",
      "Epoch 1725: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8128e-09 - rmse: 9.9059e-05 - val_loss: 9.8519e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1726/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6445e-09 - rmse: 8.7433e-05\n",
      "Epoch 1726: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3691e-08 - rmse: 1.1701e-04 - val_loss: 9.8630e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1727/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7980e-08 - rmse: 1.3409e-04\n",
      "Epoch 1727: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8302e-08 - rmse: 1.3529e-04 - val_loss: 9.8468e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1728/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3394e-09 - rmse: 7.9621e-05\n",
      "Epoch 1728: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4531e-08 - rmse: 1.2054e-04 - val_loss: 9.8881e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1729/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2503e-08 - rmse: 1.1182e-04\n",
      "Epoch 1729: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1295e-08 - rmse: 1.4593e-04 - val_loss: 9.8584e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1730/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3733e-08 - rmse: 1.1719e-04\n",
      "Epoch 1730: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7592e-08 - rmse: 1.3263e-04 - val_loss: 9.8754e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1731/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6877e-08 - rmse: 1.2991e-04\n",
      "Epoch 1731: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4236e-08 - rmse: 1.1932e-04 - val_loss: 9.8547e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1732/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9624e-09 - rmse: 9.4670e-05\n",
      "Epoch 1732: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8389e-09 - rmse: 9.9191e-05 - val_loss: 9.8687e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1733/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0570e-08 - rmse: 1.0281e-04\n",
      "Epoch 1733: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2327e-08 - rmse: 1.1103e-04 - val_loss: 9.8709e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1734/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3347e-08 - rmse: 1.1553e-04\n",
      "Epoch 1734: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0978e-08 - rmse: 1.0477e-04 - val_loss: 9.8739e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1735/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3406e-09 - rmse: 8.5677e-05\n",
      "Epoch 1735: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0351e-08 - rmse: 1.0174e-04 - val_loss: 9.8629e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1736/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6272e-08 - rmse: 1.2756e-04\n",
      "Epoch 1736: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3427e-08 - rmse: 1.1588e-04 - val_loss: 9.8784e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1737/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5869e-09 - rmse: 7.4746e-05\n",
      "Epoch 1737: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2289e-08 - rmse: 1.1086e-04 - val_loss: 9.9437e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1738/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4773e-08 - rmse: 1.2154e-04\n",
      "Epoch 1738: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2148e-08 - rmse: 1.4882e-04 - val_loss: 9.8889e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1739/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3106e-08 - rmse: 1.5201e-04\n",
      "Epoch 1739: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7189e-08 - rmse: 1.6489e-04 - val_loss: 9.8421e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1740/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0254e-08 - rmse: 1.0126e-04\n",
      "Epoch 1740: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 3.2860e-08 - rmse: 1.8127e-04 - val_loss: 9.8525e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1741/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6319e-08 - rmse: 2.1522e-04\n",
      "Epoch 1741: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.2152e-08 - rmse: 1.7931e-04 - val_loss: 9.8416e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1742/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4732e-08 - rmse: 1.8637e-04\n",
      "Epoch 1742: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 3.5186e-08 - rmse: 1.8758e-04 - val_loss: 9.8748e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1743/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9836e-08 - rmse: 1.7273e-04\n",
      "Epoch 1743: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.6523e-08 - rmse: 1.6286e-04 - val_loss: 9.9501e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1744/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0259e-08 - rmse: 1.4234e-04\n",
      "Epoch 1744: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.7137e-08 - rmse: 1.6473e-04 - val_loss: 9.8956e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1745/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0809e-08 - rmse: 1.0397e-04\n",
      "Epoch 1745: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9133e-08 - rmse: 1.3832e-04 - val_loss: 9.8765e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1746/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4589e-08 - rmse: 1.2078e-04\n",
      "Epoch 1746: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6497e-08 - rmse: 1.2844e-04 - val_loss: 9.8799e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1747/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7728e-08 - rmse: 1.6652e-04\n",
      "Epoch 1747: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6682e-08 - rmse: 1.2916e-04 - val_loss: 9.8842e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1748/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4893e-09 - rmse: 9.7413e-05\n",
      "Epoch 1748: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2903e-08 - rmse: 1.5134e-04 - val_loss: 9.8732e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1749/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0575e-08 - rmse: 1.0284e-04\n",
      "Epoch 1749: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4652e-08 - rmse: 1.2105e-04 - val_loss: 9.8728e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1750/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7923e-08 - rmse: 1.3388e-04\n",
      "Epoch 1750: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2170e-08 - rmse: 1.4890e-04 - val_loss: 9.9303e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1751/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0430e-08 - rmse: 1.0213e-04\n",
      "Epoch 1751: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5434e-08 - rmse: 1.2424e-04 - val_loss: 9.9624e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1752/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3123e-08 - rmse: 1.1455e-04\n",
      "Epoch 1752: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0445e-08 - rmse: 1.4299e-04 - val_loss: 9.9172e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1753/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8718e-08 - rmse: 1.6946e-04\n",
      "Epoch 1753: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.8456e-08 - rmse: 1.6869e-04 - val_loss: 9.9174e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1754/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0889e-08 - rmse: 2.0221e-04\n",
      "Epoch 1754: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6892e-08 - rmse: 1.2997e-04 - val_loss: 9.8834e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1755/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0997e-08 - rmse: 1.0487e-04\n",
      "Epoch 1755: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2693e-08 - rmse: 1.1266e-04 - val_loss: 9.8889e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1756/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0287e-09 - rmse: 7.0913e-05\n",
      "Epoch 1756: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.2118e-08 - rmse: 1.4872e-04 - val_loss: 9.9460e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1757/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3309e-08 - rmse: 1.1536e-04\n",
      "Epoch 1757: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 2.2079e-08 - rmse: 1.4859e-04 - val_loss: 9.9763e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1758/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7162e-09 - rmse: 9.3361e-05\n",
      "Epoch 1758: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6692e-08 - rmse: 1.2920e-04 - val_loss: 9.9023e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1759/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5436e-09 - rmse: 6.7407e-05\n",
      "Epoch 1759: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5348e-08 - rmse: 1.2389e-04 - val_loss: 9.8952e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1760/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7904e-09 - rmse: 9.3757e-05\n",
      "Epoch 1760: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4682e-08 - rmse: 1.2117e-04 - val_loss: 9.8446e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1761/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3001e-08 - rmse: 1.5166e-04\n",
      "Epoch 1761: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4306e-08 - rmse: 1.1961e-04 - val_loss: 9.8970e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1762/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7925e-09 - rmse: 9.3768e-05\n",
      "Epoch 1762: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4858e-08 - rmse: 1.2190e-04 - val_loss: 9.8545e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1763/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6211e-08 - rmse: 1.6190e-04\n",
      "Epoch 1763: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1987e-08 - rmse: 1.0948e-04 - val_loss: 9.8866e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1764/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.5897e-09 - rmse: 8.7119e-05\n",
      "Epoch 1764: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.7068e-09 - rmse: 9.8523e-05 - val_loss: 9.8578e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1765/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6767e-08 - rmse: 1.2949e-04\n",
      "Epoch 1765: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0348e-08 - rmse: 1.0172e-04 - val_loss: 9.9212e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1766/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2340e-09 - rmse: 9.6093e-05\n",
      "Epoch 1766: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5291e-08 - rmse: 1.2366e-04 - val_loss: 9.9155e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1767/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1288e-08 - rmse: 1.0624e-04\n",
      "Epoch 1767: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3111e-08 - rmse: 1.1450e-04 - val_loss: 9.8680e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1768/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2184e-08 - rmse: 1.1038e-04\n",
      "Epoch 1768: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7712e-08 - rmse: 1.3309e-04 - val_loss: 9.8577e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1769/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1283e-08 - rmse: 1.4589e-04\n",
      "Epoch 1769: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1992e-08 - rmse: 1.0951e-04 - val_loss: 9.8670e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1770/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2123e-08 - rmse: 1.7923e-04\n",
      "Epoch 1770: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4546e-08 - rmse: 1.2061e-04 - val_loss: 9.9108e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1771/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.7935e-09 - rmse: 9.3774e-05\n",
      "Epoch 1771: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1782e-08 - rmse: 1.0854e-04 - val_loss: 9.9772e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1772/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2084e-08 - rmse: 1.4861e-04\n",
      "Epoch 1772: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0165e-08 - rmse: 1.4200e-04 - val_loss: 9.9370e-05 - val_rmse: 0.0100 - lr: 1.2500e-05\n",
      "Epoch 1773/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4272e-08 - rmse: 1.5579e-04\n",
      "Epoch 1773: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7821e-08 - rmse: 1.3350e-04 - val_loss: 9.8666e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1774/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9785e-09 - rmse: 7.7321e-05\n",
      "Epoch 1774: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0371e-08 - rmse: 1.0184e-04 - val_loss: 9.8668e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1775/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4362e-09 - rmse: 6.6605e-05\n",
      "Epoch 1775: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6263e-08 - rmse: 1.2753e-04 - val_loss: 9.8753e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1776/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1718e-08 - rmse: 1.0825e-04\n",
      "Epoch 1776: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4347e-08 - rmse: 1.1978e-04 - val_loss: 9.8880e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1777/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1529e-09 - rmse: 7.1784e-05\n",
      "Epoch 1777: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9662e-09 - rmse: 9.9831e-05 - val_loss: 9.8895e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1778/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6515e-08 - rmse: 1.2851e-04\n",
      "Epoch 1778: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7516e-09 - rmse: 9.8750e-05 - val_loss: 9.8973e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1779/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1338e-09 - rmse: 5.5981e-05\n",
      "Epoch 1779: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7569e-09 - rmse: 9.3578e-05 - val_loss: 9.8871e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1780/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3591e-08 - rmse: 1.1658e-04\n",
      "Epoch 1780: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3360e-09 - rmse: 9.6623e-05 - val_loss: 9.8882e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1781/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5905e-09 - rmse: 7.4770e-05\n",
      "Epoch 1781: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.6301e-09 - rmse: 9.8133e-05 - val_loss: 9.8882e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1782/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8782e-09 - rmse: 6.9844e-05\n",
      "Epoch 1782: val_loss did not improve from 0.00009\n",
      "\n",
      "Epoch 1782: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3816e-08 - rmse: 1.1754e-04 - val_loss: 9.8959e-05 - val_rmse: 0.0099 - lr: 1.2500e-05\n",
      "Epoch 1783/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3025e-09 - rmse: 8.5455e-05\n",
      "Epoch 1783: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3109e-08 - rmse: 1.1449e-04 - val_loss: 9.8933e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1784/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8345e-08 - rmse: 1.3544e-04\n",
      "Epoch 1784: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5412e-08 - rmse: 1.2414e-04 - val_loss: 9.9043e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1785/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8680e-09 - rmse: 5.3553e-05\n",
      "Epoch 1785: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3255e-08 - rmse: 1.1513e-04 - val_loss: 9.9176e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1786/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6199e-08 - rmse: 1.2727e-04\n",
      "Epoch 1786: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0329e-08 - rmse: 1.0163e-04 - val_loss: 9.9203e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1787/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3294e-08 - rmse: 1.1530e-04\n",
      "Epoch 1787: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1226e-08 - rmse: 1.0595e-04 - val_loss: 9.9073e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1788/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.7305e-09 - rmse: 8.2039e-05\n",
      "Epoch 1788: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4100e-08 - rmse: 1.1874e-04 - val_loss: 9.9185e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1789/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1565e-08 - rmse: 1.0754e-04\n",
      "Epoch 1789: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1191e-08 - rmse: 1.0579e-04 - val_loss: 9.9122e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1790/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4704e-08 - rmse: 1.2126e-04\n",
      "Epoch 1790: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9953e-09 - rmse: 8.9417e-05 - val_loss: 9.8989e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1791/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1625e-08 - rmse: 1.0782e-04\n",
      "Epoch 1791: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9613e-09 - rmse: 8.9226e-05 - val_loss: 9.8861e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1792/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3901e-09 - rmse: 7.9938e-05\n",
      "Epoch 1792: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9968e-09 - rmse: 9.9984e-05 - val_loss: 9.9045e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1793/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4269e-08 - rmse: 1.5578e-04\n",
      "Epoch 1793: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6105e-09 - rmse: 9.2793e-05 - val_loss: 9.8428e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1794/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4377e-08 - rmse: 1.1990e-04\n",
      "Epoch 1794: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1721e-08 - rmse: 1.0826e-04 - val_loss: 9.9081e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1795/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8309e-09 - rmse: 4.2789e-05\n",
      "Epoch 1795: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1363e-09 - rmse: 9.5584e-05 - val_loss: 9.9126e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1796/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4803e-09 - rmse: 6.6935e-05\n",
      "Epoch 1796: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 8.1208e-09 - rmse: 9.0115e-05 - val_loss: 9.9016e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1797/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8141e-09 - rmse: 6.9384e-05\n",
      "Epoch 1797: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3200e-09 - rmse: 8.5557e-05 - val_loss: 9.8903e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1798/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0073e-09 - rmse: 4.4803e-05\n",
      "Epoch 1798: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7536e-09 - rmse: 9.3561e-05 - val_loss: 9.8976e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1799/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4628e-08 - rmse: 1.5693e-04\n",
      "Epoch 1799: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2124e-08 - rmse: 1.1011e-04 - val_loss: 9.8979e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1800/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2585e-09 - rmse: 5.7083e-05\n",
      "Epoch 1800: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.3775e-09 - rmse: 8.5892e-05 - val_loss: 9.9024e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1801/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9779e-09 - rmse: 8.3534e-05\n",
      "Epoch 1801: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6317e-09 - rmse: 8.7359e-05 - val_loss: 9.9098e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1802/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2881e-08 - rmse: 1.1349e-04\n",
      "Epoch 1802: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8870e-09 - rmse: 8.2988e-05 - val_loss: 9.9077e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1803/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9956e-08 - rmse: 1.4127e-04\n",
      "Epoch 1803: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1140e-09 - rmse: 9.0078e-05 - val_loss: 9.9054e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1804/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8334e-09 - rmse: 5.3230e-05\n",
      "Epoch 1804: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2198e-09 - rmse: 8.4970e-05 - val_loss: 9.8978e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1805/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0742e-09 - rmse: 4.5543e-05\n",
      "Epoch 1805: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7487e-09 - rmse: 8.2150e-05 - val_loss: 9.9017e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1806/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9637e-10 - rmse: 2.9939e-05\n",
      "Epoch 1806: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.4380e-09 - rmse: 8.6244e-05 - val_loss: 9.9067e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1807/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1601e-09 - rmse: 4.6477e-05\n",
      "Epoch 1807: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3078e-09 - rmse: 8.5485e-05 - val_loss: 9.8941e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1808/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4456e-08 - rmse: 1.2023e-04\n",
      "Epoch 1808: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8817e-09 - rmse: 8.2956e-05 - val_loss: 9.9059e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1809/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9162e-09 - rmse: 8.3164e-05\n",
      "Epoch 1809: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6538e-09 - rmse: 8.1571e-05 - val_loss: 9.9041e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1810/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2385e-08 - rmse: 1.1129e-04\n",
      "Epoch 1810: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0641e-08 - rmse: 1.0316e-04 - val_loss: 9.9196e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1811/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1465e-08 - rmse: 1.4651e-04\n",
      "Epoch 1811: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0564e-09 - rmse: 9.5165e-05 - val_loss: 9.9044e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1812/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0565e-08 - rmse: 1.0279e-04\n",
      "Epoch 1812: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.6371e-09 - rmse: 8.7391e-05 - val_loss: 9.9021e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1813/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4348e-09 - rmse: 3.7879e-05\n",
      "Epoch 1813: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5750e-09 - rmse: 8.7035e-05 - val_loss: 9.9114e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1814/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5495e-09 - rmse: 3.9364e-05\n",
      "Epoch 1814: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9777e-09 - rmse: 8.9318e-05 - val_loss: 9.9201e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1815/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3617e-08 - rmse: 1.1669e-04\n",
      "Epoch 1815: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1624e-09 - rmse: 9.0346e-05 - val_loss: 9.8898e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1816/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9737e-09 - rmse: 8.3508e-05\n",
      "Epoch 1816: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7605e-09 - rmse: 9.3597e-05 - val_loss: 9.9080e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1817/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.4867e-09 - rmse: 8.0540e-05\n",
      "Epoch 1817: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1123e-09 - rmse: 8.4334e-05 - val_loss: 9.8580e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1818/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2274e-08 - rmse: 1.1079e-04\n",
      "Epoch 1818: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.6564e-09 - rmse: 9.3040e-05 - val_loss: 9.8533e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1819/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4615e-08 - rmse: 1.2089e-04\n",
      "Epoch 1819: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0323e-09 - rmse: 8.3859e-05 - val_loss: 9.8595e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1820/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2565e-08 - rmse: 1.1210e-04\n",
      "Epoch 1820: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0034e-08 - rmse: 1.0017e-04 - val_loss: 9.8558e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1821/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7367e-08 - rmse: 1.3178e-04\n",
      "Epoch 1821: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0264e-09 - rmse: 9.5007e-05 - val_loss: 9.9204e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1822/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3474e-09 - rmse: 9.1364e-05\n",
      "Epoch 1822: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0981e-09 - rmse: 8.4250e-05 - val_loss: 9.9233e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1823/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3243e-09 - rmse: 3.6391e-05\n",
      "Epoch 1823: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6809e-09 - rmse: 8.1737e-05 - val_loss: 9.9106e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1824/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3061e-09 - rmse: 3.6141e-05\n",
      "Epoch 1824: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3513e-09 - rmse: 9.6702e-05 - val_loss: 9.9173e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1825/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8897e-09 - rmse: 5.3756e-05\n",
      "Epoch 1825: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4780e-09 - rmse: 9.7355e-05 - val_loss: 9.9095e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1826/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8489e-08 - rmse: 1.3597e-04\n",
      "Epoch 1826: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9446e-09 - rmse: 8.9132e-05 - val_loss: 9.8481e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1827/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2627e-08 - rmse: 1.1237e-04\n",
      "Epoch 1827: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.8678e-09 - rmse: 9.9337e-05 - val_loss: 9.9217e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1828/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5203e-09 - rmse: 6.7233e-05\n",
      "Epoch 1828: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0244e-09 - rmse: 9.4997e-05 - val_loss: 9.9349e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1829/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6918e-09 - rmse: 5.1882e-05\n",
      "Epoch 1829: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9998e-09 - rmse: 9.4867e-05 - val_loss: 9.9228e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1830/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2711e-09 - rmse: 5.7193e-05\n",
      "Epoch 1830: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4556e-09 - rmse: 9.1954e-05 - val_loss: 9.9285e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1831/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7072e-09 - rmse: 8.7791e-05\n",
      "Epoch 1831: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0045e-08 - rmse: 1.0022e-04 - val_loss: 9.9228e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1832/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3403e-09 - rmse: 5.7796e-05\n",
      "Epoch 1832: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.7224e-09 - rmse: 8.7877e-05 - val_loss: 9.9020e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1833/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9690e-09 - rmse: 5.4488e-05\n",
      "Epoch 1833: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.7342e-09 - rmse: 8.7944e-05 - val_loss: 9.9050e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1834/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5645e-09 - rmse: 7.4596e-05\n",
      "Epoch 1834: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.8939e-09 - rmse: 8.3029e-05 - val_loss: 9.8623e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1835/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4794e-08 - rmse: 1.2163e-04\n",
      "Epoch 1835: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9485e-09 - rmse: 8.9154e-05 - val_loss: 9.8656e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1836/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7533e-09 - rmse: 6.8944e-05\n",
      "Epoch 1836: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0566e-08 - rmse: 1.0279e-04 - val_loss: 9.9285e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1837/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8710e-09 - rmse: 7.6622e-05\n",
      "Epoch 1837: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.6011e-09 - rmse: 9.2742e-05 - val_loss: 9.9364e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1838/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1097e-08 - rmse: 1.0534e-04\n",
      "Epoch 1838: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.4745e-09 - rmse: 9.7337e-05 - val_loss: 9.8647e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1839/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3642e-08 - rmse: 1.1680e-04\n",
      "Epoch 1839: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0794e-08 - rmse: 1.0389e-04 - val_loss: 9.9182e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1840/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4419e-09 - rmse: 3.7973e-05\n",
      "Epoch 1840: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3441e-08 - rmse: 1.1594e-04 - val_loss: 9.9136e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1841/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3321e-09 - rmse: 5.7724e-05\n",
      "Epoch 1841: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.4801e-09 - rmse: 9.7366e-05 - val_loss: 9.9351e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1842/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6937e-09 - rmse: 8.7714e-05\n",
      "Epoch 1842: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.5544e-09 - rmse: 9.7747e-05 - val_loss: 9.9349e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1843/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2996e-09 - rmse: 9.6434e-05\n",
      "Epoch 1843: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1268e-08 - rmse: 1.0615e-04 - val_loss: 9.8919e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1844/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.9680e-09 - rmse: 8.3475e-05\n",
      "Epoch 1844: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1049e-08 - rmse: 1.0512e-04 - val_loss: 9.9433e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1845/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6302e-08 - rmse: 1.2768e-04\n",
      "Epoch 1845: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7484e-09 - rmse: 9.3533e-05 - val_loss: 9.9431e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1846/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9563e-09 - rmse: 6.2899e-05\n",
      "Epoch 1846: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0842e-09 - rmse: 9.5311e-05 - val_loss: 9.9220e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1847/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2984e-09 - rmse: 9.6428e-05\n",
      "Epoch 1847: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.6663e-09 - rmse: 9.8317e-05 - val_loss: 9.8813e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1848/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5100e-09 - rmse: 9.2250e-05\n",
      "Epoch 1848: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2438e-08 - rmse: 1.1152e-04 - val_loss: 9.9389e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1849/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7062e-09 - rmse: 6.0879e-05\n",
      "Epoch 1849: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1151e-08 - rmse: 1.0560e-04 - val_loss: 9.9204e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1850/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9651e-09 - rmse: 9.4684e-05\n",
      "Epoch 1850: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0450e-08 - rmse: 1.0223e-04 - val_loss: 9.8870e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1851/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4443e-08 - rmse: 1.5634e-04\n",
      "Epoch 1851: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4846e-08 - rmse: 1.2184e-04 - val_loss: 9.9313e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1852/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6909e-09 - rmse: 5.1874e-05\n",
      "Epoch 1852: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6228e-08 - rmse: 1.2739e-04 - val_loss: 9.9517e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1853/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2166e-08 - rmse: 1.1030e-04\n",
      "Epoch 1853: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3217e-08 - rmse: 1.1497e-04 - val_loss: 9.9590e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1854/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7976e-09 - rmse: 7.6142e-05\n",
      "Epoch 1854: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.4193e-08 - rmse: 1.1913e-04 - val_loss: 9.9049e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1855/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2377e-08 - rmse: 1.1125e-04\n",
      "Epoch 1855: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4444e-08 - rmse: 1.2018e-04 - val_loss: 9.9054e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1856/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8684e-09 - rmse: 7.6605e-05\n",
      "Epoch 1856: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0503e-08 - rmse: 1.0249e-04 - val_loss: 9.9467e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1857/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9560e-08 - rmse: 1.3986e-04\n",
      "Epoch 1857: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1546e-08 - rmse: 1.0745e-04 - val_loss: 9.9400e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1858/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8902e-09 - rmse: 6.2372e-05\n",
      "Epoch 1858: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2681e-09 - rmse: 9.0929e-05 - val_loss: 9.9422e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1859/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1800e-08 - rmse: 1.4765e-04\n",
      "Epoch 1859: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1001e-09 - rmse: 9.5395e-05 - val_loss: 9.9207e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1860/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3659e-09 - rmse: 7.9786e-05\n",
      "Epoch 1860: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2854e-09 - rmse: 9.1024e-05 - val_loss: 9.8800e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1861/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8978e-08 - rmse: 1.3776e-04\n",
      "Epoch 1861: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7084e-09 - rmse: 9.3319e-05 - val_loss: 9.8850e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1862/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7048e-09 - rmse: 8.7777e-05\n",
      "Epoch 1862: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1748e-09 - rmse: 9.5785e-05 - val_loss: 9.8715e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1863/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2004e-08 - rmse: 1.4834e-04\n",
      "Epoch 1863: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2896e-08 - rmse: 1.1356e-04 - val_loss: 9.8791e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1864/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0770e-09 - rmse: 6.3851e-05\n",
      "Epoch 1864: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1922e-08 - rmse: 1.0919e-04 - val_loss: 9.9296e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1865/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1381e-08 - rmse: 1.4622e-04\n",
      "Epoch 1865: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6900e-09 - rmse: 8.7693e-05 - val_loss: 9.8982e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1866/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6510e-08 - rmse: 1.2849e-04\n",
      "Epoch 1866: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0661e-08 - rmse: 1.0325e-04 - val_loss: 9.9334e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1867/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2676e-08 - rmse: 1.1259e-04\n",
      "Epoch 1867: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7257e-09 - rmse: 9.3412e-05 - val_loss: 9.8950e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1868/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0157e-09 - rmse: 7.0822e-05\n",
      "Epoch 1868: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2620e-08 - rmse: 1.1234e-04 - val_loss: 9.8816e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1869/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3672e-08 - rmse: 1.5386e-04\n",
      "Epoch 1869: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2057e-08 - rmse: 1.0980e-04 - val_loss: 9.8768e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1870/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.9663e-09 - rmse: 9.4691e-05\n",
      "Epoch 1870: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0455e-08 - rmse: 1.0225e-04 - val_loss: 9.8875e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1871/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3627e-08 - rmse: 1.1673e-04\n",
      "Epoch 1871: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3673e-09 - rmse: 9.6785e-05 - val_loss: 9.9379e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1872/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8709e-09 - rmse: 6.9792e-05\n",
      "Epoch 1872: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0761e-08 - rmse: 1.0373e-04 - val_loss: 9.9420e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1873/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3461e-08 - rmse: 1.1602e-04\n",
      "Epoch 1873: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1946e-08 - rmse: 1.0930e-04 - val_loss: 9.9161e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1874/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.4491e-09 - rmse: 7.3818e-05\n",
      "Epoch 1874: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0730e-09 - rmse: 8.9850e-05 - val_loss: 9.8848e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1875/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5757e-09 - rmse: 9.7855e-05\n",
      "Epoch 1875: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8871e-09 - rmse: 9.4271e-05 - val_loss: 9.8923e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1876/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8337e-09 - rmse: 8.8508e-05\n",
      "Epoch 1876: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8057e-09 - rmse: 9.3839e-05 - val_loss: 9.9554e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1877/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7577e-09 - rmse: 7.5879e-05\n",
      "Epoch 1877: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0088e-08 - rmse: 1.0044e-04 - val_loss: 9.9389e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1878/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0451e-09 - rmse: 7.1029e-05\n",
      "Epoch 1878: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5997e-09 - rmse: 8.7176e-05 - val_loss: 9.9410e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1879/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9019e-08 - rmse: 1.3791e-04\n",
      "Epoch 1879: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2930e-09 - rmse: 9.1066e-05 - val_loss: 9.9273e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1880/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3813e-09 - rmse: 7.9883e-05\n",
      "Epoch 1880: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5165e-09 - rmse: 9.2285e-05 - val_loss: 9.9374e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1881/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1475e-08 - rmse: 1.0712e-04\n",
      "Epoch 1881: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0801e-08 - rmse: 1.0393e-04 - val_loss: 9.9379e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1882/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1879e-09 - rmse: 9.5854e-05\n",
      "Epoch 1882: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5257e-08 - rmse: 1.2352e-04 - val_loss: 9.9287e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1883/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2105e-08 - rmse: 1.1002e-04\n",
      "Epoch 1883: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3128e-08 - rmse: 1.1458e-04 - val_loss: 9.8859e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1884/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8038e-08 - rmse: 1.6745e-04\n",
      "Epoch 1884: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3580e-08 - rmse: 1.1653e-04 - val_loss: 9.9506e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1885/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2922e-09 - rmse: 6.5515e-05\n",
      "Epoch 1885: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2996e-08 - rmse: 1.1400e-04 - val_loss: 9.9529e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1886/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7497e-09 - rmse: 8.8032e-05\n",
      "Epoch 1886: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.8541e-09 - rmse: 9.9268e-05 - val_loss: 9.9409e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1887/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7047e-08 - rmse: 1.6446e-04\n",
      "Epoch 1887: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1185e-08 - rmse: 1.0576e-04 - val_loss: 9.9415e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1888/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8099e-08 - rmse: 1.3453e-04\n",
      "Epoch 1888: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0062e-09 - rmse: 8.9477e-05 - val_loss: 9.8895e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1889/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2503e-09 - rmse: 6.5195e-05\n",
      "Epoch 1889: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.4249e-09 - rmse: 9.7082e-05 - val_loss: 9.8861e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1890/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3893e-09 - rmse: 8.5961e-05\n",
      "Epoch 1890: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1755e-09 - rmse: 9.5789e-05 - val_loss: 9.9424e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1891/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3330e-08 - rmse: 1.1546e-04\n",
      "Epoch 1891: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8625e-09 - rmse: 8.8671e-05 - val_loss: 9.9450e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1892/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4237e-08 - rmse: 1.1932e-04\n",
      "Epoch 1892: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0890e-09 - rmse: 8.4196e-05 - val_loss: 9.9253e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1893/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3734e-09 - rmse: 7.9833e-05\n",
      "Epoch 1893: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0812e-09 - rmse: 8.4150e-05 - val_loss: 9.8795e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1894/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1018e-08 - rmse: 1.0497e-04\n",
      "Epoch 1894: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9508e-09 - rmse: 9.4609e-05 - val_loss: 9.8877e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1895/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3492e-09 - rmse: 4.8468e-05\n",
      "Epoch 1895: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5627e-09 - rmse: 9.2535e-05 - val_loss: 9.9321e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1896/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7493e-08 - rmse: 1.3226e-04\n",
      "Epoch 1896: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0316e-08 - rmse: 1.0157e-04 - val_loss: 9.9473e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1897/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5872e-08 - rmse: 1.6085e-04\n",
      "Epoch 1897: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1723e-08 - rmse: 1.0827e-04 - val_loss: 9.9508e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1898/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2586e-08 - rmse: 1.1219e-04\n",
      "Epoch 1898: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1918e-08 - rmse: 1.0917e-04 - val_loss: 9.8908e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1899/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1658e-09 - rmse: 9.0365e-05\n",
      "Epoch 1899: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2276e-08 - rmse: 1.1080e-04 - val_loss: 9.8600e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1900/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5948e-08 - rmse: 1.6108e-04\n",
      "Epoch 1900: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1756e-08 - rmse: 1.4750e-04 - val_loss: 9.8915e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1901/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8639e-08 - rmse: 1.3653e-04\n",
      "Epoch 1901: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.0279e-08 - rmse: 1.4241e-04 - val_loss: 9.9556e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1902/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8730e-09 - rmse: 8.2903e-05\n",
      "Epoch 1902: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2868e-08 - rmse: 1.1344e-04 - val_loss: 9.9011e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1903/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3811e-09 - rmse: 7.9882e-05\n",
      "Epoch 1903: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8747e-09 - rmse: 9.9372e-05 - val_loss: 9.8968e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1904/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2482e-08 - rmse: 1.1172e-04\n",
      "Epoch 1904: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8050e-08 - rmse: 1.3435e-04 - val_loss: 9.9049e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1905/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3046e-09 - rmse: 3.6119e-05\n",
      "Epoch 1905: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1802e-09 - rmse: 9.5814e-05 - val_loss: 9.9586e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1906/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1637e-08 - rmse: 1.7787e-04\n",
      "Epoch 1906: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1361e-08 - rmse: 1.0659e-04 - val_loss: 9.9531e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1907/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7859e-09 - rmse: 6.9180e-05\n",
      "Epoch 1907: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2713e-09 - rmse: 9.0946e-05 - val_loss: 9.9045e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1908/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3455e-09 - rmse: 7.9659e-05\n",
      "Epoch 1908: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1497e-09 - rmse: 9.5654e-05 - val_loss: 9.9507e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1909/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3138e-09 - rmse: 5.7566e-05\n",
      "Epoch 1909: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0451e-08 - rmse: 1.0223e-04 - val_loss: 9.8998e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1910/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7871e-09 - rmse: 6.1539e-05\n",
      "Epoch 1910: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9779e-09 - rmse: 9.4752e-05 - val_loss: 9.8983e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1911/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6803e-09 - rmse: 4.0992e-05\n",
      "Epoch 1911: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8378e-09 - rmse: 8.8531e-05 - val_loss: 9.9541e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1912/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1884e-08 - rmse: 1.0902e-04\n",
      "Epoch 1912: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2522e-09 - rmse: 9.6188e-05 - val_loss: 9.9149e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1913/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3167e-09 - rmse: 7.9478e-05\n",
      "Epoch 1913: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0878e-08 - rmse: 1.0430e-04 - val_loss: 9.9547e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1914/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9983e-09 - rmse: 7.7449e-05\n",
      "Epoch 1914: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1497e-08 - rmse: 1.0723e-04 - val_loss: 9.8883e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1915/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2352e-09 - rmse: 9.0748e-05\n",
      "Epoch 1915: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0373e-08 - rmse: 1.0185e-04 - val_loss: 9.9217e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1916/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2477e-08 - rmse: 1.1170e-04\n",
      "Epoch 1916: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9497e-09 - rmse: 9.4603e-05 - val_loss: 9.8782e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1917/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5585e-08 - rmse: 1.2484e-04\n",
      "Epoch 1917: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0721e-09 - rmse: 8.9845e-05 - val_loss: 9.9126e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1918/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.7908e-09 - rmse: 8.8265e-05\n",
      "Epoch 1918: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7467e-09 - rmse: 9.8725e-05 - val_loss: 9.9382e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1919/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5675e-09 - rmse: 5.9728e-05\n",
      "Epoch 1919: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2581e-09 - rmse: 8.5195e-05 - val_loss: 9.9366e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1920/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8623e-09 - rmse: 5.3500e-05\n",
      "Epoch 1920: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2541e-09 - rmse: 8.5171e-05 - val_loss: 9.8851e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1921/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1758e-09 - rmse: 4.6646e-05\n",
      "Epoch 1921: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5819e-09 - rmse: 9.2639e-05 - val_loss: 9.8916e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1922/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1502e-09 - rmse: 8.4559e-05\n",
      "Epoch 1922: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7653e-09 - rmse: 9.3623e-05 - val_loss: 9.8887e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1923/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8978e-09 - rmse: 7.6797e-05\n",
      "Epoch 1923: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2818e-09 - rmse: 9.6342e-05 - val_loss: 9.9399e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1924/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9444e-09 - rmse: 4.4096e-05\n",
      "Epoch 1924: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2443e-09 - rmse: 9.6147e-05 - val_loss: 9.8911e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1925/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2453e-09 - rmse: 9.0803e-05\n",
      "Epoch 1925: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2809e-08 - rmse: 1.1318e-04 - val_loss: 9.8865e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1926/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9242e-08 - rmse: 1.3871e-04\n",
      "Epoch 1926: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3330e-08 - rmse: 1.1546e-04 - val_loss: 9.9077e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1927/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4696e-09 - rmse: 9.7312e-05\n",
      "Epoch 1927: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0049e-08 - rmse: 1.0025e-04 - val_loss: 9.9610e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1928/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0043e-08 - rmse: 1.0022e-04\n",
      "Epoch 1928: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0371e-08 - rmse: 1.0184e-04 - val_loss: 9.9596e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1929/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3310e-08 - rmse: 1.5267e-04\n",
      "Epoch 1929: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4377e-08 - rmse: 1.1990e-04 - val_loss: 9.9532e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1930/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2772e-09 - rmse: 6.5401e-05\n",
      "Epoch 1930: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.6098e-08 - rmse: 1.2688e-04 - val_loss: 9.8862e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1931/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2339e-08 - rmse: 1.4946e-04\n",
      "Epoch 1931: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7460e-08 - rmse: 1.3214e-04 - val_loss: 9.8971e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1932/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8759e-08 - rmse: 1.3696e-04\n",
      "Epoch 1932: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8744e-08 - rmse: 1.3691e-04 - val_loss: 9.9171e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1933/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7210e-08 - rmse: 1.3119e-04\n",
      "Epoch 1933: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4128e-09 - rmse: 9.1721e-05 - val_loss: 9.9625e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1934/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5917e-08 - rmse: 1.8952e-04\n",
      "Epoch 1934: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1071e-08 - rmse: 1.0522e-04 - val_loss: 9.9197e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1935/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8397e-09 - rmse: 5.3289e-05\n",
      "Epoch 1935: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0366e-09 - rmse: 8.3884e-05 - val_loss: 9.9616e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1936/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3204e-09 - rmse: 7.2941e-05\n",
      "Epoch 1936: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5522e-09 - rmse: 9.7736e-05 - val_loss: 9.9186e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1937/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2752e-08 - rmse: 1.1292e-04\n",
      "Epoch 1937: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4859e-09 - rmse: 8.6521e-05 - val_loss: 9.9582e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1938/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4458e-09 - rmse: 6.6677e-05\n",
      "Epoch 1938: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.8134e-09 - rmse: 9.3880e-05 - val_loss: 9.9672e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1939/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2134e-08 - rmse: 1.1015e-04\n",
      "Epoch 1939: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.1124e-09 - rmse: 9.0069e-05 - val_loss: 9.8870e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1940/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6367e-09 - rmse: 8.7388e-05\n",
      "Epoch 1940: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1411e-08 - rmse: 1.0682e-04 - val_loss: 9.8927e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1941/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8060e-09 - rmse: 6.1693e-05\n",
      "Epoch 1941: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1417e-08 - rmse: 1.0685e-04 - val_loss: 9.8948e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1942/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6751e-09 - rmse: 6.8375e-05\n",
      "Epoch 1942: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8502e-09 - rmse: 8.8601e-05 - val_loss: 9.9749e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1943/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6595e-08 - rmse: 1.2882e-04\n",
      "Epoch 1943: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3010e-08 - rmse: 1.1406e-04 - val_loss: 9.9749e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1944/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0247e-08 - rmse: 1.7392e-04\n",
      "Epoch 1944: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0809e-08 - rmse: 1.0397e-04 - val_loss: 9.9239e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1945/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3128e-08 - rmse: 1.5208e-04\n",
      "Epoch 1945: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9498e-09 - rmse: 9.9749e-05 - val_loss: 9.9122e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1946/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8549e-09 - rmse: 9.4101e-05\n",
      "Epoch 1946: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2152e-08 - rmse: 1.1024e-04 - val_loss: 9.9166e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1947/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1176e-09 - rmse: 9.0098e-05\n",
      "Epoch 1947: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2150e-09 - rmse: 9.5995e-05 - val_loss: 9.9196e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1948/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1100e-08 - rmse: 1.0536e-04\n",
      "Epoch 1948: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.9303e-09 - rmse: 9.9651e-05 - val_loss: 9.9340e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1949/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4570e-09 - rmse: 3.8170e-05\n",
      "Epoch 1949: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4168e-09 - rmse: 9.1743e-05 - val_loss: 9.9466e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1950/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2182e-08 - rmse: 1.1037e-04\n",
      "Epoch 1950: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.6203e-09 - rmse: 8.7294e-05 - val_loss: 9.9174e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1951/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6211e-09 - rmse: 6.0176e-05\n",
      "Epoch 1951: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6774e-09 - rmse: 8.1715e-05 - val_loss: 9.9203e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1952/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.5599e-09 - rmse: 6.7527e-05\n",
      "Epoch 1952: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2292e-09 - rmse: 7.8925e-05 - val_loss: 9.9327e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1953/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6884e-09 - rmse: 4.1090e-05\n",
      "Epoch 1953: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.3550e-09 - rmse: 8.5761e-05 - val_loss: 9.9169e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1954/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2475e-08 - rmse: 1.1169e-04\n",
      "Epoch 1954: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0601e-09 - rmse: 9.5185e-05 - val_loss: 9.9220e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1955/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0370e-09 - rmse: 5.5109e-05\n",
      "Epoch 1955: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0094e-08 - rmse: 1.0047e-04 - val_loss: 9.9262e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1956/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1113e-09 - rmse: 4.5949e-05\n",
      "Epoch 1956: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1953e-09 - rmse: 8.4825e-05 - val_loss: 9.9127e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1957/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1733e-09 - rmse: 4.6619e-05\n",
      "Epoch 1957: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2266e-09 - rmse: 8.5010e-05 - val_loss: 9.9240e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1958/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5777e-09 - rmse: 3.9720e-05\n",
      "Epoch 1958: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.6629e-09 - rmse: 7.5252e-05 - val_loss: 9.9386e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1959/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9938e-09 - rmse: 5.4716e-05\n",
      "Epoch 1959: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2824e-09 - rmse: 8.5337e-05 - val_loss: 9.9769e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1960/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3885e-08 - rmse: 1.1783e-04\n",
      "Epoch 1960: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9383e-09 - rmse: 9.4543e-05 - val_loss: 9.9182e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1961/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7829e-09 - rmse: 6.9158e-05\n",
      "Epoch 1961: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.1326e-09 - rmse: 9.5565e-05 - val_loss: 9.8997e-05 - val_rmse: 0.0099 - lr: 6.2500e-06\n",
      "Epoch 1962/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5364e-08 - rmse: 1.2395e-04\n",
      "Epoch 1962: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5018e-09 - rmse: 9.7477e-05 - val_loss: 9.9281e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1963/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3138e-08 - rmse: 1.1462e-04\n",
      "Epoch 1963: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.8143e-09 - rmse: 9.3885e-05 - val_loss: 9.9148e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1964/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3355e-09 - rmse: 9.6621e-05\n",
      "Epoch 1964: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5590e-09 - rmse: 9.2515e-05 - val_loss: 9.9107e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1965/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3192e-09 - rmse: 7.2933e-05\n",
      "Epoch 1965: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9842e-09 - rmse: 8.3571e-05 - val_loss: 9.9208e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1966/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4041e-08 - rmse: 1.1849e-04\n",
      "Epoch 1966: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2383e-09 - rmse: 8.5078e-05 - val_loss: 9.9767e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1967/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4642e-09 - rmse: 9.7284e-05\n",
      "Epoch 1967: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.1402e-09 - rmse: 8.4499e-05 - val_loss: 9.9326e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1968/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3031e-08 - rmse: 1.1415e-04\n",
      "Epoch 1968: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2955e-09 - rmse: 9.1080e-05 - val_loss: 9.9821e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1969/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 7.3305e-09 - rmse: 8.5618e-05\n",
      "Epoch 1969: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6322e-09 - rmse: 8.7362e-05 - val_loss: 9.9821e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1970/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.6213e-09 - rmse: 6.0178e-05\n",
      "Epoch 1970: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7709e-09 - rmse: 9.8848e-05 - val_loss: 9.9203e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1971/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8352e-09 - rmse: 4.2839e-05\n",
      "Epoch 1971: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3684e-09 - rmse: 9.6790e-05 - val_loss: 9.9132e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1972/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1592e-08 - rmse: 1.0767e-04\n",
      "Epoch 1972: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0809e-08 - rmse: 1.0397e-04 - val_loss: 9.9069e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1973/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3594e-09 - rmse: 9.1430e-05\n",
      "Epoch 1973: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2186e-08 - rmse: 1.1039e-04 - val_loss: 9.9230e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1974/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0932e-08 - rmse: 1.4468e-04\n",
      "Epoch 1974: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3672e-08 - rmse: 1.1693e-04 - val_loss: 9.9420e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1975/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2358e-08 - rmse: 1.1117e-04\n",
      "Epoch 1975: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.6838e-09 - rmse: 9.8406e-05 - val_loss: 9.9859e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1976/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.2857e-09 - rmse: 9.6362e-05\n",
      "Epoch 1976: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5966e-09 - rmse: 9.2718e-05 - val_loss: 9.9294e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1977/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7982e-09 - rmse: 4.2406e-05\n",
      "Epoch 1977: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9128e-09 - rmse: 7.6895e-05 - val_loss: 9.9146e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1978/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4596e-08 - rmse: 1.2081e-04\n",
      "Epoch 1978: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3238e-08 - rmse: 1.1506e-04 - val_loss: 9.9155e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1979/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0124e-08 - rmse: 1.0062e-04\n",
      "Epoch 1979: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1388e-08 - rmse: 1.0671e-04 - val_loss: 9.9220e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1980/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8663e-08 - rmse: 1.3661e-04\n",
      "Epoch 1980: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1135e-08 - rmse: 1.0552e-04 - val_loss: 9.9276e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1981/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4295e-09 - rmse: 5.8562e-05\n",
      "Epoch 1981: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5200e-08 - rmse: 1.2329e-04 - val_loss: 9.9257e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1982/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2669e-08 - rmse: 1.5056e-04\n",
      "Epoch 1982: val_loss did not improve from 0.00009\n",
      "\n",
      "Epoch 1982: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.8365e-08 - rmse: 1.3552e-04 - val_loss: 9.9250e-05 - val_rmse: 0.0100 - lr: 6.2500e-06\n",
      "Epoch 1983/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8071e-08 - rmse: 1.9512e-04\n",
      "Epoch 1983: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.3043e-08 - rmse: 1.1421e-04 - val_loss: 9.9881e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1984/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0321e-08 - rmse: 1.0159e-04\n",
      "Epoch 1984: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.4408e-09 - rmse: 9.1874e-05 - val_loss: 9.9348e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1985/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4060e-09 - rmse: 4.9051e-05\n",
      "Epoch 1985: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1625e-09 - rmse: 8.4631e-05 - val_loss: 9.9347e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1986/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6024e-09 - rmse: 6.7841e-05\n",
      "Epoch 1986: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4702e-09 - rmse: 8.6430e-05 - val_loss: 9.9468e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1987/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.1292e-10 - rmse: 3.0215e-05\n",
      "Epoch 1987: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9280e-09 - rmse: 7.6994e-05 - val_loss: 9.9201e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1988/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5549e-09 - rmse: 5.9623e-05\n",
      "Epoch 1988: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7735e-09 - rmse: 8.2301e-05 - val_loss: 9.9190e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1989/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1217e-09 - rmse: 6.4200e-05\n",
      "Epoch 1989: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8708e-09 - rmse: 8.8717e-05 - val_loss: 9.9218e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1990/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8329e-09 - rmse: 6.1910e-05\n",
      "Epoch 1990: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3517e-09 - rmse: 7.9698e-05 - val_loss: 9.9712e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1991/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7948e-09 - rmse: 5.2866e-05\n",
      "Epoch 1991: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5176e-09 - rmse: 8.0732e-05 - val_loss: 9.9221e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1992/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0770e-08 - rmse: 1.0378e-04\n",
      "Epoch 1992: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5094e-09 - rmse: 8.6657e-05 - val_loss: 9.9754e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1993/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7125e-09 - rmse: 7.5581e-05\n",
      "Epoch 1993: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2979e-09 - rmse: 8.5428e-05 - val_loss: 9.9260e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1994/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1445e-08 - rmse: 1.0698e-04\n",
      "Epoch 1994: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0212e-09 - rmse: 8.3792e-05 - val_loss: 9.9266e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1995/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7117e-08 - rmse: 1.3083e-04\n",
      "Epoch 1995: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2622e-09 - rmse: 8.5219e-05 - val_loss: 9.9259e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1996/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0814e-09 - rmse: 7.1284e-05\n",
      "Epoch 1996: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4810e-09 - rmse: 8.6493e-05 - val_loss: 9.9810e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1997/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.8289e-09 - rmse: 7.6347e-05\n",
      "Epoch 1997: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.9960e-09 - rmse: 8.9420e-05 - val_loss: 9.9359e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1998/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5650e-08 - rmse: 1.2510e-04\n",
      "Epoch 1998: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8901e-09 - rmse: 7.6747e-05 - val_loss: 9.9254e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 1999/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4012e-09 - rmse: 9.6960e-05\n",
      "Epoch 1999: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4862e-09 - rmse: 8.0537e-05 - val_loss: 9.9249e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2000/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4059e-09 - rmse: 3.7496e-05\n",
      "Epoch 2000: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8277e-09 - rmse: 8.8474e-05 - val_loss: 9.9385e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2001/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.6035e-09 - rmse: 7.4856e-05\n",
      "Epoch 2001: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6835e-09 - rmse: 8.1753e-05 - val_loss: 9.9149e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2002/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0956e-09 - rmse: 3.3100e-05\n",
      "Epoch 2002: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0308e-09 - rmse: 8.9615e-05 - val_loss: 9.9318e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2003/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4963e-09 - rmse: 5.9130e-05\n",
      "Epoch 2003: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6428e-09 - rmse: 7.5119e-05 - val_loss: 9.9313e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2004/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0659e-09 - rmse: 6.3764e-05\n",
      "Epoch 2004: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5496e-09 - rmse: 7.4496e-05 - val_loss: 9.9428e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2005/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3022e-09 - rmse: 5.7465e-05\n",
      "Epoch 2005: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.2942e-09 - rmse: 8.5406e-05 - val_loss: 9.9493e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2006/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6638e-09 - rmse: 5.1612e-05\n",
      "Epoch 2006: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5305e-09 - rmse: 8.0811e-05 - val_loss: 9.9846e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2007/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8171e-08 - rmse: 1.3480e-04\n",
      "Epoch 2007: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9522e-09 - rmse: 8.9175e-05 - val_loss: 9.9891e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2008/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.2640e-09 - rmse: 9.0907e-05\n",
      "Epoch 2008: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6249e-09 - rmse: 8.1394e-05 - val_loss: 9.9348e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2009/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5090e-09 - rmse: 3.8846e-05\n",
      "Epoch 2009: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.1213e-09 - rmse: 7.8239e-05 - val_loss: 9.9980e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2010/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4455e-08 - rmse: 1.2023e-04\n",
      "Epoch 2010: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.7016e-09 - rmse: 8.7759e-05 - val_loss: 9.9373e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2011/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3564e-09 - rmse: 7.9727e-05\n",
      "Epoch 2011: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1179e-09 - rmse: 7.8217e-05 - val_loss: 9.9355e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2012/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9747e-09 - rmse: 6.3045e-05\n",
      "Epoch 2012: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.0717e-09 - rmse: 7.7921e-05 - val_loss: 9.9375e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2013/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2448e-09 - rmse: 7.9024e-05\n",
      "Epoch 2013: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0452e-09 - rmse: 7.1029e-05 - val_loss: 9.9386e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2014/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1688e-09 - rmse: 3.4188e-05\n",
      "Epoch 2014: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3858e-09 - rmse: 7.9911e-05 - val_loss: 9.9444e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2015/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2089e-09 - rmse: 7.8796e-05\n",
      "Epoch 2015: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9992e-09 - rmse: 8.3661e-05 - val_loss: 9.9551e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2016/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2573e-08 - rmse: 1.1213e-04\n",
      "Epoch 2016: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0469e-09 - rmse: 8.3946e-05 - val_loss: 1.0003e-04 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2017/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0709e-08 - rmse: 1.4391e-04\n",
      "Epoch 2017: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0901e-08 - rmse: 1.0441e-04 - val_loss: 9.9531e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2018/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1710e-09 - rmse: 5.6312e-05\n",
      "Epoch 2018: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0186e-08 - rmse: 1.0093e-04 - val_loss: 9.9278e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2019/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.1140e-09 - rmse: 8.4345e-05\n",
      "Epoch 2019: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.7640e-09 - rmse: 9.3616e-05 - val_loss: 9.9348e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2020/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4143e-08 - rmse: 1.1892e-04\n",
      "Epoch 2020: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.2060e-09 - rmse: 9.0587e-05 - val_loss: 9.9312e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2021/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5795e-09 - rmse: 9.7875e-05\n",
      "Epoch 2021: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9906e-09 - rmse: 8.9390e-05 - val_loss: 9.9224e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2022/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4225e-09 - rmse: 5.8502e-05\n",
      "Epoch 2022: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1080e-09 - rmse: 7.8153e-05 - val_loss: 9.9451e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2023/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 7.8521e-09 - rmse: 8.8612e-05\n",
      "Epoch 2023: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5312e-09 - rmse: 9.2365e-05 - val_loss: 9.9405e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2024/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.2390e-09 - rmse: 7.8987e-05\n",
      "Epoch 2024: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0133e-08 - rmse: 1.0066e-04 - val_loss: 9.9342e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2025/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2323e-09 - rmse: 8.5043e-05\n",
      "Epoch 2025: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7054e-09 - rmse: 8.1886e-05 - val_loss: 9.9364e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2026/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5628e-09 - rmse: 7.4584e-05\n",
      "Epoch 2026: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4416e-09 - rmse: 8.0260e-05 - val_loss: 9.9414e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2027/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4500e-08 - rmse: 1.2041e-04\n",
      "Epoch 2027: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9805e-09 - rmse: 8.9334e-05 - val_loss: 9.9417e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2028/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9148e-09 - rmse: 5.3989e-05\n",
      "Epoch 2028: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2672e-09 - rmse: 9.6266e-05 - val_loss: 1.0011e-04 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2029/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0654e-08 - rmse: 1.4371e-04\n",
      "Epoch 2029: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4167e-08 - rmse: 1.1902e-04 - val_loss: 1.0002e-04 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2030/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3667e-08 - rmse: 1.1690e-04\n",
      "Epoch 2030: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.8871e-09 - rmse: 9.9434e-05 - val_loss: 9.9475e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2031/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5580e-08 - rmse: 1.2482e-04\n",
      "Epoch 2031: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1815e-08 - rmse: 1.0870e-04 - val_loss: 9.9428e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2032/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.5997e-09 - rmse: 5.0987e-05\n",
      "Epoch 2032: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.2284e-08 - rmse: 1.1083e-04 - val_loss: 9.9556e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2033/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8369e-08 - rmse: 1.3553e-04\n",
      "Epoch 2033: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6532e-09 - rmse: 8.7483e-05 - val_loss: 9.9349e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2034/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.7037e-09 - rmse: 5.1997e-05\n",
      "Epoch 2034: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.4262e-09 - rmse: 8.0164e-05 - val_loss: 9.9517e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2035/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8713e-09 - rmse: 6.2220e-05\n",
      "Epoch 2035: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4855e-09 - rmse: 9.2117e-05 - val_loss: 9.9393e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2036/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7586e-09 - rmse: 6.8982e-05\n",
      "Epoch 2036: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.7436e-09 - rmse: 8.2119e-05 - val_loss: 9.9354e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2037/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5278e-09 - rmse: 5.9395e-05\n",
      "Epoch 2037: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8030e-09 - rmse: 8.8334e-05 - val_loss: 9.9484e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2038/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0928e-09 - rmse: 8.9960e-05\n",
      "Epoch 2038: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.7388e-09 - rmse: 9.3482e-05 - val_loss: 9.9379e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2039/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4872e-09 - rmse: 6.6987e-05\n",
      "Epoch 2039: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9233e-09 - rmse: 9.4463e-05 - val_loss: 9.9366e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2040/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2892e-09 - rmse: 4.7846e-05\n",
      "Epoch 2040: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.6575e-09 - rmse: 9.8273e-05 - val_loss: 9.9424e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2041/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5175e-09 - rmse: 3.8956e-05\n",
      "Epoch 2041: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5793e-09 - rmse: 9.2624e-05 - val_loss: 9.9396e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2042/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2556e-09 - rmse: 4.7493e-05\n",
      "Epoch 2042: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.3551e-09 - rmse: 8.5762e-05 - val_loss: 9.9369e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2043/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.3028e-09 - rmse: 9.6451e-05\n",
      "Epoch 2043: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.8685e-09 - rmse: 9.4172e-05 - val_loss: 9.9300e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2044/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1574e-09 - rmse: 5.6191e-05\n",
      "Epoch 2044: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.0613e-09 - rmse: 7.7854e-05 - val_loss: 9.9448e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2045/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2464e-08 - rmse: 1.1164e-04\n",
      "Epoch 2045: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6315e-09 - rmse: 8.1434e-05 - val_loss: 9.9403e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2046/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4713e-09 - rmse: 9.7320e-05\n",
      "Epoch 2046: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4434e-09 - rmse: 9.1888e-05 - val_loss: 9.9361e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2047/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4288e-09 - rmse: 3.7799e-05\n",
      "Epoch 2047: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9149e-09 - rmse: 7.6908e-05 - val_loss: 9.9408e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2048/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3323e-08 - rmse: 1.1542e-04\n",
      "Epoch 2048: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3753e-09 - rmse: 7.9845e-05 - val_loss: 9.9648e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2049/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.0748e-09 - rmse: 8.9860e-05\n",
      "Epoch 2049: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5626e-09 - rmse: 8.1010e-05 - val_loss: 9.9458e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2050/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 5.5287e-09 - rmse: 7.4355e-05\n",
      "Epoch 2050: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.2370e-09 - rmse: 7.8975e-05 - val_loss: 9.9544e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2051/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8541e-09 - rmse: 4.3059e-05\n",
      "Epoch 2051: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8289e-09 - rmse: 8.2637e-05 - val_loss: 9.9456e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2052/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3922e-09 - rmse: 9.1609e-05\n",
      "Epoch 2052: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.7839e-09 - rmse: 9.3723e-05 - val_loss: 9.9429e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2053/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2355e-08 - rmse: 1.1115e-04\n",
      "Epoch 2053: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4814e-09 - rmse: 8.6495e-05 - val_loss: 9.9395e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2054/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.9053e-09 - rmse: 7.6846e-05\n",
      "Epoch 2054: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8362e-09 - rmse: 8.8523e-05 - val_loss: 9.9416e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2055/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6578e-08 - rmse: 1.2875e-04\n",
      "Epoch 2055: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.0678e-09 - rmse: 8.4070e-05 - val_loss: 9.9327e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2056/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4800e-09 - rmse: 8.6487e-05\n",
      "Epoch 2056: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.5988e-09 - rmse: 8.1233e-05 - val_loss: 9.9315e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2057/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2672e-08 - rmse: 1.1257e-04\n",
      "Epoch 2057: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1239e-08 - rmse: 1.0601e-04 - val_loss: 9.9527e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2058/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.4183e-09 - rmse: 6.6470e-05\n",
      "Epoch 2058: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8641e-09 - rmse: 8.8680e-05 - val_loss: 9.9529e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2059/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6138e-08 - rmse: 1.2703e-04\n",
      "Epoch 2059: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0819e-09 - rmse: 9.5299e-05 - val_loss: 9.9246e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2060/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5543e-08 - rmse: 1.2467e-04\n",
      "Epoch 2060: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5787e-09 - rmse: 8.1109e-05 - val_loss: 9.9476e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2061/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3304e-09 - rmse: 7.3010e-05\n",
      "Epoch 2061: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8648e-09 - rmse: 8.2854e-05 - val_loss: 9.9396e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2062/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8812e-09 - rmse: 6.2300e-05\n",
      "Epoch 2062: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0198e-09 - rmse: 7.7587e-05 - val_loss: 9.9278e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2063/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6668e-08 - rmse: 1.2910e-04\n",
      "Epoch 2063: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.5338e-09 - rmse: 9.2378e-05 - val_loss: 9.9562e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2064/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.5613e-09 - rmse: 8.1002e-05\n",
      "Epoch 2064: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.8381e-09 - rmse: 8.2693e-05 - val_loss: 9.9593e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2065/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.3265e-09 - rmse: 5.7676e-05\n",
      "Epoch 2065: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2945e-09 - rmse: 7.9338e-05 - val_loss: 9.9573e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2066/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1963e-09 - rmse: 9.0533e-05\n",
      "Epoch 2066: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3558e-09 - rmse: 7.3183e-05 - val_loss: 9.9425e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2067/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5843e-08 - rmse: 1.2587e-04\n",
      "Epoch 2067: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2681e-09 - rmse: 7.2581e-05 - val_loss: 9.9433e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2068/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3669e-09 - rmse: 3.6971e-05\n",
      "Epoch 2068: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4638e-09 - rmse: 8.6393e-05 - val_loss: 9.9518e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2069/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5147e-08 - rmse: 1.2307e-04\n",
      "Epoch 2069: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6055e-09 - rmse: 7.4870e-05 - val_loss: 9.9516e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2070/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.8200e-09 - rmse: 9.3915e-05\n",
      "Epoch 2070: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6122e-09 - rmse: 7.4915e-05 - val_loss: 9.9343e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2071/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5953e-09 - rmse: 3.9941e-05\n",
      "Epoch 2071: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6139e-09 - rmse: 7.4926e-05 - val_loss: 9.9384e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2072/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6694e-09 - rmse: 6.8333e-05\n",
      "Epoch 2072: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.9740e-09 - rmse: 7.7291e-05 - val_loss: 9.9614e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2073/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.5871e-08 - rmse: 1.2598e-04\n",
      "Epoch 2073: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.7946e-09 - rmse: 7.6123e-05 - val_loss: 9.9429e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2074/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7708e-09 - rmse: 9.8847e-05\n",
      "Epoch 2074: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0736e-09 - rmse: 7.7933e-05 - val_loss: 9.9670e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2075/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.9699e-10 - rmse: 3.1575e-05\n",
      "Epoch 2075: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2412e-09 - rmse: 7.2396e-05 - val_loss: 9.9630e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2076/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4018e-08 - rmse: 1.1840e-04\n",
      "Epoch 2076: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7714e-09 - rmse: 8.2288e-05 - val_loss: 9.9650e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2077/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8553e-09 - rmse: 6.9680e-05\n",
      "Epoch 2077: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9909e-09 - rmse: 8.3611e-05 - val_loss: 9.9548e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2078/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7381e-08 - rmse: 1.3184e-04\n",
      "Epoch 2078: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.5731e-09 - rmse: 9.2591e-05 - val_loss: 9.9580e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2079/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.1301e-09 - rmse: 6.4266e-05\n",
      "Epoch 2079: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9620e-09 - rmse: 8.3439e-05 - val_loss: 9.9498e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2080/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6303e-09 - rmse: 6.8046e-05\n",
      "Epoch 2080: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.2699e-09 - rmse: 9.6281e-05 - val_loss: 9.9459e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2081/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.9377e-09 - rmse: 5.4200e-05\n",
      "Epoch 2081: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8609e-09 - rmse: 7.6556e-05 - val_loss: 9.9381e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2082/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1575e-09 - rmse: 4.6449e-05\n",
      "Epoch 2082: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2539e-09 - rmse: 9.0851e-05 - val_loss: 9.9549e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2083/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.6460e-09 - rmse: 5.1439e-05\n",
      "Epoch 2083: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6954e-09 - rmse: 8.1825e-05 - val_loss: 9.9531e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2084/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0634e-08 - rmse: 1.0312e-04\n",
      "Epoch 2084: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.1213e-09 - rmse: 8.4388e-05 - val_loss: 9.9452e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2085/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0534e-09 - rmse: 6.3666e-05\n",
      "Epoch 2085: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.1022e-09 - rmse: 7.8116e-05 - val_loss: 9.9523e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2086/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4680e-09 - rmse: 5.8889e-05\n",
      "Epoch 2086: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0675e-08 - rmse: 1.0332e-04 - val_loss: 9.9528e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2087/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.3974e-09 - rmse: 7.3467e-05\n",
      "Epoch 2087: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.2707e-09 - rmse: 7.9188e-05 - val_loss: 9.9636e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2088/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.8347e-09 - rmse: 6.1925e-05\n",
      "Epoch 2088: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 7.1290e-09 - rmse: 8.4433e-05 - val_loss: 9.9755e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2089/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0594e-09 - rmse: 3.2548e-05\n",
      "Epoch 2089: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.4106e-09 - rmse: 8.0066e-05 - val_loss: 9.9666e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2090/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.0297e-09 - rmse: 5.5042e-05\n",
      "Epoch 2090: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0521e-09 - rmse: 7.7795e-05 - val_loss: 9.9523e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2091/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.1236e-09 - rmse: 4.6082e-05\n",
      "Epoch 2091: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5688e-09 - rmse: 7.4625e-05 - val_loss: 9.9587e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2092/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.3473e-09 - rmse: 6.5934e-05\n",
      "Epoch 2092: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.5462e-09 - rmse: 7.4473e-05 - val_loss: 9.9459e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2093/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4442e-09 - rmse: 3.8003e-05\n",
      "Epoch 2093: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7163e-09 - rmse: 7.5606e-05 - val_loss: 9.9623e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2094/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6270e-09 - rmse: 8.7333e-05\n",
      "Epoch 2094: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4776e-09 - rmse: 8.6473e-05 - val_loss: 9.9706e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2095/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8924e-08 - rmse: 1.3756e-04\n",
      "Epoch 2095: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5098e-09 - rmse: 8.6659e-05 - val_loss: 9.9577e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2096/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.6244e-09 - rmse: 8.7318e-05\n",
      "Epoch 2096: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.8819e-09 - rmse: 8.8780e-05 - val_loss: 9.9533e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2097/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.3454e-09 - rmse: 4.8430e-05\n",
      "Epoch 2097: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.1713e-09 - rmse: 9.0395e-05 - val_loss: 9.9684e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2098/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9251e-08 - rmse: 1.3875e-04\n",
      "Epoch 2098: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.9507e-09 - rmse: 9.4608e-05 - val_loss: 9.9693e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2099/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.3095e-09 - rmse: 9.1156e-05\n",
      "Epoch 2099: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.5971e-09 - rmse: 9.7965e-05 - val_loss: 9.9453e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2100/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.2482e-09 - rmse: 6.5178e-05\n",
      "Epoch 2100: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.0933e-09 - rmse: 9.5359e-05 - val_loss: 9.9494e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2101/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.4841e-08 - rmse: 1.2182e-04\n",
      "Epoch 2101: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.2106e-09 - rmse: 9.0612e-05 - val_loss: 9.9611e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2102/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.7837e-09 - rmse: 6.1512e-05\n",
      "Epoch 2102: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6049e-09 - rmse: 8.1270e-05 - val_loss: 9.9585e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2103/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0997e-08 - rmse: 1.0487e-04\n",
      "Epoch 2103: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.4114e-09 - rmse: 8.6090e-05 - val_loss: 9.9637e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 9.5307e-10 - rmse: 3.0872e-05\n",
      "Epoch 2104: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6950e-09 - rmse: 8.1823e-05 - val_loss: 9.9617e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2105/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.5676e-09 - rmse: 9.2561e-05\n",
      "Epoch 2105: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.5601e-09 - rmse: 8.0994e-05 - val_loss: 9.9333e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2106/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.9890e-09 - rmse: 6.3159e-05\n",
      "Epoch 2106: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.9704e-09 - rmse: 8.3489e-05 - val_loss: 9.9511e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2107/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1041e-08 - rmse: 1.0508e-04\n",
      "Epoch 2107: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.5134e-09 - rmse: 7.4252e-05 - val_loss: 9.9644e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2108/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.8309e-09 - rmse: 4.2789e-05\n",
      "Epoch 2108: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3905e-09 - rmse: 7.3420e-05 - val_loss: 9.9644e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2109/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.4381e-09 - rmse: 5.8636e-05\n",
      "Epoch 2109: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.0469e-09 - rmse: 7.7762e-05 - val_loss: 9.9672e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2110/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1840e-08 - rmse: 1.0881e-04\n",
      "Epoch 2110: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8699e-09 - rmse: 6.9785e-05 - val_loss: 9.9524e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2111/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.2306e-08 - rmse: 1.1093e-04\n",
      "Epoch 2111: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3509e-09 - rmse: 7.3150e-05 - val_loss: 9.9616e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2112/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1826e-09 - rmse: 3.4389e-05\n",
      "Epoch 2112: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1565e-09 - rmse: 7.1809e-05 - val_loss: 9.9534e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2113/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0740e-08 - rmse: 1.0363e-04\n",
      "Epoch 2113: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.2460e-09 - rmse: 7.2429e-05 - val_loss: 9.9503e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2114/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4042e-09 - rmse: 4.9033e-05\n",
      "Epoch 2114: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1362e-09 - rmse: 7.1667e-05 - val_loss: 9.9568e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2115/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6644e-08 - rmse: 1.2901e-04\n",
      "Epoch 2115: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.1200e-09 - rmse: 7.8230e-05 - val_loss: 9.9596e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2116/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.7564e-09 - rmse: 7.5871e-05\n",
      "Epoch 2116: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3940e-09 - rmse: 7.9962e-05 - val_loss: 9.9447e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2117/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9635e-08 - rmse: 1.4013e-04\n",
      "Epoch 2117: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.6292e-09 - rmse: 9.2894e-05 - val_loss: 9.9557e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2118/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0974e-08 - rmse: 1.0475e-04\n",
      "Epoch 2118: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.3184e-09 - rmse: 7.9488e-05 - val_loss: 9.9690e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2119/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.6573e-08 - rmse: 1.2873e-04\n",
      "Epoch 2119: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7300e-09 - rmse: 7.5696e-05 - val_loss: 9.9626e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2120/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.1672e-09 - rmse: 7.1883e-05\n",
      "Epoch 2120: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1505e-09 - rmse: 7.1767e-05 - val_loss: 9.9448e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2121/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7853e-08 - rmse: 1.3362e-04\n",
      "Epoch 2121: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3861e-09 - rmse: 7.3390e-05 - val_loss: 9.9600e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2122/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.9112e-10 - rmse: 2.2161e-05\n",
      "Epoch 2122: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.8244e-09 - rmse: 6.9458e-05 - val_loss: 9.9636e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2123/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0619e-09 - rmse: 3.2586e-05\n",
      "Epoch 2123: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.1692e-09 - rmse: 7.1897e-05 - val_loss: 9.9516e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2124/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7306e-09 - rmse: 6.8780e-05\n",
      "Epoch 2124: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3564e-09 - rmse: 7.9727e-05 - val_loss: 9.9555e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2125/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0131e-08 - rmse: 1.0065e-04\n",
      "Epoch 2125: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9324e-09 - rmse: 7.7022e-05 - val_loss: 9.9790e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2126/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.8289e-09 - rmse: 6.9490e-05\n",
      "Epoch 2126: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.4978e-09 - rmse: 9.2183e-05 - val_loss: 9.9619e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2127/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0245e-08 - rmse: 1.0122e-04\n",
      "Epoch 2127: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.6198e-09 - rmse: 7.4965e-05 - val_loss: 9.9603e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2128/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 5.0008e-09 - rmse: 7.0716e-05\n",
      "Epoch 2128: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4275e-09 - rmse: 7.3671e-05 - val_loss: 9.9554e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2129/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8742e-09 - rmse: 5.3612e-05\n",
      "Epoch 2129: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.9849e-09 - rmse: 7.0604e-05 - val_loss: 9.9414e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2130/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1500e-08 - rmse: 1.0724e-04\n",
      "Epoch 2130: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.6436e-09 - rmse: 8.1508e-05 - val_loss: 9.9499e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0849e-08 - rmse: 1.0416e-04\n",
      "Epoch 2131: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1055e-09 - rmse: 7.1453e-05 - val_loss: 9.9521e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2132/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.1029e-09 - rmse: 5.5704e-05\n",
      "Epoch 2132: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3265e-09 - rmse: 7.9539e-05 - val_loss: 9.9637e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2133/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.3737e-09 - rmse: 3.7063e-05\n",
      "Epoch 2133: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3979e-09 - rmse: 7.3470e-05 - val_loss: 9.9708e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2134/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0874e-09 - rmse: 3.2975e-05\n",
      "Epoch 2134: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.4066e-09 - rmse: 7.3530e-05 - val_loss: 9.9525e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2135/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8805e-09 - rmse: 5.3670e-05\n",
      "Epoch 2135: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7021e-09 - rmse: 7.5512e-05 - val_loss: 9.9748e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2136/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.2551e-09 - rmse: 5.7054e-05\n",
      "Epoch 2136: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.3891e-09 - rmse: 7.3411e-05 - val_loss: 9.9559e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2137/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5080e-09 - rmse: 5.9229e-05\n",
      "Epoch 2137: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.3761e-09 - rmse: 7.3322e-05 - val_loss: 9.9465e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2138/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.4759e-09 - rmse: 4.9759e-05\n",
      "Epoch 2138: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9793e-09 - rmse: 7.7326e-05 - val_loss: 9.9658e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2139/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8339e-09 - rmse: 5.3235e-05\n",
      "Epoch 2139: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.0020e-09 - rmse: 7.0725e-05 - val_loss: 9.9788e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2140/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.9062e-09 - rmse: 4.3660e-05\n",
      "Epoch 2140: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.3744e-09 - rmse: 7.9840e-05 - val_loss: 9.9676e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2141/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.0075e-09 - rmse: 3.1742e-05\n",
      "Epoch 2141: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.8386e-09 - rmse: 7.6411e-05 - val_loss: 9.9591e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2142/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2414e-09 - rmse: 4.7343e-05\n",
      "Epoch 2142: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4139e-09 - rmse: 7.3579e-05 - val_loss: 9.9674e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2143/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.3928e-09 - rmse: 7.9955e-05\n",
      "Epoch 2143: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7546e-09 - rmse: 7.5859e-05 - val_loss: 9.9542e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2144/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.6647e-09 - rmse: 6.8298e-05\n",
      "Epoch 2144: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6059e-09 - rmse: 8.7212e-05 - val_loss: 9.9391e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2145/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.4321e-09 - rmse: 8.6210e-05\n",
      "Epoch 2145: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 8.0066e-09 - rmse: 8.9479e-05 - val_loss: 9.9629e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2146/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.4665e-09 - rmse: 9.7296e-05\n",
      "Epoch 2146: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.7002e-09 - rmse: 9.8490e-05 - val_loss: 9.9624e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2147/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.0069e-09 - rmse: 6.3300e-05\n",
      "Epoch 2147: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.5169e-09 - rmse: 8.6700e-05 - val_loss: 9.9732e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2148/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.7271e-08 - rmse: 1.3142e-04\n",
      "Epoch 2148: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.6505e-09 - rmse: 8.7467e-05 - val_loss: 9.9693e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2149/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 8.1631e-09 - rmse: 9.0350e-05\n",
      "Epoch 2149: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.4181e-09 - rmse: 8.0113e-05 - val_loss: 9.9626e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2150/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.8013e-09 - rmse: 5.2927e-05\n",
      "Epoch 2150: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.7068e-09 - rmse: 8.1895e-05 - val_loss: 9.9619e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2151/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 9.7483e-09 - rmse: 9.8733e-05\n",
      "Epoch 2151: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 7.9383e-09 - rmse: 8.9097e-05 - val_loss: 9.9739e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2152/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 4.7203e-09 - rmse: 6.8704e-05\n",
      "Epoch 2152: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.3576e-09 - rmse: 8.5776e-05 - val_loss: 9.9667e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2153/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 6.8499e-09 - rmse: 8.2764e-05\n",
      "Epoch 2153: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.1418e-09 - rmse: 8.4509e-05 - val_loss: 9.9791e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2154/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 7.2486e-09 - rmse: 8.5139e-05\n",
      "Epoch 2154: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.7202e-09 - rmse: 7.5632e-05 - val_loss: 9.9779e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2155/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 3.5025e-09 - rmse: 5.9182e-05\n",
      "Epoch 2155: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.1680e-09 - rmse: 7.1889e-05 - val_loss: 9.9767e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2156/10000\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 2.2539e-09 - rmse: 4.7475e-05Restoring model weights from the end of the best epoch: 1156.\n",
      "\n",
      "Epoch 2156: val_loss did not improve from 0.00009\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.8018e-09 - rmse: 7.6170e-05 - val_loss: 9.9744e-05 - val_rmse: 0.0100 - lr: 3.1250e-06\n",
      "Epoch 2156: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN, validation_steps=VALIDATION_STEPS,\n",
    "                    epochs=10000, shuffle=True, callbacks=[es, ckpt, rp])\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:02:18.372154\n"
     ]
    }
   ],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fbce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = \"D:\\\\VAWT_data\\\\flap_steady\\\\flap_steady\\\\result\\\\\"+\"20221130MLP_optimalSettings\\\\test\"+str(test_rate)+\"Clonly\"\n",
    "if not os.path.exists(storage_dir):\n",
    "    os.makedirs(storage_dir)\n",
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2, label='Training loss')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation loss')\n",
    "plt.title('Training loss (mean squared error)\\nMLP, optimal settings, $C_l$ only', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"TrainingLoss_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.plot(hist['val_rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error, optimal settings, $C_l$ only', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2, label='Training RMSE')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation RMSE')\n",
    "plt.title('Root Mean Squared Error\\nMLP, optimal settings, $C_l$ only', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"RMSE_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c76ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 6.6312e-07 - rmse: 8.1432e-04\n"
     ]
    }
   ],
   "source": [
    "train_results = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abc70d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 5.3435e-05 - rmse: 0.0073\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "745feda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "decoded_train_ = model.predict(x_train)\n",
    "decoded_val_ = model.predict(x_val)\n",
    "decoded_test_ = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44d47ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = np.unique(np.where(np.isin(cl, y_train)))\n",
    "index_val = np.unique(np.where(np.isin(cl, y_val)))\n",
    "index_test = np.unique(np.where(np.isin(cl, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81909f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "y_val = y_val*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "y_test = y_test*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e9b60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = decoded_train_*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "decoded_val = decoded_val_*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "decoded_test = decoded_test_*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55d01da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20221130\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "os.chdir(model_directory)\n",
    "model_name = \"20221130steadyValidation_MLP_val_\"+str(val_rate)+\"_test\"+str(test_rate)+ \"_\" + str(n_units) +\"units_optimalSettings_Clonly.h5\"\n",
    "model.save(model_name, overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = np.abs(decoded_train - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21721b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_val_abs = np.abs(decoded_val - y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c0dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_abs = np.abs(decoded_test - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e21d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012443460325499286\n"
     ]
    }
   ],
   "source": [
    "l2_error_train = np.sqrt(np.sum((decoded_train - y_train)**2) / np.sum(y_train**2))\n",
    "print(l2_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af2e6524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012824080134894014\n"
     ]
    }
   ],
   "source": [
    "l2_error_val = np.sqrt(np.sum((decoded_val - y_val)**2) / np.sum(y_val**2))\n",
    "print(l2_error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3770434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010934804211194247\n"
     ]
    }
   ],
   "source": [
    "l2_error_test = np.sqrt(np.sum((decoded_test - y_test)**2) / np.sum(y_test**2))\n",
    "print(l2_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(x_train)):\n",
    "    l2_error_train_data = np.sqrt(np.sum((decoded_train[i] - y_train[i])**2) / np.sum((y_train[i]+1e-07)**2))\n",
    "    l2_error_train_list.append(l2_error_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ab3dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val_list = []\n",
    "for i in range(0, len(x_val)):\n",
    "    l2_error_val_data = np.sqrt(np.sum((decoded_val[i] - y_val[i])**2) / np.sum((y_val[i]+1e-07)**2))\n",
    "    l2_error_val_list.append(l2_error_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(x_test)):\n",
    "    l2_error_test_data = np.sqrt(np.sum((decoded_test[i] - y_test[i])**2) / np.sum((y_test[i]+1e-07)**2))\n",
    "    l2_error_test_list.append(l2_error_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd795141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(1,x_train.shape[0],x_train.shape[0]),\n",
    "         l2_error_train*np.ones(x_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, x_train.shape[0], x_train.shape[0]), l2_error_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - MLP, training\\nValidation rate {0}, test rate {1}, optimal settings ($C_l$)'.format(\n",
    "    val_rate, test_rate), fontsize=15\n",
    "         )\n",
    "plt.grid()\n",
    "saveName = \"trainingErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0e07db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(1,x_val.shape[0],x_val.shape[0]),\n",
    "         l2_error_val*np.ones(x_val.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, x_val.shape[0], x_val.shape[0]), l2_error_val_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - MLP, validation\\nValidation rate {0}, test rate {1}, optimal settings ($C_l$)'.format(\n",
    "    val_rate, test_rate), fontsize=15\n",
    "         )\n",
    "plt.grid()\n",
    "saveName = \"validationErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(1,x_test.shape[0],x_test.shape[0]),\n",
    "         l2_error_test*np.ones(x_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, x_test.shape[0], x_test.shape[0]), l2_error_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - MLP, test\\nValidation rate {0}, test rate {1}, optimal settings ($C_l$)'.format(\n",
    "    val_rate, test_rate), fontsize=15\n",
    "         )\n",
    "plt.grid()\n",
    "saveName = \"testErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8978795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "397bb29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  14,  16,  33,  42,  48,  53,  69,  74,  84,  91,  94, 108,\n",
       "       112, 128], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1d9be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "iTrain=[]\n",
    "iVal=[]\n",
    "iTest=[]\n",
    "for i, index in enumerate(index_train):\n",
    "    iTrain.append(y[index])\n",
    "for i, index in enumerate(index_val):\n",
    "    iVal.append(y[index])\n",
    "for j, index in enumerate(index_test):\n",
    "    iTest.append(y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ab1b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iTrain = np.array(iTrain)\n",
    "iVal = np.array(iVal)\n",
    "iTest = np.array(iTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91230484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CL_trainTestSplit_Plot(i, CL, cl, aTrain, aTest, iTrain, iTest):\n",
    "    \n",
    "    #title_0_Cd = 'Gurney flap not attached (NACA0018)\\n$C_D$ prediction, L2 error=%.4f' % l2_error_Cd\n",
    "    title_0_Cl = 'Gurney flap not attached (NACA0018)\\n$C_L$ prediction, L2 error=%.4f' % l2_error_Cl\n",
    "    \n",
    "    #title_n_Cd = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_D$ prediction, L2 error=%.4f'%(l2_error_Cd)\n",
    "    title_n_Cl = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_L$ prediction, L2 error=%.4f'%(l2_error_Cl)\n",
    "    \n",
    "    if i==0:\n",
    "#         title_Cd, title_Cl = title_0_Cd, title_0_Cl\n",
    "#         savename1,savename2 = \"CdComparison_NACA0018.jpg\", \"ClComparison_NACA0018.jpg\"\n",
    "        title_Cl = title_0_Cl\n",
    "        savename2 = \"ClComparison_NACA0018.jpg\"\n",
    "    else:\n",
    "#         title_Cd, title_Cl = title_n_Cd, title_n_Cl\n",
    "        title_Cl = title_n_Cl\n",
    "        savename2 = \"ClComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    \n",
    "    '''# CD graph plot\n",
    "    plt.plot(alpha, CD, 'k-', label='Ground truth')\n",
    "    plt.plot(alpha, cd, 'k--', label='Predicted value')\n",
    "    plt.scatter(aTrain, iTrain*(np.max(cd_orig)-np.max(cd_orig))+np.min(cd_orig), color='b', label='Training set')\n",
    "    plt.scatter(aVal, iVal*(np.max(cd_orig)-np.max(cd_orig))+np.min(cd_orig), color='g', label='Validation set')\n",
    "    plt.scatter(aTest, iTest*(np.max(cd_orig)-np.max(cd_orig))+np.min(cd_orig), color='r', label='Test set')\n",
    "    plt.xlabel('AoA (degree)')\n",
    "    plt.ylabel('$C_D$')\n",
    "    plt.title(title_Cd, fontsize=15)        \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0, 0.12])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()'''\n",
    "\n",
    "   # CL graph plot\n",
    "    plt.plot(alpha, CL, 'k-', label='Ground truth')\n",
    "    plt.plot(alpha, cl, 'k--', label='Predicted value')\n",
    "    plt.scatter(aTrain, iTrain, color='b', label='Training set')\n",
    "    plt.scatter(aVal, iVal, color='g', label='Validation set')\n",
    "    plt.scatter(aTest, iTest, color='r', label='Test set')\n",
    "    plt.xlabel('AoA (degree)')\n",
    "    plt.ylabel('$C_L$')\n",
    "    plt.title(title_Cl, fontsize=15)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0, 2])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename2, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf177275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "NACA0018 airfoil without Gurney flap\n",
      "L2 error of Cl: 0.0171\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0040\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "L2 error of Cl: 0.0017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0034\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0041\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0050\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0076\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0138\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0039\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "L2 error of Cl: 0.0035\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0056\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0040\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "L2 error of Cl: 0.0170\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEwCAYAAACkMUZEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABT0UlEQVR4nO3dd3gUVffA8e8h1NBBQAElqCCd0HsTacKrFBEwKlH5Ib4qlteCYgFfUV7FLoKgiCUKiqJIsVEEBBVQujSBaABBkZIQCCQ5vz9mEpdlk+ym7CZwPs+zT7J37tw5O5vs2bkzc6+oKsYYY0xWCoU6AGOMMQWDJQxjjDF+sYRhjDHGL5YwjDHG+MUShjHGGL9YwjDGGOMXSxjGGGP8YgnDGGOMXyxhBImI9BWRr0TkoIicFJE9IjJDRNqFOrbcJCKPua8tVUSmu4/VoY7Lk4hcKyLR/pbn4nbzbF+ISAMRURHpHMIY6onIQhFJFJG9IvKEiITldD0RuUZEVrj/OydEZKuIPCIiRXMYb0MRme+2e1BEZotI5Ry22VdE1otIkojsEpF7fdTJ1n7KDyxhBIGIvAB8DOwBhgFXAKOA0sByEbkkhOHlGhFpDowFXgXaAf8NbUQZuhaIDqDcZEFEygPfAApcDTwB/Afn7yGn61UEFuP87/QCpgGjgedzEG81t00FooDbgI7APTlosx3wCfAj8C83zv+JyN0edbK1n/KLwqEO4GwnIlcDdwM3qep0r8Xvisi/gOM53EYYEKaqJ3PSTi6o4/6cqKpHAUQkhOGYIBoBlAD6u+/91yJSBhgjIs+k/T1kZz1Vfd1rncVundtF5E7N3vhGI4Gj7naTAETkZpwvcdn1GLBcVYe5z79yE8RjIvKa+/+Z3f2UL9gRRt67G1jlI1kAoKqfq+peABFZIiKzPJeLSGe3q6GBR9l0EVntHv5uAk4ArTzKu7mHxcdEZLmI1Pdqs72IfOseEh8UkakiUtpjeW+3S6mm13o13fKrvF+HiEwH3nWfHsmse0RE2ojIHPdw/JiIrBWRKO/2PF7jFrcrYrmI1PPVpr9tu3EOADq5MaqIjMmo3N943XodRWSxiCSIyBH3/Wzio16O3h+3zr9F5He3jc+BCzLbL4HGkA29gC+9PvBm4Hw4dsqD9Q4COemS6g3M9kgW5YH2wKoctBmJc/Tg6SugPNDGfZ7d15svWMLIQyJSGOcP5as8aD4CeAZ4GrgS2OWWXwQ8C4wDhgCVgQ/F/arvHjYvBP4ArsFJaFcCb3m0/QWwFxjqtc1o4E9gvo94/gs86f5+Oc7r/imD2GsA3+F0MfwLp7vuLREZ4qPe827b1wFlgS9FpHgG7frT9n9xuiJ+dmNsA7yRSblf8brJcSFwCme/DQKWAdW84svx++MetU4E5gL9gQ043R/+yioGEZHCWT282qwDbPEsUNXfgET+OfL0xe/1RCRMRMJFpD3OEcKk7BxdiEhJoC6wSkRKi0gHnL/5OGCmWyc7+6A44H2Un+T+rBvo682XVNUeefQAquD0Vd7qVS443YFpD3HLlwCzvOp2dtto4FE23S2L9Ko7HUgGanmU9XXr1nGfLwMWe613uY9tPImThMQj5t3AhExeb7TbTimvmFZnsk7avngdWOTjNbb1KKvhvr4Rfu7/jNqeBSzxUd9nuZ9trgRWp+2vDNbNlfcHp498gVedqW6dzlnE708Mae9jpg+vdk8Bd/vYXhzwVCbx+L0ezpF02vbfBgpl8/+yjdvGZcDf7u8ngNY+/pYD2QdrgI+9yh506z6ck/2UXx52hJG30jrwvb8F/QfnDyftcXs22t6jqmt9lO9W1e0ezze7P6uLSDjOP8uHXt+SlrtxNPNYbxrOB3Rn93kX97nnkUi2iEh5EXlZRGL5Zx8MB2p7VT2gqivSnqhqLM4/ZctcaDvX4nW/sbYC3lb3vz8TOXp/xDlf1QT4zKvdTwJ4SRnG4P78HGjhx8Obr9cuGZRnZ722QAec/5+rcS6uyI5IIAHYiXMUNwLny9E8ETnfrZOdfTAZuFpE/s/9m+nhxgqQ4lEvu/sp5Oykd976C+eQtLpX+bs4RxOQ/T7T/RmUH/Z6nnaIXBynLzUMeM19eLsw7RdV3SkiS4CbcLpqbgJ+VNVN2YzX03SgNU430Gack4+34XwIeDrgY90DZN5f72/buRlveZx/+H1+tHXY63mg708lnP9b733ja19lJwZwvnUfCaA9gENAOR/lZX1sL1vrqWpaF+dyEfkLeFtEnlPVXwOMtQmwTlVPAYuARSKyCNiGcx5hJtnbB9OAxsAkYApON9ODwCv88/+a3f2UL1jCyEOqmiwiK4HuOFdQpJXvx/0DktOvIjrBmSfyKmTUfDZCOuyuNwbf5yH2ej1/A5gqIg/h9JX/58xVAuOef+gN3KGqkz3KfR3t+romvjLgM2kF2HZuxnsISCXAE88+HCbr9+dPnC4l732To/sHvAzFvyNJzz/eLZx5zuFCoCReffZesrteWvKoCQSaMCKBH7zKTrg/0z7YA94HqpoC3CEij+J8SdzFP6/te/dndl9vvmAJI++9CHwqIjeo6rtZ1I3DuRbcU7fcCkRVj4nI98BlqvqEH6t8gnNydQbOBRIzciGMYjjfotNOBuJeAXQVZybByiLSNq1bSkQuApqS8T+yv22f5J9v02RRnmWb7n79AbhRRF71o1vKJ3/fHxFZi3N0M9mjuH92tpmBtO6YQCwA7heR0qoa75YNwrlk/Ns8WC/thtddgQTpduk1wHmNnqJwjiqWu8+zsw8AUNVDOF8iEJF/AytUNS0ZZPf15guWMPKYqn4mIi8C00WkC84f4l84NyOlJYME9+ds4BZxbvSbh3PeoEcuh/QAsFBEUnFO8sbjXDXTGxitqts8Yj8hIjE451g+UNXDOd24qh4RkVU416YfxflmPgrn8L+MV/W/cO5VeRTnH+oJnK6X6TlsewtOX3NfnCS9V51Lm32W+9nmKJxLKheIyBTgGM75iNWqOjeAXeTP+/MU8ImITML5m+kE9AxgG5lS1YM4l60GYjLOlUufiMj/gItxjpSe13/uybkRp9vmEvd8lL/rfYGzbzfhnAtoh3O0O9OzO8q9Um0x0EVVl2QQZx2cS1gfEJGDwC84l9OOBm5T1eTs7gMRae22tRbnb2MIzv9v+0D2U74W6rPu58oD6Ad8jfMt5hRO98LHQC+veg8Bv+N8ULzHP99kva+SOuPKI1/lOJffKtDHo6wVzmWER3E+2DbjXL5a1kebV7jrX+HHa4zGj6ukgEtx+o6PAb/hfEiOAf7yXg/nm/M2nG/433nuhwxi8Kft83A+aNOukBmTRXmWbbr1OgFLcfquD+N8eEXmxfsD3IGT1BJxuq+64/9VUlnGkM2/8XrufjqOcz7nvzg3lHr/fUQEuN5/gY04X6wO43RH3QkU8WrnSrf9epnEGIVzJPmOu3+P4HQXDciF//FmOOckE9y25wENA91P+fmRdsmkMT6JyDM4h8w1VTU1iNudjpMcmgdrm6ZgE5GxQEdV7ZJJnWeB7qraOHiRnT2sS8r4JCKX4XwTug0YG8xkYUw2tSXr8aWa4NycabLBEobJyOs4XSNzgJdDHIsxWVJVfy4QaYxzh7zJBuuSMsYY4xe709sYY4xfLGEYY4zxiyUMY4wxfrGEYYwxxi+WMIwxxvjFEoYxxhi/WMIooESkiIjcIyI/ijMd6HERWeOW5WTqyqARkQbiMZWruNOyBtjGtSIS7aM84LZykzjTvv6VRZ2B4kz9ukecaV3XyJmzDp61RKSeiCwUZyravSLyhDs4YI7XFZFLReR1EVknIinuUP2+2lki/0zJ6/1o4+/2zhV2414BJM78w98Al+CMtZ82dHovYDywB/gwNNHlyH9xBoYLxLU4Y0BNz4W2gu1enNFW78EZaPFK4H0ROU9VXwlpZHnM4294M87Iu5cAz+F8iX0kF9atj7M/vyfzub//zZmDXj6Bc0f4qpzGetYJ9WBW9gjsgTP+/mKcQcvq+FjeHGfcp2DEEgYUzcH6DfBjwLws2shyWtUQvU9j8Bqc0Eed83yUvQ/sCtZ7lQvvYbbWxxlk8xBQxqPsAZzBFMvkdF08pm8N5G8EJ7n8jTNfeI5jPdse1iVV8AzFmTZ1hP4zxn46VV2tqoHOETBdRFaLSF8R2SIiJ0RkuYjUy6TeJpxJZ1q5y9qLyLfuIftBEZnqzhvhuf6/ReR3ETkmIp/jNeFQRt1IItJRRBa73TZH3G6EJu4AhQOATh7dCGMyasvtvtogIkluHOPEmQLV+/V1E5H1bpzLRaR+IPvTX6rqq8vqZ/yYDCmr/Z3Re5XFe5jp/sms3Wy8/F7Al3r6kN4zcI4KO+V0Xc3+2Gc9cWY+/CCXYj2rWMIoeO4FflFV7zmdc6oGzsBt/wWuw5ky8ktxZpzzFAE8AzyNc8i/S0TaAQuBP3DmSL7bXZY+0ZGIXI0zGdNcnCHLN+DMjZApcc5vLMQZEn4ozsi5y4BqbqyLcT5k27iPNzJopzvO1Js/4XQrvALcx5nzQl8EPAuMw5nPoDLOHNtCcLTlnzm2ffJnf7si8HqvMioPYP9ktL6IxzzkGT082qiD1wxzqvobzrf202ak8yEn62ZlME6X7rIgba9AsXMYBYiI1AAakjf9pucBV+s/s9utwZn6MprTZ3ariDM3xlqPuD7AmVVskEfZHpyJgBqo6kacCWq+UNXb3CpfikglYFgWcT0NrAN6qNsXgDNXRNp2/sbpfvje18oensDplhia1oabA54WkSdVNc4trwC0U9XtbvuFcObIuIw8nkJTRLrifFjfnEXV8WS9v8H3e5VReVq3TVb7J6P1owlsStPy+J7D+pC7LDM5WTfjwETCgX8BUzz+1vJsewWRHWEULA3dnxszrQWIyDUisiCAtg+kJQsAdWZEWwO09Kq3x+uDIhznm/2HXt8kl+McFTQT52qSJoD3UdEnWbyGkjjdHW97/QMHxN1+U+Ajr0Uzcf4H2niU7U5LFq60b/vVs7t9f4hIBM75i89UdXom9bLc3x7VT3uvMioPcP9k1G7alKZZPTz5ek8lg3JvOVk3I/8CSnF6d1Rebq/AsSOMgqWs+3N/prUckTjfzP11IIOyC7zKvLddHufE52vuw9uFQCWcvzXvbfjapnfbgnOCPyfOA4pwZuxpzyt4lB32qnPS/elrDvBcISIVcOZ6/g24Povq/uzvNBn9nXiXB7J/Mmr3b5zZ6/x1CCjno7wsvr/N59a6mRkM7FBV7/NoebW9AscSRsGS9gFb1Y+6jXG+sfrL14nWyjjzKHvy/kZ12C0bgzNVqLe9wJ9Aso9tZHVy9xDOHNreSStQf+F8+/beXhX35985bD/b3COGuThX5/RW1WNZrHKYrPd3moy+/XqXB7p/fLU7lMC6pLbg1f8vIhcCJcm66y8n6/oOSqQszsntZ4KxvYLKuqQKlpU4cwXf5GuhiHhONh9JYEcYlUWkrUdbF+F0U/yY2UruB9z3wGXuFVrej72qmgKsxemf99Tfj7Z/AG7M5KTzSbL49u9ufw0w0GvRtTgJaWVm6+cVtyvpI6AWztzuWR1x+bW/A40jl/ZPoF1SC4AeXlfSDcKZ5/rbLLaVk3Uz0g8ohu/uqLzYXoFkRxgFiKomiMiDwCQR+Qx4F+fb+yU4/+xlgHZuF8d5wNYAmv8LeFdEHsX5R3gC54hmuh/rPoBzwjUV55r3eJyrjXoDo1V1G/AU8ImITMI5idwJ5xLGrIzCuWlqgYhMAY7h9KmvVtW5ON/wrhaRvkAcsDeDD83HcU60v4VzSWRDnKuspnqd0M2Se+XWYqCLqi7JpGpREbnGR/m3qvonTpfSlcBdQAURae1R52dVTcqgXX/2d6BytH9U9SBwMIDtTQZG4vxN/A+4GOeo6XnPy1dF5Eacq+kucc+r+bWue+R2pVu/GlDG472Yr6qJXvEMBtap6i/ZjfWcEOobQewR+APnm/oyIMF9bMb5o27pLr8c5wPV3/amA6txvvFvA5KA74AGvupl0EYrnKuXjuJ8qG/GuUy3rEedO3A+1BNxulO643HjXkbt4ySXpe56h3E+rCPdZefhJKC/3bbGZNQWzrfCDThHJXE4l84Wzuz14VxCqkAfj7Ir3bJ6mezTMW4dX4+017s7kzoRWbxnme7vTPZlZu9hpvsnq/Wz8XdcD1iE8wVlH06CCvOqE+1rf2S1rsf7luW+df+GTgGjchLrufCwKVrPQiJyD86H/S1+1p/u1m+ep4GdJURkLNBRVbuEOhZjgsnOYZydGgMDRGS3x+PCLNcy/mqL823emHNK0BKGiFwozvAOv4jIJhG5y0cdEZGXRWSHOEMzNPVY1lNEtrrLRgUr7oJIVaNVtZyqRng8fg91XGcLVe2mqp+HOg5jgi1oXVIicgFwgar+5F5tsAboq6qbPepcCdyJ00fcCnhJVVu5NxZtA7rh9K2uAoZ4rmuMMSZvBe0IQ1X3qepP7u/xwC84Vy94uhp4Rx3fA+XcRNMS54aanap6EucqDu9LNI0xxuShkFxW6w6D0ATnGntP1QDPrpM4t8xX+RkjZIrIcGA4QIkSJZpdeGH2u+1TU1MpVCj/neKxuAJjcQXG4grM2RjXtm3b/lLVSj4XBvuyLJyxWtYA/X0smwe093i+EGdsnIHAGx7lNwCvZLadZs2aaU4sXrw4R+vnFYsrMBZXYCyuwJyNcZHJZdNBPcIQkSLAx0CMqvoaeC6O08fCqY4z1EHRDMqNMcYESTCvkhLgTZy5HDK6JHEO7jAQ7l2vR1R1H85J7loiUlOc+aoHu3WNMcYESTCPMNrhdCVtEJG1btnDOEMaoKqTce7+vRLYgXNX703usmQRuQP4Emekzmmq6j0onjHGmDwUtIShqsv5Z6TKjOoocHsGy+bje3ROv506dYq4uDhOnDiRZd2yZcvyyy++hpUJrXM9ruLFi1O9enWKFCmS59syxpzunBp8MC4ujtKlSxMREZE281iG4uPjKV26dKZ1QuFcjktVOXjwIHFxcdSsWTNPt2WMOVP+ux4sD504cYKKFStmmSxM/iQiVKxY0a8jRGNM7junEgZgyaKAs/fPmNA55xKGMcaY7LGEEWT79+/nuuuu4+KLL6ZZs2a0adOG2bNnBzWG3bt306BBA5/l778fyKyu/5g4cSKJif/MSVOqVKlsx2eMyZ8sYQSRqtK3b186duzIzp07WbNmDTNmzCAu7swJzZKTk4MeX2YJI6t4Jk2adFrCMMacfc6pq6RCbdGiRRQtWpQRI0akl9WoUYM777wTgOnTpzNv3jxOnDjBsWPHmDVrFjfffDM7d+4kPDycKVOmULNmTcaMGUOpUqW47777AGjQoAFz584FoFevXrRv354VK1ZQrVo1PvvsM0qUKMGaNWu4+eabCQ8Pp3379mcGB4waNYpffvmFyMhIhg4dSvny5U+L57HHHmPChAnp27rjjjto3rw5R48eZd++fXTp0oXzzjuPxYsXAzB69Gjmzp1LiRIl+Oyzz6hSpUqe7VtjTN47ZxPG3Xffzdq1azNcnpKSQlhYWEBtRkZG8uKLL2a4fNOmTTRt2jTD5QArV65k/fr1VKhQgTvvvJMmTZrw6aefsmjRIm688UaWLVuW6frbt2/ngw8+YOrUqVx77bV8/PHHXH/99dx000288sordOrUifvvv9/nuuPHjz8tIUyfPv20eJYsWeJzvZEjR/Lcc8+xePFizjvvPACOHTtG69atGTduHA888ABTp07lkUceyTR2Y0z+Zl1SIXT77bfTuHFjWrRokV7WrVs3KlSoAMDy5cu54YYbALj88ss5ePAgR44cybTNmjVrEhkZCUCzZs3YvXs3R44c4fDhw3Tq1AkgvU1/eMYTiKJFi9KnT5/T4jDGFGzn7BFGZkcCkDc3otWvX5+PP/44/fnEiRP566+/aN78n6m0S5Ysmf67+pjcSkQoXLgwqamp6WWe9yUUK1Ys/fewsDCOHz/uTN6ezctRPePJbLveihQpkr7NsLCwkJyTMcbkLjvCCKLLL7+cEydOMGnSpPSyzE4Ud+zYkZiYGACWLFnCeeedR5kyZYiIiOCnn34C4KeffmLXrl2ZbrdcuXKULVuW5cuXA6S36a106dLEx8dn2E6NGjXYvHkzSUlJHDlyhIULF6YvK1WqVKbrGmMKvnP2CCMURIRPP/2Ue+65h2eeeYZKlSpRsmRJ/ve///msP2bMGG666SYaNWpEeHg4b7/9NgADBgzgnXfeITIykhYtWlC7du0st/3WW2+ln/Tu0aOHzzqNGjWicOHCNG7cmOjoaMqXL3/a8gsvvJBrr72WRo0aUatWLZo0aZK+LDo6ml69enHBBRekn/Q2xpxlMpooo6A/fE2gtHnzZr8nETl69KjfdYPJ4grsfTwbJ7jJSxZXYM7GuMhkAiXrkjLGGOMXSxjGGGP8YgnDGGOMXyxhGGOM8YslDGOMMX4J2mW1IjIN6AMcUNUzhkoVkfuBKI+46gKVVPVvEdkNxAMpQLKqNvde3xhjTN4K5hHGdKBnRgtV9VlVjVTVSOAh4FtV/dujShd3eYFOFmFhYURGRtKgQQMGDhyYoxFeo6OjmTVrFgDDhg1j8+bNGdZdsmQJK1asCHgbERER/PXXX9mOMbfbMcaETtAShqouBf7OsqJjCPBBHoYTMiVKlGDt2rVs3LiRokWLMnny5NOWp6SkZKvdN954g3r16mW4PLsJwxhj0uS7cxgiEo5zJPKxR7ECX4nIGhEZHprIcl+HDh3YsWMHS5YsoUuXLlx33XU0bNiQlJQU7r//flq0aEGjRo14/fXXAecmy//85z/Uq1eP3r17c+DAgfS2OnfuzOrVqwH44osvaNq0KY0bN6Zr167s3r2byZMn88ILLxAZGcmyZcv4888/GTBgAC1atKBFixZ89913ABw8eJDu3bvTpEkTbr31Vp/jWU2aNIkHHngg/fn06dPTh1rv27cvzZo1o379+kyZMuWMdb0nb5owYQJjxowB4Ndff6Vnz540a9aMDh06sGXLlhzuYWNMbsqPQ4P8C/jOqzuqnaruFZHKwNcissU9YjmNm0yGA1SpUuWM4bjLli172nhHV1555Rkb79evH//3f/9HfHy8z+VRUVFERUVx8ODBM0Z9nT9/vl8vMD4+nuTkZD7//HOuuOIKEhMT+fHHH/n++++JiIhg4sSJFC9enEWLFpGUlET37t1p27Yt69evZ/v27axYsYIDBw7QsmVLhgwZQnx8PCkpKRw7doxdu3YxbNgwFixYQEREBH///TcVKlTgpptuolSpUowcORKAm2++mVtvvZU2bdrw+++/069fP1avXs3o0aNp0aIFo0aN4osvvmDKlCkkJCScNqhhz5496dq1K48++ijgjE117733Eh8fz0svvUSFChU4fvw4nTt3pnv37lSsWBFVJSEhgYSEBFJTU9Pfh6SkJJKSkoiPj+eWW27hhRde4NJLL2XVqlXceuut6UOtezpx4kSGQ617S0hI8LtuMFlcgbG4ApNXceXHhDEYr+4oVd3r/jwgIrOBlsAZCUNVpwBTAJo3b66dO3c+bfkvv/xy2gi0vua7KF68OKVLlyYxMTHT5UlJSWcs92d02+PHj9OhQwfAOcK4/fbbWbFiBS1btqRhw4YALF26lPXr1/P5558DcOTIEfbt28eqVasYOHAg5cqVo1y5clx++eWUKFGC0qVLExYWRsmSJdm4cSOdOnVKbystpmLFilGsWLH0599++y3bt29PjyshIQGA77//nk8++YTSpUszcOBAypcvT6lSpU57baVLl+bSSy9l06ZN1KpVi19//ZV27dpRunRpnnvuufQpZ/fs2cMff/xBREQEIpI+bWuhQoVOi+vUqVOICD/88AM33XRT+naSkpJ87tPixYufNo5VZpYsWYL330F+YHEFxuIKTF7Fla8ShoiUBToB13uUlQQKqWq8+3t34Inc2F5mGTg8PDzT5eedd162MnjaOQxv3sOav/LKK2cMEjh//vwshylXP4cyT01NZeXKlZQoUeKMZf6sP2jQID788EPq1KlDv379EBGWLFnCN998w8qVKwkPD6dz585nDIGe0RDpqamplCtXLtNJrYwxoRW0cxgi8gGwErhMROJE5BYRGSEiIzyq9QO+UtVjHmVVgOUisg74EZinql8EK+5Q6NGjB5MmTeLUqVMAbNu2jWPHjtGxY0dmzZpFSkoK+/bt8zkqbJs2bfj222/Thzz/+2+nZ8976PLu3bvz6quvpj9P+6D2HFJ9wYIFHDp0yGeM/fv359NPP+WDDz5g0KBBgHMkVL58ecLDw9myZQvff//9GetVqVKFAwcOcPDgQZKSktK7nMqUKUPNmjX56KOPACfxrVu3zv+dZozJc0E7wlDVIX7UmY5z+a1n2U6gcd5ElT8NGzaM3bt307RpU1SVSpUq8emnn9KvXz+++OILGjZsSO3atdNn0PNUqVIlpkyZQv/+/UlNTaVy5cp8/fXX/Otf/+Kaa67hs88+45VXXuHll1/m9ttvp1GjRiQnJ9OxY0cmT57M448/zpAhQ2jatCmdOnXioosu8hlj+fLlqVevHps3b6Zly5bEx8fTs2dPJk+eTKNGjbjsssto3br1GesVKVKExx57jFatWlGzZk3q1KmTviwmJobbbruNJ598klOnTjF48GAaNz6n3npj8reMhrEt6A8b3jy4bHjzwFhcgbG4AmPDmxtjjAkpSxjGGGP8YgnDGGOMXyxhGGOM8YslDGOMMX6xhGGMMcYvljCC6ODBg0RGRhIZGcn5559PtWrV0p+fPHky03VXr16dPg5UZtq2bZtb4QZkwoQJIdmuMSZ48tXQIGe7ihUrpt9RPWbMGEqVKpU+yitAcnIyhQv7fkuaN29O8+bNT7tb25dQDWH+3HPPMXbs2JBs2xgTHHaEkYmYGIiIgEKFnJ/uiBm5Kjo6mnvvvZcuXbrw4IMP8uOPP9K2bVuaNGlC27Zt2bp1K+CMe9WnTx/ASTY333wznTt35uKLL+bll19Oby9tgL+0wceuueYa6tSpQ1RUVPpQ5fPnz6dOnTq0b9+ekSNHprfradOmTbRs2ZLIyEgaNWqUPlDhe++9l15+6623kpKSwqhRozh+/DiRkZFERUWd0ZYx5uxgRxgZ+PDDwowcCWkT4sXGwnB3Jo7c/kzctm0b33zzDWFhYRw9epSlS5dSuHBhvvnmGx5++GE+/vjjM9bZsmULixcvJj4+nssuu4zbbruNIkWKnFbn559/ZtOmTVStWpV27drx3Xff0bx5c2699VaWLl1KzZo1GTLE94gtkydP5q677iIqKoqTJ0+SkpLCL7/8wsyZM/nuu+8oUqQI//73v4mJiWH8+PG8+uqrNnCgMWc5SxgZGDu2GN6zpyYmwujRuZ8wBg4cmD5U+pEjRxg6dCjbt29HRNIHIPTWu3fv9CHLK1euzP79+6levfppdVq2bJleFhkZye7duylVqhQXX3wxNWvWBGDIkCE+Jzpq06YN48aNIy4ujv79+1OrVi0WLlzImjVraNGiBeAM1V65cuVc2w/GmPzNEkYG4uJ8D/H922+5vy3Poc0fffRRunTpwuzZs9m9e3eGY9p7TmgUFhZGcnKyX3XSuqWyct1119GqVSvmzZtHjx49eOONN1BVhg4dytNPP+3nKzPGnE3sHEYGqlf3/cGaweCtuebIkSNUq1YNcKY+zW116tRh586d7N69G4CZM2f6rLdz504uvvhiRo4cyVVXXcX69evp2rUrs2bNSp8a9u+//yY2NhZwRqHN6GjIGHN2sISRgccfTyI8/PSy8HAYNy5vt/vAAw/w0EMP0a5dO1JSUnK9/RIlSvDaa6/Rs2dP2rdvT5UqVShbtuwZ9WbOnEmDBg2IjIxky5Yt3HjjjdSrV48nn3yS7t2706hRI7p168a+ffsA5+R9o0aN7KS3MWezjIaxLeiP3Bje/L33VGvUUBVxfr73nt+r55ncGEY8Pj5eVVVTU1P1tttu0+effz7Hbdrw5oGxuAJjcQXGhjcPgago2L0bUlOdn2fLl+epU6cSGRlJ/fr1OXLkCLfeemuoQzLGFAB20vscdM8993DPPfeEOgxjTAETzDm9p4nIARHZmMHyziJyRETWuo/HPJb1FJGtIrJDREYFK2ZjjDH/CGaX1HSgZxZ1lqlqpPt4AkBEwoCJQC+gHjBEROrlaaTGGGPOELSEoapLgb+zsWpLYIeq7lTVk8AM4OpcDc4YY0yW8ttJ7zYisk5EFohIfbesGvC7R504t8wYY0wQ5aeT3j8BNVQ1QUSuBD4FagG+brn2eVediAwHhgNUqVKFJUuWnLa8bNmyWY72miYlJcXvuv668soruffee7niiivSyyZOnMiOHTt44YUXMlznySefpGnTpgwYMICpU6eeUeepp56iVKlSmQ5/PnfuXC699FLq1KkDwJNPPkm7du3o0qVLDl+Vw9/9NWHChNNG6M2OEydOnPHeZiQhIcHvusFkcQXG4gpMnsWV0fW2efEAIoCNftbdDZwHtAG+9Ch/CHgoq/Vz4z6M3DZ58mSNjo4+raxVq1a6dOnSDNfp1KmTrlq1KtO4Hn/8cX322Wcz3fbQoUP1o48+CjBi//m7v0qWLJnjbdl9GHnH4grM2RgXBeE+DBE5X0TE/b0lTnfZQWAVUEtEaopIUWAwMCcYMcVsiCHixQgKjS1ExIsRxGzI2fjm11xzDXPnziUpKQmA3bt3s3fvXtq3b89tt91G8+bNqV+/Po8//rjP9SMiIjh48CAA48aN47LLLuOKK65IHwIdnHssWrRoQePGjRkwYACJiYmsWLGCOXPmcP/99xMZGcmvv/5KdHQ0s2bNAmDhwoU0adKEhg0bcvPNN6fHFxERweOPP07Tpk1p2LAhW7ZsOSOmtGHQ27VrZ8OgG3OWC+ZltR8AK4HLRCRORG4RkREiMsKtcg2wUUTWAS8Dg92ElwzcAXwJ/AJ8qKqb8jreD3/5kOGfDyf2SCyKEnskluGfD89R0qhYsSItW7bkiy++AGDGjBkMGjQIEWHcuHGsXr2a9evX8+2337J+/foM21mzZg0zZszg559/5pNPPmHVqlXpy/r378+qVatYt24ddevW5c0336Rt27ZcddVVPPvss6xdu5ZLLrkkvf6JEyeIjo5m5syZbNiwgeTkZCZNmpS+/LzzzuOnn37itttu8zmrXtow6N999x2rV6+mevXqpw2DvnbtWsLCwtKHQS9RogRr164lJi8mFzHG5KlgXiU1RFUvUNUiqlpdVd9U1cmqOtld/qqq1lfVxqraWlVXeKw7X1Vrq+olqprHozk5xi4fS+Kp08c3TzyVyOiFo3PU7pAhQ5gxYwbgJIy0+Sg+/PBDmjZtSpMmTdi0aRObN2/OsI1ly5bRr18/wsPDKVOmDFdddVX6so0bN9KhQwcaNmxITEwMmzZlnlu3bt1KzZo1qV27NgBDhw5l6dKl6cv79+8PQLNmzdIHLPTUpk0bnnrqKV544QViY2MpUaLEacOgR0ZGsnDhQnbu3OnfDjLG5Fv56aR3vhIXH+ez/LcjORvfvG/fvtx777389NNPHD9+nKZNm7Jr1y4mTJjAqlWrKF++PNHR0Zw4cSLTdtzeuzNER0fz6aef0rhxY6ZPn57liS/NYrjztCHSMxpCPW0Y9I8//tiGQTfmLJdvzmHkN9VLV/dZflHZnI1vXqpUKTp37szNN9+cfnRx9OhRSpYsSdmyZdm/fz8LFizItI2OHTsye/Zsjh8/Tnx8PJ9//nn6svj4eC644AJOnTp1WrdP6dKlfV7FVKdOHXbv3s2OHTsAePfdd+nUqZPfrydtGPTbbrvNhkE35ixnCSMDj7d/nPAip49vHl4knHFdc94jNmTIENatW8fgwYMBaNy4MU2aNKF+/frcfPPNtGvXLtP1mzZtyqBBg4iMjGTAgAF06NAhfdl///tfWrVqRbdu3dIvoQUYPHgwzz77LE2aNOHXX39NLy9evDhvvfUWAwcOpGHDhhQqVIgRI0bgr7Rh0Nu1a+fXMOjDhw+3YdCNKagyunyqoD9yZXjz9e9pjRdqqIwRrfFCDX1vfejHNw/mMOKBsOHNA2NxBcbiCkxeXVZr5zAyEdUwiqiG9k3YGGPAuqSMMcb4yRKGMcYYv1jCMMYY4xdLGMYYY/xiCcMYY4xfLGEE0cGDB4mMjCQyMpLzzz+fatWqpT8/efJklusvWbKEH374IcdxHD58mNdeey3H7Rhjzi2WMIKoYsWKrF27lrVr1zJixAjuueee9OdFixbNcn1LGMaYULKEkZmYGIiIgEKFnJ95MMLqmjVr6NSpE82aNaNHjx7pd0S//PLL1KtXj0aNGjF48GB2797N5MmTmThxIpGRkSxbtuy0dr799tv0o5UmTZqkDwPy7LPP0qJFCxo1apQ+bPqoUaP49ddfiYyM5P7778/112SMOTvZjXsZKPzhhzByJCS6I9bGxsLw4c7vuTSshapy55138tlnn1GpUiVmzpzJ6NGjmTZtGuPHj2fXrl0UK1aMw4cPU65cOUaMGEGRIkUYPfrMEXMnTJjAxIkTadeuHQkJCRQvXpyvvvqK7du38+OPP6KqXHXVVSxdupTx48ezceNG1q5dmyuvwxhzbrCEkYFiY8f+kyzSJCbC6NG5ljCSkpLYuHEj3bp1A5xpTi+44AKA9PGW+vbtS9++fbNsq127dtx7771ERUXRv39/qlevzldffcVXX31FkyZNAGfaxu3bt3PRRTkbQNEYc26yhJEBifM9vDm/5Wx4c0+qSv369Vm5cuUZy+bNm8fSpUuZM2cO//3vf7Oc12LUqFH07t2b+fPn07p1a7755htUlYceeohbb731tLq+5rUwxpis2DmMDGh138Obk4vfzosVK8aff/6ZnjBOnTrFpk2bSE1N5ffff6dLly4888wzHD58mISEhAyHKAf49ddfadiwIQ8++CDNmzdny5Yt9OjRg2nTppGQkADAnj17OHDgQKbtGGNMRixhZCDp8cch/PThzQkPh3G5N+FfoUKFmDVrFg8++CCNGzcmMjKSFStWkJKSwvXXX0/Dhg1p0qQJ99xzD+XKleNf//oXc+fO9XnS+8UXX6RBgwY0btyYEiVK0KtXL7p37851111HmzZtaNiwIddccw3x8fFUrFiRdu3a0aBBAzvpbYzxm3VJZSD52muheHHnnMVvvzlHFuPG5dr5izFjxqT/7jklaprly5efUVa7dm1WrlxJ6dKlz1j2yiuv+NzOXXfdxV133XVG+fvvvx9AtMYYE8SEISLTgD7AAVVt4GN5FPCg+zQBuE1V17nLdgPxQAqQrKrNgxJ0VFSuJQhjjCnogtklNR3omcnyXUAnVW0E/BeY4rW8i6pGBi1ZGGOMOU3QEoaqLgX+zmT5ClU95D79HsjgrHOO48iLZk2Q2PtnTOhIMP8BRSQCmOurS8qr3n1AHVUd5j7fBRwCFHhdVb2PPtLWGw4MB6hSpUqzGTNmnLa8VKlSVKlShbJlyyIimcaakpJCWFiYX68rmM7luFSVI0eOsH///vQrv7KSkJBAqVKl8jSu7LC4AmNxBSYncXXp0mVNRj05+S5hiEgX4DWgvaoedMuqqupeEakMfA3c6R6xZKh58+a6evXq08pOnTpFXFwcJ06cyDLWEydOULx48SzrBdu5Hlfx4sWpXr06RYoU8av+kiVL6Ny5c94GlQ0WV2AsrsDkJC4RyTBh5KurpESkEfAG0CstWQCo6l735wERmQ20BDJNGL4UKVKEmjVr+lV3yZIl6XdI5ycWlzEmVPLNfRgichHwCXCDqm7zKC8pIqXTfge6AxtDE6Uxxpy7gnlZ7QdAZ+A8EYkDHgeKAKjqZOAxoCLwmnt+Ie3y2SrAbLesMPC+qn4RrLiNMcY4gpYwVHVIFsuHAcN8lO8EGudVXMYYY/yTb7qkjDHG5G+WMIwxxvjFEoYxxhi/WMIwxhjjF0sYxhhj/GIJwxhjjF8sYRhjjPGLJQxjjDF+sYRhjDHGL5YwjDHG+MUShjHGGL9YwjDGGOMXSxjGGGP8YgnDGGMCFBMDERGwZo3zMyYm1BEFR76acc8YY/K7mBgYPhwSE53nsbHOc4CoqNDFFQyWMIwxJhN79uxh48aNbNu2jV27djF58u8cP54CVGfu3D+Bt0lMrM7ddzene/e2VKpUKdQh5xlLGMaYc4qqcvDgQY4fP84ff/zBl19+ycaNG9m3bx9//vknhw4dIiUlhQoVKvDHH39w5MiRDFoqy7JlicApAP76CypXhkKFClGtWjV69erFJZdcwt69e6lbty7t2rWjbt26hIWFBe215jZLGMaYfCsmBkaPhjvvhOhoGDcu426fQ4cOsWnTJrZu3UpsbCw1atRg//79LFy4kC1bthAfH8/x48dJTk7OcHsiQtGiRSlXrhyNGjWiW7duHD58mFKlShEREUGtWrW444667NtXEyjO008v5IEHqgIrKVXqJ1q12kJsbCzJycl88skn/PXXX2dso1ixYtSvX58ePXoQERHBgQMHaNWqFW3atKFUqVK5st/ySo4Thoh0UNVlftSbBvQBDqhqAx/LBXgJuBJIBKJV9Sd3WU93WRjwhqqOz2ncxpj87Z9zBTtZs+YrYmMXM3RoLOPH76VQof3UqlWLgwcPsnHjRp8fzGmKFi0KQHh4ONWqVaNChQpccMEF9O3bl/PPP5/ChQtTtWpVateuTYkSJbKM6/jxf85hFCoUBtQlPLwukyfffEYyO3z4MN999x0//vgjGzduZOfOnezdu5e4uDieffbZM5JXWFgYpUuXpk2bNlx++eVUrVqVlJQU2rdvT0REBM7HZOb7zN8Emx25cYQxEMgyYQDTgVeBdzJY3guo5T5aAZOAViISBkwEugFxwCoRmaOqm3MYtzEmn0lOTmbjxo18+eWXjB8fRmLiF8AiPvhAAUhJgY0bnbpHjx6levXq1KpVi6pVq1KlShWqVq1KREQEl1xyCW3btqVq1ap+JYFApH0Ajx7t/KxRI+MP5nLlytG7d2969+7t87X++uuvLFy4kJ9//pmtW7fy+++/89dff7F06VIWLFhwWn0RoUSJElSoUIEePXrQrl07KleuTJkyZWjZsiWzZhXL85PxAScMEZkD7AJ+Atb424aqLhWRiEyqXA28o6oKfC8i5UTkAiAC2KGqO93tz3DrWsIw5izw22+/8frrr7NkyRJWr17NyZMnPZbWBm6ja9cjLFzYBbgMqI9q+dAE64qKch5LlsDu3dlro3Dhwlx22WVcdtllPpcfOnSItWvX8uWXX7J582Z27tzJH3/8wf79+3nrrbd48803vdYoApQBzmf16n8BnUlMdBJbbiUMcT6fM6kg8iiQqKrPeZTVAJoCzYAmqnpm+vTdVgQwN4MuqbnAeFVd7j5fCDyIkzB6quowt/wGoJWq3uGjjeHAcIAqVao0mzFjhj9h+ZSQkJAv+xMtrsBYXIHJy7hSUlKIjY1l48aNbN68mfbt23PxxRfz6aef8tFHH6XXq1SpEh06dKBWrd6cd15NRITq1ROIi3PiKloUGjbMkxADFqr3MTk5mf3797Np0yZWr17Nnj172LPnTxITj5KcfJLmzVszaNBT6fWbNfO/7S5duqxR1eY+F6pqpg9gGxDuo3wY8FBW63utEwFszGDZPKC9x/OFOAlpIM55i7TyG4BXstpWs2bNNCcWL16co/XzisUVGIsrMLkZV3JysqqqHj9+XK+44gotXbq0AgpoeHi4VqtWLf15ZGSkPvXUU7p169b09d97TzU8XBVUJ0xYrOA8f++9XAsxx/LT+1ijhrOvIFWffvpL93enPBDAas3gc9Wf7qTjqproo/wd4GfgaT/a8EcccKHH8+rAXqBoBuXGmHwiNTWVX375hRUrVrBy5UpWrlxJ/fr1mTVrFsWKFePkyZPUrl2bffv2sXfvXhITE2ncuDH33HMP/fv3p2bNmme0Gci5AuPsG+cchlCkSNqJfqc8t/iVMETkAlXd51moqidFJOPr0wI3B7jDPUfRCjiiqvtE5E+glojUBPYAg4HrcnG7xpgAHTlyhK1bt9KyZUsAunbtypIlSwCoWLEirVu35pJLLmHUqFF8/PHH7Nixg0KFCtGhQwdGjRpFv379qF69epbbyY1zBeeKYCRYfxLGc8BnIjJQVWPTCkWkMpDq74ZE5AOgM3CeiMQBj+OcpUFVJwPzcS6p3YFzWe1N7rJkEbkD+BLnstppqrrJ3+0aY7IWsyGG0QtHc2eVO4l+MZpxXccR1fCfT5rY2FgWLVqUfgSxefNmihcvzpEjRyhSpAgjRozgxhtvpHjx4vzwww/Mnj2befPmERYWxuWXX879999P3759qVy5cghf5dkvrxNslglDVT8SkXBgjYh8D6zFGbRwIDDG3w2p6pAslitwewbL5uMkFGNMLovZEMPwz4eTeCoRqkDsgVhuefEWZpeYzRtPvkG5cuV45513eOyxxyhfvjytW7dm0KBBtGnThpSUFJYtW8bSpUuZPXs2+/bto2jRonTv3p2xY8dy1VVXUaFChVC/RJNL/L0k9m0R+QToB9QHjgFDVHV1XgZnjMl7oxeOJvFQIqyA56Y9B79DkibxsXzMyGtH0rFjR26++WYGDhxI7dq1SU5OZtGiRcycOZMhQ4bw119/UaJECXr16sWAAQPo06cPZcqUCfXLMnnA7/swVDWejG+6M8YUUL8d+Q3ige+hdP3S7Ku5z7nMpDp07NgRcM5LrFmzhqeeeorPP/88fbiMPn36cM0119CzZ09KliwZ0tdh8p6NJWXMOejkyZO8/vrr7Nq1i4suuohYYuFeGN50OPdtuw+AC4tfyEcffcTHH3/MvHnzSEhIoFy5clx99dUMGDCAbt26Ubx48RC/EhNMljCMOYekpqYyY8YMHnnkEXbt2kXXrl0Ze/1Y/v3Fv0kslcjxxOOwHsK2hPHHr39wbdK1VKpUiSFDhjBgwAC6dOmSPjaTOfdYwjDmHLFhwwZuvPFG1q5dS+PGjfniiy/o3r07AFvWbOGll19izJYxkAylK5UmalgU11xzDe3bt6dwYfuoMJYwjDnrJSUlUaxYMSpWrEhycjIxMTEMHjyYpKQk3njjDV566SU2bdpEpUqV6NS3E/fccw+tW7emUCGbwdmczv4ijDlLbd++nWuvvZYePXqgqlStWpX169fTsWNHHnnkEapXr87w4cMpUqQIb731Fr/99hu33347bdu2tWRhfLIjDGPOMvv27eOJJ55g6tSpFC9enP/85z8kJyezZs0aXnzxRWbNmoWqcvXVV3PXXXfRsWPHLOdZMAYsYRhzVlm6dCm9evXi5MmTjBgxggcffJBly5bRvn17fvzxR8qWLctdd93FHXfc4XP8JmMyYwnDmAIuKSmJ3bt3c9lll9G8eXNuuOEGbrrpJr755htatWrFvn37qF27Nq+++ipDhw7Nl8Oqm4LBEoYxBVRKSgrvv/8+jz76KGFhYWzZsoUdO3Zw6tQpOnXqRFJSEt27d+eNN96gZ8+edl7C5JglDGMKGFVlwYIFjBo1ig0bNtC0aVOuuuoqevToweLFiylRogTR0dGMHDmSevXqhTpccxaxrxzGFDBfffUVvXv3JiEhgRtvvJFDhw4xZswYduzYwfjx44mLi2Py5MmWLEyus4RhTAGwZcsWPv30UwAiIiLo1q0bBw4c4J133qFq1ap8+OGH7Ny5kwcffNBGhzV5xrqkjMnH9uzZw9ixY5k2bRoVKlRg6tSpLFiwgMKFCzNo0CDuuusumjf3Pf2yMbnNEoYx+dDhw4f53//+x0svvcTJkycpW7Ysf/75J6tWreLRRx9lxIgRXHDBBaEO05xjLGEYkw99++23jB8/nqJFi5KSksJFF13Ec889x+DBg22EWBMyljCMyQdSUlJ49913Wb58OQkJCcyaNQsRoXfv3tx999106NDB7sY2IRfUhCEiPYGXcObmfkNVx3stvx9Im0i4MFAXqKSqf4vIbpxpXlKAZFW1jltT4Kkqn376KSNHjiQuLg6AMmXK2N3YJl8KWsIQkTBgItANiANWicgcVd2cVkdVnwWedev/C7hHVf/2aKaLqv4VrJiNyW0xMTB6NNx5JwwevJyUlOv5669YAC644AIefvhhoqOj7W5sky8F8wijJbBDVXcCiMgM4Gpgcwb1hwAfBCk2Y/JcTAwMHw6JiT/x4YfPsH//QuAkVavWZdKk8fTp08fuxjb5mqhqcDYkcg3QU1WHuc9vAFqp6h0+6objHIVcmnaEISK7gEOAAq+r6hQf6w0HhgNUqVKl2YwZM7Idb0JCQr78lmdxBSa/xKWqTJkyj3nzphEff4iiRYvStGkP2rbtS0TExTRsGOoIHfllf3mzuAKTk7i6dOmyJsMuf1UNygMYiHPeIu35DcArGdQdBHzuVVbV/VkZWAd0zGx7zZo105xYvHhxjtbPKxZXYEId16lTp/SJJ57QsmXLKqAgCp10zJjZCqqgKhLSEE8T6v2VEYsrMDmJC1itGXyuBvP4Nw640ON5dWBvBnUH49Udpap73Z8HgNk4XVzG5Fvffvst9erV47HHHiM+Pp4SJa7G+ZNfQqlS5dLrXXRRqCI0JjDBTBirgFoiUlNEiuIkhTnelUSkLNAJ+MyjrKSIlE77HegObAxK1MYEIC4ujsGDB1OvXj06d+7M4cOHiY6O5vDhw0yd+inh4eefVj88HMaNC1GwxgQoaCe9VTVZRO4AvsS5rHaaqm4SkRHu8slu1X7AV6p6zGP1KsBs9zr0wsD7qvpFsGI3Jivr1q3j3nvvZfHixagqpUuX5uWXX2bYsGGUKFECgCj3gvHRo52fNWo4ySKt3Jj8Lqj3YajqfGC+V9lkr+fTgeleZTuBxnkcnjEBS01NpU+fPixYsACA0qVL8+CDD3LfffdRrFixM+pHRTmPJUtg9+7gxmpMTtmd3sYE6OTJk3zwwQeoKs899xwbN26kQoUKjBkzhhEjRlCkSJFQh2hMnrCEYYyfDh8+zKRJk3j22Wc5dOgQAHXr1uW9995j0KBBFC5s/07m7GZ/4cZkITk5mXvvvZcpU6aQlJQEOHNS/O9//2PAgAGEhYWFOEJjgsNuKzUmA7GxsSQlJTF16lSmTp1KUlISderUYfbs2fz6669ce+21lizMOcWOMIzxkJqayrx583jmmWdYuXIllSpV4o8//qBVq1Y89thj9OrVy0aNNecsSxjGAMePH+fdd99lwoQJbN++nUKFCpGamsoll1zCu+++S9euXS1RmHOeJQxzTlNVRIRt27YxYsSI9MH/OnfuzOOPP07Hjh1DHKEx+YclDHNO2rZtGy+88AL79u0jMjKSl156CVWle/fuPProo7Rp0ybUIRqT71jCMOcMVeW7775jwoQJzJkzh0KFClGoUCE+++wz+vbtyyOPPEKzZs1CHaYx+ZZdJWXOSjEbYoh4MYI1+9YQ8WIEMRtimDp1Kh06dODLL7+kcOHCpKSk0K9fP9atW8fs2bMtWRiTBTvCMGedmA0xDP98OIkJiSz7eRmxKbEM2zeM1jtaU7hwYZKSkrjuuusYPXo0devWDXW4xhQYljDMWefhLx8mcVkifAufHf8MKsGJv0+wRJdw09CbeOihh6hVq1aowzSmwLGEYc4qX3zxBb89/Rv8DZQCKSToQYUmQHuY9uK0UIdoTIFlCcOcVX755RcKnShEaqFUSIR23dqxvN5yKAs1ytYIdXjGFGiWMEyB9vvvvzN69GgaN27MsWPHePbZZ0k9nkpY0zBSOqTQt2Vflm9bTniRcMZ1tZmKjMkJSximQIqPj2f8+PE8//zzJCcn88knn3Ds2DH69+/Pk08+yU/JPzF6oTNTUY2yNRjXdRxRDW2mImNywhKGKXBmz57NiBEjOHDgAOHh4SQnJ9OxY0eefvppWrZ0pnqvS12iGkaxZMkSdg/ZHdqAjTlL2H0YpsBITk5GVdmwYQMJCQmAMx/F119/zcKFC9OThTEmbwT1CENEegIv4czp/Yaqjvda3hn4DNjlFn2iqk/4s645e23YsIH77ruPcuXK8dtvv/H9999Tq1YtnnrqKQYMGGCDAhoTJEFLGCISBkwEugFxwCoRmaOqm72qLlPVPtlc15xF/vjjDx599FGmTZtGWFgYp06dolq1akydOpXo6Gib4c6YIAvmf1xLYIeq7gQQkRnA1YA/H/o5WdcUQLNmzWLo0KGcOHGC1NRUSpcuzSOPPMLtt99OiRIlQh2eMeckUdXgbEjkGqCnqg5zn98AtFLVOzzqdAY+xjmK2Avcp6qb/FnXLR8ODAeoUqVKsxkzZmQ73oSEBEqVKpXt9fPK2RxXamoqiYmJnDhxgkmTJrFo0SKKFi3Ktddey6BBg7LV/tm8v/KCxRWYszGuLl26rFHV5j4XqmpQHsBAnHMPac9vAF7xqlMGKOX+fiWw3d91vR/NmjXTnFi8eHGO1s8rZ2tcixYt0kaNGmnt2rW1RIkSWqRIEb399tt13759IY0rr1hcgbG4ApOTuIDVmsHnajC7pOKACz2eV8c5ikinqkc9fp8vIq+JyHn+rGsKpq1bt3Lvvfcyf/58RARV5frrr2fs2LFcfPHFoQ7PGOMhmAljFVBLRGoCe4DBwHWeFUTkfGC/qqqItMS57PcgcDirdU3BM3PmTK677rq0o0Z69uzJ+PHjadSoUYgjM8b4ErSEoarJInIH8CXOpbHT1Dk/McJdPhm4BrhNRJKB48Bg9xDJ57rBit3knhMnTrB3715+/PFHHn74YVJTU2nRogXPP/887du3D3V4xphMBPW6RFWdD8z3Kpvs8furwKv+rmsKDlVl5syZ3H333Rw9epTjx4/TsGFD5s6dy5VXXmn3UhhTANiF7CbPrVy5kv/7v/9j0ybnoPD8889n6tSpDBkyhEKFbLABYwoK+281eWrixIm0bduWTZs2UaZMGV555RViY2OJioqyZGFMAWNHGCbXHTp0iG+//ZbZs2fzzjvvUKxYMR588EEeeOABSpYsGerwjDHZZF/xTI7ExEBEBKxZAzVqnGLgwHFUrVqVfv36MXPmTO6//3727NnD2LFjLVkYU8DZEYbJtpgYGD4cEhOVn39eyG+/DeC33/4GoH///rz00ktUr149xFEaY3KLJQyTbaNHQ2JiEnAvMTGvuaXtueCCqXz8cZ1QhmaMyQPWJWWy5ffffyc29l6gDvAa559/MbASWMYff1iyMOZsZAnDBOTYsWNER0cTEREBvACUBr7ivvveBFoDcNFFoYvPGJN3LGEYv6SkpDBu3DgqVqzI22+/TbFixRgyZAIlSqzFmabEER4O48aFLExjTB6yhGGytG/fPgYPHswjjzxCcnIyt912GwcPHuT99//D1KmFqFHDqVejBkyZAlFRoY3XGJM37KS3ydDPP//Mww8/zLJly0hKSmLgwIFMnDiRSpUqpdeJinIeS5bA7t0hC9UYEwSWMMwZ9u/fz3XXXceiRYsAuOqqq3juuee49NJLQxyZMSaULGGYdElJSdx+++289dZbpKamUqVKFaZNm8aVV14Z6tCMMfmAncMwAKxevZrOnTvz5ptvUrx4cV544QX27dtnycIYk84Sxjluzpw51KlThxYtWvDrr78yduxYDh8+zN13321DjhtjTmNdUueojRs3MmjQIDZv3gzA7bffzlNPPUWZMmVCHJkxJr+yhHGOOXToEIMGDeLrr78GoGHDhsycOZO6deuGODJjTH5nXVLniNTUVN5//30aN27M119/zfnnn8/8+fNZv369JQtjjF+CmjBEpKeIbBWRHSIyysfyKBFZ7z5WiEhjj2W7RWSDiKwVkdXBjLuge/7556lYsSJRUVFUrFiR2bNns2/fPnr16hXq0IwxBUjQuqREJAyYiDOORBywSkTmqOpmj2q7gE6qekhEegFTgFYey7uo6l/Birmgmzt3LsOGDWP//v2EhYXx9NNP88ADD9hMd8aYbAnmOYyWwA5V3QkgIjOAq4H0hKGqKzzqfw/YZArZsHPnTq666qr0ObR79uzJ+++/T/ny5UMcmTGmIAvmV81qwO8ez+PcsozcAizweK7AVyKyRkSG50F8Bd7Ro0d5/PHHadCgAZs3b6Zhw4Zs3ryZBQsWWLIwxuSYqGpwNiQyEOihqsPc5zcALVX1Th91uwCvAe1V9aBbVlVV94pIZeBr4E5VXeq13nBgOECVKlWazZgxI9vxJiQkUKpUqWyvn1d8xZWcnMxLL73EggULSElJoXPnzkRHR1MjbVTAEMWVH1hcgbG4AnM2xtWlS5c1qtrc50JVDcoDaAN86fH8IeAhH/UaAb8CtTNpawxwX2bba9asmebE4sWLc7R+XvGMKzU1VSdMmKAlSpRQQMPDw/Xdd98NeVz5icUVGIsrMGdjXMBqzeBzNZhdUquAWiJSU0SKAoOBOZ4VROQi4BPgBlXd5lFeUkRKp/0OdAc2Bi3yfCAmBiIiYM0a5+fjj6/g/PPP57777uPkyZOMGDGCw4cPc/3114c6VGPMWSpoJ71VNVlE7gC+BMKAaaq6SURGuMsnA48BFYHX3GEpktU5NKoCzHbLCgPvq+oXwYo91GJiYPhwSEyEP//8ndjYwTzxxEyKFClO9+7def/996lYsWKowzTGnOWCeqe3qs4H5nuVTfb4fRgwzMd6O4HG3uXnitGjITHxTyCK//3va6AY8ChVqtzHl1/aUB7GmOCwoUHyuZMnTxIbexcwFUihZMlyHDv2EXAFe/aEODhjzDnF7uDKp1SV2bNnU6FCBWAyUAR4hjFjPgGuAOCii0IYoDHmnGMJIx9atGgRnTt3pn///oSHh9Op0y0UL34IuD99yPHwcBg3LrRxGmPOLZYw8pHt27fTpEkTunbtyrp163jttdfYu3cvS5a8wRtvFCfttooaNWDKFGcubWOMCRY7h5EPHD16lBtuuIE5c5yrjGvXrs2MGTNo0qRJep2oKOexZAns3h2aOI0x5zY7wgihlJQUpk2bRqVKlZgzZw4VKlRgxowZbN269bRkYYwx+YEljBB5++23adKkCbfccgsXXXQRY8aM4c8//2TQoEGhDs0YY3yyLqkg++6774iKiiI2NpaKFSsyY8YMrr32Wps/2xiT71nCCJLff/+da6+9lu+//x6Atm3bMnPmTKpXtxHcjTEFg3VJ5bGkpCQmTJjAxRdfzPfff09ERATfffcd3333nSULY0yBYkcYeURVeeKJJ3jrrbeIjY2ldevW3HrrrURHR4c6NGOMyRZLGHngww8/ZMSIERw6dIgqVarw1Vdf0a1bt1CHZYwxOWIJIxf99NNPDB48mO3btyMi9OvXj3feeSdfTrBijDGBsnMYueDo0aM8/PDDtGjRgu3bt9OsWTN27NjBJ598YsnCGHPWsCOMHDh58iT//ve/+fTTTzl48CBXX301I0eO5PLLLw91aMYYk+ssYWTTc889x6OPPsrx48epXr06P/74Iy1atAh1WMYYk2esSypA8+bNo0qVKulTo955553s3r3bkoUx5qxnCcNP+/fvZ8SIEfTp04cDBw7Qq1cv/vzzT15++WXCwsJCHZ4xxuS5oCYMEekpIltFZIeIjPKxXETkZXf5ehFp6u+6eeXIkSP07t2biy++mDfffJP/+7//Y/PmzcyfP5/y5csHKwxjjAm5oCUMEQkDJgK9gHrAEBGp51WtF1DLfQwHJgWwbq6IiYGICFi1KpUyZUZSoUJF5s+fT9WqVdm0aRNTpkyhbt26ebFpY4zJ14J5hNES2KGqO1X1JDADuNqrztXAO+r4HignIhf4uW6OxcTA8OEQGzuFRx7pTXz8K6SmFmHIkGfZvn07tWvXzu1NGmNMgRHMhFEN+N3jeZxb5k8df9bNsdGjITHxB+BWTp1KAm4GjrBixX25vSljjClwgnlZra/xu9XPOv6si4gMx+nKAkgQka0BRUizZu5PVP8E1gFtiY0FkTVrAmsrz5wH/BXqIHywuAJjcQXG4gpMTuKqkdGCYCaMOOBCj+fVgb1+1inqx7qo6hRgSm4EKyKrVWOb50ZbucmJSy0uP1lcgbG4AnOuxRXMLqlVQC0RqSkiRYHBwByvOnOAG92rpVoDR1R1n5/rGmOMyUNBO8JQ1WQRuQP4EggDpqnqJhEZ4S6fDMwHrgR2AInATZmtG6zYjTHGBHloEFWdj5MUPMsme/yuwO3+rpvHcqVrKw9YXIGxuAJjcQXmnIpLnM9oY4wxJnM2NIgxxhi/WMLwEqohSDIjIheKyGIR+UVENonIXaGOyZOIhInIzyIyN9SxpBGRciIyS0S2uPutTahjAhCRe9z3cKOIfCAixUMYyzQROSAiGz3KKojI1yKy3f0Z9PFvMojrWfe9XC8is0WkXH6Iy2PZfSKiInJefolLRO50P8s2icgzubEtSxgegjkESYCSgf+oal2gNXB7PokrzV3AL6EOwstLwBeqWgdoTD6IT0SqASOB5qraAOcCjsEhDGk60NOrbBSwUFVrAQvd58E2nTPj+hpooKqNgG3AQ8EOCt9xISIXAt2A34IdkGs6XnGJSBec0TAaqWp9YEJubMgSxumCMgRJoFR1n6r+5P4ej/Phl+t3umeHiFQHegNvhDqWNCJSBugIvAmgqidV9XBIg/pHYaCEiBQGwvFxP1GwqOpS4G+v4quBt93f3wb6BjMm8B2Xqn6lqsnu0+9x7sUKeVyuF4AH8HEzcTBkENdtwHhVTXLrHMiNbVnCOF1QhiDJCRGJAJoAP4Q4lDQv4vyzpIY4Dk8XA38Cb7ldZW+ISMlQB6Wqe3C+6f0G7MO5z+ir0EZ1hiruvU+4PyuHOB5fbgYWhDoIABG5CtijqutCHYuX2kAHEflBRL4VkVyZsMcSxun8GoIkVESkFPAxcLeqHs0H8fQBDqhqfhk2JU1hoCkwSVWbAMcITdfKadzzAVcDNYGqQEkRuT60URUsIjIap4s2Jh/EEg6MBh4LdSw+FAbK43Rh3w98KCK+Pt8CYgnjdP4MXxISIlIEJ1nEqOonoY7H1Q64SkR243TfXS4i74U2JMB5H+NUNe0obBZOAgm1K4Bdqvqnqp4CPgHahjgmb/vdEaJxf+ZKV0ZuEJGhQB8gSvPH/QCX4CT/de7/QHXgJxE5P6RROeKAT9yRv3/E6QHI8Ql5Sxiny5dDkLjfDN4EflHV50MdTxpVfUhVq6tqBM6+WqSqIf/GrKp/AL+LyGVuUVdgcwhDSvMb0FpEwt33tCv54GS8lznAUPf3ocBnIYwlnYj0BB4ErlLVxFDHA6CqG1S1sqpGuP8DcUBT9+8v1D4FLgcQkdo44/HleJBESxge3JNqaUOQ/AJ8mE+GIGkH3IDzDX6t+7gy1EHlc3cCMSKyHogEngptOOAe8cwCfgI24Pz/hexOYRH5AFgJXCYicSJyCzAe6CYi23Gu/BmfT+J6FSgNfO3+/U/OtJHgxRVyGcQ1DbjYvdR2BjA0N47K7E5vY4wxfrEjDGOMMX6xhGGMMcYvljCMMcb4xRKGMcYYv1jCMMYY4xdLGOacJSL93BFG6wSwzksiskdEMvzfEZEmIuJzbC0R2R2KEU3dbfcRkbGh2LY5O1jCMOeyIcBy/Bwx1k0S/XDGG+uYSdWHgVdyHF3msWRntsx5OHfmh+d2PObcYAnDnJPccbnaAbfgkTBEpLiIvCUiG9yBC7t4rNYF2AhMwkk2vtotjTOk9Dr3eUUR+cpt63U8xisTketF5Ef3RrTX3eH1EZFbRGSbiCwRkaki8qpbPl1EnheRxcD/ROQSEflCRNaIyLK0IyURqSQiH4vIKvfRDtKnQF6CM7yGMQGzhGHOVX1x5svYBvwtImljTd0OoKoNcZLC2/LPJEdDgA+A2UAfd3wvb81xkkqax4Hl7iCIc4CLAESkLjAIaKeqkUAKECUiVYFHcQaN6wZ4d5fVBq5Q1f/g3CV+p6o2A+4DXnPrvAS8oKotgAGcPvT8aqBDlnvHGB+yc1hrzNlgCM7Q7OAMnTAEZ8iO9rjdSaq6RURigdoisgW4ErhHVeNF5AegO043j6cLcIZWT9MR6O+2N09EDrnlXYFmwCp3ENESOAP9tQS+VdW/AUTkI5wkkeYjVU1xj5DaAh95DEJazP15BVDPo7yMiJR251I5gDNSrjEBs4RhzjkiUhFnYLYGIqI4M9+piDyA7yHuwZnRrCywwf0gDgcSOTNhHAe8p131Nf6OAG+r6mkzx4lIvyzCP+b+LAQcdo9OvBUC2qjqcR/LirsxGhMw65Iy56JrgHdUtYY70uiFwC6co4ulQBSkj/J5EbAV5whkmMfIpDWB7j5OIP8CXOrx3LO9XjhzFIAz/ek1IlLZXVZBRGoAPwKdRKS8e2J7gK8X4M6HsktEBrrri4g0dhd/hTOIJu6ySI9Va3N6l5kxfrOEYc5FQ3DOQ3j6GLgO5zxAmIhsAGYC0ThHID3wOJpQ1WM4V1j9y7MRVd0ClHVPfgOMBTqKyE84XVi/ufU2A48AX7kj6n4NXODOyvcUzoyK3+AMy34kg9cRBdwiIuuATfwznfBIoLmIrBeRzcAIj3W6cOZRkTF+sdFqjcllInIPEK+q2ZrnXERKqWqCe4QxG5imqt4JLjvtVgHeV9WuOW3LnJvsCMOY3DcJSMrB+mNEZC1O19EunMlwcsNFwH9yqS1zDrIjDGOMMX6xIwxjjDF+sYRhjDHGL5YwjDHG+MUShjHGGL9YwjDGGOMXSxjGGGP88v8NAMPTABsLigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = [0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.03, 0.03, 0.03, 0.03, 0.03]\n",
    "beta = [0, 30, 45, 60, 75, 90, 30, 45, 60, 75, 90, 30, 45, 60, 75, 90]\n",
    "for i in range(0, 16):\n",
    "    # Index from each dataset\n",
    "    iTrain = []\n",
    "    iVal = []\n",
    "    iTest = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    alpha_train = []\n",
    "    alpha_val = []\n",
    "    alpha_test = []\n",
    "    \n",
    "    predictedValue = model.predict(x[n_alpha*i:n_alpha*(i+1),:])\n",
    "    y_corres = y[n_alpha*i:n_alpha*(i+1),:]\n",
    "    \n",
    "    l2_error_Cl = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    if i==0:\n",
    "        print('NACA0018 airfoil without Gurney flap\\nL2 error of Cl: {0:0.4f}'.format(l2_error_Cl))\n",
    "    else:\n",
    "        print('L2 error of Cl: {0:0.4f}'.format(l2_error_Cl))\n",
    "    \n",
    "    cl = predicted[n_alpha*i:n_alpha*(i+1)]*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "    CL = y[n_alpha*i:n_alpha*(i+1)]*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*n_alpha) & ((index_train>=i*n_alpha)))]):\n",
    "        iTrain.append(predicted[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*n_alpha) & ((index_val>=i*n_alpha)))]):\n",
    "        iVal.append(predicted[index])    \n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*n_alpha) & (index_test>=i*n_alpha))]):\n",
    "        iTest.append(predicted[index])\n",
    "        \n",
    "    iTrain = np.array(iTrain)*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "    iTest = np.array(iTest)*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "    iVal = np.array(iVal)*(np.max(cl_orig)-np.min(cl_orig))+np.min(cl_orig)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*n_alpha) & ((index_train>=i*n_alpha)))]):\n",
    "        alpha_train.append(aa[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*n_alpha) & ((index_val>=i*n_alpha)))]):\n",
    "        alpha_val.append(aa[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*n_alpha) & ((index_test>=i*n_alpha)))]):\n",
    "        alpha_test.append(aa[index])\n",
    "        \n",
    "    aTrain = np.array(alpha_train)*np.max(alpha)\n",
    "    aVal = np.array(alpha_val)*np.max(alpha)\n",
    "    aTest = np.array(alpha_test)*np.max(alpha)\n",
    "    \n",
    "    CL_trainTestSplit_Plot(i, CL, cl, aTrain, aTest, iTrain, iTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e694d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
