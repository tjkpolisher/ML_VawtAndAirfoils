{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of the steady-state simulation - Case 3: AeroCNN-II\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining parameters and hyperparameters of the model\n",
    "n_layers=4\n",
    "n_kernels=300 # Number of kernels in convolutional network\n",
    "kernel_size1=2\n",
    "strides=1\n",
    "n_units=128 # Number of units in the hidden layer of the MLP network\n",
    "input_size = 100 # Size of input for the network (100 coefficients and 3 other parameters, AoA, h, beta)\n",
    "lr = 1e-04 # Learning rate of the network\n",
    "test_rate=0.1 # Defines the ratio of training dataset and test dataset\n",
    "val_rate=0.2\n",
    "n_data = 16 # Number of txt files from which the aerodynamic coefficients are extracted\n",
    "batch_size = 20 # Mini-batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing working directory\n",
    "\n",
    "main_directory = 'D:\\\\VAWT_data\\\\flap_steady\\\\flap_steady'\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb294db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic parameters\n",
    "\n",
    "c = 1 # Chord length\n",
    "h = np.array([0.01, 0.02, 0.03]) * c # Height of the Gurney flaps\n",
    "t = 0.02 * h # Thickness of the Gurney flaps\n",
    "alpha = np.linspace(0, 16, 9).reshape((9,1)) # Angles of attack\n",
    "beta = np.linspace(30, 90, 5).reshape((5,1))\n",
    "\n",
    "h = h.reshape((-1,1))\n",
    "t = t.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8ca6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alpha = alpha.shape[0] # Number of the angles of attack\n",
    "n_beta = beta.shape[0] # Number of the Gurney flap inclination\n",
    "n_h = h.shape[0] # Number of the height of the Gurney flaps\n",
    "n_cases = n_data * n_alpha\n",
    "aa_ = np.zeros((n_cases,1))\n",
    "for i in range(0, n_data):\n",
    "    aa_[n_alpha*i:n_alpha*(i+1),:] = alpha[:,:]\n",
    "    \n",
    "aa = aa_ / np.max(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18aaa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.reshape((-1,1))\n",
    "t = t.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9745480",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alpha = alpha.shape[0] # Number of the angles of attack\n",
    "n_beta = beta.shape[0] # Number of the Gurney flap inclination\n",
    "n_h = h.shape[0] # Number of the height of the Gurney flaps\n",
    "n_cases = n_data * n_alpha # Total number of cases(Number of geometries * Number of angles of attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519040fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating input dataset - mask\n",
    "mask_dir = main_directory + '\\\\aeroCNN2Mask'\n",
    "os.chdir(mask_dir)\n",
    "mask_list = os.listdir(mask_dir)\n",
    "mask_target = [file for file in mask_list if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce37035a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask_df = pd.DataFrame()\n",
    "for file in mask_target:\n",
    "    data = pd.read_csv(file, header=None)\n",
    "    mask_df = pd.concat([mask_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e559a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mask_df.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cc4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_alligned = np.zeros((x.shape[0],x.shape[1]))\n",
    "for i in range(0,144*2):\n",
    "    if i%2==0:\n",
    "        x_alligned[i*100:(i+1)*100,:] = x[i*100:(i+1)*100,:]\n",
    "    else:\n",
    "        x_alligned[i*100:(i+1)*100,:] = x[i*100:(i+1)*100,:].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2d602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_alligned.reshape((16*9,2,input_size,input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b41130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating output dataset - Cl and Cd\n",
    "files_orig = os.listdir(main_directory)\n",
    "files_target = [file for file in files_orig if file.endswith('.txt')]\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c62765",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame()\n",
    "for file in files_target:\n",
    "    data = pd.read_table(file, header=None)\n",
    "    target_df = pd.concat([target_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac849035",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_orig = target_df.iloc[:,3].values # Cd values\n",
    "#target_c4 = target_df.iloc[:,4].values# Cl values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4ccbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = (cd_orig-np.min(cd_orig))/(np.max(cd_orig)-np.min(cd_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7444ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cd.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "330c3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all, x_test, y_all, y_test = train_test_split(x, y, test_size=test_rate, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_all, y_all, test_size=val_rate/(1-test_rate), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bbc2f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2, 100, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00d21f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82d60c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.keras.Input(shape=(2, input_size, input_size))\n",
    "\n",
    "x_conv1 = tf.keras.layers.Conv2D(n_kernels, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same'\n",
    "                                )(input_image)\n",
    "x1_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv1)\n",
    "x_conv2 = tf.keras.layers.Conv2D(n_kernels, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same'\n",
    "                                )(x1_)\n",
    "x2_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv2)\n",
    "x_conv3 = tf.keras.layers.Conv2D(n_kernels, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same'\n",
    "                                )(x2_)\n",
    "x3_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv3)\n",
    "x_conv4 = tf.keras.layers.Conv2D(n_kernels, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same'\n",
    "                                )(x3_)\n",
    "x4_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv4)\n",
    "x_flat = tf.keras.layers.Flatten()(x4_)\n",
    "x_fc1 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc1')(x_flat)\n",
    "x_fc2 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc2')(x_fc1)\n",
    "x_fc3 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc3')(x_fc2)\n",
    "x_fc4 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc4')(x_fc3)\n",
    "x_fc5 = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc5')(x_fc4)\n",
    "\n",
    "output_data = tf.keras.layers.Dense(units=1, activation='linear', name='outputLayer')(x_fc5)\n",
    "# AeroCNN-II based\n",
    "model = tf.keras.Model(input_image, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2, 100, 100)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 300, 100, 100)     2700      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 300, 50, 50)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 300, 50, 50)       360300    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 300, 25, 25)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 300, 25, 25)       360300    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 300, 12, 12)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 300, 12, 12)       360300    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 300, 6, 6)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10800)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               1382528   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " fc4 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " fc5 (Dense)                 (None, 128)               16512     \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,532,305\n",
      "Trainable params: 2,532,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3880888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20221130\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf477620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_name = model_directory + \"\\\\20221130steadyValidation_AeroCNN2_val_\"+str(val_rate) + \"_test\"+str(test_rate)+ \"_\" + str(n_units) +\"units_OptimalSettings_Cdcheckpoint.h5\"\n",
    "\n",
    "# ckpt = tf.keras.callbacks.ModelCheckpoint(ckpt_name, monitor=\"val_loss\", mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1000, min_delta=6e-7,\n",
    "                                      restore_best_weights=True, verbose=1)\n",
    "rp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=200, factor=0.5,\n",
    "                                          min_delta = 1e-09, min_lr=1e-06, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4cc904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = len(x_train)//batch_size\n",
    "VALIDATION_STEPS = len(x_val)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "5/5 [==============================] - 7s 75ms/step - loss: 0.0753 - rmse: 0.2745 - val_loss: 0.0090 - val_rmse: 0.0949 - lr: 1.0000e-04\n",
      "Epoch 2/10000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0116 - rmse: 0.1077 - val_loss: 0.0029 - val_rmse: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 3/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0071 - rmse: 0.0843 - val_loss: 0.0046 - val_rmse: 0.0682 - lr: 1.0000e-04\n",
      "Epoch 4/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0046 - rmse: 0.0676 - val_loss: 0.0081 - val_rmse: 0.0898 - lr: 1.0000e-04\n",
      "Epoch 5/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0056 - rmse: 0.0747 - val_loss: 0.0043 - val_rmse: 0.0654 - lr: 1.0000e-04\n",
      "Epoch 6/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0075 - rmse: 0.0863 - val_loss: 0.0104 - val_rmse: 0.1021 - lr: 1.0000e-04\n",
      "Epoch 7/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0054 - rmse: 0.0736 - val_loss: 0.0044 - val_rmse: 0.0666 - lr: 1.0000e-04\n",
      "Epoch 8/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0055 - rmse: 0.0743 - val_loss: 0.0054 - val_rmse: 0.0737 - lr: 1.0000e-04\n",
      "Epoch 9/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0042 - rmse: 0.0646 - val_loss: 0.0041 - val_rmse: 0.0637 - lr: 1.0000e-04\n",
      "Epoch 10/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0023 - rmse: 0.0478 - val_loss: 0.0038 - val_rmse: 0.0618 - lr: 1.0000e-04\n",
      "Epoch 11/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0032 - rmse: 0.0569 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 12/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0022 - rmse: 0.0470 - val_loss: 0.0030 - val_rmse: 0.0544 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0019 - rmse: 0.0436 - val_loss: 0.0025 - val_rmse: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0015 - rmse: 0.0393 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0015 - rmse: 0.0393 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0013 - rmse: 0.0364 - val_loss: 0.0032 - val_rmse: 0.0569 - lr: 1.0000e-04\n",
      "Epoch 17/10000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0012 - rmse: 0.0347 - val_loss: 0.0021 - val_rmse: 0.0458 - lr: 1.0000e-04\n",
      "Epoch 18/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0020 - rmse: 0.0442 - val_loss: 0.0033 - val_rmse: 0.0575 - lr: 1.0000e-04\n",
      "Epoch 19/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0017 - rmse: 0.0414 - val_loss: 0.0021 - val_rmse: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 20/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0016 - rmse: 0.0403 - val_loss: 0.0050 - val_rmse: 0.0704 - lr: 1.0000e-04\n",
      "Epoch 21/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0019 - rmse: 0.0439 - val_loss: 0.0024 - val_rmse: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 22/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0019 - rmse: 0.0434 - val_loss: 0.0046 - val_rmse: 0.0675 - lr: 1.0000e-04\n",
      "Epoch 23/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0016 - rmse: 0.0399 - val_loss: 0.0037 - val_rmse: 0.0609 - lr: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0031 - rmse: 0.0558 - val_loss: 0.0048 - val_rmse: 0.0693 - lr: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0020 - rmse: 0.0450 - val_loss: 0.0032 - val_rmse: 0.0566 - lr: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0017 - rmse: 0.0415 - val_loss: 0.0058 - val_rmse: 0.0763 - lr: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0017 - rmse: 0.0413 - val_loss: 0.0021 - val_rmse: 0.0461 - lr: 1.0000e-04\n",
      "Epoch 28/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0351 - val_loss: 0.0043 - val_rmse: 0.0658 - lr: 1.0000e-04\n",
      "Epoch 29/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0014 - rmse: 0.0373 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 30/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0011 - rmse: 0.0326 - val_loss: 0.0023 - val_rmse: 0.0484 - lr: 1.0000e-04\n",
      "Epoch 31/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7265e-04 - rmse: 0.0259 - val_loss: 0.0038 - val_rmse: 0.0620 - lr: 1.0000e-04\n",
      "Epoch 32/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1710e-04 - rmse: 0.0286 - val_loss: 0.0022 - val_rmse: 0.0468 - lr: 1.0000e-04\n",
      "Epoch 33/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.1798e-04 - rmse: 0.0268 - val_loss: 0.0032 - val_rmse: 0.0564 - lr: 1.0000e-04\n",
      "Epoch 34/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4136e-04 - rmse: 0.0307 - val_loss: 0.0030 - val_rmse: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 35/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.5336e-04 - rmse: 0.0235 - val_loss: 0.0032 - val_rmse: 0.0562 - lr: 1.0000e-04\n",
      "Epoch 36/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.6547e-04 - rmse: 0.0238 - val_loss: 0.0025 - val_rmse: 0.0501 - lr: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1617e-04 - rmse: 0.0248 - val_loss: 0.0028 - val_rmse: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.9257e-04 - rmse: 0.0263 - val_loss: 0.0027 - val_rmse: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.7163e-04 - rmse: 0.0278 - val_loss: 0.0046 - val_rmse: 0.0678 - lr: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3552e-04 - rmse: 0.0289 - val_loss: 0.0024 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 41/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0875e-04 - rmse: 0.0226 - val_loss: 0.0031 - val_rmse: 0.0554 - lr: 1.0000e-04\n",
      "Epoch 42/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.6447e-04 - rmse: 0.0216 - val_loss: 0.0027 - val_rmse: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 43/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0486e-04 - rmse: 0.0201 - val_loss: 0.0030 - val_rmse: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 44/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2256e-04 - rmse: 0.0250 - val_loss: 0.0034 - val_rmse: 0.0584 - lr: 1.0000e-04\n",
      "Epoch 45/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.3128e-04 - rmse: 0.0182 - val_loss: 0.0028 - val_rmse: 0.0534 - lr: 1.0000e-04\n",
      "Epoch 46/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4608e-04 - rmse: 0.0186 - val_loss: 0.0031 - val_rmse: 0.0560 - lr: 1.0000e-04\n",
      "Epoch 47/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5357e-04 - rmse: 0.0159 - val_loss: 0.0029 - val_rmse: 0.0540 - lr: 1.0000e-04\n",
      "Epoch 48/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5244e-04 - rmse: 0.0159 - val_loss: 0.0029 - val_rmse: 0.0539 - lr: 1.0000e-04\n",
      "Epoch 49/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2258e-04 - rmse: 0.0149 - val_loss: 0.0029 - val_rmse: 0.0540 - lr: 1.0000e-04\n",
      "Epoch 50/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6236e-04 - rmse: 0.0190 - val_loss: 0.0030 - val_rmse: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 51/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2990e-04 - rmse: 0.0152 - val_loss: 0.0028 - val_rmse: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 52/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6214e-04 - rmse: 0.0127 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 53/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4014e-04 - rmse: 0.0118 - val_loss: 0.0032 - val_rmse: 0.0566 - lr: 1.0000e-04\n",
      "Epoch 54/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2951e-04 - rmse: 0.0151 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 55/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1596e-04 - rmse: 0.0147 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 56/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2339e-04 - rmse: 0.0111 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 57/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8845e-04 - rmse: 0.0137 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 58/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3087e-04 - rmse: 0.0114 - val_loss: 0.0027 - val_rmse: 0.0517 - lr: 1.0000e-04\n",
      "Epoch 59/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.2929e-04 - rmse: 0.0114 - val_loss: 0.0031 - val_rmse: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 60/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5876e-05 - rmse: 0.0098 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 61/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.8342e-05 - rmse: 0.0089 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 62/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9688e-05 - rmse: 0.0089 - val_loss: 0.0027 - val_rmse: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 63/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7926e-05 - rmse: 0.0082 - val_loss: 0.0028 - val_rmse: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 64/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8235e-05 - rmse: 0.0083 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 65/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9297e-05 - rmse: 0.0077 - val_loss: 0.0028 - val_rmse: 0.0529 - lr: 1.0000e-04\n",
      "Epoch 66/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4363e-05 - rmse: 0.0092 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 67/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4889e-04 - rmse: 0.0122 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 68/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1242e-04 - rmse: 0.0146 - val_loss: 0.0033 - val_rmse: 0.0577 - lr: 1.0000e-04\n",
      "Epoch 69/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0554e-04 - rmse: 0.0143 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 70/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.4335e-04 - rmse: 0.0156 - val_loss: 0.0031 - val_rmse: 0.0560 - lr: 1.0000e-04\n",
      "Epoch 71/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9283e-04 - rmse: 0.0198 - val_loss: 0.0024 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 72/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0378e-04 - rmse: 0.0143 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 73/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8568e-04 - rmse: 0.0136 - val_loss: 0.0030 - val_rmse: 0.0547 - lr: 1.0000e-04\n",
      "Epoch 74/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5116e-04 - rmse: 0.0123 - val_loss: 0.0023 - val_rmse: 0.0475 - lr: 1.0000e-04\n",
      "Epoch 75/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0438e-04 - rmse: 0.0143 - val_loss: 0.0037 - val_rmse: 0.0612 - lr: 1.0000e-04\n",
      "Epoch 76/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9963e-04 - rmse: 0.0224 - val_loss: 0.0020 - val_rmse: 0.0442 - lr: 1.0000e-04\n",
      "Epoch 77/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.6883e-04 - rmse: 0.0239 - val_loss: 0.0041 - val_rmse: 0.0642 - lr: 1.0000e-04\n",
      "Epoch 78/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4186e-04 - rmse: 0.0210 - val_loss: 0.0017 - val_rmse: 0.0410 - lr: 1.0000e-04\n",
      "Epoch 79/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.8029e-04 - rmse: 0.0167 - val_loss: 0.0034 - val_rmse: 0.0585 - lr: 1.0000e-04\n",
      "Epoch 80/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1580e-04 - rmse: 0.0204 - val_loss: 0.0023 - val_rmse: 0.0479 - lr: 1.0000e-04\n",
      "Epoch 81/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.1748e-04 - rmse: 0.0178 - val_loss: 0.0033 - val_rmse: 0.0574 - lr: 1.0000e-04\n",
      "Epoch 82/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.3190e-04 - rmse: 0.0182 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 83/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.4750e-04 - rmse: 0.0157 - val_loss: 0.0033 - val_rmse: 0.0571 - lr: 1.0000e-04\n",
      "Epoch 84/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0340e-04 - rmse: 0.0143 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 85/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.4011e-04 - rmse: 0.0155 - val_loss: 0.0027 - val_rmse: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 86/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.8599e-04 - rmse: 0.0136 - val_loss: 0.0029 - val_rmse: 0.0542 - lr: 1.0000e-04\n",
      "Epoch 87/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8952e-04 - rmse: 0.0138 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 88/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.3899e-04 - rmse: 0.0155 - val_loss: 0.0021 - val_rmse: 0.0462 - lr: 1.0000e-04\n",
      "Epoch 89/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8452e-04 - rmse: 0.0136 - val_loss: 0.0035 - val_rmse: 0.0592 - lr: 1.0000e-04\n",
      "Epoch 90/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7605e-04 - rmse: 0.0133 - val_loss: 0.0023 - val_rmse: 0.0482 - lr: 1.0000e-04\n",
      "Epoch 91/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6487e-04 - rmse: 0.0128 - val_loss: 0.0029 - val_rmse: 0.0541 - lr: 1.0000e-04\n",
      "Epoch 92/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0314e-04 - rmse: 0.0143 - val_loss: 0.0031 - val_rmse: 0.0559 - lr: 1.0000e-04\n",
      "Epoch 93/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0547e-04 - rmse: 0.0103 - val_loss: 0.0026 - val_rmse: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 94/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1297e-04 - rmse: 0.0106 - val_loss: 0.0030 - val_rmse: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 95/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2945e-05 - rmse: 0.0091 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 96/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0915e-05 - rmse: 0.0090 - val_loss: 0.0029 - val_rmse: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 97/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1142e-04 - rmse: 0.0106 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 98/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2036e-04 - rmse: 0.0110 - val_loss: 0.0030 - val_rmse: 0.0546 - lr: 1.0000e-04\n",
      "Epoch 99/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5883e-04 - rmse: 0.0161 - val_loss: 0.0028 - val_rmse: 0.0525 - lr: 1.0000e-04\n",
      "Epoch 100/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2882e-04 - rmse: 0.0151 - val_loss: 0.0030 - val_rmse: 0.0548 - lr: 1.0000e-04\n",
      "Epoch 101/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.7748e-04 - rmse: 0.0167 - val_loss: 0.0031 - val_rmse: 0.0558 - lr: 1.0000e-04\n",
      "Epoch 102/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.3284e-04 - rmse: 0.0182 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 103/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4601e-04 - rmse: 0.0186 - val_loss: 0.0029 - val_rmse: 0.0538 - lr: 1.0000e-04\n",
      "Epoch 104/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.3842e-04 - rmse: 0.0154 - val_loss: 0.0029 - val_rmse: 0.0542 - lr: 1.0000e-04\n",
      "Epoch 105/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4940e-04 - rmse: 0.0122 - val_loss: 0.0025 - val_rmse: 0.0497 - lr: 1.0000e-04\n",
      "Epoch 106/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2010e-04 - rmse: 0.0148 - val_loss: 0.0031 - val_rmse: 0.0555 - lr: 1.0000e-04\n",
      "Epoch 107/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7511e-04 - rmse: 0.0132 - val_loss: 0.0029 - val_rmse: 0.0539 - lr: 1.0000e-04\n",
      "Epoch 108/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5066e-04 - rmse: 0.0158 - val_loss: 0.0032 - val_rmse: 0.0564 - lr: 1.0000e-04\n",
      "Epoch 109/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5834e-04 - rmse: 0.0161 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 1.0000e-04\n",
      "Epoch 110/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6718e-04 - rmse: 0.0163 - val_loss: 0.0029 - val_rmse: 0.0541 - lr: 1.0000e-04\n",
      "Epoch 111/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.0429e-04 - rmse: 0.0174 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 112/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7484e-04 - rmse: 0.0132 - val_loss: 0.0034 - val_rmse: 0.0587 - lr: 1.0000e-04\n",
      "Epoch 113/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2182e-04 - rmse: 0.0149 - val_loss: 0.0031 - val_rmse: 0.0555 - lr: 1.0000e-04\n",
      "Epoch 114/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9656e-04 - rmse: 0.0199 - val_loss: 0.0027 - val_rmse: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 115/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9910e-04 - rmse: 0.0200 - val_loss: 0.0031 - val_rmse: 0.0556 - lr: 1.0000e-04\n",
      "Epoch 116/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0512e-04 - rmse: 0.0266 - val_loss: 0.0034 - val_rmse: 0.0582 - lr: 1.0000e-04\n",
      "Epoch 117/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0031 - rmse: 0.0556 - val_loss: 0.0082 - val_rmse: 0.0905 - lr: 1.0000e-04\n",
      "Epoch 118/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0025 - rmse: 0.0501 - val_loss: 0.0020 - val_rmse: 0.0443 - lr: 1.0000e-04\n",
      "Epoch 119/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0017 - rmse: 0.0417 - val_loss: 0.0036 - val_rmse: 0.0603 - lr: 1.0000e-04\n",
      "Epoch 120/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0014 - rmse: 0.0374 - val_loss: 0.0023 - val_rmse: 0.0482 - lr: 1.0000e-04\n",
      "Epoch 121/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9429e-04 - rmse: 0.0315 - val_loss: 0.0058 - val_rmse: 0.0762 - lr: 1.0000e-04\n",
      "Epoch 122/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0014 - rmse: 0.0381 - val_loss: 0.0020 - val_rmse: 0.0445 - lr: 1.0000e-04\n",
      "Epoch 123/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0017 - rmse: 0.0407 - val_loss: 0.0042 - val_rmse: 0.0645 - lr: 1.0000e-04\n",
      "Epoch 124/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0012 - rmse: 0.0343 - val_loss: 0.0041 - val_rmse: 0.0640 - lr: 1.0000e-04\n",
      "Epoch 125/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1687e-04 - rmse: 0.0286 - val_loss: 0.0040 - val_rmse: 0.0631 - lr: 1.0000e-04\n",
      "Epoch 126/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0018 - rmse: 0.0419 - val_loss: 0.0044 - val_rmse: 0.0665 - lr: 1.0000e-04\n",
      "Epoch 127/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0015 - rmse: 0.0388 - val_loss: 0.0033 - val_rmse: 0.0578 - lr: 1.0000e-04\n",
      "Epoch 128/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0014 - rmse: 0.0376 - val_loss: 0.0037 - val_rmse: 0.0608 - lr: 1.0000e-04\n",
      "Epoch 129/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9476e-04 - rmse: 0.0299 - val_loss: 0.0029 - val_rmse: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 130/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0015 - rmse: 0.0382 - val_loss: 0.0019 - val_rmse: 0.0437 - lr: 1.0000e-04\n",
      "Epoch 131/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0010 - rmse: 0.0321 - val_loss: 0.0031 - val_rmse: 0.0558 - lr: 1.0000e-04\n",
      "Epoch 132/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8492e-04 - rmse: 0.0242 - val_loss: 0.0031 - val_rmse: 0.0553 - lr: 1.0000e-04\n",
      "Epoch 133/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2967e-04 - rmse: 0.0305 - val_loss: 0.0018 - val_rmse: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 134/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1514e-04 - rmse: 0.0178 - val_loss: 0.0024 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 135/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3433e-04 - rmse: 0.0153 - val_loss: 0.0019 - val_rmse: 0.0440 - lr: 1.0000e-04\n",
      "Epoch 136/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.4331e-04 - rmse: 0.0156 - val_loss: 0.0023 - val_rmse: 0.0478 - lr: 1.0000e-04\n",
      "Epoch 137/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0851e-04 - rmse: 0.0144 - val_loss: 0.0022 - val_rmse: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 138/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1294e-04 - rmse: 0.0146 - val_loss: 0.0023 - val_rmse: 0.0480 - lr: 1.0000e-04\n",
      "Epoch 139/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3708e-04 - rmse: 0.0117 - val_loss: 0.0024 - val_rmse: 0.0492 - lr: 1.0000e-04\n",
      "Epoch 140/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5405e-04 - rmse: 0.0124 - val_loss: 0.0023 - val_rmse: 0.0479 - lr: 1.0000e-04\n",
      "Epoch 141/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5557e-04 - rmse: 0.0125 - val_loss: 0.0025 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 142/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8521e-04 - rmse: 0.0136 - val_loss: 0.0025 - val_rmse: 0.0501 - lr: 1.0000e-04\n",
      "Epoch 143/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2897e-04 - rmse: 0.0114 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 1.0000e-04\n",
      "Epoch 144/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2101e-04 - rmse: 0.0110 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 145/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3759e-04 - rmse: 0.0117 - val_loss: 0.0024 - val_rmse: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 146/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5102e-04 - rmse: 0.0123 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 147/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8106e-04 - rmse: 0.0135 - val_loss: 0.0025 - val_rmse: 0.0497 - lr: 1.0000e-04\n",
      "Epoch 148/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2703e-04 - rmse: 0.0113 - val_loss: 0.0022 - val_rmse: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 149/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6923e-04 - rmse: 0.0130 - val_loss: 0.0026 - val_rmse: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 150/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5995e-04 - rmse: 0.0161 - val_loss: 0.0030 - val_rmse: 0.0547 - lr: 1.0000e-04\n",
      "Epoch 151/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8254e-04 - rmse: 0.0196 - val_loss: 0.0021 - val_rmse: 0.0463 - lr: 1.0000e-04\n",
      "Epoch 152/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6714e-04 - rmse: 0.0163 - val_loss: 0.0026 - val_rmse: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 153/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9869e-04 - rmse: 0.0141 - val_loss: 0.0023 - val_rmse: 0.0477 - lr: 1.0000e-04\n",
      "Epoch 154/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3053e-04 - rmse: 0.0114 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 155/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3258e-04 - rmse: 0.0115 - val_loss: 0.0022 - val_rmse: 0.0466 - lr: 1.0000e-04\n",
      "Epoch 156/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2167e-04 - rmse: 0.0110 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 157/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0304e-04 - rmse: 0.0102 - val_loss: 0.0023 - val_rmse: 0.0484 - lr: 1.0000e-04\n",
      "Epoch 158/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3615e-04 - rmse: 0.0117 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 159/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.6049e-04 - rmse: 0.0127 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 160/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1388e-04 - rmse: 0.0107 - val_loss: 0.0025 - val_rmse: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 161/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7494e-04 - rmse: 0.0132 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 162/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6076e-05 - rmse: 0.0087 - val_loss: 0.0030 - val_rmse: 0.0546 - lr: 1.0000e-04\n",
      "Epoch 163/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2862e-04 - rmse: 0.0113 - val_loss: 0.0025 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 164/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1652e-05 - rmse: 0.0072 - val_loss: 0.0022 - val_rmse: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 165/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6693e-05 - rmse: 0.0061 - val_loss: 0.0026 - val_rmse: 0.0508 - lr: 1.0000e-04\n",
      "Epoch 166/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8799e-05 - rmse: 0.0054 - val_loss: 0.0023 - val_rmse: 0.0480 - lr: 1.0000e-04\n",
      "Epoch 167/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7096e-05 - rmse: 0.0069 - val_loss: 0.0028 - val_rmse: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 168/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3635e-05 - rmse: 0.0080 - val_loss: 0.0022 - val_rmse: 0.0468 - lr: 1.0000e-04\n",
      "Epoch 169/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.2773e-05 - rmse: 0.0073 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 170/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5429e-05 - rmse: 0.0081 - val_loss: 0.0023 - val_rmse: 0.0481 - lr: 1.0000e-04\n",
      "Epoch 171/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8953e-05 - rmse: 0.0070 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 1.0000e-04\n",
      "Epoch 172/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6675e-05 - rmse: 0.0075 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 173/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.3327e-05 - rmse: 0.0073 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 174/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6873e-05 - rmse: 0.0082 - val_loss: 0.0022 - val_rmse: 0.0473 - lr: 1.0000e-04\n",
      "Epoch 175/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5186e-05 - rmse: 0.0087 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 176/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3786e-05 - rmse: 0.0066 - val_loss: 0.0025 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 177/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.0830e-05 - rmse: 0.0056 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 178/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4146e-05 - rmse: 0.0058 - val_loss: 0.0024 - val_rmse: 0.0489 - lr: 1.0000e-04\n",
      "Epoch 179/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.2884e-05 - rmse: 0.0057 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 180/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2628e-05 - rmse: 0.0048 - val_loss: 0.0024 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 181/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7691e-05 - rmse: 0.0042 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 182/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5514e-05 - rmse: 0.0039 - val_loss: 0.0025 - val_rmse: 0.0496 - lr: 1.0000e-04\n",
      "Epoch 183/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.3592e-05 - rmse: 0.0049 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 184/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3696e-05 - rmse: 0.0037 - val_loss: 0.0025 - val_rmse: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 185/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2582e-05 - rmse: 0.0035 - val_loss: 0.0026 - val_rmse: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 186/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2871e-05 - rmse: 0.0036 - val_loss: 0.0024 - val_rmse: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 187/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0043e-05 - rmse: 0.0032 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 188/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6179e-06 - rmse: 0.0024 - val_loss: 0.0024 - val_rmse: 0.0491 - lr: 1.0000e-04\n",
      "Epoch 189/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5882e-06 - rmse: 0.0028 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 190/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1450e-05 - rmse: 0.0034 - val_loss: 0.0024 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 191/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5362e-05 - rmse: 0.0039 - val_loss: 0.0025 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 192/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1608e-05 - rmse: 0.0034 - val_loss: 0.0023 - val_rmse: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 193/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0915e-06 - rmse: 0.0028 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 194/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6329e-05 - rmse: 0.0040 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 195/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5679e-06 - rmse: 0.0028 - val_loss: 0.0025 - val_rmse: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 196/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0001e-06 - rmse: 0.0024 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 197/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1552e-06 - rmse: 0.0023 - val_loss: 0.0025 - val_rmse: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 198/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.4746e-06 - rmse: 0.0023 - val_loss: 0.0025 - val_rmse: 0.0498 - lr: 1.0000e-04\n",
      "Epoch 199/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9692e-06 - rmse: 0.0024 - val_loss: 0.0025 - val_rmse: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 200/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.2335e-06 - rmse: 0.0023 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 201/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0148e-06 - rmse: 0.0020 - val_loss: 0.0025 - val_rmse: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 202/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.8552e-06 - rmse: 0.0020 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 203/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.5950e-06 - rmse: 0.0021 - val_loss: 0.0024 - val_rmse: 0.0491 - lr: 1.0000e-04\n",
      "Epoch 204/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1364e-06 - rmse: 0.0023 - val_loss: 0.0025 - val_rmse: 0.0498 - lr: 1.0000e-04\n",
      "Epoch 205/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9818e-06 - rmse: 0.0030 - val_loss: 0.0025 - val_rmse: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 206/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8327e-06 - rmse: 0.0024 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 207/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7542e-06 - rmse: 0.0031 - val_loss: 0.0026 - val_rmse: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 208/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2849e-05 - rmse: 0.0036 - val_loss: 0.0023 - val_rmse: 0.0479 - lr: 1.0000e-04\n",
      "Epoch 209/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4146e-05 - rmse: 0.0038 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 210/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3220e-05 - rmse: 0.0036 - val_loss: 0.0024 - val_rmse: 0.0491 - lr: 1.0000e-04\n",
      "Epoch 211/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0485e-05 - rmse: 0.0032 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 212/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1390e-05 - rmse: 0.0034 - val_loss: 0.0024 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 213/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2073e-06 - rmse: 0.0030 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 214/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3124e-06 - rmse: 0.0029 - val_loss: 0.0024 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 215/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6569e-05 - rmse: 0.0041 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 216/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3019e-05 - rmse: 0.0048 - val_loss: 0.0025 - val_rmse: 0.0498 - lr: 1.0000e-04\n",
      "Epoch 217/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2290e-05 - rmse: 0.0047 - val_loss: 0.0024 - val_rmse: 0.0494 - lr: 1.0000e-04\n",
      "Epoch 218/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1720e-05 - rmse: 0.0034 - val_loss: 0.0028 - val_rmse: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 219/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.1635e-05 - rmse: 0.0047 - val_loss: 0.0023 - val_rmse: 0.0480 - lr: 1.0000e-04\n",
      "Epoch 220/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7867e-06 - rmse: 0.0031 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 221/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6461e-05 - rmse: 0.0041 - val_loss: 0.0023 - val_rmse: 0.0479 - lr: 1.0000e-04\n",
      "Epoch 222/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4561e-05 - rmse: 0.0038 - val_loss: 0.0026 - val_rmse: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 223/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4209e-05 - rmse: 0.0038 - val_loss: 0.0023 - val_rmse: 0.0482 - lr: 1.0000e-04\n",
      "Epoch 224/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4168e-05 - rmse: 0.0038 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 225/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3797e-05 - rmse: 0.0049 - val_loss: 0.0024 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 226/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8828e-05 - rmse: 0.0043 - val_loss: 0.0025 - val_rmse: 0.0499 - lr: 1.0000e-04\n",
      "Epoch 227/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8790e-05 - rmse: 0.0043 - val_loss: 0.0024 - val_rmse: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 228/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1908e-05 - rmse: 0.0035 - val_loss: 0.0024 - val_rmse: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 229/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9182e-05 - rmse: 0.0044 - val_loss: 0.0024 - val_rmse: 0.0489 - lr: 1.0000e-04\n",
      "Epoch 230/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9755e-05 - rmse: 0.0044 - val_loss: 0.0024 - val_rmse: 0.0492 - lr: 1.0000e-04\n",
      "Epoch 231/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3685e-05 - rmse: 0.0049 - val_loss: 0.0026 - val_rmse: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 232/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.2427e-05 - rmse: 0.0065 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 1.0000e-04\n",
      "Epoch 233/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6627e-05 - rmse: 0.0088 - val_loss: 0.0024 - val_rmse: 0.0489 - lr: 1.0000e-04\n",
      "Epoch 234/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5904e-05 - rmse: 0.0093 - val_loss: 0.0022 - val_rmse: 0.0464 - lr: 1.0000e-04\n",
      "Epoch 235/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5576e-04 - rmse: 0.0125 - val_loss: 0.0026 - val_rmse: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 236/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6835e-04 - rmse: 0.0130 - val_loss: 0.0023 - val_rmse: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 237/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0006e-04 - rmse: 0.0141 - val_loss: 0.0032 - val_rmse: 0.0566 - lr: 1.0000e-04\n",
      "Epoch 238/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9896e-04 - rmse: 0.0141 - val_loss: 0.0029 - val_rmse: 0.0541 - lr: 1.0000e-04\n",
      "Epoch 239/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1683e-04 - rmse: 0.0147 - val_loss: 0.0032 - val_rmse: 0.0567 - lr: 1.0000e-04\n",
      "Epoch 240/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5991e-04 - rmse: 0.0161 - val_loss: 0.0022 - val_rmse: 0.0469 - lr: 1.0000e-04\n",
      "Epoch 241/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7421e-04 - rmse: 0.0132 - val_loss: 0.0026 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 242/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2901e-04 - rmse: 0.0114 - val_loss: 0.0022 - val_rmse: 0.0470 - lr: 1.0000e-04\n",
      "Epoch 243/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.9282e-04 - rmse: 0.0171 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 244/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9257e-04 - rmse: 0.0243 - val_loss: 0.0029 - val_rmse: 0.0536 - lr: 1.0000e-04\n",
      "Epoch 245/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.2960e-04 - rmse: 0.0207 - val_loss: 0.0029 - val_rmse: 0.0542 - lr: 1.0000e-04\n",
      "Epoch 246/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.2488e-04 - rmse: 0.0180 - val_loss: 0.0033 - val_rmse: 0.0577 - lr: 1.0000e-04\n",
      "Epoch 247/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0811e-04 - rmse: 0.0202 - val_loss: 0.0023 - val_rmse: 0.0479 - lr: 1.0000e-04\n",
      "Epoch 248/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.3889e-04 - rmse: 0.0155 - val_loss: 0.0025 - val_rmse: 0.0495 - lr: 1.0000e-04\n",
      "Epoch 249/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8920e-04 - rmse: 0.0138 - val_loss: 0.0022 - val_rmse: 0.0468 - lr: 1.0000e-04\n",
      "Epoch 250/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6319e-04 - rmse: 0.0128 - val_loss: 0.0026 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 251/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2173e-04 - rmse: 0.0110 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 252/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.2603e-04 - rmse: 0.0112 - val_loss: 0.0023 - val_rmse: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 253/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6671e-05 - rmse: 0.0093 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 254/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1476e-04 - rmse: 0.0107 - val_loss: 0.0024 - val_rmse: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 255/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8705e-05 - rmse: 0.0083 - val_loss: 0.0024 - val_rmse: 0.0489 - lr: 1.0000e-04\n",
      "Epoch 256/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8085e-05 - rmse: 0.0076 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 257/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6427e-05 - rmse: 0.0060 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 258/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.5489e-05 - rmse: 0.0067 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 259/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4530e-05 - rmse: 0.0059 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 260/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4734e-05 - rmse: 0.0080 - val_loss: 0.0027 - val_rmse: 0.0517 - lr: 1.0000e-04\n",
      "Epoch 261/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3260e-05 - rmse: 0.0091 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 262/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1818e-04 - rmse: 0.0109 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 1.0000e-04\n",
      "Epoch 263/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6970e-04 - rmse: 0.0192 - val_loss: 0.0016 - val_rmse: 0.0397 - lr: 1.0000e-04\n",
      "Epoch 264/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3484e-04 - rmse: 0.0209 - val_loss: 0.0030 - val_rmse: 0.0549 - lr: 1.0000e-04\n",
      "Epoch 265/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5099e-04 - rmse: 0.0255 - val_loss: 0.0024 - val_rmse: 0.0495 - lr: 1.0000e-04\n",
      "Epoch 266/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9007e-04 - rmse: 0.0281 - val_loss: 0.0034 - val_rmse: 0.0582 - lr: 1.0000e-04\n",
      "Epoch 267/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1782e-04 - rmse: 0.0286 - val_loss: 0.0020 - val_rmse: 0.0449 - lr: 1.0000e-04\n",
      "Epoch 268/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0010 - rmse: 0.0317 - val_loss: 0.0035 - val_rmse: 0.0595 - lr: 1.0000e-04\n",
      "Epoch 269/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7916e-04 - rmse: 0.0261 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 270/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5189e-04 - rmse: 0.0309 - val_loss: 0.0038 - val_rmse: 0.0615 - lr: 1.0000e-04\n",
      "Epoch 271/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6149e-04 - rmse: 0.0190 - val_loss: 0.0034 - val_rmse: 0.0579 - lr: 1.0000e-04\n",
      "Epoch 272/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.6919e-04 - rmse: 0.0217 - val_loss: 0.0031 - val_rmse: 0.0559 - lr: 1.0000e-04\n",
      "Epoch 273/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0063e-04 - rmse: 0.0200 - val_loss: 0.0035 - val_rmse: 0.0592 - lr: 1.0000e-04\n",
      "Epoch 274/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7124e-04 - rmse: 0.0193 - val_loss: 0.0023 - val_rmse: 0.0481 - lr: 1.0000e-04\n",
      "Epoch 275/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.1758e-04 - rmse: 0.0178 - val_loss: 0.0034 - val_rmse: 0.0581 - lr: 1.0000e-04\n",
      "Epoch 276/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.4179e-04 - rmse: 0.0155 - val_loss: 0.0023 - val_rmse: 0.0477 - lr: 1.0000e-04\n",
      "Epoch 277/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5606e-04 - rmse: 0.0125 - val_loss: 0.0033 - val_rmse: 0.0575 - lr: 1.0000e-04\n",
      "Epoch 278/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7212e-05 - rmse: 0.0099 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 279/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2397e-05 - rmse: 0.0096 - val_loss: 0.0033 - val_rmse: 0.0578 - lr: 1.0000e-04\n",
      "Epoch 280/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3188e-05 - rmse: 0.0086 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 281/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.5220e-05 - rmse: 0.0067 - val_loss: 0.0030 - val_rmse: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 282/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3318e-05 - rmse: 0.0066 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 283/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6001e-05 - rmse: 0.0060 - val_loss: 0.0029 - val_rmse: 0.0537 - lr: 1.0000e-04\n",
      "Epoch 284/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9604e-05 - rmse: 0.0063 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 285/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.5968e-05 - rmse: 0.0060 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 286/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7003e-05 - rmse: 0.0041 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 1.0000e-04\n",
      "Epoch 287/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7874e-05 - rmse: 0.0042 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 288/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4965e-05 - rmse: 0.0039 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 1.0000e-04\n",
      "Epoch 289/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6131e-05 - rmse: 0.0040 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 290/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3315e-05 - rmse: 0.0036 - val_loss: 0.0028 - val_rmse: 0.0529 - lr: 1.0000e-04\n",
      "Epoch 291/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7237e-05 - rmse: 0.0042 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 292/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3805e-05 - rmse: 0.0037 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 293/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5531e-05 - rmse: 0.0039 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 294/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3972e-05 - rmse: 0.0037 - val_loss: 0.0026 - val_rmse: 0.0508 - lr: 1.0000e-04\n",
      "Epoch 295/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.9292e-05 - rmse: 0.0044 - val_loss: 0.0026 - val_rmse: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 296/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.1316e-05 - rmse: 0.0034 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 297/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2369e-06 - rmse: 0.0029 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 298/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9253e-06 - rmse: 0.0024 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 299/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3308e-06 - rmse: 0.0027 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 1.0000e-04\n",
      "Epoch 300/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9300e-06 - rmse: 0.0024 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 301/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8526e-06 - rmse: 0.0022 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 302/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7770e-06 - rmse: 0.0022 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 303/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4152e-06 - rmse: 0.0027 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 304/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6602e-06 - rmse: 0.0031 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 305/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2311e-05 - rmse: 0.0035 - val_loss: 0.0026 - val_rmse: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 306/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0129e-05 - rmse: 0.0032 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 307/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.7237e-05 - rmse: 0.0042 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 308/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7331e-06 - rmse: 0.0030 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 1.0000e-04\n",
      "Epoch 309/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.8248e-06 - rmse: 0.0030 - val_loss: 0.0025 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 310/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0791e-05 - rmse: 0.0033 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 311/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3371e-06 - rmse: 0.0027 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 312/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.5546e-05 - rmse: 0.0051 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 1.0000e-04\n",
      "Epoch 313/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8290e-05 - rmse: 0.0043 - val_loss: 0.0026 - val_rmse: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4652e-05 - rmse: 0.0038 - val_loss: 0.0025 - val_rmse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 315/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4902e-05 - rmse: 0.0059 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 316/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2428e-05 - rmse: 0.0047 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 317/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.0832e-05 - rmse: 0.0056 - val_loss: 0.0026 - val_rmse: 0.0507 - lr: 1.0000e-04\n",
      "Epoch 318/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6703e-05 - rmse: 0.0061 - val_loss: 0.0029 - val_rmse: 0.0539 - lr: 1.0000e-04\n",
      "Epoch 319/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6816e-05 - rmse: 0.0052 - val_loss: 0.0024 - val_rmse: 0.0490 - lr: 1.0000e-04\n",
      "Epoch 320/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.5306e-05 - rmse: 0.0074 - val_loss: 0.0029 - val_rmse: 0.0542 - lr: 1.0000e-04\n",
      "Epoch 321/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7187e-05 - rmse: 0.0061 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 322/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.1532e-05 - rmse: 0.0056 - val_loss: 0.0027 - val_rmse: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 323/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5120e-05 - rmse: 0.0074 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 324/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8416e-05 - rmse: 0.0076 - val_loss: 0.0026 - val_rmse: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 325/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.2271e-05 - rmse: 0.0072 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 1.0000e-04\n",
      "Epoch 326/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1463e-05 - rmse: 0.0096 - val_loss: 0.0025 - val_rmse: 0.0498 - lr: 1.0000e-04\n",
      "Epoch 327/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1308e-04 - rmse: 0.0106 - val_loss: 0.0030 - val_rmse: 0.0544 - lr: 1.0000e-04\n",
      "Epoch 328/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0296e-05 - rmse: 0.0084 - val_loss: 0.0025 - val_rmse: 0.0503 - lr: 1.0000e-04\n",
      "Epoch 329/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2858e-05 - rmse: 0.0085 - val_loss: 0.0027 - val_rmse: 0.0524 - lr: 1.0000e-04\n",
      "Epoch 330/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3228e-05 - rmse: 0.0066 - val_loss: 0.0024 - val_rmse: 0.0489 - lr: 1.0000e-04\n",
      "Epoch 331/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7606e-05 - rmse: 0.0069 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 332/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6359e-05 - rmse: 0.0060 - val_loss: 0.0025 - val_rmse: 0.0497 - lr: 1.0000e-04\n",
      "Epoch 333/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9087e-05 - rmse: 0.0063 - val_loss: 0.0027 - val_rmse: 0.0522 - lr: 1.0000e-04\n",
      "Epoch 334/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4050e-05 - rmse: 0.0066 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 335/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1269e-05 - rmse: 0.0078 - val_loss: 0.0026 - val_rmse: 0.0508 - lr: 1.0000e-04\n",
      "Epoch 336/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9038e-05 - rmse: 0.0062 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 337/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0218e-05 - rmse: 0.0071 - val_loss: 0.0024 - val_rmse: 0.0494 - lr: 1.0000e-04\n",
      "Epoch 338/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6251e-05 - rmse: 0.0051 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 339/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5782e-05 - rmse: 0.0040 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 1.0000e-04\n",
      "Epoch 340/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0916e-05 - rmse: 0.0046 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 341/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6544e-05 - rmse: 0.0041 - val_loss: 0.0026 - val_rmse: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 342/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3234e-05 - rmse: 0.0036 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 343/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4279e-05 - rmse: 0.0038 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 344/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0050e-05 - rmse: 0.0032 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 345/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4954e-05 - rmse: 0.0039 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 346/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3686e-05 - rmse: 0.0037 - val_loss: 0.0029 - val_rmse: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 347/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3164e-05 - rmse: 0.0036 - val_loss: 0.0026 - val_rmse: 0.0511 - lr: 1.0000e-04\n",
      "Epoch 348/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3355e-05 - rmse: 0.0037 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 349/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.4542e-06 - rmse: 0.0025 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 350/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7948e-06 - rmse: 0.0022 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 351/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2238e-06 - rmse: 0.0025 - val_loss: 0.0026 - val_rmse: 0.0513 - lr: 1.0000e-04\n",
      "Epoch 352/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2973e-05 - rmse: 0.0036 - val_loss: 0.0025 - val_rmse: 0.0500 - lr: 1.0000e-04\n",
      "Epoch 353/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6063e-05 - rmse: 0.0040 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 354/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4590e-05 - rmse: 0.0038 - val_loss: 0.0026 - val_rmse: 0.0506 - lr: 1.0000e-04\n",
      "Epoch 355/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1199e-05 - rmse: 0.0046 - val_loss: 0.0028 - val_rmse: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 356/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7944e-05 - rmse: 0.0042 - val_loss: 0.0028 - val_rmse: 0.0534 - lr: 1.0000e-04\n",
      "Epoch 357/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.6465e-05 - rmse: 0.0041 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 358/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6792e-05 - rmse: 0.0061 - val_loss: 0.0028 - val_rmse: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 359/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7295e-05 - rmse: 0.0061 - val_loss: 0.0024 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 360/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2577e-04 - rmse: 0.0112 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 361/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4163e-04 - rmse: 0.0119 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 362/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0088e-04 - rmse: 0.0100 - val_loss: 0.0030 - val_rmse: 0.0550 - lr: 1.0000e-04\n",
      "Epoch 363/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9481e-05 - rmse: 0.0077 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 364/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4136e-05 - rmse: 0.0066 - val_loss: 0.0031 - val_rmse: 0.0559 - lr: 1.0000e-04\n",
      "Epoch 365/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.6447e-05 - rmse: 0.0075 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 366/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8005e-05 - rmse: 0.0076 - val_loss: 0.0030 - val_rmse: 0.0552 - lr: 1.0000e-04\n",
      "Epoch 367/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7996e-05 - rmse: 0.0099 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 368/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2038e-05 - rmse: 0.0085 - val_loss: 0.0028 - val_rmse: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 369/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0059e-04 - rmse: 0.0100 - val_loss: 0.0024 - val_rmse: 0.0495 - lr: 1.0000e-04\n",
      "Epoch 370/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.0023e-05 - rmse: 0.0095 - val_loss: 0.0029 - val_rmse: 0.0542 - lr: 1.0000e-04\n",
      "Epoch 371/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1402e-04 - rmse: 0.0107 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 372/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0462e-05 - rmse: 0.0095 - val_loss: 0.0031 - val_rmse: 0.0556 - lr: 1.0000e-04\n",
      "Epoch 373/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1158e-05 - rmse: 0.0078 - val_loss: 0.0029 - val_rmse: 0.0540 - lr: 1.0000e-04\n",
      "Epoch 374/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.2846e-05 - rmse: 0.0073 - val_loss: 0.0027 - val_rmse: 0.0517 - lr: 1.0000e-04\n",
      "Epoch 375/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5624e-05 - rmse: 0.0081 - val_loss: 0.0028 - val_rmse: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 376/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.1367e-05 - rmse: 0.0064 - val_loss: 0.0026 - val_rmse: 0.0505 - lr: 1.0000e-04\n",
      "Epoch 377/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.9240e-05 - rmse: 0.0054 - val_loss: 0.0029 - val_rmse: 0.0537 - lr: 1.0000e-04\n",
      "Epoch 378/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.0448e-05 - rmse: 0.0055 - val_loss: 0.0025 - val_rmse: 0.0498 - lr: 1.0000e-04\n",
      "Epoch 379/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8614e-05 - rmse: 0.0043 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 380/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.0270e-05 - rmse: 0.0055 - val_loss: 0.0026 - val_rmse: 0.0509 - lr: 1.0000e-04\n",
      "Epoch 381/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4663e-05 - rmse: 0.0038 - val_loss: 0.0029 - val_rmse: 0.0539 - lr: 1.0000e-04\n",
      "Epoch 382/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9079e-05 - rmse: 0.0044 - val_loss: 0.0028 - val_rmse: 0.0530 - lr: 1.0000e-04\n",
      "Epoch 383/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3438e-05 - rmse: 0.0037 - val_loss: 0.0029 - val_rmse: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 384/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.8895e-05 - rmse: 0.0043 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 385/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5077e-05 - rmse: 0.0059 - val_loss: 0.0031 - val_rmse: 0.0557 - lr: 1.0000e-04\n",
      "Epoch 386/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7409e-05 - rmse: 0.0093 - val_loss: 0.0032 - val_rmse: 0.0565 - lr: 1.0000e-04\n",
      "Epoch 387/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1287e-04 - rmse: 0.0106 - val_loss: 0.0032 - val_rmse: 0.0562 - lr: 1.0000e-04\n",
      "Epoch 388/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3082e-04 - rmse: 0.0114 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 389/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1299e-04 - rmse: 0.0106 - val_loss: 0.0020 - val_rmse: 0.0445 - lr: 1.0000e-04\n",
      "Epoch 390/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2733e-04 - rmse: 0.0113 - val_loss: 0.0033 - val_rmse: 0.0578 - lr: 1.0000e-04\n",
      "Epoch 391/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.1385e-04 - rmse: 0.0107 - val_loss: 0.0024 - val_rmse: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 392/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4731e-04 - rmse: 0.0121 - val_loss: 0.0035 - val_rmse: 0.0590 - lr: 1.0000e-04\n",
      "Epoch 393/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.4742e-04 - rmse: 0.0121 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 394/10000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.3374e-04 - rmse: 0.0116 - val_loss: 0.0031 - val_rmse: 0.0559 - lr: 1.0000e-04\n",
      "Epoch 395/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.7064e-04 - rmse: 0.0131 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 396/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.2877e-04 - rmse: 0.0151 - val_loss: 0.0024 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 397/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.4629e-04 - rmse: 0.0157 - val_loss: 0.0033 - val_rmse: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 398/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.2978e-04 - rmse: 0.0182 - val_loss: 0.0028 - val_rmse: 0.0533 - lr: 1.0000e-04\n",
      "Epoch 399/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4190e-04 - rmse: 0.0185 - val_loss: 0.0034 - val_rmse: 0.0583 - lr: 1.0000e-04\n",
      "Epoch 400/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6270e-04 - rmse: 0.0162 - val_loss: 0.0031 - val_rmse: 0.0561 - lr: 1.0000e-04\n",
      "Epoch 401/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3734e-04 - rmse: 0.0209 - val_loss: 0.0024 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 402/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3644e-04 - rmse: 0.0209 - val_loss: 0.0036 - val_rmse: 0.0602 - lr: 1.0000e-04\n",
      "Epoch 403/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3178e-04 - rmse: 0.0208 - val_loss: 0.0023 - val_rmse: 0.0484 - lr: 1.0000e-04\n",
      "Epoch 404/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.1212e-04 - rmse: 0.0177 - val_loss: 0.0039 - val_rmse: 0.0625 - lr: 1.0000e-04\n",
      "Epoch 405/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6600e-04 - rmse: 0.0163 - val_loss: 0.0028 - val_rmse: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 406/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0668e-04 - rmse: 0.0202 - val_loss: 0.0034 - val_rmse: 0.0579 - lr: 1.0000e-04\n",
      "Epoch 407/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4836e-04 - rmse: 0.0187 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 408/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5355e-04 - rmse: 0.0256 - val_loss: 0.0018 - val_rmse: 0.0419 - lr: 1.0000e-04\n",
      "Epoch 409/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6331e-04 - rmse: 0.0310 - val_loss: 0.0035 - val_rmse: 0.0590 - lr: 1.0000e-04\n",
      "Epoch 410/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6901e-04 - rmse: 0.0259 - val_loss: 0.0032 - val_rmse: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 411/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9888e-04 - rmse: 0.0300 - val_loss: 0.0037 - val_rmse: 0.0606 - lr: 1.0000e-04\n",
      "Epoch 412/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.6976e-04 - rmse: 0.0217 - val_loss: 0.0039 - val_rmse: 0.0626 - lr: 1.0000e-04\n",
      "Epoch 413/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0013 - rmse: 0.0360 - val_loss: 0.0039 - val_rmse: 0.0626 - lr: 1.0000e-04\n",
      "Epoch 414/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7189e-04 - rmse: 0.0278 - val_loss: 0.0030 - val_rmse: 0.0548 - lr: 1.0000e-04\n",
      "Epoch 415/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0745e-04 - rmse: 0.0284 - val_loss: 0.0019 - val_rmse: 0.0430 - lr: 1.0000e-04\n",
      "Epoch 416/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0033 - rmse: 0.0577 - val_loss: 0.0043 - val_rmse: 0.0654 - lr: 1.0000e-04\n",
      "Epoch 417/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0027 - rmse: 0.0522 - val_loss: 0.0058 - val_rmse: 0.0760 - lr: 1.0000e-04\n",
      "Epoch 418/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0036 - rmse: 0.0598 - val_loss: 0.0024 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 419/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0022 - rmse: 0.0466 - val_loss: 0.0034 - val_rmse: 0.0582 - lr: 1.0000e-04\n",
      "Epoch 420/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0013 - rmse: 0.0356 - val_loss: 0.0026 - val_rmse: 0.0508 - lr: 1.0000e-04\n",
      "Epoch 421/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0014 - rmse: 0.0378 - val_loss: 0.0025 - val_rmse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 422/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1361e-04 - rmse: 0.0302 - val_loss: 0.0031 - val_rmse: 0.0561 - lr: 1.0000e-04\n",
      "Epoch 423/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0012 - rmse: 0.0350 - val_loss: 0.0037 - val_rmse: 0.0608 - lr: 1.0000e-04\n",
      "Epoch 424/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0032 - rmse: 0.0563 - val_loss: 0.0048 - val_rmse: 0.0691 - lr: 1.0000e-04\n",
      "Epoch 425/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0029 - rmse: 0.0540 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 1.0000e-04\n",
      "Epoch 426/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0018 - rmse: 0.0424 - val_loss: 0.0047 - val_rmse: 0.0689 - lr: 1.0000e-04\n",
      "Epoch 427/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0012 - rmse: 0.0352 - val_loss: 0.0025 - val_rmse: 0.0501 - lr: 1.0000e-04\n",
      "Epoch 428/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4273e-04 - rmse: 0.0307 - val_loss: 0.0034 - val_rmse: 0.0586 - lr: 1.0000e-04\n",
      "Epoch 429/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4817e-04 - rmse: 0.0291 - val_loss: 0.0033 - val_rmse: 0.0571 - lr: 1.0000e-04\n",
      "Epoch 430/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3659e-04 - rmse: 0.0271 - val_loss: 0.0019 - val_rmse: 0.0441 - lr: 1.0000e-04\n",
      "Epoch 431/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4606e-04 - rmse: 0.0211 - val_loss: 0.0034 - val_rmse: 0.0587 - lr: 1.0000e-04\n",
      "Epoch 432/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4847e-04 - rmse: 0.0187 - val_loss: 0.0020 - val_rmse: 0.0446 - lr: 1.0000e-04\n",
      "Epoch 433/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5808e-04 - rmse: 0.0189 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 1.0000e-04\n",
      "Epoch 434/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8226e-04 - rmse: 0.0196 - val_loss: 0.0034 - val_rmse: 0.0581 - lr: 1.0000e-04\n",
      "Epoch 435/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0341e-04 - rmse: 0.0246 - val_loss: 0.0037 - val_rmse: 0.0605 - lr: 1.0000e-04\n",
      "Epoch 436/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8998e-04 - rmse: 0.0243 - val_loss: 0.0025 - val_rmse: 0.0495 - lr: 1.0000e-04\n",
      "Epoch 437/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9893e-04 - rmse: 0.0223 - val_loss: 0.0025 - val_rmse: 0.0498 - lr: 1.0000e-04\n",
      "Epoch 438/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2711e-04 - rmse: 0.0181 - val_loss: 0.0032 - val_rmse: 0.0570 - lr: 1.0000e-04\n",
      "Epoch 439/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.6407e-04 - rmse: 0.0163 - val_loss: 0.0032 - val_rmse: 0.0568 - lr: 1.0000e-04\n",
      "Epoch 440/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.4894e-04 - rmse: 0.0158 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 441/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5935e-04 - rmse: 0.0126 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 442/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0089e-04 - rmse: 0.0100 - val_loss: 0.0029 - val_rmse: 0.0535 - lr: 1.0000e-04\n",
      "Epoch 443/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0402e-04 - rmse: 0.0102 - val_loss: 0.0032 - val_rmse: 0.0563 - lr: 1.0000e-04\n",
      "Epoch 444/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3443e-04 - rmse: 0.0116 - val_loss: 0.0024 - val_rmse: 0.0485 - lr: 1.0000e-04\n",
      "Epoch 445/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5079e-04 - rmse: 0.0187 - val_loss: 0.0035 - val_rmse: 0.0588 - lr: 1.0000e-04\n",
      "Epoch 446/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8341e-04 - rmse: 0.0220 - val_loss: 0.0026 - val_rmse: 0.0510 - lr: 1.0000e-04\n",
      "Epoch 447/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.8999e-04 - rmse: 0.0170 - val_loss: 0.0023 - val_rmse: 0.0483 - lr: 1.0000e-04\n",
      "Epoch 448/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0556e-04 - rmse: 0.0143 - val_loss: 0.0030 - val_rmse: 0.0548 - lr: 1.0000e-04\n",
      "Epoch 449/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.3056e-04 - rmse: 0.0114 - val_loss: 0.0030 - val_rmse: 0.0543 - lr: 1.0000e-04\n",
      "Epoch 450/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1505e-04 - rmse: 0.0107 - val_loss: 0.0028 - val_rmse: 0.0526 - lr: 1.0000e-04\n",
      "Epoch 451/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1032e-04 - rmse: 0.0105 - val_loss: 0.0028 - val_rmse: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 452/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3163e-05 - rmse: 0.0086 - val_loss: 0.0029 - val_rmse: 0.0541 - lr: 1.0000e-04\n",
      "Epoch 453/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.2130e-05 - rmse: 0.0072 - val_loss: 0.0028 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 454/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0983e-05 - rmse: 0.0064 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 455/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8086e-05 - rmse: 0.0043 - val_loss: 0.0028 - val_rmse: 0.0531 - lr: 1.0000e-04\n",
      "Epoch 456/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4162e-05 - rmse: 0.0038 - val_loss: 0.0028 - val_rmse: 0.0527 - lr: 1.0000e-04\n",
      "Epoch 457/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2284e-05 - rmse: 0.0035 - val_loss: 0.0028 - val_rmse: 0.0532 - lr: 1.0000e-04\n",
      "Epoch 458/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7822e-05 - rmse: 0.0042 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 459/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3201e-05 - rmse: 0.0036 - val_loss: 0.0026 - val_rmse: 0.0514 - lr: 1.0000e-04\n",
      "Epoch 460/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.0840e-05 - rmse: 0.0033 - val_loss: 0.0027 - val_rmse: 0.0523 - lr: 1.0000e-04\n",
      "Epoch 461/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3419e-06 - rmse: 0.0027 - val_loss: 0.0027 - val_rmse: 0.0515 - lr: 1.0000e-04\n",
      "Epoch 462/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4078e-06 - rmse: 0.0025 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 463/10000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 7.0266e-06 - rmse: 0.0027\n",
      "Epoch 463: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7399e-06 - rmse: 0.0026 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 1.0000e-04\n",
      "Epoch 464/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.1073e-06 - rmse: 0.0020 - val_loss: 0.0026 - val_rmse: 0.0512 - lr: 5.0000e-05\n",
      "Epoch 465/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.6544e-06 - rmse: 0.0022 - val_loss: 0.0027 - val_rmse: 0.0524 - lr: 5.0000e-05\n",
      "Epoch 466/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5134e-06 - rmse: 0.0029 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 5.0000e-05\n",
      "Epoch 467/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7811e-06 - rmse: 0.0022 - val_loss: 0.0027 - val_rmse: 0.0521 - lr: 5.0000e-05\n",
      "Epoch 468/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.9598e-06 - rmse: 0.0020 - val_loss: 0.0026 - val_rmse: 0.0515 - lr: 5.0000e-05\n",
      "Epoch 469/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4070e-06 - rmse: 0.0021 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 5.0000e-05\n",
      "Epoch 470/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9265e-06 - rmse: 0.0020 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 471/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2635e-06 - rmse: 0.0018 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 5.0000e-05\n",
      "Epoch 472/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5579e-06 - rmse: 0.0019 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 473/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.0528e-06 - rmse: 0.0017 - val_loss: 0.0027 - val_rmse: 0.0516 - lr: 5.0000e-05\n",
      "Epoch 474/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2572e-06 - rmse: 0.0015 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 475/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.1030e-06 - rmse: 0.0015 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 476/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7273e-06 - rmse: 0.0013 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 477/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.8230e-06 - rmse: 0.0014 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 478/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.9088e-06 - rmse: 0.0014 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 479/10000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.2565e-06 - rmse: 0.0015 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 5.0000e-05\n",
      "Epoch 480/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.6979e-06 - rmse: 0.0016 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 481/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.7033e-06 - rmse: 0.0016 - val_loss: 0.0027 - val_rmse: 0.0517 - lr: 5.0000e-05\n",
      "Epoch 482/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.0652e-06 - rmse: 0.0014 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 5.0000e-05\n",
      "Epoch 483/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.7676e-06 - rmse: 0.0013 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 484/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4532e-06 - rmse: 0.0012 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 485/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.3265e-06 - rmse: 0.0012 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 486/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3321e-06 - rmse: 0.0012 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 487/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2840e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 488/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.4889e-06 - rmse: 0.0012 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 489/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.2044e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 490/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3045e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 491/10000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.2621e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 5.0000e-05\n",
      "Epoch 492/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.3751e-06 - rmse: 0.0012 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 493/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0932e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0520 - lr: 5.0000e-05\n",
      "Epoch 494/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0870e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 495/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1286e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 496/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0375e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 497/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1425e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 498/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0315e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 499/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0086e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 500/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0231e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 501/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.0239e-06 - rmse: 0.0010 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 502/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5450e-07 - rmse: 9.7698e-04 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 503/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3616e-07 - rmse: 9.6755e-04 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 504/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9439e-07 - rmse: 9.4572e-04 - val_loss: 0.0027 - val_rmse: 0.0519 - lr: 5.0000e-05\n",
      "Epoch 505/10000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.1689e-06 - rmse: 0.0011 - val_loss: 0.0027 - val_rmse: 0.0518 - lr: 5.0000e-05\n",
      "Epoch 506/10000\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 1.4496e-06 - rmse: 0.0012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSTEP_SIZE_TRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVALIDATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1433\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1434\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1443\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1444\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1445\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1458\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN, validation_steps=VALIDATION_STEPS,\n",
    "                    epochs=10000, shuffle=True, callbacks=[es, rp])\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = \"D:\\\\VAWT_data\\\\flap_steady\\\\flap_steady\\\\result\\\\\"+\"20221205AeroCNN2_optimalSettings\\\\test\"+str(test_rate)+\"Cdonly\"\n",
    "if not os.path.exists(storage_dir):\n",
    "    os.makedirs(storage_dir)\n",
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2, label='Training loss')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation loss')\n",
    "plt.title('Training loss (mean squared error)\\nAeroCNN-II, optimal settings, $C_d$ only', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"TrainingLoss_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.plot(hist['val_rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error, optimal settings, $C_d$ only', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['rmse'], lw=2, label='Training RMSE')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation RMSE')\n",
    "plt.title('Root Mean Squared Error\\nAeroCNN-II, optimal settings, $C_d$ only', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"RMSE_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc70d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745feda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train_ = model.predict(x_train)\n",
    "decoded_val_ = model.predict(x_val)\n",
    "decoded_test_ = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2202ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = np.unique(np.where(np.isin(cd, y_train)))\n",
    "index_val = np.unique(np.where(np.isin(cd, y_val)))\n",
    "index_test = np.unique(np.where(np.isin(cd, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train*(np.max(cd_orig)-np.min(cd_orig))+np.min(cd_orig)\n",
    "y_val = y_val*(np.max(cd_orig)-np.min(cd_orig))+np.min(cd_orig)\n",
    "y_test = y_test*(np.max(cd_orig)-np.min(cd_orig))+np.min(cd_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee135fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = decoded_train_*(np.max(cd_orig)-np.min(cd_orig))+np.min(cd_orig)\n",
    "decoded_val = decoded_val_*(np.max(cd_orig)-np.min(cd_orig))+np.min(cd_orig)\n",
    "decoded_test = decoded_test_*(np.max(cd_orig)-np.min(cd_orig))+np.min(cd_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d01da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20221205\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "os.chdir(model_directory)\n",
    "model_name = \"20221205steadyValidation_AeroCNN2_val_\"+str(val_rate)+\"_test\"+str(test_rate)+ \"_\" + str(n_kernels) +\"units_optimalSettings_Cdonly.h5\"\n",
    "model.save(model_name, overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = np.abs(decoded_train - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_abs = np.abs(decoded_test - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_train = np.sqrt(np.sum((decoded_train - y_train)**2) / np.sum(y_train**2))\n",
    "print(l2_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2917e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val = np.sqrt(np.sum((decoded_val - y_val)**2) / np.sum(y_val**2))\n",
    "print(l2_error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_test = np.sqrt(np.sum((decoded_test - y_test)**2) / np.sum(y_test**2))\n",
    "print(l2_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(x_train)):\n",
    "    l2_error_train_data = np.sqrt(np.sum((decoded_train[i] - y_train[i])**2) / np.sum(y_train[i]**2))\n",
    "    l2_error_train_list.append(l2_error_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val_list = []\n",
    "for i in range(0, len(x_val)):\n",
    "    l2_error_val_data = np.sqrt(np.sum((decoded_val[i] - y_val[i])**2) / np.sum((y_val[i]+1e-07)**2))\n",
    "    l2_error_val_list.append(l2_error_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(x_test)):\n",
    "    l2_error_test_data = np.sqrt(np.sum((decoded_test[i] - y_test[i])**2) / np.sum(y_test[i]**2))\n",
    "    l2_error_test_list.append(l2_error_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd795141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1,x_train.shape[0],x_train.shape[0]),\n",
    "         l2_error_train*np.ones(x_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, x_train.shape[0], x_train.shape[0]), l2_error_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - AeroCNN-II, training\\nValidation rate {0}, test rate {1}, optimal settings ($C_d$)'.format(\n",
    "    val_rate, test_rate), fontsize=15\n",
    "         )\n",
    "plt.grid()\n",
    "saveName = \"trainingErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1,x_val.shape[0],x_val.shape[0]),\n",
    "         l2_error_val*np.ones(x_val.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, x_val.shape[0], x_val.shape[0]), l2_error_val_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - AeroCNN-II, validation\\nValidation rate {0}, test rate {1}, optimal settings ($C_d$)'.format(\n",
    "    val_rate, test_rate), fontsize=15\n",
    "         )\n",
    "plt.grid()\n",
    "saveName = \"validationErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1,x_test.shape[0],x_test.shape[0]),\n",
    "         l2_error_test*np.ones(x_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, x_test.shape[0], x_test.shape[0]), l2_error_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - AeroCNN-II, test\\nValidation rate {0}, test rate {1}, optimal settings ($C_d$)'.format(\n",
    "    val_rate, test_rate), fontsize=15\n",
    "         )\n",
    "plt.grid()\n",
    "saveName = \"testErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8978795",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CD_trainTestSplit_Plot(i, CD, cd, aTrain, aTest, iTrain, iTest):\n",
    "    \n",
    "    title_0_Cd = 'Gurney flap not attached (NACA0018)\\n$C_D$ prediction, L2 error=%.4f' % l2_error_Cd\n",
    "    #title_0_Cl = 'Gurney flap not attached (NACA0018)\\n$C_L$ prediction, L2 error=%.4f' % l2_error_Cl\n",
    "    \n",
    "    title_n_Cd = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_D$ prediction, L2 error=%.4f'%(l2_error_Cd)\n",
    "    #title_n_Cl = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_L$ prediction, L2 error=%.4f'%(l2_error_Cl)\n",
    "    \n",
    "    if i==0:\n",
    "#         title_Cd, title_Cl = title_0_Cd, title_0_Cl\n",
    "#         savename1,savename2 = \"CdComparison_NACA0018.jpg\", \"ClComparison_NACA0018.jpg\"\n",
    "        title_Cd = title_0_Cd\n",
    "        savename1 = \"CdComparison_NACA0018.jpg\"\n",
    "    else:\n",
    "#         title_Cd, title_Cl = title_n_Cd, title_n_Cl\n",
    "        title_Cd = title_n_Cd\n",
    "        savename1 = \"CdComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "#         savename2 = \"ClComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    \n",
    "    # CD graph plot\n",
    "    plt.plot(alpha, CD, 'k-', label='Ground truth')\n",
    "    plt.plot(alpha, cd, 'k--', label='Predicted value')\n",
    "    plt.scatter(aTrain, iTrain, color='b', label='Training set')\n",
    "    plt.scatter(aVal, iVal, color='g', label='Validation set')\n",
    "    plt.scatter(aTest, iTest, color='r', label='Test set')\n",
    "    plt.xlabel('AoA (degree)')\n",
    "    plt.ylabel('$C_D$')\n",
    "    plt.title(title_Cd, fontsize=15)        \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0, 0.12])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    '''# CL graph plot\n",
    "    plt.plot(alpha, CL, 'k-', label='Ground truth')\n",
    "    plt.plot(alpha, cl, 'k--', label='Predicted value')\n",
    "    plt.scatter(aTrain, iTrain[:,1]*(np.max(cl_orig)-np.min(cl_orig)) + np.min(cl_orig), color='b', label='Training set')\n",
    "    plt.scatter(aTest, iTest[:,1]*(np.max(cl_orig)-np.min(cl_orig)) + np.min(cl_orig), color='r', label='Test set')\n",
    "    plt.xlabel('AoA (degree)')\n",
    "    plt.ylabel('$C_L$')\n",
    "    plt.title(title_Cl, fontsize=15)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0, 2])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename2, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [0, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.03, 0.03, 0.03, 0.03, 0.03]\n",
    "beta = [0, 30, 45, 60, 75, 90, 30, 45, 60, 75, 90, 30, 45, 60, 75, 90]\n",
    "for i in range(0, 16):\n",
    "    # Index from each dataset\n",
    "    iTrain = []\n",
    "    iVal = []\n",
    "    iTest = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    alpha_train = []\n",
    "    alpha_val = []\n",
    "    alpha_test = []\n",
    "    \n",
    "    predictedValue = model.predict(x[n_alpha*i:n_alpha*(i+1),:])\n",
    "    y_corres = y[n_alpha*i:n_alpha*(i+1),:]\n",
    "    \n",
    "    l2_error_Cd = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    if i==0:\n",
    "        print('NACA0018 airfoil without Gurney flap\\nL2 error of Cd: {0:0.4f}'.format(l2_error_Cd))\n",
    "    else:\n",
    "        print('L2 error of Cd: {0:0.4f}'.format(l2_error_Cd))\n",
    "    \n",
    "    cd = predicted[n_alpha*i:n_alpha*(i+1)]*(np.max(cd_orig)-np.min(cd_orig)) + np.min(cd_orig)\n",
    "    CD = y[n_alpha*i:n_alpha*(i+1)]*(np.max(cd_orig)-np.min(cd_orig)) + np.min(cd_orig)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*n_alpha) & ((index_train>=i*n_alpha)))]):\n",
    "        iTrain.append(predicted[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*n_alpha) & ((index_val>=i*n_alpha)))]):\n",
    "        iVal.append(predicted[index])    \n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*n_alpha) & (index_test>=i*n_alpha))]):\n",
    "        iTest.append(predicted[index])\n",
    "        \n",
    "    iTrain = np.array(iTrain)*(np.max(cd_orig)-np.min(cd_orig)) + np.min(cd_orig)\n",
    "    iTest = np.array(iTest)*(np.max(cd_orig)-np.min(cd_orig)) + np.min(cd_orig)\n",
    "    iVal = np.array(iVal)*(np.max(cd_orig)-np.min(cd_orig)) + np.min(cd_orig)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*n_alpha) & ((index_train>=i*n_alpha)))]):\n",
    "        alpha_train.append(aa[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*n_alpha) & ((index_val>=i*n_alpha)))]):\n",
    "        alpha_val.append(aa[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*n_alpha) & ((index_test>=i*n_alpha)))]):\n",
    "        alpha_test.append(aa[index])\n",
    "        \n",
    "    aTrain = np.array(alpha_train)*np.max(alpha)\n",
    "    aVal = np.array(alpha_val)*np.max(alpha)\n",
    "    aTest = np.array(alpha_test)*np.max(alpha)\n",
    "    \n",
    "    CD_trainTestSplit_Plot(i, CD, cd, aTrain, aTest, iTrain, iTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774efa2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
