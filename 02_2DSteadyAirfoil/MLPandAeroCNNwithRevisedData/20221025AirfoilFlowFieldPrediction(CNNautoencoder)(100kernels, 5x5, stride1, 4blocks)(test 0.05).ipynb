{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AeroCNN-II\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77da164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78591a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy([\"/GPU:0\",\"/GPU:1\", \"/GPU:2\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernel=100\n",
    "l2Regularizer=1e-09\n",
    "kernel_size1 = 5\n",
    "kernel_size2 = 5\n",
    "#kernel_size3 = 5\n",
    "n_grid = 128\n",
    "strides = 1\n",
    "input_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d7f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.linspace(-10,20,16).reshape((16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f0eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.zeros((16*133,1))\n",
    "for i in range(0, 133):\n",
    "    aa[16*i:16*(i+1), :] = alpha[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e191fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = aa.reshape((133, 16, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ba4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\AeroCNN2Inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = \"D:\\\\AeroCNN2Inputs\"\n",
    "origin_data = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\"\n",
    "origin_coord = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a9cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_orig = os.listdir(origin)\n",
    "folders = [file for file in folders_orig if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c16d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for j in range(0, alpha.shape[0]):\n",
    "        csv_file_name = origin + '\\\\airfoil' + str(i) + \"_alpha\"+ str(int(alpha[j])) + \".csv\"\n",
    "        data = pd.read_csv(csv_file_name, header=None)\n",
    "        image_df = pd.concat([image_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa448a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_np = image_df.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba6d479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_np.reshape((133, 16, n_grid+1, n_grid+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "438d1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 1-image/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d6b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\airfoilFlowField'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0bd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = origin_data + \"\\\\AirfoilIndexList.xlsx\"\n",
    "airfoilName_df = pd.read_excel(file_name)\n",
    "geometry_orig = airfoilName_df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b3225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\airfoilFlowField\\airfoil1alpha-8_interpolated.csv\n"
     ]
    }
   ],
   "source": [
    "data_name = path + '\\\\' + str(geometry_orig[0]) + \"alpha\"+ str(int(alpha[1])) + \"_interpolated.csv\"\n",
    "print(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7049560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\rotatedInterpolation_pow2\\\\n_grid128\\\\velocityMagnitudeField'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa87b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmag_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for j in range(0, alpha.shape[0]):\n",
    "        data_name = path + '\\\\' + str(geometry_orig[i-1]) + \"alpha\"+ str(int(alpha[j])) + \"_velocityMagnitudeInterpolated.csv\"\n",
    "        data = pd.read_csv(data_name, header=None)\n",
    "        Vmag_df = pd.concat([Vmag_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "997d7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imp = Vmag_df.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88dd409c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274512, 129)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08309a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272448"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "132*16*129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cd109b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35412048"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_grid+1)**2 * 133 *16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9aa02000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2128"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "133*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31449c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_imp.reshape((133, 16, n_grid+1, n_grid+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb3458bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = np.zeros((133*16,1))\n",
    "geometry = geometry.astype(np.string_)\n",
    "for i in geometry_orig:\n",
    "    index_ = np.where(geometry_orig==i)\n",
    "    for j in range(0,16):\n",
    "        geometry[16*index_[0]+j,:] = np.asarray(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e31070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a65b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = geometry.reshape((133, 16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train, x_test, aa_train, aa_test, geo_train, geo_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(image, aa, geometry, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, aa_train, aa_test, geo_train, geo_test, y_train, y_test = train_test_split(image, aa, geometry, y, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0290ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mx_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mreshape((x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mx_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      3\u001b[0m aa_train \u001b[38;5;241m=\u001b[39m aa_train\u001b[38;5;241m.\u001b[39mreshape((aa_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39maa_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], aa_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], aa_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0]*x_train.shape[1], x_train.shape[2], x_train.shape[3], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0]*x_test.shape[1], x_test.shape[2], x_test.shape[3], 1))\n",
    "aa_train = aa_train.reshape((aa_train.shape[0]*aa_train.shape[1], aa_train.shape[2], aa_train.shape[3]))\n",
    "aa_test = aa_test.reshape((aa_test.shape[0]*aa_test.shape[1], aa_test.shape[2], aa_test.shape[3]))\n",
    "geo_train = geo_train.reshape((geo_train.shape[0]*geo_train.shape[1], geo_train.shape[2]))\n",
    "geo_test = geo_test.reshape((geo_test.shape[0]*geo_test.shape[1], geo_test.shape[2]))\n",
    "y_train = y_train.reshape((y_train.shape[0]*y_train.shape[1], y_train.shape[2], y_train.shape[3],1))\n",
    "y_test = y_test.reshape((y_test.shape[0]*y_test.shape[1], y_test.shape[2], y_test.shape[3],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "input_image = tf.keras.Input(shape=(100, 100,1))\n",
    "\n",
    "x_conv = tf.keras.layers.Conv2D(n_kernel, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                name='Conv2DLayer1')(input_image)\n",
    "x_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv)\n",
    "x_conv = tf.keras.layers.Conv2D(n_kernel*2, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                name='Conv2DLayer2')(x_)\n",
    "x_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv)\n",
    "x_conv = tf.keras.layers.Conv2D(n_kernel*4, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                name='Conv2DLayer3')(x_)\n",
    "x_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv)\n",
    "\n",
    "x_ = tf.keras.layers.Conv2DTranspose(n_kernel*4, (kernel_size1, kernel_size1), strides = (2, 2),\n",
    "                                     padding='same', activation='relu')(x_)\n",
    "x_ = tf.keras.layers.Conv2DTranspose(n_kernel*2, (kernel_size1, kernel_size1), strides = (2, 2),\n",
    "                                     padding='same', activation='relu')(x_)\n",
    "x_ = tf.keras.layers.Conv2DTranspose(n_kernel, (kernel_size1, kernel_size1), strides = (2, 2),\n",
    "                                     padding='same', activation='relu')(x_)\n",
    "\n",
    "output_impr = tf.keras.layers.Conv2D(1, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                     activation='relu', padding='same',\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                     name='Conv2Doutput')(x_)\n",
    "x_ = tf.keras.layers.Flatten()(output_impr)\n",
    "x_ = tf.keras.layers.Dense(units=(n_grid+1)**2, activation='linear', name='outputLayer')(x_)\n",
    "output_data = tf.keras.layers.Reshape((n_grid+1, n_grid+1,1))(x_)\n",
    "# CNN autoencoder\n",
    "model = tf.keras.Model(input_image, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " Conv2DLayer1 (Conv2D)       (None, 100, 100, 100)     2600      \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 50, 50, 100)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " Conv2DLayer2 (Conv2D)       (None, 50, 50, 200)       500200    \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 25, 25, 200)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " Conv2DLayer3 (Conv2D)       (None, 25, 25, 400)       2000400   \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 12, 12, 400)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose_48 (Conv2D  (None, 24, 24, 400)      4000400   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_49 (Conv2D  (None, 48, 48, 200)      2000200   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_50 (Conv2D  (None, 96, 96, 100)      500100    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " Conv2Doutput (Conv2D)       (None, 96, 96, 1)         2501      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 16641)             153380097 \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 129, 129, 1)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,386,498\n",
      "Trainable params: 162,386,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss = tf.keras.losses.MeanSquaredError(),\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 539, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 646, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 860, in _create_all_weights\n        self._create_slots(var_list)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 122, in _create_slots\n        self.add_slot(var, 'm')\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 946, in add_slot\n        weight = tf.Variable(\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\", line 152, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: OOM when allocating tensor with shape[16384,16641] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#with mirrored_strategy.scope():\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1127\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1128\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 539, in minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 646, in apply_gradients\n        self._create_all_weights(var_list)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 860, in _create_all_weights\n        self._create_slots(var_list)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py\", line 122, in _create_slots\n        self.add_slot(var, 'm')\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 946, in add_slot\n        weight = tf.Variable(\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\", line 152, in __call__\n        return tf.zeros(shape, dtype)\n\n    ResourceExhaustedError: OOM when allocating tensor with shape[16384,16641] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    start = datetime.datetime.now()\n",
    "    history = model.fit(x_train, y_train, epochs=5000, shuffle=True,\n",
    "                        callbacks=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100,\n",
    "                                                                   restore_best_weights=True))\n",
    "    end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2)\n",
    "plt.title('Training loss (mean squared error)\\nCNN Autoencoder', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error\\nCNN Autoencoder', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745feda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    test_results = model.evaluate(x_train)\n",
    "    decoded_train = model.predict(x_train)\n",
    "    decoded_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results2 = model.evaluate(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fd234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(decoded_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f887b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(decoded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfe737",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(n_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = decoded_train.reshape((int(y_train.shape[0]),int(n_grid),int(n_grid)))\n",
    "decoded_test = decoded_test.reshape((int(y_test.shape[0]),int(n_grid),int(n_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9fc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = np.abs(decoded_train - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_abs = np.abs(decoded_test - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_Cl_abs = np.abs(decoded_train[:,0,:] - y_train[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_Cd_abs = np.abs(decoded_train[:,1,:] - y_train[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_Cl_abs = np.abs(decoded_test[:,0,:] - y_test[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_Cd_abs = np.abs(decoded_test[:,1,:] - y_test[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c9ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\\\TrainedModels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\\\TrainedModels\\\\20221024\")\n",
    "model.save('CNNautoencoder_FlowFieldPrediction_100kernel_2by2MaxPooling_4blocks_testSize0.05.h5',\n",
    "           overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_train = np.sqrt(np.sum((decoded_train - y_train)**2) / np.sum(y_train**2))\n",
    "print(l2_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_test = np.sqrt(np.sum((decoded_test - y_test)**2) / np.sum(y_test**2))\n",
    "print(l2_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(aa_train)):\n",
    "    l2_error_train_data = np.sqrt(np.sum((decoded_train[i] - y_train[i])**2) / np.sum(y_train[i]**2))\n",
    "    l2_error_train_list.append(l2_error_train_data)\n",
    "print(l2_error_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(aa_test)):\n",
    "    l2_error_test_data = np.sqrt(np.sum((decoded_test[i] - y_test[i])**2) / np.sum(y_test[i]**2))\n",
    "    l2_error_test_list.append(l2_error_test_data)\n",
    "print(l2_error_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd795141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_train.shape[0], aa_train.shape[0]),\n",
    "         l2_error_train*np.ones(aa_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_train.shape[0], aa_train.shape[0]), l2_error_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, training\\nFlow field prediction, 1 CNN layer, 50 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, test\\nFlow field prediction, 1 CNN layer, 50 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddbea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_test2_rotate = y_test[2*16+c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_test[2*16+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    xrange = np.linspace(-2, 2, n_grid)\n",
    "    yrange = np.linspace(-2, 2, n_grid)\n",
    "    xmesh, ymesh = np.meshgrid(xrange, yrange)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_test2_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Test dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_test2[2*16+c])[3:-2], aa_test[2*16+c]),fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369c4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_test0_rotate = y_test[c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_test[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    xrange = np.linspace(-2, 2, n_grid)\n",
    "    yrange = np.linspace(-2, 2, n_grid)\n",
    "    xmesh, ymesh = np.meshgrid(xrange, yrange)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_test0_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Test dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_test2[c])[3:-2], aa_test[c]),fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e49554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_train0_rotate = y_train[c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_train[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    xrange = np.linspace(-2, 2, n_grid)\n",
    "    yrange = np.linspace(-2, 2, n_grid)\n",
    "    xmesh, ymesh = np.meshgrid(xrange, yrange)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_train0_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Training dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_train2[c])[3:-2], aa_train[c]),fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd7cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_train20_rotate = y_train[20*16+c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_train[20*16+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    xrange = np.linspace(-2, 2, n_grid)\n",
    "    yrange = np.linspace(-2, 2, n_grid)\n",
    "    xmesh, ymesh = np.meshgrid(xrange, yrange)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_train20_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=0, vmax=11, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Training dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_train2[20*16+c])[3:-2], aa_train[20*16+c]),fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_test_abs2_rotate = error_test_abs[2*16+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_test_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_test2[2*16+c])[3:-2],\n",
    "                                                                       aa_test[2*16+c], l2_error_test_list[2*16+c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c85b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_test_abs2_rotate = error_test_abs[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_test_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_test2[c])[3:-2],\n",
    "                                                                       aa_test[c], l2_error_test_list[c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_train_abs2_rotate = error_train_abs[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_train_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_train2[c])[3:-2],\n",
    "                                                                       aa_train[c], l2_error_train_list[c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_train_abs2_rotate = error_train_abs[16*20+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_train_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_train2[16*20+c])[3:-2],\n",
    "                                                                       aa_train[16*20+c], l2_error_train_list[16*20+c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ede101",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = origin_data + \"\\\\AirfoilIndexList.xlsx\"\n",
    "airfoilName_df = pd.read_excel(file_name)\n",
    "geometry_orig2 = airfoilName_df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = geometry.reshape((133, 16, 1))\n",
    "geometry2 = np.zeros((133*16,1))\n",
    "geometry2 = geometry2.astype(np.string_)\n",
    "for i in geometry_orig2:\n",
    "    index_ = np.where(geometry_orig2==i)\n",
    "    for j in range(0,16):\n",
    "        geometry2[16*index_[0]+j,:] = np.asarray(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b84a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry2 = geometry2.reshape((133, 16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, geo_train, geo_test, geo_train2, geo_test2 = train_test_split(1-image_np.reshape((133, 16, 100, 100))/1000, geometry, geometry2, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db403559",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_train2 = geo_train2.reshape((geo_train.shape[0]*geo_train.shape[1], geo_train.shape[2]))\n",
    "geo_test2 = geo_test2.reshape((geo_test.shape[0]*geo_test.shape[1], geo_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7472bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
