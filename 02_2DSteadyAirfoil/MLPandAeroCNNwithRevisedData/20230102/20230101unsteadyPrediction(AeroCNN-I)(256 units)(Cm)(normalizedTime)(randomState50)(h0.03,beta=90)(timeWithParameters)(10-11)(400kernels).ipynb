{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of the steady-state simulation - Case 2: AeroCNN-I\n",
    "##\n",
    "## 1. Train/Validation/Test dataset ratio = 0.7/0.2/0.1\n",
    "## 2. Using CNN structure to extract geometry features (characteristics)\n",
    "## 3. The time interval used to train is revolution 10 to 11.\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining parameters and hyperparameters of the model\n",
    "\n",
    "n_kernels=400 # Number of filters (kernels) in Convolutional layer\n",
    "n_units=256 # Number of units in the hidden layer of the MLP network\n",
    "n_layers=5\n",
    "input_size = 110 # Size of input for the network (110 coefficients and 3 other parameters, time, h, beta)\n",
    "lr = 1e-04 # Learning rate of the network\n",
    "test_rate = 0.1 # Defines the ratio of test dataset\n",
    "val_rate = 0.2 # Defines the ratio of validation dataset\n",
    "batch_size = 200 # Mini-batch size\n",
    "l2_regularizer=1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0439fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of revolution\n",
    "t_lower = 10 # Lower limit of the interval of time\n",
    "t_upper = 11 # Upper limit of the interval of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing working directory\n",
    "\n",
    "main_directory = 'D:\\\\VAWT_data\\\\flap_steady\\\\flap_steady'\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ec4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case number: NACA 0018 without Gurney flap - case 0\n",
    "# the others, which are Case 1,2,4,5,7,8,13,14,15,16,17,18,19,20,21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb294db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic parameters\n",
    "\n",
    "c = 1 # Chord length\n",
    "h = np.array([0.01, 0.02, 0.03]) * c # Height of the Gurney flaps\n",
    "thickness = 0.02 * h # Thickness of the Gurney flaps\n",
    "beta = np.linspace(30, 90, 5).reshape((5,1))\n",
    "\n",
    "beta = beta[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18aaa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.reshape((-1,1))\n",
    "thickness = thickness.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9745480",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interval = 0.001\n",
    "t_len = int((t_upper-t_lower) / t_interval)\n",
    "\n",
    "n_beta = len(beta)# Number of the Gurney flap inclination\n",
    "n_h = len(h) # Number of the height of the Gurney flaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d7f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Input dataset\n",
    "# Defining time as input\n",
    "\n",
    "main_directory = 'D:\\\\VAWT_data'\n",
    "cm_dir = main_directory + \"\\\\blade_1_cm_data\"\n",
    "cm_list = os.listdir(cm_dir)\n",
    "os.chdir(cm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5014fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_target = [file for file in cm_list if file.endswith('.csv')]\n",
    "cm_target = sorted(cm_target, key=lambda s: int(re.search(r'\\d+',s).group()))\n",
    "cm_target = [cm_target[-8],]\n",
    "n_data = len(cm_target) # Number of txt files from which the aerodynamic coefficients are extracted\n",
    "n_cases = n_data * t_len # Total number of cases(Number of geometries * Number of angles of attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d3bbcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['case15cm_blade1.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62d3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create input and output data\n",
    "### This function is the main framework where data are reordered with respect to the shape the NNs require.\n",
    "### Each input features are made by calling the corresponding functions, which generate the data,\n",
    "### e.g., time, cm, h, beta, coordinates of airfoil and Gurney flaps, etc.\n",
    "def genereate_input_output(cm_target, n_beta, t_len, normalize:bool=False):\n",
    "    \n",
    "    input_time_cm = time_and_cm(cm_target)\n",
    "    t = input_time_cm[:,0].reshape((-1, 1))\n",
    "    cm = input_time_cm[:,1].reshape((-1, 1))\n",
    "    \n",
    "    #hh = generate_h(n_beta, t_len, normalize)\n",
    "    #bb = generate_beta(n_beta, t_len, normalize)\n",
    "    total_coords = generate_coordinates(n_cases)\n",
    "    \n",
    "    # Concatenate data for input dataset\n",
    "    x_time = t\n",
    "    x_coord = total_coords.reshape((t_len,2,55,1))\n",
    "    \n",
    "    # Generating output dataset (depending on whether the data be normalized or not)\n",
    "    if normalize==True:\n",
    "        y = (cm-np.min(cm))/(np.max(cm)-np.min(cm))\n",
    "    else:\n",
    "        y = cm\n",
    "    print(\"Dimension - x_time: \", x_time.shape)\n",
    "    print(\"Dimension - x_coordinates: \", x_coord.shape)\n",
    "    print(\"Dimension - y: \", y.shape)\n",
    "    \n",
    "    return x_time, x_coord, y, t, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa96208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating time for input, and Cm (moment coefficient) for output\n",
    "def time_and_cm(cm_target):\n",
    "    cm_df = pd.DataFrame()\n",
    "    for i, file in enumerate(cm_target):\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        data = pd.read_csv(file, header=None)\n",
    "        df = pd.concat([df, data], axis=0)\n",
    "        \n",
    "        time = df.iloc[:,0].values\n",
    "        cm = df.iloc[:,1].values\n",
    "        \n",
    "        time_beUsed = time[np.where(np.logical_and(time>=t_lower, time<t_upper))]\n",
    "        cm_beUsed = cm[np.where(np.logical_and(time>=t_lower, time<t_upper))]\n",
    "        \n",
    "        # Handle the time that is duplicated because of digits\n",
    "        # Also, outliers are regulated at the second conditional statement.\n",
    "        time_beUsed = handler_time(time_beUsed)\n",
    "        cm_beUsed = handler_cm(cm_beUsed)\n",
    "        \n",
    "        linear_func = interpolate.interp1d(time_beUsed, cm_beUsed,\n",
    "                                           bounds_error=False,kind='quadratic',\n",
    "                                           fill_value='extrapolate')\n",
    "        time_interp = np.arange(10, 11, t_interval).reshape((-1,1))\n",
    "        cm_interp=linear_func(time_interp).reshape((-1,1))\n",
    "        \n",
    "        cm_df = pd.concat([cm_df, pd.DataFrame(np.hstack((time_interp, cm_interp)))], axis=0)\n",
    "    \n",
    "    input_time_cm = cm_df.iloc[:,:].values\n",
    "    print(\"Dimension - time and Cm: \", input_time_cm.shape)\n",
    "    return input_time_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c96f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling duplicated time value\n",
    "def handler_time(time_beUsed):\n",
    "    for i in range(len(time_beUsed)):\n",
    "        if time_beUsed[i]==time_beUsed[i-1]:\n",
    "            time_beUsed[i] += 0.0005\n",
    "            \n",
    "    return time_beUsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d715ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outlier, (if there are)\n",
    "def handler_cm(cm_beUsed):\n",
    "    period = int(len(cm_beUsed) / 5)\n",
    "    for i in range(len(cm_beUsed)):\n",
    "        if np.abs(cm_beUsed[i]-cm_beUsed[i-1])>0.3:\n",
    "            cm_beUsed[i-1] = cm_beUsed[i-1 + period]\n",
    "            \n",
    "    return cm_beUsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "937cc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining beta, the Gurney flap inclination\n",
    "## In case of mere NACA0018, the bb in those indexes are considered as zero.\n",
    "def generate_beta(n_beta=n_beta, t_len=t_len, normalize=True):\n",
    "\n",
    "#     beta_0 = np.zeros((t_len,1)) # Values for sheer NACA0018\n",
    "    b_ = np.ones((t_len,1)) # Template for the inclination for a single h and single beta\n",
    "    bb_imp = np.zeros((t_len*n_beta,1))\n",
    "\n",
    "    for j in range(n_beta):\n",
    "        b_imp = b_ * beta[j]\n",
    "        bb_imp[t_len*j:t_len*(j+1),:] = b_imp[:,:]\n",
    "\n",
    "    bb_imp = bb_imp.reshape((-1,1))\n",
    "    bb = bb_imp\n",
    "    if normalize==True:\n",
    "        bb = bb / np.max(beta)\n",
    "    \n",
    "    print(\"Dimension - inclination(beta): \", bb.shape)\n",
    "\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6302058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Gurney flap height\n",
    "## In case of mere NACA0018, the hh in those indexes are considered as zero.\n",
    "def generate_h(n_beta=n_beta, t_len=t_len, normalize:bool=True):\n",
    "    #hh = np.concatenate((np.zeros(t_len), h[0]*np.ones(n_beta*t_len), h[1]*np.ones(n_beta*t_len), h[2]*np.ones(n_beta*t_len)))\n",
    "    hh = h[0]*np.ones(n_beta*t_len)\n",
    "    hh = hh.reshape((-1,1))\n",
    "    \n",
    "    if normalize==True:\n",
    "        hh = hh / np.max(h)\n",
    "    \n",
    "    print(\"Dimension - heights of Gurney flaps: \", hh.shape)\n",
    "    return hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2d882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generates coordinate data of NACA0018 airfoil and Gurney flaps\n",
    "## AeroCNN-1: coordinates are replaced with grid data of 2*50 shape.\n",
    "def generate_coordinates(n_cases):\n",
    "    origin_coord = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\\\\airfoil15\"\n",
    "\n",
    "    csv_file_name = origin_coord + '\\\\airfoilOut15.txt'\n",
    "    data = pd.read_csv(csv_file_name, header=None)\n",
    "    baseline_coord_high = data.iloc[0,:] # 1*50\n",
    "    baseline_coord_low = data.iloc[1,:] # 1*50\n",
    "    baseline_coord = np.vstack((baseline_coord_high, baseline_coord_low)).reshape((2,-1)) # 2*50\n",
    "    airfoil_coord = np.repeat(baseline_coord, n_cases, axis=0)\n",
    "    print(\"Dimension - airfoil coordinates: \", airfoil_coord.shape)\n",
    "    \n",
    "    flap_coords= coord_with_flaps(n_cases)\n",
    "    total_coords = np.hstack((airfoil_coord, flap_coords))\n",
    "    \n",
    "    print(\"Dimension - total coordinates: \", total_coords.shape)\n",
    "    \n",
    "    return total_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a25f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data of Gurney flap coordinates\n",
    "def coord_with_flaps(n_cases):\n",
    "    flap_left = np.zeros((15,5))\n",
    "    flap_right = np.zeros((15,5))\n",
    "\n",
    "    for i in range(n_h):\n",
    "        # Defining coordinates of the flaps with respect to beta=90 degree.\n",
    "        yLeft = np.linspace(-h[i]/5, -h[i], 5).reshape((-1,1))\n",
    "        yRight = np.linspace(-h[i]/5, -h[i], 5).reshape((-1,1))\n",
    "        xLeft = 0.5*np.ones((5,1)) - 0.02*h[i]\n",
    "        xRight = 0.5*np.ones((5,1))\n",
    "\n",
    "        for j, betaValue in enumerate(beta):\n",
    "            # Rotating transformation\n",
    "            rotateTransf = np.array([[np.cos(90-betaValue), -np.sin(90-betaValue)],\n",
    "                                     [np.sin(90-betaValue), np.cos(90-betaValue)]])\n",
    "            rotateTransf = rotateTransf.reshape((2,2))\n",
    "\n",
    "            LeftImp = np.hstack((xLeft-0.5, yLeft))\n",
    "            RightImp = np.hstack((xRight-0.5, yRight))\n",
    "\n",
    "            rotatedFlapLeft = rotateTransf @ LeftImp.T # shape: 2*5 (x-coordinates on first row, y-coordinates on second row)\n",
    "            rotatedFlapRight = rotateTransf @ RightImp.T\n",
    "\n",
    "            # All we need is the y-coordinates of the flaps\n",
    "            flap_left[5*i+j,:] = rotatedFlapLeft[1,:]\n",
    "            flap_right[5*i+j,:] = rotatedFlapRight[1,:]\n",
    "    \n",
    "    # flap_coords = np.hstack((flap_left, np.flip(flap_right, axis=1)))\n",
    "    flap_coords = np.vstack((flap_left, flap_right))\n",
    "    flap_coords2 = np.zeros((n_cases*2,5))\n",
    "    \n",
    "    for i in range(t_len, n_cases):\n",
    "        flap_coords2[i,:] = flap_coords[i%15,:]\n",
    "    print(\"Dimension - coord with flaps: \", flap_coords2.shape)\n",
    "    \n",
    "    return flap_coords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc16d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension - time and Cm:  (1000, 2)\n",
      "Dimension - airfoil coordinates:  (2000, 50)\n",
      "Dimension - coord with flaps:  (2000, 5)\n",
      "Dimension - total coordinates:  (2000, 55)\n",
      "Dimension - x_time:  (1000, 1)\n",
      "Dimension - x_coordinates:  (1000, 2, 55, 1)\n",
      "Dimension - y:  (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generating x, y and cm (for denormalizing)\n",
    "x_time, x_coord, y, t, cm = genereate_input_output(cm_target, n_beta, t_len, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766ff9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[:,0] -= 10\n",
    "# x[:,0] /= 5\n",
    "x_time -= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7444ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(x_time, x_coord, y, cm, test_rate, random_state=1, **kwargs):\n",
    "    if kwargs.get('validation')==True:\n",
    "        val_rate = kwargs.get('val_rate')\n",
    "        x_time_all, x_time_test, x_coord_all, x_coord_test, y_all, y_test, cm_all, cm_test = train_test_split(x_time, x_coord, y, cm, test_size=test_rate, random_state=kwargs.get('random_state'))\n",
    "        x_time_train, x_time_val, x_coord_train, x_coord_val, y_train, y_val, cm_train, cm_val = train_test_split(x_time_all, x_coord_all, y_all, cm_all,\n",
    "                                                                                                                  test_size=val_rate/(1-test_rate),\n",
    "                                                                                                                  random_state=kwargs.get('random_state'))\n",
    "        return x_time_train, x_time_val, x_time_test, x_coord_train, x_coord_val, x_coord_test, y_train, y_val, y_test, cm_train, cm_val, cm_test\n",
    "    else:\n",
    "        x_time_train, x_time_test, x_coord_train, x_coord_test, y_train, y_test, cm_train, cm_test = train_test_split(x_time, x_coord, y, cm, test_size=test_rate, random_state=kwargs.get('random_state'))\n",
    "        return x_time_train, x_time_test, x_coord_train, x_coord_test, y_train, y_test, cm_train, cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time_train, x_time_val, x_time_test, x_coord_train, x_coord_val, x_coord_test, y_train, y_val, y_test, cm_train, cm_val, cm_test = dataset_split(x_time,x_coord, y, cm, test_rate, val_rate=val_rate,\n",
    "                                                                                                                                                   validation=True, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_aerocnn1_model(num_layer:int = 1): # This function can only generate model with at least 3 hidden layers\n",
    "    input_time = tf.keras.Input(shape=1)\n",
    "    input_coord = tf.keras.Input(shape=(2,55,1))\n",
    "    \n",
    "    # The convolutional layer\n",
    "    x_conv1 = tf.keras.layers.Conv2D(filters=n_kernels, kernel_size=(2,2), strides=1,\n",
    "                                     padding='same', activation='relu',\n",
    "                                     name='convLayer')(input_coord)\n",
    "    x_pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x_conv1)\n",
    "    \n",
    "    x_flat = tf.keras.layers.Flatten()(x_pool)\n",
    "    x_concat = tf.keras.layers.Concatenate()([x_flat, input_time])\n",
    "\n",
    "    # The first hidden layer\n",
    "    x_fc = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc1',\n",
    "                                kernel_regularizer=regularizers.l2(l2_regularizer))(x_concat)\n",
    "    \n",
    "    # The other hidden layers, which will be placed between the first hidden layer and the last hidden layer.\n",
    "    # The number of layers that the user desires is input of this function.\n",
    "    for i in range(0, num_layer-2):\n",
    "        x_fc = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc%d' % (i+2),\n",
    "                                     kernel_regularizer=regularizers.l2(l2_regularizer))(x_fc)\n",
    "    \n",
    "    # The last hidden layer\n",
    "    x_fc_final = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc%d' % num_layer,\n",
    "                                       kernel_regularizer=regularizers.l2(l2_regularizer))(x_fc)\n",
    "\n",
    "    # The output layer\n",
    "    output_data = tf.keras.layers.Dense(units=1, activation='linear', name='outputLayer')(x_fc_final)\n",
    "    \n",
    "    # MLP(FC layer)-based\n",
    "    model = tf.keras.Model([input_time, input_coord], output_data)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2, 55, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " convLayer (Conv2D)             (None, 2, 55, 400)   2000        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 27, 400)   0           ['convLayer[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10800)        0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10801)        0           ['flatten[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " fc1 (Dense)                    (None, 256)          2765312     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 256)          65792       ['fc1[0][0]']                    \n",
      "                                                                                                  \n",
      " fc3 (Dense)                    (None, 256)          65792       ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      " fc4 (Dense)                    (None, 256)          65792       ['fc3[0][0]']                    \n",
      "                                                                                                  \n",
      " fc5 (Dense)                    (None, 256)          65792       ['fc4[0][0]']                    \n",
      "                                                                                                  \n",
      " outputLayer (Dense)            (None, 1)            257         ['fc5[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,030,737\n",
      "Trainable params: 3,030,737\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_aerocnn1_model(num_layer=n_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360fbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20230102\\\\Case15\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74b6c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = model_directory + \"20230102unsteady_AeroCNN1_Case15_val_\"+str(val_rate) + \"_test\"+str(test_rate)+ \"_\" +str(n_kernels)+ \"kernels_\" +str(n_layers)+\"FClayers_\"+ str(n_units) +\"units_checkpoint.h5\"\n",
    "\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(ckpt_name, monitor=\"val_loss\", mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, min_delta=1e-05,\n",
    "                                      restore_best_weights=True, verbose=1)\n",
    "rp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=100, factor=0.5,\n",
    "                                          min_delta = 1e-05, min_lr=1e-05, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4cc904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = len(x_time_train)//batch_size\n",
    "VALIDATION_STEPS = len(x_time_val)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/3 [=========>....................] - ETA: 7s - loss: 0.1998 - rmse: 0.4468\n",
      "Epoch 1: val_loss improved from inf to 0.19644, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 4s 232ms/step - loss: 0.2034 - rmse: 0.4509 - val_loss: 0.1964 - val_rmse: 0.4430 - lr: 1.0000e-04\n",
      "Epoch 2/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.2298 - rmse: 0.4792\n",
      "Epoch 2: val_loss improved from 0.19644 to 0.18860, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.2157 - rmse: 0.4643 - val_loss: 0.1886 - val_rmse: 0.4341 - lr: 1.0000e-04\n",
      "Epoch 3/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1503 - rmse: 0.3876\n",
      "Epoch 3: val_loss improved from 0.18860 to 0.17775, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1827 - rmse: 0.4273 - val_loss: 0.1778 - val_rmse: 0.4214 - lr: 1.0000e-04\n",
      "Epoch 4/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1738 - rmse: 0.4167\n",
      "Epoch 4: val_loss improved from 0.17775 to 0.16304, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1781 - rmse: 0.4219 - val_loss: 0.1630 - val_rmse: 0.4036 - lr: 1.0000e-04\n",
      "Epoch 5/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1617 - rmse: 0.4019\n",
      "Epoch 5: val_loss improved from 0.16304 to 0.14330, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1614 - rmse: 0.4015 - val_loss: 0.1433 - val_rmse: 0.3784 - lr: 1.0000e-04\n",
      "Epoch 6/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1526 - rmse: 0.3904\n",
      "Epoch 6: val_loss improved from 0.14330 to 0.11818, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1369 - rmse: 0.3698 - val_loss: 0.1182 - val_rmse: 0.3436 - lr: 1.0000e-04\n",
      "Epoch 7/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1321 - rmse: 0.3632\n",
      "Epoch 7: val_loss improved from 0.11818 to 0.08937, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1104 - rmse: 0.3321 - val_loss: 0.0894 - val_rmse: 0.2987 - lr: 1.0000e-04\n",
      "Epoch 8/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0960 - rmse: 0.3097\n",
      "Epoch 8: val_loss improved from 0.08937 to 0.06425, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0894 - rmse: 0.2987 - val_loss: 0.0643 - val_rmse: 0.2532 - lr: 1.0000e-04\n",
      "Epoch 9/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0488 - rmse: 0.2206\n",
      "Epoch 9: val_loss improved from 0.06425 to 0.05946, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0602 - rmse: 0.2451 - val_loss: 0.0595 - val_rmse: 0.2435 - lr: 1.0000e-04\n",
      "Epoch 10/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0728 - rmse: 0.2695\n",
      "Epoch 10: val_loss did not improve from 0.05946\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0666 - rmse: 0.2578 - val_loss: 0.0712 - val_rmse: 0.2666 - lr: 1.0000e-04\n",
      "Epoch 11/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0792 - rmse: 0.2812\n",
      "Epoch 11: val_loss did not improve from 0.05946\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0747 - rmse: 0.2731 - val_loss: 0.0652 - val_rmse: 0.2550 - lr: 1.0000e-04\n",
      "Epoch 12/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0634 - rmse: 0.2514\n",
      "Epoch 12: val_loss improved from 0.05946 to 0.05724, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0615 - rmse: 0.2477 - val_loss: 0.0572 - val_rmse: 0.2389 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0576 - rmse: 0.2397\n",
      "Epoch 13: val_loss improved from 0.05724 to 0.05719, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0559 - rmse: 0.2361 - val_loss: 0.0572 - val_rmse: 0.2388 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0745 - rmse: 0.2727\n",
      "Epoch 14: val_loss did not improve from 0.05719\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0703 - rmse: 0.2648 - val_loss: 0.0594 - val_rmse: 0.2433 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0501 - rmse: 0.2235\n",
      "Epoch 15: val_loss did not improve from 0.05719\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0517 - rmse: 0.2271 - val_loss: 0.0590 - val_rmse: 0.2426 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0576 - rmse: 0.2396\n",
      "Epoch 16: val_loss did not improve from 0.05719\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0645 - rmse: 0.2536 - val_loss: 0.0572 - val_rmse: 0.2388 - lr: 1.0000e-04\n",
      "Epoch 17/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0571 - rmse: 0.2386\n",
      "Epoch 17: val_loss improved from 0.05719 to 0.05648, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0593 - rmse: 0.2431 - val_loss: 0.0565 - val_rmse: 0.2373 - lr: 1.0000e-04\n",
      "Epoch 18/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0566 - rmse: 0.2377\n",
      "Epoch 18: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0617 - rmse: 0.2481 - val_loss: 0.0574 - val_rmse: 0.2392 - lr: 1.0000e-04\n",
      "Epoch 19/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569 - rmse: 0.2382\n",
      "Epoch 19: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0571 - rmse: 0.2387 - val_loss: 0.0577 - val_rmse: 0.2398 - lr: 1.0000e-04\n",
      "Epoch 20/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0657 - rmse: 0.2561\n",
      "Epoch 20: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0585 - rmse: 0.2416 - val_loss: 0.0570 - val_rmse: 0.2385 - lr: 1.0000e-04\n",
      "Epoch 21/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0621 - rmse: 0.2488\n",
      "Epoch 21: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0607 - rmse: 0.2461 - val_loss: 0.0565 - val_rmse: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 22/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0463 - rmse: 0.2148\n",
      "Epoch 22: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0576 - rmse: 0.2397 - val_loss: 0.0567 - val_rmse: 0.2377 - lr: 1.0000e-04\n",
      "Epoch 23/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0583 - rmse: 0.2412\n",
      "Epoch 23: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0597 - rmse: 0.2441 - val_loss: 0.0568 - val_rmse: 0.2380 - lr: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0619 - rmse: 0.2484\n",
      "Epoch 24: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0561 - rmse: 0.2365 - val_loss: 0.0567 - val_rmse: 0.2378 - lr: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0670 - rmse: 0.2585\n",
      "Epoch 25: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0587 - rmse: 0.2420 - val_loss: 0.0565 - val_rmse: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0591 - rmse: 0.2428\n",
      "Epoch 26: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0550 - rmse: 0.2342 - val_loss: 0.0565 - val_rmse: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0646 - rmse: 0.2538\n",
      "Epoch 27: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0607 - rmse: 0.2461 - val_loss: 0.0565 - val_rmse: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 28/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0597 - rmse: 0.2440\n",
      "Epoch 28: val_loss did not improve from 0.05648\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0597 - rmse: 0.2441 - val_loss: 0.0565 - val_rmse: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 29/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0591 - rmse: 0.2427\n",
      "Epoch 29: val_loss improved from 0.05648 to 0.05645, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0581 - rmse: 0.2408 - val_loss: 0.0564 - val_rmse: 0.2373 - lr: 1.0000e-04\n",
      "Epoch 30/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0604 - rmse: 0.2454\n",
      "Epoch 30: val_loss improved from 0.05645 to 0.05641, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0638 - rmse: 0.2523 - val_loss: 0.0564 - val_rmse: 0.2372 - lr: 1.0000e-04\n",
      "Epoch 31/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0459 - rmse: 0.2140\n",
      "Epoch 31: val_loss improved from 0.05641 to 0.05636, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0558 - rmse: 0.2359 - val_loss: 0.0564 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 32/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0580 - rmse: 0.2404\n",
      "Epoch 32: val_loss improved from 0.05636 to 0.05635, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0559 - rmse: 0.2362 - val_loss: 0.0563 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 33/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0589 - rmse: 0.2423\n",
      "Epoch 33: val_loss improved from 0.05635 to 0.05635, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0579 - rmse: 0.2403 - val_loss: 0.0563 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 34/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0610 - rmse: 0.2466\n",
      "Epoch 34: val_loss did not improve from 0.05635\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0536 - rmse: 0.2312 - val_loss: 0.0564 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 35/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0678 - rmse: 0.2600\n",
      "Epoch 35: val_loss did not improve from 0.05635\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0617 - rmse: 0.2481 - val_loss: 0.0564 - val_rmse: 0.2372 - lr: 1.0000e-04\n",
      "Epoch 36/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0623 - rmse: 0.2493\n",
      "Epoch 36: val_loss did not improve from 0.05635\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0602 - rmse: 0.2451 - val_loss: 0.0565 - val_rmse: 0.2373 - lr: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0551 - rmse: 0.2344\n",
      "Epoch 37: val_loss did not improve from 0.05635\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0575 - rmse: 0.2395 - val_loss: 0.0565 - val_rmse: 0.2374 - lr: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0639 - rmse: 0.2525\n",
      "Epoch 38: val_loss did not improve from 0.05635\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0614 - rmse: 0.2475 - val_loss: 0.0564 - val_rmse: 0.2373 - lr: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0521 - rmse: 0.2279\n",
      "Epoch 39: val_loss improved from 0.05635 to 0.05629, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0561 - rmse: 0.2366 - val_loss: 0.0563 - val_rmse: 0.2369 - lr: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0596 - rmse: 0.2439\n",
      "Epoch 40: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0589 - rmse: 0.2424 - val_loss: 0.0563 - val_rmse: 0.2370 - lr: 1.0000e-04\n",
      "Epoch 41/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0618 - rmse: 0.2483\n",
      "Epoch 41: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0596 - rmse: 0.2439 - val_loss: 0.0563 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 42/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0514 - rmse: 0.2264\n",
      "Epoch 42: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0588 - rmse: 0.2421 - val_loss: 0.0563 - val_rmse: 0.2370 - lr: 1.0000e-04\n",
      "Epoch 43/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0611 - rmse: 0.2470\n",
      "Epoch 43: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0548 - rmse: 0.2337 - val_loss: 0.0564 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 44/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0548 - rmse: 0.2339\n",
      "Epoch 44: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0602 - rmse: 0.2449 - val_loss: 0.0564 - val_rmse: 0.2372 - lr: 1.0000e-04\n",
      "Epoch 45/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0582 - rmse: 0.2410\n",
      "Epoch 45: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0584 - rmse: 0.2413 - val_loss: 0.0563 - val_rmse: 0.2370 - lr: 1.0000e-04\n",
      "Epoch 46/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0571 - rmse: 0.2386\n",
      "Epoch 46: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0532 - rmse: 0.2304 - val_loss: 0.0564 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 47/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0653 - rmse: 0.2552\n",
      "Epoch 47: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0628 - rmse: 0.2503 - val_loss: 0.0566 - val_rmse: 0.2376 - lr: 1.0000e-04\n",
      "Epoch 48/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0561 - rmse: 0.2366\n",
      "Epoch 48: val_loss did not improve from 0.05629\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0587 - rmse: 0.2420 - val_loss: 0.0564 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 49/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0464 - rmse: 0.2151\n",
      "Epoch 49: val_loss improved from 0.05629 to 0.05622, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0585 - rmse: 0.2415 - val_loss: 0.0562 - val_rmse: 0.2368 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0576 - rmse: 0.2396\n",
      "Epoch 50: val_loss did not improve from 0.05622\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0580 - rmse: 0.2406 - val_loss: 0.0563 - val_rmse: 0.2369 - lr: 1.0000e-04\n",
      "Epoch 51/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0575 - rmse: 0.2395\n",
      "Epoch 51: val_loss did not improve from 0.05622\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0557 - rmse: 0.2357 - val_loss: 0.0562 - val_rmse: 0.2368 - lr: 1.0000e-04\n",
      "Epoch 52/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0668 - rmse: 0.2582\n",
      "Epoch 52: val_loss did not improve from 0.05622\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0608 - rmse: 0.2462 - val_loss: 0.0562 - val_rmse: 0.2368 - lr: 1.0000e-04\n",
      "Epoch 53/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0602 - rmse: 0.2450\n",
      "Epoch 53: val_loss did not improve from 0.05622\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0576 - rmse: 0.2396 - val_loss: 0.0563 - val_rmse: 0.2370 - lr: 1.0000e-04\n",
      "Epoch 54/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0615 - rmse: 0.2476\n",
      "Epoch 54: val_loss did not improve from 0.05622\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0581 - rmse: 0.2408 - val_loss: 0.0563 - val_rmse: 0.2369 - lr: 1.0000e-04\n",
      "Epoch 55/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0599 - rmse: 0.2444\n",
      "Epoch 55: val_loss improved from 0.05622 to 0.05621, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0613 - rmse: 0.2474 - val_loss: 0.0562 - val_rmse: 0.2368 - lr: 1.0000e-04\n",
      "Epoch 56/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0563 - rmse: 0.2370\n",
      "Epoch 56: val_loss improved from 0.05621 to 0.05617, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0556 - rmse: 0.2356 - val_loss: 0.0562 - val_rmse: 0.2367 - lr: 1.0000e-04\n",
      "Epoch 57/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0467 - rmse: 0.2157\n",
      "Epoch 57: val_loss improved from 0.05617 to 0.05609, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0594 - rmse: 0.2434 - val_loss: 0.0561 - val_rmse: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 58/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0502 - rmse: 0.2237\n",
      "Epoch 58: val_loss did not improve from 0.05609\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0565 - rmse: 0.2373 - val_loss: 0.0561 - val_rmse: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 59/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0599 - rmse: 0.2443\n",
      "Epoch 59: val_loss improved from 0.05609 to 0.05607, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0575 - rmse: 0.2394 - val_loss: 0.0561 - val_rmse: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 60/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0642 - rmse: 0.2530\n",
      "Epoch 60: val_loss improved from 0.05607 to 0.05606, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0587 - rmse: 0.2420 - val_loss: 0.0561 - val_rmse: 0.2364 - lr: 1.0000e-04\n",
      "Epoch 61/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0634 - rmse: 0.2514\n",
      "Epoch 61: val_loss did not improve from 0.05606\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0578 - rmse: 0.2402 - val_loss: 0.0561 - val_rmse: 0.2366 - lr: 1.0000e-04\n",
      "Epoch 62/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0589 - rmse: 0.2425\n",
      "Epoch 62: val_loss did not improve from 0.05606\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0574 - rmse: 0.2394 - val_loss: 0.0561 - val_rmse: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 63/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0581 - rmse: 0.2407\n",
      "Epoch 63: val_loss did not improve from 0.05606\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0590 - rmse: 0.2425 - val_loss: 0.0561 - val_rmse: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 64/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0667 - rmse: 0.2580\n",
      "Epoch 64: val_loss did not improve from 0.05606\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0577 - rmse: 0.2399 - val_loss: 0.0561 - val_rmse: 0.2365 - lr: 1.0000e-04\n",
      "Epoch 65/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0554 - rmse: 0.2350\n",
      "Epoch 65: val_loss improved from 0.05606 to 0.05604, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0576 - rmse: 0.2396 - val_loss: 0.0560 - val_rmse: 0.2364 - lr: 1.0000e-04\n",
      "Epoch 66/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0604 - rmse: 0.2454\n",
      "Epoch 66: val_loss improved from 0.05604 to 0.05596, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0622 - rmse: 0.2491 - val_loss: 0.0560 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 67/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0537 - rmse: 0.2314\n",
      "Epoch 67: val_loss improved from 0.05596 to 0.05592, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0542 - rmse: 0.2325 - val_loss: 0.0559 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 68/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0725 - rmse: 0.2690\n",
      "Epoch 68: val_loss improved from 0.05592 to 0.05592, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0578 - rmse: 0.2401 - val_loss: 0.0559 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 69/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0612 - rmse: 0.2471\n",
      "Epoch 69: val_loss did not improve from 0.05592\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0569 - rmse: 0.2382 - val_loss: 0.0559 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 70/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0638 - rmse: 0.2523\n",
      "Epoch 70: val_loss did not improve from 0.05592\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0624 - rmse: 0.2494 - val_loss: 0.0560 - val_rmse: 0.2363 - lr: 1.0000e-04\n",
      "Epoch 71/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0511 - rmse: 0.2256\n",
      "Epoch 71: val_loss did not improve from 0.05592\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0529 - rmse: 0.2296 - val_loss: 0.0560 - val_rmse: 0.2363 - lr: 1.0000e-04\n",
      "Epoch 72/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0651 - rmse: 0.2548\n",
      "Epoch 72: val_loss did not improve from 0.05592\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0599 - rmse: 0.2445 - val_loss: 0.0559 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 73/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0594 - rmse: 0.2433\n",
      "Epoch 73: val_loss did not improve from 0.05592\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0573 - rmse: 0.2391 - val_loss: 0.0559 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 74/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0604 - rmse: 0.2454\n",
      "Epoch 74: val_loss improved from 0.05592 to 0.05584, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0615 - rmse: 0.2476 - val_loss: 0.0558 - val_rmse: 0.2360 - lr: 1.0000e-04\n",
      "Epoch 75/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0524 - rmse: 0.2285\n",
      "Epoch 75: val_loss improved from 0.05584 to 0.05580, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0534 - rmse: 0.2308 - val_loss: 0.0558 - val_rmse: 0.2359 - lr: 1.0000e-04\n",
      "Epoch 76/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0622 - rmse: 0.2491\n",
      "Epoch 76: val_loss improved from 0.05580 to 0.05577, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0587 - rmse: 0.2420 - val_loss: 0.0558 - val_rmse: 0.2358 - lr: 1.0000e-04\n",
      "Epoch 77/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0588 - rmse: 0.2421\n",
      "Epoch 77: val_loss did not improve from 0.05577\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0559 - rmse: 0.2362 - val_loss: 0.0558 - val_rmse: 0.2359 - lr: 1.0000e-04\n",
      "Epoch 78/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0677 - rmse: 0.2599\n",
      "Epoch 78: val_loss improved from 0.05577 to 0.05576, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0609 - rmse: 0.2466 - val_loss: 0.0558 - val_rmse: 0.2358 - lr: 1.0000e-04\n",
      "Epoch 79/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0566 - rmse: 0.2375\n",
      "Epoch 79: val_loss did not improve from 0.05576\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0551 - rmse: 0.2345 - val_loss: 0.0558 - val_rmse: 0.2358 - lr: 1.0000e-04\n",
      "Epoch 80/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0571 - rmse: 0.2386\n",
      "Epoch 80: val_loss did not improve from 0.05576\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0588 - rmse: 0.2422 - val_loss: 0.0558 - val_rmse: 0.2359 - lr: 1.0000e-04\n",
      "Epoch 81/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0545 - rmse: 0.2331\n",
      "Epoch 81: val_loss did not improve from 0.05576\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0582 - rmse: 0.2409 - val_loss: 0.0558 - val_rmse: 0.2358 - lr: 1.0000e-04\n",
      "Epoch 82/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0549 - rmse: 0.2339\n",
      "Epoch 82: val_loss did not improve from 0.05576\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0518 - rmse: 0.2274 - val_loss: 0.0558 - val_rmse: 0.2360 - lr: 1.0000e-04\n",
      "Epoch 83/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0726 - rmse: 0.2692\n",
      "Epoch 83: val_loss improved from 0.05576 to 0.05569, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0614 - rmse: 0.2475 - val_loss: 0.0557 - val_rmse: 0.2357 - lr: 1.0000e-04\n",
      "Epoch 84/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0579 - rmse: 0.2403\n",
      "Epoch 84: val_loss improved from 0.05569 to 0.05561, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0590 - rmse: 0.2427 - val_loss: 0.0556 - val_rmse: 0.2355 - lr: 1.0000e-04\n",
      "Epoch 85/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0486 - rmse: 0.2200\n",
      "Epoch 85: val_loss improved from 0.05561 to 0.05556, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0577 - rmse: 0.2400 - val_loss: 0.0556 - val_rmse: 0.2354 - lr: 1.0000e-04\n",
      "Epoch 86/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0552 - rmse: 0.2347\n",
      "Epoch 86: val_loss improved from 0.05556 to 0.05550, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0569 - rmse: 0.2382 - val_loss: 0.0555 - val_rmse: 0.2353 - lr: 1.0000e-04\n",
      "Epoch 87/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0577 - rmse: 0.2398\n",
      "Epoch 87: val_loss improved from 0.05550 to 0.05542, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0554 - rmse: 0.2351 - val_loss: 0.0554 - val_rmse: 0.2351 - lr: 1.0000e-04\n",
      "Epoch 88/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0595 - rmse: 0.2436\n",
      "Epoch 88: val_loss improved from 0.05542 to 0.05536, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0593 - rmse: 0.2432 - val_loss: 0.0554 - val_rmse: 0.2350 - lr: 1.0000e-04\n",
      "Epoch 89/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0529 - rmse: 0.2297\n",
      "Epoch 89: val_loss improved from 0.05536 to 0.05534, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0563 - rmse: 0.2369 - val_loss: 0.0553 - val_rmse: 0.2349 - lr: 1.0000e-04\n",
      "Epoch 90/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0627 - rmse: 0.2501\n",
      "Epoch 90: val_loss did not improve from 0.05534\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0609 - rmse: 0.2466 - val_loss: 0.0553 - val_rmse: 0.2349 - lr: 1.0000e-04\n",
      "Epoch 91/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0595 - rmse: 0.2437\n",
      "Epoch 91: val_loss improved from 0.05534 to 0.05531, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0511 - rmse: 0.2258 - val_loss: 0.0553 - val_rmse: 0.2349 - lr: 1.0000e-04\n",
      "Epoch 92/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0559 - rmse: 0.2361\n",
      "Epoch 92: val_loss improved from 0.05531 to 0.05525, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0605 - rmse: 0.2456 - val_loss: 0.0552 - val_rmse: 0.2347 - lr: 1.0000e-04\n",
      "Epoch 93/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0665 - rmse: 0.2577\n",
      "Epoch 93: val_loss improved from 0.05525 to 0.05521, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0569 - rmse: 0.2381 - val_loss: 0.0552 - val_rmse: 0.2346 - lr: 1.0000e-04\n",
      "Epoch 94/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0579 - rmse: 0.2404\n",
      "Epoch 94: val_loss improved from 0.05521 to 0.05517, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0557 - rmse: 0.2356 - val_loss: 0.0552 - val_rmse: 0.2346 - lr: 1.0000e-04\n",
      "Epoch 95/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0598 - rmse: 0.2442\n",
      "Epoch 95: val_loss improved from 0.05517 to 0.05508, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0557 - rmse: 0.2357 - val_loss: 0.0551 - val_rmse: 0.2344 - lr: 1.0000e-04\n",
      "Epoch 96/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0662 - rmse: 0.2570\n",
      "Epoch 96: val_loss improved from 0.05508 to 0.05502, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0596 - rmse: 0.2438 - val_loss: 0.0550 - val_rmse: 0.2342 - lr: 1.0000e-04\n",
      "Epoch 97/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0563 - rmse: 0.2370\n",
      "Epoch 97: val_loss did not improve from 0.05502\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0554 - rmse: 0.2351 - val_loss: 0.0550 - val_rmse: 0.2343 - lr: 1.0000e-04\n",
      "Epoch 98/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0647 - rmse: 0.2541\n",
      "Epoch 98: val_loss improved from 0.05502 to 0.05499, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0592 - rmse: 0.2429 - val_loss: 0.0550 - val_rmse: 0.2342 - lr: 1.0000e-04\n",
      "Epoch 99/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0558 - rmse: 0.2358\n",
      "Epoch 99: val_loss improved from 0.05499 to 0.05493, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0609 - rmse: 0.2466 - val_loss: 0.0549 - val_rmse: 0.2341 - lr: 1.0000e-04\n",
      "Epoch 100/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0478 - rmse: 0.2184\n",
      "Epoch 100: val_loss improved from 0.05493 to 0.05480, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0515 - rmse: 0.2265 - val_loss: 0.0548 - val_rmse: 0.2338 - lr: 1.0000e-04\n",
      "Epoch 101/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0450 - rmse: 0.2118\n",
      "Epoch 101: val_loss improved from 0.05480 to 0.05475, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0570 - rmse: 0.2384 - val_loss: 0.0548 - val_rmse: 0.2337 - lr: 1.0000e-04\n",
      "Epoch 102/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0539 - rmse: 0.2318\n",
      "Epoch 102: val_loss did not improve from 0.05475\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0577 - rmse: 0.2400 - val_loss: 0.0548 - val_rmse: 0.2337 - lr: 1.0000e-04\n",
      "Epoch 103/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0575 - rmse: 0.2394\n",
      "Epoch 103: val_loss improved from 0.05475 to 0.05465, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0545 - rmse: 0.2332 - val_loss: 0.0547 - val_rmse: 0.2335 - lr: 1.0000e-04\n",
      "Epoch 104/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0536 - rmse: 0.2313\n",
      "Epoch 104: val_loss improved from 0.05465 to 0.05453, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0564 - rmse: 0.2372 - val_loss: 0.0545 - val_rmse: 0.2332 - lr: 1.0000e-04\n",
      "Epoch 105/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0568 - rmse: 0.2380\n",
      "Epoch 105: val_loss did not improve from 0.05453\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0528 - rmse: 0.2294 - val_loss: 0.0546 - val_rmse: 0.2333 - lr: 1.0000e-04\n",
      "Epoch 106/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0779 - rmse: 0.2789\n",
      "Epoch 106: val_loss improved from 0.05453 to 0.05450, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0596 - rmse: 0.2438 - val_loss: 0.0545 - val_rmse: 0.2331 - lr: 1.0000e-04\n",
      "Epoch 107/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0528 - rmse: 0.2294\n",
      "Epoch 107: val_loss improved from 0.05450 to 0.05426, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0551 - rmse: 0.2344 - val_loss: 0.0543 - val_rmse: 0.2326 - lr: 1.0000e-04\n",
      "Epoch 108/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0604 - rmse: 0.2455\n",
      "Epoch 108: val_loss improved from 0.05426 to 0.05409, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0579 - rmse: 0.2403 - val_loss: 0.0541 - val_rmse: 0.2322 - lr: 1.0000e-04\n",
      "Epoch 109/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0562 - rmse: 0.2367\n",
      "Epoch 109: val_loss improved from 0.05409 to 0.05406, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0550 - rmse: 0.2343 - val_loss: 0.0541 - val_rmse: 0.2322 - lr: 1.0000e-04\n",
      "Epoch 110/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0603 - rmse: 0.2453\n",
      "Epoch 110: val_loss did not improve from 0.05406\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0573 - rmse: 0.2391 - val_loss: 0.0542 - val_rmse: 0.2325 - lr: 1.0000e-04\n",
      "Epoch 111/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0580 - rmse: 0.2405\n",
      "Epoch 111: val_loss did not improve from 0.05406\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0584 - rmse: 0.2413 - val_loss: 0.0543 - val_rmse: 0.2327 - lr: 1.0000e-04\n",
      "Epoch 112/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0570 - rmse: 0.2384\n",
      "Epoch 112: val_loss improved from 0.05406 to 0.05378, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0527 - rmse: 0.2292 - val_loss: 0.0538 - val_rmse: 0.2316 - lr: 1.0000e-04\n",
      "Epoch 113/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0647 - rmse: 0.2540\n",
      "Epoch 113: val_loss improved from 0.05378 to 0.05364, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0559 - rmse: 0.2362 - val_loss: 0.0536 - val_rmse: 0.2313 - lr: 1.0000e-04\n",
      "Epoch 114/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0519 - rmse: 0.2275\n",
      "Epoch 114: val_loss did not improve from 0.05364\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0538 - rmse: 0.2317 - val_loss: 0.0540 - val_rmse: 0.2320 - lr: 1.0000e-04\n",
      "Epoch 115/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0557 - rmse: 0.2357\n",
      "Epoch 115: val_loss improved from 0.05364 to 0.05355, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0567 - rmse: 0.2378 - val_loss: 0.0535 - val_rmse: 0.2311 - lr: 1.0000e-04\n",
      "Epoch 116/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0546 - rmse: 0.2333\n",
      "Epoch 116: val_loss improved from 0.05355 to 0.05340, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0545 - rmse: 0.2332 - val_loss: 0.0534 - val_rmse: 0.2308 - lr: 1.0000e-04\n",
      "Epoch 117/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0574 - rmse: 0.2394\n",
      "Epoch 117: val_loss improved from 0.05340 to 0.05314, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0547 - rmse: 0.2336 - val_loss: 0.0531 - val_rmse: 0.2302 - lr: 1.0000e-04\n",
      "Epoch 118/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0549 - rmse: 0.2339\n",
      "Epoch 118: val_loss improved from 0.05314 to 0.05296, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0536 - rmse: 0.2312 - val_loss: 0.0530 - val_rmse: 0.2298 - lr: 1.0000e-04\n",
      "Epoch 119/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0559 - rmse: 0.2361\n",
      "Epoch 119: val_loss improved from 0.05296 to 0.05275, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0561 - rmse: 0.2366 - val_loss: 0.0527 - val_rmse: 0.2293 - lr: 1.0000e-04\n",
      "Epoch 120/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0509 - rmse: 0.2252\n",
      "Epoch 120: val_loss improved from 0.05275 to 0.05262, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0537 - rmse: 0.2315 - val_loss: 0.0526 - val_rmse: 0.2291 - lr: 1.0000e-04\n",
      "Epoch 121/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0603 - rmse: 0.2453\n",
      "Epoch 121: val_loss improved from 0.05262 to 0.05245, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0548 - rmse: 0.2337 - val_loss: 0.0525 - val_rmse: 0.2287 - lr: 1.0000e-04\n",
      "Epoch 122/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0516 - rmse: 0.2268\n",
      "Epoch 122: val_loss improved from 0.05245 to 0.05227, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0516 - rmse: 0.2268 - val_loss: 0.0523 - val_rmse: 0.2283 - lr: 1.0000e-04\n",
      "Epoch 123/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0532 - rmse: 0.2304\n",
      "Epoch 123: val_loss did not improve from 0.05227\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0532 - rmse: 0.2304 - val_loss: 0.0523 - val_rmse: 0.2284 - lr: 1.0000e-04\n",
      "Epoch 124/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0452 - rmse: 0.2123\n",
      "Epoch 124: val_loss improved from 0.05227 to 0.05201, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0563 - rmse: 0.2370 - val_loss: 0.0520 - val_rmse: 0.2277 - lr: 1.0000e-04\n",
      "Epoch 125/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0513 - rmse: 0.2262\n",
      "Epoch 125: val_loss improved from 0.05201 to 0.05173, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0540 - rmse: 0.2321 - val_loss: 0.0517 - val_rmse: 0.2271 - lr: 1.0000e-04\n",
      "Epoch 126/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0499 - rmse: 0.2231\n",
      "Epoch 126: val_loss improved from 0.05173 to 0.05172, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0529 - rmse: 0.2298 - val_loss: 0.0517 - val_rmse: 0.2271 - lr: 1.0000e-04\n",
      "Epoch 127/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0531 - rmse: 0.2302\n",
      "Epoch 127: val_loss did not improve from 0.05172\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0546 - rmse: 0.2334 - val_loss: 0.0519 - val_rmse: 0.2274 - lr: 1.0000e-04\n",
      "Epoch 128/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0469 - rmse: 0.2162\n",
      "Epoch 128: val_loss improved from 0.05172 to 0.05113, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0508 - rmse: 0.2250 - val_loss: 0.0511 - val_rmse: 0.2258 - lr: 1.0000e-04\n",
      "Epoch 129/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0445 - rmse: 0.2105\n",
      "Epoch 129: val_loss improved from 0.05113 to 0.05079, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0521 - rmse: 0.2279 - val_loss: 0.0508 - val_rmse: 0.2250 - lr: 1.0000e-04\n",
      "Epoch 130/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0566 - rmse: 0.2376\n",
      "Epoch 130: val_loss improved from 0.05079 to 0.05068, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0538 - rmse: 0.2315 - val_loss: 0.0507 - val_rmse: 0.2248 - lr: 1.0000e-04\n",
      "Epoch 131/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0484 - rmse: 0.2197\n",
      "Epoch 131: val_loss improved from 0.05068 to 0.05061, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0493 - rmse: 0.2217 - val_loss: 0.0506 - val_rmse: 0.2246 - lr: 1.0000e-04\n",
      "Epoch 132/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0499 - rmse: 0.2230\n",
      "Epoch 132: val_loss did not improve from 0.05061\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0533 - rmse: 0.2306 - val_loss: 0.0506 - val_rmse: 0.2247 - lr: 1.0000e-04\n",
      "Epoch 133/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0457 - rmse: 0.2133\n",
      "Epoch 133: val_loss improved from 0.05061 to 0.04982, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0511 - rmse: 0.2256 - val_loss: 0.0498 - val_rmse: 0.2229 - lr: 1.0000e-04\n",
      "Epoch 134/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0534 - rmse: 0.2307\n",
      "Epoch 134: val_loss did not improve from 0.04982\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0498 - rmse: 0.2228 - val_loss: 0.0501 - val_rmse: 0.2236 - lr: 1.0000e-04\n",
      "Epoch 135/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0505 - rmse: 0.2244\n",
      "Epoch 135: val_loss did not improve from 0.04982\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0527 - rmse: 0.2293 - val_loss: 0.0509 - val_rmse: 0.2252 - lr: 1.0000e-04\n",
      "Epoch 136/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0542 - rmse: 0.2326\n",
      "Epoch 136: val_loss improved from 0.04982 to 0.04948, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0519 - rmse: 0.2275 - val_loss: 0.0495 - val_rmse: 0.2221 - lr: 1.0000e-04\n",
      "Epoch 137/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0443 - rmse: 0.2100\n",
      "Epoch 137: val_loss improved from 0.04948 to 0.04840, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0487 - rmse: 0.2204 - val_loss: 0.0484 - val_rmse: 0.2197 - lr: 1.0000e-04\n",
      "Epoch 138/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569 - rmse: 0.2383\n",
      "Epoch 138: val_loss did not improve from 0.04840\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0521 - rmse: 0.2279 - val_loss: 0.0486 - val_rmse: 0.2201 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0460 - rmse: 0.2141\n",
      "Epoch 139: val_loss did not improve from 0.04840\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0497 - rmse: 0.2225 - val_loss: 0.0484 - val_rmse: 0.2197 - lr: 1.0000e-04\n",
      "Epoch 140/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0419 - rmse: 0.2044\n",
      "Epoch 140: val_loss improved from 0.04840 to 0.04759, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0489 - rmse: 0.2208 - val_loss: 0.0476 - val_rmse: 0.2178 - lr: 1.0000e-04\n",
      "Epoch 141/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0468 - rmse: 0.2161\n",
      "Epoch 141: val_loss improved from 0.04759 to 0.04723, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0490 - rmse: 0.2210 - val_loss: 0.0472 - val_rmse: 0.2170 - lr: 1.0000e-04\n",
      "Epoch 142/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0454 - rmse: 0.2127\n",
      "Epoch 142: val_loss improved from 0.04723 to 0.04644, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0441 - rmse: 0.2097 - val_loss: 0.0464 - val_rmse: 0.2151 - lr: 1.0000e-04\n",
      "Epoch 143/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0539 - rmse: 0.2318\n",
      "Epoch 143: val_loss improved from 0.04644 to 0.04604, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0511 - rmse: 0.2258 - val_loss: 0.0460 - val_rmse: 0.2142 - lr: 1.0000e-04\n",
      "Epoch 144/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0471 - rmse: 0.2168\n",
      "Epoch 144: val_loss improved from 0.04604 to 0.04561, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0454 - rmse: 0.2128 - val_loss: 0.0456 - val_rmse: 0.2132 - lr: 1.0000e-04\n",
      "Epoch 145/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0492 - rmse: 0.2214\n",
      "Epoch 145: val_loss improved from 0.04561 to 0.04513, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0459 - rmse: 0.2139 - val_loss: 0.0451 - val_rmse: 0.2121 - lr: 1.0000e-04\n",
      "Epoch 146/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0474 - rmse: 0.2174\n",
      "Epoch 146: val_loss did not improve from 0.04513\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0480 - rmse: 0.2186 - val_loss: 0.0453 - val_rmse: 0.2124 - lr: 1.0000e-04\n",
      "Epoch 147/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0393 - rmse: 0.1980\n",
      "Epoch 147: val_loss improved from 0.04513 to 0.04405, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0425 - rmse: 0.2057 - val_loss: 0.0441 - val_rmse: 0.2095 - lr: 1.0000e-04\n",
      "Epoch 148/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0510 - rmse: 0.2254\n",
      "Epoch 148: val_loss improved from 0.04405 to 0.04380, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0461 - rmse: 0.2145 - val_loss: 0.0438 - val_rmse: 0.2089 - lr: 1.0000e-04\n",
      "Epoch 149/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0483 - rmse: 0.2194\n",
      "Epoch 149: val_loss improved from 0.04380 to 0.04326, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0436 - rmse: 0.2085 - val_loss: 0.0433 - val_rmse: 0.2076 - lr: 1.0000e-04\n",
      "Epoch 150/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0472 - rmse: 0.2168\n",
      "Epoch 150: val_loss improved from 0.04326 to 0.04265, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0435 - rmse: 0.2083 - val_loss: 0.0427 - val_rmse: 0.2062 - lr: 1.0000e-04\n",
      "Epoch 151/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0454 - rmse: 0.2127\n",
      "Epoch 151: val_loss improved from 0.04265 to 0.04216, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0435 - rmse: 0.2082 - val_loss: 0.0422 - val_rmse: 0.2050 - lr: 1.0000e-04\n",
      "Epoch 152/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0435 - rmse: 0.2083\n",
      "Epoch 152: val_loss improved from 0.04216 to 0.04163, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0430 - rmse: 0.2069 - val_loss: 0.0416 - val_rmse: 0.2037 - lr: 1.0000e-04\n",
      "Epoch 153/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0385 - rmse: 0.1958\n",
      "Epoch 153: val_loss improved from 0.04163 to 0.04117, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0429 - rmse: 0.2067 - val_loss: 0.0412 - val_rmse: 0.2025 - lr: 1.0000e-04\n",
      "Epoch 154/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0364 - rmse: 0.1905\n",
      "Epoch 154: val_loss improved from 0.04117 to 0.04116, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0429 - rmse: 0.2069 - val_loss: 0.0412 - val_rmse: 0.2025 - lr: 1.0000e-04\n",
      "Epoch 155/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0337 - rmse: 0.1831\n",
      "Epoch 155: val_loss improved from 0.04116 to 0.03999, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0395 - rmse: 0.1984 - val_loss: 0.0400 - val_rmse: 0.1996 - lr: 1.0000e-04\n",
      "Epoch 156/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0417 - rmse: 0.2038\n",
      "Epoch 156: val_loss improved from 0.03999 to 0.03986, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0396 - rmse: 0.1987 - val_loss: 0.0399 - val_rmse: 0.1993 - lr: 1.0000e-04\n",
      "Epoch 157/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0360 - rmse: 0.1892\n",
      "Epoch 157: val_loss improved from 0.03986 to 0.03891, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0412 - rmse: 0.2026 - val_loss: 0.0389 - val_rmse: 0.1969 - lr: 1.0000e-04\n",
      "Epoch 158/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0340 - rmse: 0.1839\n",
      "Epoch 158: val_loss improved from 0.03891 to 0.03884, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0392 - rmse: 0.1976 - val_loss: 0.0388 - val_rmse: 0.1967 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0409 - rmse: 0.2019\n",
      "Epoch 159: val_loss improved from 0.03884 to 0.03829, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0408 - rmse: 0.2016 - val_loss: 0.0383 - val_rmse: 0.1953 - lr: 1.0000e-04\n",
      "Epoch 160/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0406 - rmse: 0.2011\n",
      "Epoch 160: val_loss improved from 0.03829 to 0.03792, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0372 - rmse: 0.1925 - val_loss: 0.0379 - val_rmse: 0.1944 - lr: 1.0000e-04\n",
      "Epoch 161/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0396 - rmse: 0.1986\n",
      "Epoch 161: val_loss did not improve from 0.03792\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0396 - rmse: 0.1987 - val_loss: 0.0395 - val_rmse: 0.1983 - lr: 1.0000e-04\n",
      "Epoch 162/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0335 - rmse: 0.1827\n",
      "Epoch 162: val_loss improved from 0.03792 to 0.03694, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0377 - rmse: 0.1937 - val_loss: 0.0369 - val_rmse: 0.1918 - lr: 1.0000e-04\n",
      "Epoch 163/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0377 - rmse: 0.1937\n",
      "Epoch 163: val_loss improved from 0.03694 to 0.03649, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0366 - rmse: 0.1909 - val_loss: 0.0365 - val_rmse: 0.1906 - lr: 1.0000e-04\n",
      "Epoch 164/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0369 - rmse: 0.1917\n",
      "Epoch 164: val_loss improved from 0.03649 to 0.03546, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0379 - rmse: 0.1942 - val_loss: 0.0355 - val_rmse: 0.1879 - lr: 1.0000e-04\n",
      "Epoch 165/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0298 - rmse: 0.1723\n",
      "Epoch 165: val_loss improved from 0.03546 to 0.03515, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0353 - rmse: 0.1875 - val_loss: 0.0351 - val_rmse: 0.1871 - lr: 1.0000e-04\n",
      "Epoch 166/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0444 - rmse: 0.2104\n",
      "Epoch 166: val_loss improved from 0.03515 to 0.03482, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0395 - rmse: 0.1983 - val_loss: 0.0348 - val_rmse: 0.1862 - lr: 1.0000e-04\n",
      "Epoch 167/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0322 - rmse: 0.1790\n",
      "Epoch 167: val_loss improved from 0.03482 to 0.03356, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0310 - rmse: 0.1757 - val_loss: 0.0336 - val_rmse: 0.1828 - lr: 1.0000e-04\n",
      "Epoch 168/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0331 - rmse: 0.1816\n",
      "Epoch 168: val_loss improved from 0.03356 to 0.03304, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0355 - rmse: 0.1880 - val_loss: 0.0330 - val_rmse: 0.1814 - lr: 1.0000e-04\n",
      "Epoch 169/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0389 - rmse: 0.1968\n",
      "Epoch 169: val_loss improved from 0.03304 to 0.03297, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0336 - rmse: 0.1828 - val_loss: 0.0330 - val_rmse: 0.1812 - lr: 1.0000e-04\n",
      "Epoch 170/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0326 - rmse: 0.1802\n",
      "Epoch 170: val_loss improved from 0.03297 to 0.03136, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0327 - rmse: 0.1804 - val_loss: 0.0314 - val_rmse: 0.1767 - lr: 1.0000e-04\n",
      "Epoch 171/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0341 - rmse: 0.1842\n",
      "Epoch 171: val_loss did not improve from 0.03136\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0341 - rmse: 0.1842 - val_loss: 0.0335 - val_rmse: 0.1825 - lr: 1.0000e-04\n",
      "Epoch 172/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0312 - rmse: 0.1763\n",
      "Epoch 172: val_loss improved from 0.03136 to 0.03038, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0311 - rmse: 0.1758 - val_loss: 0.0304 - val_rmse: 0.1739 - lr: 1.0000e-04\n",
      "Epoch 173/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0347 - rmse: 0.1860\n",
      "Epoch 173: val_loss improved from 0.03038 to 0.02995, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0312 - rmse: 0.1762 - val_loss: 0.0300 - val_rmse: 0.1726 - lr: 1.0000e-04\n",
      "Epoch 174/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0308 - rmse: 0.1751\n",
      "Epoch 174: val_loss improved from 0.02995 to 0.02864, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0298 - rmse: 0.1722 - val_loss: 0.0286 - val_rmse: 0.1688 - lr: 1.0000e-04\n",
      "Epoch 175/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0272 - rmse: 0.1644\n",
      "Epoch 175: val_loss improved from 0.02864 to 0.02764, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0287 - rmse: 0.1689 - val_loss: 0.0276 - val_rmse: 0.1658 - lr: 1.0000e-04\n",
      "Epoch 176/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0259 - rmse: 0.1604\n",
      "Epoch 176: val_loss improved from 0.02764 to 0.02653, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0288 - rmse: 0.1691 - val_loss: 0.0265 - val_rmse: 0.1624 - lr: 1.0000e-04\n",
      "Epoch 177/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0302 - rmse: 0.1733\n",
      "Epoch 177: val_loss did not improve from 0.02653\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0284 - rmse: 0.1682 - val_loss: 0.0269 - val_rmse: 0.1634 - lr: 1.0000e-04\n",
      "Epoch 178/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0214 - rmse: 0.1458\n",
      "Epoch 178: val_loss improved from 0.02653 to 0.02585, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0251 - rmse: 0.1581 - val_loss: 0.0259 - val_rmse: 0.1603 - lr: 1.0000e-04\n",
      "Epoch 179/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0254 - rmse: 0.1589\n",
      "Epoch 179: val_loss improved from 0.02585 to 0.02417, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0244 - rmse: 0.1558 - val_loss: 0.0242 - val_rmse: 0.1550 - lr: 1.0000e-04\n",
      "Epoch 180/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0288 - rmse: 0.1692\n",
      "Epoch 180: val_loss improved from 0.02417 to 0.02413, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0270 - rmse: 0.1640 - val_loss: 0.0241 - val_rmse: 0.1549 - lr: 1.0000e-04\n",
      "Epoch 181/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0246 - rmse: 0.1564\n",
      "Epoch 181: val_loss did not improve from 0.02413\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0262 - rmse: 0.1613 - val_loss: 0.0245 - val_rmse: 0.1562 - lr: 1.0000e-04\n",
      "Epoch 182/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0207 - rmse: 0.1435\n",
      "Epoch 182: val_loss improved from 0.02413 to 0.02155, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0237 - rmse: 0.1535 - val_loss: 0.0216 - val_rmse: 0.1463 - lr: 1.0000e-04\n",
      "Epoch 183/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0230 - rmse: 0.1513\n",
      "Epoch 183: val_loss did not improve from 0.02155\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0222 - rmse: 0.1484 - val_loss: 0.0218 - val_rmse: 0.1472 - lr: 1.0000e-04\n",
      "Epoch 184/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0295 - rmse: 0.1714\n",
      "Epoch 184: val_loss did not improve from 0.02155\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0228 - rmse: 0.1505 - val_loss: 0.0219 - val_rmse: 0.1476 - lr: 1.0000e-04\n",
      "Epoch 185/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0248 - rmse: 0.1570\n",
      "Epoch 185: val_loss improved from 0.02155 to 0.01785, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0208 - rmse: 0.1435 - val_loss: 0.0178 - val_rmse: 0.1330 - lr: 1.0000e-04\n",
      "Epoch 186/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0183 - rmse: 0.1348\n",
      "Epoch 186: val_loss improved from 0.01785 to 0.01677, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0184 - rmse: 0.1352 - val_loss: 0.0168 - val_rmse: 0.1289 - lr: 1.0000e-04\n",
      "Epoch 187/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0169 - rmse: 0.1295\n",
      "Epoch 187: val_loss did not improve from 0.01677\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0180 - rmse: 0.1338 - val_loss: 0.0172 - val_rmse: 0.1307 - lr: 1.0000e-04\n",
      "Epoch 188/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0175 - rmse: 0.1318\n",
      "Epoch 188: val_loss improved from 0.01677 to 0.01552, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0170 - rmse: 0.1300 - val_loss: 0.0155 - val_rmse: 0.1240 - lr: 1.0000e-04\n",
      "Epoch 189/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0144 - rmse: 0.1193\n",
      "Epoch 189: val_loss improved from 0.01552 to 0.01385, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0152 - rmse: 0.1227 - val_loss: 0.0139 - val_rmse: 0.1171 - lr: 1.0000e-04\n",
      "Epoch 190/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0153 - rmse: 0.1231\n",
      "Epoch 190: val_loss improved from 0.01385 to 0.01326, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0149 - rmse: 0.1213 - val_loss: 0.0133 - val_rmse: 0.1145 - lr: 1.0000e-04\n",
      "Epoch 191/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0129 - rmse: 0.1127\n",
      "Epoch 191: val_loss improved from 0.01326 to 0.01213, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0124 - rmse: 0.1109 - val_loss: 0.0121 - val_rmse: 0.1095 - lr: 1.0000e-04\n",
      "Epoch 192/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0114 - rmse: 0.1062\n",
      "Epoch 192: val_loss improved from 0.01213 to 0.01193, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0124 - rmse: 0.1106 - val_loss: 0.0119 - val_rmse: 0.1085 - lr: 1.0000e-04\n",
      "Epoch 193/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0141 - rmse: 0.1181\n",
      "Epoch 193: val_loss improved from 0.01193 to 0.01139, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0134 - rmse: 0.1150 - val_loss: 0.0114 - val_rmse: 0.1060 - lr: 1.0000e-04\n",
      "Epoch 194/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0099 - rmse: 0.0986\n",
      "Epoch 194: val_loss improved from 0.01139 to 0.00932, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0101 - rmse: 0.0996 - val_loss: 0.0093 - val_rmse: 0.0957 - lr: 1.0000e-04\n",
      "Epoch 195/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0104 - rmse: 0.1014\n",
      "Epoch 195: val_loss improved from 0.00932 to 0.00818, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0097 - rmse: 0.0979 - val_loss: 0.0082 - val_rmse: 0.0896 - lr: 1.0000e-04\n",
      "Epoch 196/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086 - rmse: 0.0917\n",
      "Epoch 196: val_loss did not improve from 0.00818\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0094 - rmse: 0.0959 - val_loss: 0.0115 - val_rmse: 0.1064 - lr: 1.0000e-04\n",
      "Epoch 197/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101 - rmse: 0.0997\n",
      "Epoch 197: val_loss improved from 0.00818 to 0.00677, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0085 - rmse: 0.0914 - val_loss: 0.0068 - val_rmse: 0.0814 - lr: 1.0000e-04\n",
      "Epoch 198/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0081 - rmse: 0.0893\n",
      "Epoch 198: val_loss improved from 0.00677 to 0.00587, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0077 - rmse: 0.0870 - val_loss: 0.0059 - val_rmse: 0.0757 - lr: 1.0000e-04\n",
      "Epoch 199/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0056 - rmse: 0.0740\n",
      "Epoch 199: val_loss did not improve from 0.00587\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0057 - rmse: 0.0746 - val_loss: 0.0062 - val_rmse: 0.0776 - lr: 1.0000e-04\n",
      "Epoch 200/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0058 - rmse: 0.0749\n",
      "Epoch 200: val_loss improved from 0.00587 to 0.00480, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0054 - rmse: 0.0721 - val_loss: 0.0048 - val_rmse: 0.0682 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0050 - rmse: 0.0696\n",
      "Epoch 201: val_loss improved from 0.00480 to 0.00452, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0046 - rmse: 0.0668 - val_loss: 0.0045 - val_rmse: 0.0661 - lr: 1.0000e-04\n",
      "Epoch 202/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0054 - rmse: 0.0728\n",
      "Epoch 202: val_loss did not improve from 0.00452\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0049 - rmse: 0.0691 - val_loss: 0.0057 - val_rmse: 0.0747 - lr: 1.0000e-04\n",
      "Epoch 203/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0057 - rmse: 0.0745\n",
      "Epoch 203: val_loss improved from 0.00452 to 0.00379, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0048 - rmse: 0.0683 - val_loss: 0.0038 - val_rmse: 0.0604 - lr: 1.0000e-04\n",
      "Epoch 204/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0049 - rmse: 0.0691\n",
      "Epoch 204: val_loss did not improve from 0.00379\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0046 - rmse: 0.0668 - val_loss: 0.0038 - val_rmse: 0.0604 - lr: 1.0000e-04\n",
      "Epoch 205/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0043 - rmse: 0.0646\n",
      "Epoch 205: val_loss improved from 0.00379 to 0.00316, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0038 - rmse: 0.0603 - val_loss: 0.0032 - val_rmse: 0.0549 - lr: 1.0000e-04\n",
      "Epoch 206/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0028 - rmse: 0.0516\n",
      "Epoch 206: val_loss did not improve from 0.00316\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0030 - rmse: 0.0537 - val_loss: 0.0033 - val_rmse: 0.0565 - lr: 1.0000e-04\n",
      "Epoch 207/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0031 - rmse: 0.0547\n",
      "Epoch 207: val_loss did not improve from 0.00316\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0032 - rmse: 0.0553 - val_loss: 0.0037 - val_rmse: 0.0594 - lr: 1.0000e-04\n",
      "Epoch 208/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0046 - rmse: 0.0671\n",
      "Epoch 208: val_loss improved from 0.00316 to 0.00241, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0037 - rmse: 0.0595 - val_loss: 0.0024 - val_rmse: 0.0475 - lr: 1.0000e-04\n",
      "Epoch 209/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0025 - rmse: 0.0488\n",
      "Epoch 209: val_loss did not improve from 0.00241\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0029 - rmse: 0.0522 - val_loss: 0.0044 - val_rmse: 0.0651 - lr: 1.0000e-04\n",
      "Epoch 210/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0045 - rmse: 0.0656\n",
      "Epoch 210: val_loss improved from 0.00241 to 0.00213, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0034 - rmse: 0.0569 - val_loss: 0.0021 - val_rmse: 0.0445 - lr: 1.0000e-04\n",
      "Epoch 211/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0437\n",
      "Epoch 211: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0024 - rmse: 0.0479 - val_loss: 0.0023 - val_rmse: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 212/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0417\n",
      "Epoch 212: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - rmse: 0.0448 - val_loss: 0.0025 - val_rmse: 0.0488 - lr: 1.0000e-04\n",
      "Epoch 213/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0025 - rmse: 0.0486\n",
      "Epoch 213: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - rmse: 0.0480 - val_loss: 0.0023 - val_rmse: 0.0459 - lr: 1.0000e-04\n",
      "Epoch 214/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0421\n",
      "Epoch 214: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - rmse: 0.0442 - val_loss: 0.0023 - val_rmse: 0.0459 - lr: 1.0000e-04\n",
      "Epoch 215/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0418\n",
      "Epoch 215: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0022 - rmse: 0.0451 - val_loss: 0.0022 - val_rmse: 0.0448 - lr: 1.0000e-04\n",
      "Epoch 216/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0023 - rmse: 0.0463\n",
      "Epoch 216: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0020 - rmse: 0.0431 - val_loss: 0.0022 - val_rmse: 0.0450 - lr: 1.0000e-04\n",
      "Epoch 217/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0023 - rmse: 0.0469\n",
      "Epoch 217: val_loss improved from 0.00213 to 0.00190, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0019 - rmse: 0.0421 - val_loss: 0.0019 - val_rmse: 0.0419 - lr: 1.0000e-04\n",
      "Epoch 218/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0446\n",
      "Epoch 218: val_loss improved from 0.00190 to 0.00184, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0019 - rmse: 0.0423 - val_loss: 0.0018 - val_rmse: 0.0411 - lr: 1.0000e-04\n",
      "Epoch 219/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0393\n",
      "Epoch 219: val_loss improved from 0.00184 to 0.00175, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0020 - rmse: 0.0428 - val_loss: 0.0017 - val_rmse: 0.0400 - lr: 1.0000e-04\n",
      "Epoch 220/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0342\n",
      "Epoch 220: val_loss improved from 0.00175 to 0.00168, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0017 - rmse: 0.0392 - val_loss: 0.0017 - val_rmse: 0.0392 - lr: 1.0000e-04\n",
      "Epoch 221/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0417\n",
      "Epoch 221: val_loss did not improve from 0.00168\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - rmse: 0.0403 - val_loss: 0.0018 - val_rmse: 0.0400 - lr: 1.0000e-04\n",
      "Epoch 222/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0394\n",
      "Epoch 222: val_loss did not improve from 0.00168\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0018 - rmse: 0.0404 - val_loss: 0.0017 - val_rmse: 0.0398 - lr: 1.0000e-04\n",
      "Epoch 223/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0368\n",
      "Epoch 223: val_loss improved from 0.00168 to 0.00161, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0019 - rmse: 0.0419 - val_loss: 0.0016 - val_rmse: 0.0382 - lr: 1.0000e-04\n",
      "Epoch 224/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0348\n",
      "Epoch 224: val_loss did not improve from 0.00161\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0014 - rmse: 0.0350 - val_loss: 0.0019 - val_rmse: 0.0421 - lr: 1.0000e-04\n",
      "Epoch 225/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0441\n",
      "Epoch 225: val_loss improved from 0.00161 to 0.00159, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0016 - rmse: 0.0385 - val_loss: 0.0016 - val_rmse: 0.0380 - lr: 1.0000e-04\n",
      "Epoch 226/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0400\n",
      "Epoch 226: val_loss improved from 0.00159 to 0.00145, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0019 - rmse: 0.0418 - val_loss: 0.0014 - val_rmse: 0.0360 - lr: 1.0000e-04\n",
      "Epoch 227/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.4872e-04 - rmse: 0.0283\n",
      "Epoch 227: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - rmse: 0.0348 - val_loss: 0.0015 - val_rmse: 0.0368 - lr: 1.0000e-04\n",
      "Epoch 228/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0396\n",
      "Epoch 228: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - rmse: 0.0382 - val_loss: 0.0018 - val_rmse: 0.0407 - lr: 1.0000e-04\n",
      "Epoch 229/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0020 - rmse: 0.0428\n",
      "Epoch 229: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0015 - rmse: 0.0373 - val_loss: 0.0016 - val_rmse: 0.0381 - lr: 1.0000e-04\n",
      "Epoch 230/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0393\n",
      "Epoch 230: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0018 - rmse: 0.0405 - val_loss: 0.0015 - val_rmse: 0.0373 - lr: 1.0000e-04\n",
      "Epoch 231/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.5893e-04 - rmse: 0.0267\n",
      "Epoch 231: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - rmse: 0.0322 - val_loss: 0.0016 - val_rmse: 0.0382 - lr: 1.0000e-04\n",
      "Epoch 232/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0399\n",
      "Epoch 232: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - rmse: 0.0369 - val_loss: 0.0016 - val_rmse: 0.0379 - lr: 1.0000e-04\n",
      "Epoch 233/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0334\n",
      "Epoch 233: val_loss did not improve from 0.00145\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0014 - rmse: 0.0358 - val_loss: 0.0016 - val_rmse: 0.0375 - lr: 1.0000e-04\n",
      "Epoch 234/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0020 - rmse: 0.0432\n",
      "Epoch 234: val_loss improved from 0.00145 to 0.00138, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0016 - rmse: 0.0385 - val_loss: 0.0014 - val_rmse: 0.0351 - lr: 1.0000e-04\n",
      "Epoch 235/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0371\n",
      "Epoch 235: val_loss did not improve from 0.00138\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - rmse: 0.0331 - val_loss: 0.0017 - val_rmse: 0.0397 - lr: 1.0000e-04\n",
      "Epoch 236/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0391\n",
      "Epoch 236: val_loss improved from 0.00138 to 0.00129, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0016 - rmse: 0.0376 - val_loss: 0.0013 - val_rmse: 0.0339 - lr: 1.0000e-04\n",
      "Epoch 237/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0366\n",
      "Epoch 237: val_loss did not improve from 0.00129\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0015 - rmse: 0.0362 - val_loss: 0.0015 - val_rmse: 0.0362 - lr: 1.0000e-04\n",
      "Epoch 238/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0405\n",
      "Epoch 238: val_loss did not improve from 0.00129\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - rmse: 0.0386 - val_loss: 0.0022 - val_rmse: 0.0453 - lr: 1.0000e-04\n",
      "Epoch 239/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0439\n",
      "Epoch 239: val_loss improved from 0.00129 to 0.00125, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0020 - rmse: 0.0425 - val_loss: 0.0013 - val_rmse: 0.0332 - lr: 1.0000e-04\n",
      "Epoch 240/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.3836e-04 - rmse: 0.0263\n",
      "Epoch 240: val_loss did not improve from 0.00125\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0012 - rmse: 0.0330 - val_loss: 0.0015 - val_rmse: 0.0371 - lr: 1.0000e-04\n",
      "Epoch 241/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0354\n",
      "Epoch 241: val_loss did not improve from 0.00125\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0015 - rmse: 0.0371 - val_loss: 0.0017 - val_rmse: 0.0393 - lr: 1.0000e-04\n",
      "Epoch 242/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0405\n",
      "Epoch 242: val_loss did not improve from 0.00125\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0016 - rmse: 0.0375 - val_loss: 0.0016 - val_rmse: 0.0375 - lr: 1.0000e-04\n",
      "Epoch 243/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0363\n",
      "Epoch 243: val_loss did not improve from 0.00125\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - rmse: 0.0380 - val_loss: 0.0014 - val_rmse: 0.0348 - lr: 1.0000e-04\n",
      "Epoch 244/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0322\n",
      "Epoch 244: val_loss improved from 0.00125 to 0.00115, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0013 - rmse: 0.0332 - val_loss: 0.0012 - val_rmse: 0.0317 - lr: 1.0000e-04\n",
      "Epoch 245/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.7327e-04 - rmse: 0.0287\n",
      "Epoch 245: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0012 - rmse: 0.0326 - val_loss: 0.0013 - val_rmse: 0.0335 - lr: 1.0000e-04\n",
      "Epoch 246/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0367\n",
      "Epoch 246: val_loss improved from 0.00115 to 0.00111, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0012 - rmse: 0.0324 - val_loss: 0.0011 - val_rmse: 0.0310 - lr: 1.0000e-04\n",
      "Epoch 247/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0326\n",
      "Epoch 247: val_loss improved from 0.00111 to 0.00109, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0013 - rmse: 0.0337 - val_loss: 0.0011 - val_rmse: 0.0308 - lr: 1.0000e-04\n",
      "Epoch 248/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0365\n",
      "Epoch 248: val_loss did not improve from 0.00109\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0011 - rmse: 0.0301 - val_loss: 0.0012 - val_rmse: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 249/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0376\n",
      "Epoch 249: val_loss did not improve from 0.00109\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0012 - rmse: 0.0330 - val_loss: 0.0011 - val_rmse: 0.0309 - lr: 1.0000e-04\n",
      "Epoch 250/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5531e-04 - rmse: 0.0202\n",
      "Epoch 250: val_loss improved from 0.00109 to 0.00106, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0010 - rmse: 0.0294 - val_loss: 0.0011 - val_rmse: 0.0302 - lr: 1.0000e-04\n",
      "Epoch 251/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.3950e-04 - rmse: 0.0281\n",
      "Epoch 251: val_loss did not improve from 0.00106\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0011 - rmse: 0.0305 - val_loss: 0.0011 - val_rmse: 0.0304 - lr: 1.0000e-04\n",
      "Epoch 252/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0321\n",
      "Epoch 252: val_loss did not improve from 0.00106\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0011 - rmse: 0.0304 - val_loss: 0.0011 - val_rmse: 0.0305 - lr: 1.0000e-04\n",
      "Epoch 253/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0303\n",
      "Epoch 253: val_loss improved from 0.00106 to 0.00103, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0010 - rmse: 0.0293 - val_loss: 0.0010 - val_rmse: 0.0296 - lr: 1.0000e-04\n",
      "Epoch 254/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0341\n",
      "Epoch 254: val_loss improved from 0.00103 to 0.00102, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0011 - rmse: 0.0316 - val_loss: 0.0010 - val_rmse: 0.0295 - lr: 1.0000e-04\n",
      "Epoch 255/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0307\n",
      "Epoch 255: val_loss did not improve from 0.00102\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0012 - rmse: 0.0329 - val_loss: 0.0010 - val_rmse: 0.0300 - lr: 1.0000e-04\n",
      "Epoch 256/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3204e-04 - rmse: 0.0220\n",
      "Epoch 256: val_loss did not improve from 0.00102\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 8.7200e-04 - rmse: 0.0269 - val_loss: 0.0011 - val_rmse: 0.0303 - lr: 1.0000e-04\n",
      "Epoch 257/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.7385e-04 - rmse: 0.0287\n",
      "Epoch 257: val_loss improved from 0.00102 to 0.00099, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0011 - rmse: 0.0304 - val_loss: 9.9356e-04 - val_rmse: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 258/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.4071e-04 - rmse: 0.0282\n",
      "Epoch 258: val_loss did not improve from 0.00099\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 9.8009e-04 - rmse: 0.0289 - val_loss: 0.0010 - val_rmse: 0.0298 - lr: 1.0000e-04\n",
      "Epoch 259/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.4129e-04 - rmse: 0.0263\n",
      "Epoch 259: val_loss did not improve from 0.00099\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0010 - rmse: 0.0297 - val_loss: 0.0010 - val_rmse: 0.0295 - lr: 1.0000e-04\n",
      "Epoch 260/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.2257e-04 - rmse: 0.0260\n",
      "Epoch 260: val_loss improved from 0.00099 to 0.00097, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0010 - rmse: 0.0298 - val_loss: 9.6933e-04 - val_rmse: 0.0287 - lr: 1.0000e-04\n",
      "Epoch 261/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0317\n",
      "Epoch 261: val_loss did not improve from 0.00097\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0010 - rmse: 0.0296 - val_loss: 9.7456e-04 - val_rmse: 0.0288 - lr: 1.0000e-04\n",
      "Epoch 262/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.7177e-04 - rmse: 0.0287\n",
      "Epoch 262: val_loss did not improve from 0.00097\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 9.2867e-04 - rmse: 0.0280 - val_loss: 9.9382e-04 - val_rmse: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 263/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0334\n",
      "Epoch 263: val_loss improved from 0.00097 to 0.00092, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 9.9779e-04 - rmse: 0.0292 - val_loss: 9.1606e-04 - val_rmse: 0.0277 - lr: 1.0000e-04\n",
      "Epoch 264/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.9680e-04 - rmse: 0.0274\n",
      "Epoch 264: val_loss did not improve from 0.00092\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 9.5271e-04 - rmse: 0.0284 - val_loss: 9.6004e-04 - val_rmse: 0.0285 - lr: 1.0000e-04\n",
      "Epoch 265/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.9863e-04 - rmse: 0.0292\n",
      "Epoch 265: val_loss did not improve from 0.00092\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0010 - rmse: 0.0295 - val_loss: 9.3127e-04 - val_rmse: 0.0280 - lr: 1.0000e-04\n",
      "Epoch 266/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9672e-04 - rmse: 0.0187\n",
      "Epoch 266: val_loss improved from 0.00092 to 0.00089, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 8.0692e-04 - rmse: 0.0257 - val_loss: 8.9119e-04 - val_rmse: 0.0273 - lr: 1.0000e-04\n",
      "Epoch 267/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0300\n",
      "Epoch 267: val_loss did not improve from 0.00089\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 9.1558e-04 - rmse: 0.0277 - val_loss: 9.1226e-04 - val_rmse: 0.0277 - lr: 1.0000e-04\n",
      "Epoch 268/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0899e-04 - rmse: 0.0276\n",
      "Epoch 268: val_loss improved from 0.00089 to 0.00088, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 9.5204e-04 - rmse: 0.0284 - val_loss: 8.7691e-04 - val_rmse: 0.0270 - lr: 1.0000e-04\n",
      "Epoch 269/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.8065e-04 - rmse: 0.0208\n",
      "Epoch 269: val_loss improved from 0.00088 to 0.00087, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 8.1078e-04 - rmse: 0.0258 - val_loss: 8.7414e-04 - val_rmse: 0.0270 - lr: 1.0000e-04\n",
      "Epoch 270/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0372\n",
      "Epoch 270: val_loss improved from 0.00087 to 0.00085, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0011 - rmse: 0.0310 - val_loss: 8.4930e-04 - val_rmse: 0.0265 - lr: 1.0000e-04\n",
      "Epoch 271/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.1135e-04 - rmse: 0.0238\n",
      "Epoch 271: val_loss did not improve from 0.00085\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 9.0574e-04 - rmse: 0.0275 - val_loss: 8.8062e-04 - val_rmse: 0.0271 - lr: 1.0000e-04\n",
      "Epoch 272/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.5299e-04 - rmse: 0.0284\n",
      "Epoch 272: val_loss improved from 0.00085 to 0.00084, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 8.4050e-04 - rmse: 0.0263 - val_loss: 8.4199e-04 - val_rmse: 0.0264 - lr: 1.0000e-04\n",
      "Epoch 273/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.7530e-04 - rmse: 0.0270\n",
      "Epoch 273: val_loss did not improve from 0.00084\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.2869e-04 - rmse: 0.0280 - val_loss: 8.5132e-04 - val_rmse: 0.0265 - lr: 1.0000e-04\n",
      "Epoch 274/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.8000e-04 - rmse: 0.0231\n",
      "Epoch 274: val_loss did not improve from 0.00084\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 8.8423e-04 - rmse: 0.0272 - val_loss: 8.4762e-04 - val_rmse: 0.0265 - lr: 1.0000e-04\n",
      "Epoch 275/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0676e-04 - rmse: 0.0276\n",
      "Epoch 275: val_loss did not improve from 0.00084\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 8.2941e-04 - rmse: 0.0261 - val_loss: 9.0952e-04 - val_rmse: 0.0276 - lr: 1.0000e-04\n",
      "Epoch 276/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.7047e-04 - rmse: 0.0250\n",
      "Epoch 276: val_loss improved from 0.00084 to 0.00081, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 8.9592e-04 - rmse: 0.0274 - val_loss: 8.0789e-04 - val_rmse: 0.0257 - lr: 1.0000e-04\n",
      "Epoch 277/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0329\n",
      "Epoch 277: val_loss improved from 0.00081 to 0.00080, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 9.1144e-04 - rmse: 0.0277 - val_loss: 7.9813e-04 - val_rmse: 0.0255 - lr: 1.0000e-04\n",
      "Epoch 278/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.0511e-04 - rmse: 0.0189\n",
      "Epoch 278: val_loss did not improve from 0.00080\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 7.0644e-04 - rmse: 0.0237 - val_loss: 8.3478e-04 - val_rmse: 0.0262 - lr: 1.0000e-04\n",
      "Epoch 279/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0296\n",
      "Epoch 279: val_loss improved from 0.00080 to 0.00078, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 8.6026e-04 - rmse: 0.0267 - val_loss: 7.8247e-04 - val_rmse: 0.0252 - lr: 1.0000e-04\n",
      "Epoch 280/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.9048e-04 - rmse: 0.0273\n",
      "Epoch 280: val_loss did not improve from 0.00078\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 8.6788e-04 - rmse: 0.0269 - val_loss: 8.0018e-04 - val_rmse: 0.0256 - lr: 1.0000e-04\n",
      "Epoch 281/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.7771e-04 - rmse: 0.0251\n",
      "Epoch 281: val_loss did not improve from 0.00078\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.0245e-04 - rmse: 0.0256 - val_loss: 8.3886e-04 - val_rmse: 0.0263 - lr: 1.0000e-04\n",
      "Epoch 282/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.3052e-04 - rmse: 0.0280\n",
      "Epoch 282: val_loss did not improve from 0.00078\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.6305e-04 - rmse: 0.0268 - val_loss: 8.4098e-04 - val_rmse: 0.0263 - lr: 1.0000e-04\n",
      "Epoch 283/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.8542e-04 - rmse: 0.0272\n",
      "Epoch 283: val_loss did not improve from 0.00078\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 7.9210e-04 - rmse: 0.0254 - val_loss: 7.8440e-04 - val_rmse: 0.0253 - lr: 1.0000e-04\n",
      "Epoch 284/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.7460e-04 - rmse: 0.0251\n",
      "Epoch 284: val_loss improved from 0.00078 to 0.00077, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 8.3364e-04 - rmse: 0.0262 - val_loss: 7.7337e-04 - val_rmse: 0.0250 - lr: 1.0000e-04\n",
      "Epoch 285/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0308\n",
      "Epoch 285: val_loss improved from 0.00077 to 0.00074, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 8.3909e-04 - rmse: 0.0263 - val_loss: 7.3626e-04 - val_rmse: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 286/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9254e-04 - rmse: 0.0186\n",
      "Epoch 286: val_loss did not improve from 0.00074\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 5.7229e-04 - rmse: 0.0206 - val_loss: 8.1588e-04 - val_rmse: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 287/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.9977e-04 - rmse: 0.0274\n",
      "Epoch 287: val_loss did not improve from 0.00074\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.0501e-04 - rmse: 0.0275 - val_loss: 7.4590e-04 - val_rmse: 0.0245 - lr: 1.0000e-04\n",
      "Epoch 288/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.6495e-04 - rmse: 0.0249\n",
      "Epoch 288: val_loss improved from 0.00074 to 0.00071, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 7.2847e-04 - rmse: 0.0241 - val_loss: 7.1471e-04 - val_rmse: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 289/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.5453e-04 - rmse: 0.0176\n",
      "Epoch 289: val_loss did not improve from 0.00071\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 6.9026e-04 - rmse: 0.0233 - val_loss: 7.4307e-04 - val_rmse: 0.0244 - lr: 1.0000e-04\n",
      "Epoch 290/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.6967e-04 - rmse: 0.0287\n",
      "Epoch 290: val_loss did not improve from 0.00071\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 7.7138e-04 - rmse: 0.0250 - val_loss: 7.1479e-04 - val_rmse: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 291/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.5137e-04 - rmse: 0.0266\n",
      "Epoch 291: val_loss did not improve from 0.00071\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 7.8472e-04 - rmse: 0.0253 - val_loss: 7.4474e-04 - val_rmse: 0.0245 - lr: 1.0000e-04\n",
      "Epoch 292/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.9425e-04 - rmse: 0.0234\n",
      "Epoch 292: val_loss improved from 0.00071 to 0.00071, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 6.5938e-04 - rmse: 0.0227 - val_loss: 7.0543e-04 - val_rmse: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 293/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3829e-04 - rmse: 0.0198\n",
      "Epoch 293: val_loss improved from 0.00071 to 0.00070, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 6.9667e-04 - rmse: 0.0235 - val_loss: 7.0296e-04 - val_rmse: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 294/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.3090e-04 - rmse: 0.0262\n",
      "Epoch 294: val_loss improved from 0.00070 to 0.00070, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 7.6636e-04 - rmse: 0.0249 - val_loss: 7.0079e-04 - val_rmse: 0.0235 - lr: 1.0000e-04\n",
      "Epoch 295/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.5472e-04 - rmse: 0.0225\n",
      "Epoch 295: val_loss did not improve from 0.00070\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 7.4065e-04 - rmse: 0.0244 - val_loss: 7.2165e-04 - val_rmse: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 296/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.1937e-04 - rmse: 0.0218\n",
      "Epoch 296: val_loss improved from 0.00070 to 0.00066, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 102ms/step - loss: 6.7104e-04 - rmse: 0.0229 - val_loss: 6.6142e-04 - val_rmse: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 297/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.6767e-04 - rmse: 0.0205\n",
      "Epoch 297: val_loss did not improve from 0.00066\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 7.1534e-04 - rmse: 0.0239 - val_loss: 6.6899e-04 - val_rmse: 0.0229 - lr: 1.0000e-04\n",
      "Epoch 298/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4694e-04 - rmse: 0.0173\n",
      "Epoch 298: val_loss did not improve from 0.00066\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 6.4423e-04 - rmse: 0.0223 - val_loss: 6.7515e-04 - val_rmse: 0.0230 - lr: 1.0000e-04\n",
      "Epoch 299/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.0191e-04 - rmse: 0.0256\n",
      "Epoch 299: val_loss did not improve from 0.00066\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 6.3368e-04 - rmse: 0.0221 - val_loss: 7.1030e-04 - val_rmse: 0.0238 - lr: 1.0000e-04\n",
      "Epoch 300/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.1649e-04 - rmse: 0.0278\n",
      "Epoch 300: val_loss improved from 0.00066 to 0.00065, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 6.8962e-04 - rmse: 0.0233 - val_loss: 6.5119e-04 - val_rmse: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 301/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.4818e-04 - rmse: 0.0224\n",
      "Epoch 301: val_loss did not improve from 0.00065\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 6.7219e-04 - rmse: 0.0229 - val_loss: 7.0251e-04 - val_rmse: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 302/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.7539e-04 - rmse: 0.0230\n",
      "Epoch 302: val_loss did not improve from 0.00065\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 7.6977e-04 - rmse: 0.0250 - val_loss: 6.8257e-04 - val_rmse: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 303/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4861e-04 - rmse: 0.0174\n",
      "Epoch 303: val_loss did not improve from 0.00065\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 5.8553e-04 - rmse: 0.0210 - val_loss: 7.9851e-04 - val_rmse: 0.0255 - lr: 1.0000e-04\n",
      "Epoch 304/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.2984e-04 - rmse: 0.0262\n",
      "Epoch 304: val_loss did not improve from 0.00065\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 7.2471e-04 - rmse: 0.0241 - val_loss: 6.7131e-04 - val_rmse: 0.0229 - lr: 1.0000e-04\n",
      "Epoch 305/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4166e-04 - rmse: 0.0199\n",
      "Epoch 305: val_loss did not improve from 0.00065\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 7.3462e-04 - rmse: 0.0243 - val_loss: 6.8687e-04 - val_rmse: 0.0233 - lr: 1.0000e-04\n",
      "Epoch 306/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3923e-04 - rmse: 0.0198\n",
      "Epoch 306: val_loss improved from 0.00065 to 0.00064, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 7.3615e-04 - rmse: 0.0243 - val_loss: 6.3599e-04 - val_rmse: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 307/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.6440e-04 - rmse: 0.0205\n",
      "Epoch 307: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 5.7109e-04 - rmse: 0.0206 - val_loss: 7.1663e-04 - val_rmse: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 308/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.0792e-04 - rmse: 0.0215\n",
      "Epoch 308: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 7.0828e-04 - rmse: 0.0237 - val_loss: 6.5936e-04 - val_rmse: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 309/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3893e-04 - rmse: 0.0222\n",
      "Epoch 309: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 6.2576e-04 - rmse: 0.0219 - val_loss: 7.1841e-04 - val_rmse: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 310/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.7182e-04 - rmse: 0.0287\n",
      "Epoch 310: val_loss improved from 0.00064 to 0.00063, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 7.8464e-04 - rmse: 0.0253 - val_loss: 6.2616e-04 - val_rmse: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 311/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.2552e-04 - rmse: 0.0219\n",
      "Epoch 311: val_loss did not improve from 0.00063\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 6.8608e-04 - rmse: 0.0232 - val_loss: 7.3660e-04 - val_rmse: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 312/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.0382e-04 - rmse: 0.0236\n",
      "Epoch 312: val_loss did not improve from 0.00063\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 6.2003e-04 - rmse: 0.0218 - val_loss: 7.2740e-04 - val_rmse: 0.0241 - lr: 1.0000e-04\n",
      "Epoch 313/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.2310e-04 - rmse: 0.0219\n",
      "Epoch 313: val_loss improved from 0.00063 to 0.00062, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 6.8247e-04 - rmse: 0.0232 - val_loss: 6.2326e-04 - val_rmse: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 314/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5868e-04 - rmse: 0.0203\n",
      "Epoch 314: val_loss did not improve from 0.00062\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 7.1936e-04 - rmse: 0.0240 - val_loss: 7.4105e-04 - val_rmse: 0.0244 - lr: 1.0000e-04\n",
      "Epoch 315/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.8144e-04 - rmse: 0.0232\n",
      "Epoch 315: val_loss did not improve from 0.00062\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 8.0804e-04 - rmse: 0.0257 - val_loss: 6.2508e-04 - val_rmse: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 316/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4682e-04 - rmse: 0.0200\n",
      "Epoch 316: val_loss did not improve from 0.00062\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 7.2989e-04 - rmse: 0.0242 - val_loss: 0.0011 - val_rmse: 0.0316 - lr: 1.0000e-04\n",
      "Epoch 317/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.5579e-04 - rmse: 0.0285\n",
      "Epoch 317: val_loss did not improve from 0.00062\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 8.1521e-04 - rmse: 0.0259 - val_loss: 7.3784e-04 - val_rmse: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 318/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0951e-04 - rmse: 0.0276\n",
      "Epoch 318: val_loss did not improve from 0.00062\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 7.9092e-04 - rmse: 0.0254 - val_loss: 8.1986e-04 - val_rmse: 0.0260 - lr: 1.0000e-04\n",
      "Epoch 319/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0078e-04 - rmse: 0.0275\n",
      "Epoch 319: val_loss improved from 0.00062 to 0.00061, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 7.5698e-04 - rmse: 0.0247 - val_loss: 6.1388e-04 - val_rmse: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 320/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4513e-04 - rmse: 0.0200\n",
      "Epoch 320: val_loss did not improve from 0.00061\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 6.1768e-04 - rmse: 0.0217 - val_loss: 7.3457e-04 - val_rmse: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 321/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3502e-04 - rmse: 0.0221\n",
      "Epoch 321: val_loss improved from 0.00061 to 0.00058, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 6.1986e-04 - rmse: 0.0218 - val_loss: 5.8363e-04 - val_rmse: 0.0209 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.7770e-04 - rmse: 0.0251\n",
      "Epoch 322: val_loss improved from 0.00058 to 0.00055, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 6.2873e-04 - rmse: 0.0220 - val_loss: 5.4811e-04 - val_rmse: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 323/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9318e-04 - rmse: 0.0187\n",
      "Epoch 323: val_loss improved from 0.00055 to 0.00054, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.8878e-04 - rmse: 0.0211 - val_loss: 5.3830e-04 - val_rmse: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 324/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.7022e-04 - rmse: 0.0206\n",
      "Epoch 324: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 5.7356e-04 - rmse: 0.0207 - val_loss: 5.7423e-04 - val_rmse: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 325/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.7125e-04 - rmse: 0.0206\n",
      "Epoch 325: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 6.2713e-04 - rmse: 0.0220 - val_loss: 5.5191e-04 - val_rmse: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 326/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7267e-04 - rmse: 0.0151\n",
      "Epoch 326: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 5.3476e-04 - rmse: 0.0197 - val_loss: 7.0785e-04 - val_rmse: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 327/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.0098e-04 - rmse: 0.0236\n",
      "Epoch 327: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 6.7336e-04 - rmse: 0.0230 - val_loss: 5.5088e-04 - val_rmse: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 328/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5936e-04 - rmse: 0.0204\n",
      "Epoch 328: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 6.1127e-04 - rmse: 0.0216 - val_loss: 6.5682e-04 - val_rmse: 0.0226 - lr: 1.0000e-04\n",
      "Epoch 329/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.9286e-04 - rmse: 0.0234\n",
      "Epoch 329: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 6.7389e-04 - rmse: 0.0230 - val_loss: 6.9166e-04 - val_rmse: 0.0234 - lr: 1.0000e-04\n",
      "Epoch 330/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3751e-04 - rmse: 0.0222\n",
      "Epoch 330: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.0049e-04 - rmse: 0.0256 - val_loss: 9.9958e-04 - val_rmse: 0.0292 - lr: 1.0000e-04\n",
      "Epoch 331/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.9249e-04 - rmse: 0.0273\n",
      "Epoch 331: val_loss improved from 0.00054 to 0.00053, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 8.9705e-04 - rmse: 0.0274 - val_loss: 5.2920e-04 - val_rmse: 0.0196 - lr: 1.0000e-04\n",
      "Epoch 332/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3856e-04 - rmse: 0.0222\n",
      "Epoch 332: val_loss did not improve from 0.00053\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 7.6012e-04 - rmse: 0.0248 - val_loss: 8.4636e-04 - val_rmse: 0.0265 - lr: 1.0000e-04\n",
      "Epoch 333/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.7725e-04 - rmse: 0.0289\n",
      "Epoch 333: val_loss improved from 0.00053 to 0.00050, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 7.4316e-04 - rmse: 0.0245 - val_loss: 4.9574e-04 - val_rmse: 0.0187 - lr: 1.0000e-04\n",
      "Epoch 334/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.0354e-04 - rmse: 0.0161\n",
      "Epoch 334: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 5.7773e-04 - rmse: 0.0208 - val_loss: 7.1600e-04 - val_rmse: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 335/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.0082e-04 - rmse: 0.0214\n",
      "Epoch 335: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 5.6430e-04 - rmse: 0.0205 - val_loss: 4.9989e-04 - val_rmse: 0.0188 - lr: 1.0000e-04\n",
      "Epoch 336/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5159e-04 - rmse: 0.0202\n",
      "Epoch 336: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 5.3746e-04 - rmse: 0.0198 - val_loss: 5.1481e-04 - val_rmse: 0.0192 - lr: 1.0000e-04\n",
      "Epoch 337/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.3948e-04 - rmse: 0.0172\n",
      "Epoch 337: val_loss improved from 0.00050 to 0.00048, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 4.5247e-04 - rmse: 0.0175 - val_loss: 4.7766e-04 - val_rmse: 0.0182 - lr: 1.0000e-04\n",
      "Epoch 338/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.2470e-04 - rmse: 0.0241\n",
      "Epoch 338: val_loss did not improve from 0.00048\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 4.7942e-04 - rmse: 0.0183 - val_loss: 5.1507e-04 - val_rmse: 0.0192 - lr: 1.0000e-04\n",
      "Epoch 339/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9094e-04 - rmse: 0.0186\n",
      "Epoch 339: val_loss did not improve from 0.00048\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 5.1390e-04 - rmse: 0.0192 - val_loss: 4.7943e-04 - val_rmse: 0.0183 - lr: 1.0000e-04\n",
      "Epoch 340/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.8899e-04 - rmse: 0.0186\n",
      "Epoch 340: val_loss did not improve from 0.00048\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 4.8023e-04 - rmse: 0.0183 - val_loss: 4.9379e-04 - val_rmse: 0.0187 - lr: 1.0000e-04\n",
      "Epoch 341/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9096e-04 - rmse: 0.0157\n",
      "Epoch 341: val_loss improved from 0.00048 to 0.00047, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 4.2979e-04 - rmse: 0.0169 - val_loss: 4.6959e-04 - val_rmse: 0.0180 - lr: 1.0000e-04\n",
      "Epoch 342/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.7230e-04 - rmse: 0.0230\n",
      "Epoch 342: val_loss did not improve from 0.00047\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 4.8130e-04 - rmse: 0.0184 - val_loss: 5.3186e-04 - val_rmse: 0.0197 - lr: 1.0000e-04\n",
      "Epoch 343/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1923e-04 - rmse: 0.0194\n",
      "Epoch 343: val_loss improved from 0.00047 to 0.00045, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 4.2791e-04 - rmse: 0.0168 - val_loss: 4.4975e-04 - val_rmse: 0.0175 - lr: 1.0000e-04\n",
      "Epoch 344/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.5880e-04 - rmse: 0.0177\n",
      "Epoch 344: val_loss improved from 0.00045 to 0.00045, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 4.6520e-04 - rmse: 0.0179 - val_loss: 4.4679e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 345/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9984e-04 - rmse: 0.0160\n",
      "Epoch 345: val_loss improved from 0.00045 to 0.00044, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 4.0944e-04 - rmse: 0.0163 - val_loss: 4.3710e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.7106e-04 - rmse: 0.0181\n",
      "Epoch 346: val_loss did not improve from 0.00044\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.5179e-04 - rmse: 0.0175 - val_loss: 4.4515e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 347/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5633e-04 - rmse: 0.0146\n",
      "Epoch 347: val_loss improved from 0.00044 to 0.00043, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 3.9158e-04 - rmse: 0.0157 - val_loss: 4.3490e-04 - val_rmse: 0.0170 - lr: 1.0000e-04\n",
      "Epoch 348/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8162e-04 - rmse: 0.0154\n",
      "Epoch 348: val_loss improved from 0.00043 to 0.00043, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 4.2583e-04 - rmse: 0.0168 - val_loss: 4.3480e-04 - val_rmse: 0.0170 - lr: 1.0000e-04\n",
      "Epoch 349/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6599e-04 - rmse: 0.0149\n",
      "Epoch 349: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.3445e-04 - rmse: 0.0170 - val_loss: 4.3706e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 350/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9951e-04 - rmse: 0.0125\n",
      "Epoch 350: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.9497e-04 - rmse: 0.0158 - val_loss: 4.4182e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 351/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.5554e-04 - rmse: 0.0176\n",
      "Epoch 351: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.7077e-04 - rmse: 0.0151 - val_loss: 4.3600e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 352/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9265e-04 - rmse: 0.0158\n",
      "Epoch 352: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 4.5167e-04 - rmse: 0.0175 - val_loss: 4.3976e-04 - val_rmse: 0.0172 - lr: 1.0000e-04\n",
      "Epoch 353/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9950e-04 - rmse: 0.0160\n",
      "Epoch 353: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4.1792e-04 - rmse: 0.0165 - val_loss: 4.5285e-04 - val_rmse: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 354/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1848e-04 - rmse: 0.0194\n",
      "Epoch 354: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.0136e-04 - rmse: 0.0160 - val_loss: 4.4177e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 355/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1798e-04 - rmse: 0.0193\n",
      "Epoch 355: val_loss did not improve from 0.00043\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.7990e-04 - rmse: 0.0183 - val_loss: 4.4991e-04 - val_rmse: 0.0175 - lr: 1.0000e-04\n",
      "Epoch 356/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7869e-04 - rmse: 0.0153\n",
      "Epoch 356: val_loss improved from 0.00043 to 0.00042, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 3.6824e-04 - rmse: 0.0150 - val_loss: 4.2017e-04 - val_rmse: 0.0166 - lr: 1.0000e-04\n",
      "Epoch 357/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.3283e-04 - rmse: 0.0170\n",
      "Epoch 357: val_loss did not improve from 0.00042\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4.2858e-04 - rmse: 0.0169 - val_loss: 4.2345e-04 - val_rmse: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 358/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6899e-04 - rmse: 0.0112\n",
      "Epoch 358: val_loss improved from 0.00042 to 0.00041, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 4.1267e-04 - rmse: 0.0164 - val_loss: 4.1213e-04 - val_rmse: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 359/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7170e-04 - rmse: 0.0113\n",
      "Epoch 359: val_loss did not improve from 0.00041\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.7106e-04 - rmse: 0.0151 - val_loss: 4.5948e-04 - val_rmse: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 360/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4626e-04 - rmse: 0.0174\n",
      "Epoch 360: val_loss improved from 0.00041 to 0.00040, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 3.8290e-04 - rmse: 0.0155 - val_loss: 4.0210e-04 - val_rmse: 0.0161 - lr: 1.0000e-04\n",
      "Epoch 361/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.5079e-04 - rmse: 0.0175\n",
      "Epoch 361: val_loss improved from 0.00040 to 0.00038, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 3.8967e-04 - rmse: 0.0157 - val_loss: 3.8161e-04 - val_rmse: 0.0154 - lr: 1.0000e-04\n",
      "Epoch 362/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9214e-04 - rmse: 0.0122\n",
      "Epoch 362: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.5708e-04 - rmse: 0.0146 - val_loss: 3.8850e-04 - val_rmse: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 363/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8396e-04 - rmse: 0.0155\n",
      "Epoch 363: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.4702e-04 - rmse: 0.0143 - val_loss: 3.8323e-04 - val_rmse: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 364/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5693e-04 - rmse: 0.0146\n",
      "Epoch 364: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.6474e-04 - rmse: 0.0149 - val_loss: 3.8508e-04 - val_rmse: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 365/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2829e-04 - rmse: 0.0136\n",
      "Epoch 365: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.5504e-04 - rmse: 0.0145 - val_loss: 3.9113e-04 - val_rmse: 0.0157 - lr: 1.0000e-04\n",
      "Epoch 366/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.1000e-04 - rmse: 0.0163\n",
      "Epoch 366: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.6939e-04 - rmse: 0.0150 - val_loss: 3.8927e-04 - val_rmse: 0.0157 - lr: 1.0000e-04\n",
      "Epoch 367/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8006e-04 - rmse: 0.0154\n",
      "Epoch 367: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.7120e-04 - rmse: 0.0151 - val_loss: 3.9165e-04 - val_rmse: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 368/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2148e-04 - rmse: 0.0133\n",
      "Epoch 368: val_loss did not improve from 0.00038\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.5629e-04 - rmse: 0.0146 - val_loss: 4.2371e-04 - val_rmse: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 369/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1842e-04 - rmse: 0.0132\n",
      "Epoch 369: val_loss improved from 0.00038 to 0.00037, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 3.5196e-04 - rmse: 0.0144 - val_loss: 3.6879e-04 - val_rmse: 0.0150 - lr: 1.0000e-04\n",
      "Epoch 370/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.6269e-04 - rmse: 0.0179\n",
      "Epoch 370: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.6114e-04 - rmse: 0.0148 - val_loss: 4.0246e-04 - val_rmse: 0.0161 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.2067e-04 - rmse: 0.0167\n",
      "Epoch 371: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 4.0053e-04 - rmse: 0.0160 - val_loss: 3.7153e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 372/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0329e-04 - rmse: 0.0126\n",
      "Epoch 372: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.4953e-04 - rmse: 0.0144 - val_loss: 3.8515e-04 - val_rmse: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 373/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6931e-04 - rmse: 0.0150\n",
      "Epoch 373: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8759e-04 - rmse: 0.0156 - val_loss: 4.3537e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 374/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1159e-04 - rmse: 0.0130\n",
      "Epoch 374: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.6269e-04 - rmse: 0.0148 - val_loss: 3.7185e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 375/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3749e-04 - rmse: 0.0139\n",
      "Epoch 375: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.3827e-04 - rmse: 0.0140 - val_loss: 4.1103e-04 - val_rmse: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 376/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5149e-04 - rmse: 0.0144\n",
      "Epoch 376: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.9853e-04 - rmse: 0.0160 - val_loss: 3.8077e-04 - val_rmse: 0.0154 - lr: 1.0000e-04\n",
      "Epoch 377/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.1551e-04 - rmse: 0.0165\n",
      "Epoch 377: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.5708e-04 - rmse: 0.0146 - val_loss: 3.7030e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 378/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5212e-04 - rmse: 0.0145\n",
      "Epoch 378: val_loss did not improve from 0.00037\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.2919e-04 - rmse: 0.0136 - val_loss: 3.7052e-04 - val_rmse: 0.0151 - lr: 1.0000e-04\n",
      "Epoch 379/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.2651e-04 - rmse: 0.0168\n",
      "Epoch 379: val_loss improved from 0.00037 to 0.00036, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 3.4222e-04 - rmse: 0.0141 - val_loss: 3.5682e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 380/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6059e-04 - rmse: 0.0108\n",
      "Epoch 380: val_loss improved from 0.00036 to 0.00034, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 3.6408e-04 - rmse: 0.0149 - val_loss: 3.4371e-04 - val_rmse: 0.0142 - lr: 1.0000e-04\n",
      "Epoch 381/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5152e-04 - rmse: 0.0144\n",
      "Epoch 381: val_loss did not improve from 0.00034\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.1687e-04 - rmse: 0.0132 - val_loss: 3.5496e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 382/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5847e-04 - rmse: 0.0147\n",
      "Epoch 382: val_loss did not improve from 0.00034\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.3890e-04 - rmse: 0.0140 - val_loss: 3.5928e-04 - val_rmse: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 383/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2372e-04 - rmse: 0.0134\n",
      "Epoch 383: val_loss improved from 0.00034 to 0.00034, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 3.2536e-04 - rmse: 0.0135 - val_loss: 3.4224e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 384/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4961e-04 - rmse: 0.0144\n",
      "Epoch 384: val_loss improved from 0.00034 to 0.00034, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 3.4422e-04 - rmse: 0.0142 - val_loss: 3.3650e-04 - val_rmse: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 385/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9417e-04 - rmse: 0.0123\n",
      "Epoch 385: val_loss did not improve from 0.00034\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.9532e-04 - rmse: 0.0124 - val_loss: 3.4849e-04 - val_rmse: 0.0143 - lr: 1.0000e-04\n",
      "Epoch 386/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.3969e-04 - rmse: 0.0172\n",
      "Epoch 386: val_loss did not improve from 0.00034\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.2665e-04 - rmse: 0.0136 - val_loss: 3.3988e-04 - val_rmse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 387/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2632e-04 - rmse: 0.0135\n",
      "Epoch 387: val_loss did not improve from 0.00034\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.0057e-04 - rmse: 0.0126 - val_loss: 3.5235e-04 - val_rmse: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 388/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2256e-04 - rmse: 0.0134\n",
      "Epoch 388: val_loss improved from 0.00034 to 0.00033, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 3.6358e-04 - rmse: 0.0149 - val_loss: 3.3168e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 389/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5636e-04 - rmse: 0.0146\n",
      "Epoch 389: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.1264e-04 - rmse: 0.0130 - val_loss: 3.4275e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 390/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3840e-04 - rmse: 0.0140\n",
      "Epoch 390: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.5031e-04 - rmse: 0.0144 - val_loss: 3.5516e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 391/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7253e-04 - rmse: 0.0152\n",
      "Epoch 391: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.0720e-04 - rmse: 0.0128 - val_loss: 3.4735e-04 - val_rmse: 0.0143 - lr: 1.0000e-04\n",
      "Epoch 392/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6911e-04 - rmse: 0.0151\n",
      "Epoch 392: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.3658e-04 - rmse: 0.0139 - val_loss: 3.5676e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 393/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.7014e-04 - rmse: 0.0181\n",
      "Epoch 393: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.4274e-04 - rmse: 0.0142 - val_loss: 3.5348e-04 - val_rmse: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 394/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0913e-04 - rmse: 0.0082\n",
      "Epoch 394: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.7315e-04 - rmse: 0.0114 - val_loss: 3.3777e-04 - val_rmse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 395/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4543e-04 - rmse: 0.0142\n",
      "Epoch 395: val_loss improved from 0.00033 to 0.00033, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 3.3213e-04 - rmse: 0.0138 - val_loss: 3.2620e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 396/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8340e-04 - rmse: 0.0119\n",
      "Epoch 396: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.1583e-04 - rmse: 0.0132 - val_loss: 3.3146e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 397/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8615e-04 - rmse: 0.0156\n",
      "Epoch 397: val_loss improved from 0.00033 to 0.00032, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 3.1780e-04 - rmse: 0.0132 - val_loss: 3.2321e-04 - val_rmse: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 398/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0565e-04 - rmse: 0.0080\n",
      "Epoch 398: val_loss improved from 0.00032 to 0.00031, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 2.7842e-04 - rmse: 0.0117 - val_loss: 3.1317e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 399/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2113e-04 - rmse: 0.0134\n",
      "Epoch 399: val_loss improved from 0.00031 to 0.00030, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 3.0504e-04 - rmse: 0.0128 - val_loss: 3.0440e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 400/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9149e-04 - rmse: 0.0122\n",
      "Epoch 400: val_loss did not improve from 0.00030\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.7050e-04 - rmse: 0.0113 - val_loss: 3.1189e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 401/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6609e-04 - rmse: 0.0111\n",
      "Epoch 401: val_loss improved from 0.00030 to 0.00030, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 2.6769e-04 - rmse: 0.0112 - val_loss: 2.9859e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 402/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5849e-04 - rmse: 0.0147\n",
      "Epoch 402: val_loss did not improve from 0.00030\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 2.9847e-04 - rmse: 0.0125 - val_loss: 2.9971e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 403/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4260e-04 - rmse: 0.0100\n",
      "Epoch 403: val_loss improved from 0.00030 to 0.00029, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 2.5607e-04 - rmse: 0.0107 - val_loss: 2.9304e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 404/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6414e-04 - rmse: 0.0110\n",
      "Epoch 404: val_loss improved from 0.00029 to 0.00029, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 2.8698e-04 - rmse: 0.0120 - val_loss: 2.9030e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 405/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5782e-04 - rmse: 0.0108\n",
      "Epoch 405: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 2.8979e-04 - rmse: 0.0122 - val_loss: 3.0553e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 406/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9575e-04 - rmse: 0.0073\n",
      "Epoch 406: val_loss improved from 0.00029 to 0.00029, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 2.4805e-04 - rmse: 0.0103 - val_loss: 2.8523e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 407/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9903e-04 - rmse: 0.0125\n",
      "Epoch 407: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 2.9702e-04 - rmse: 0.0125 - val_loss: 2.9103e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 408/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0365e-04 - rmse: 0.0127\n",
      "Epoch 408: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.6364e-04 - rmse: 0.0110 - val_loss: 2.8627e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 409/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6280e-04 - rmse: 0.0110\n",
      "Epoch 409: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 2.6919e-04 - rmse: 0.0113 - val_loss: 3.0188e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 410/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9128e-04 - rmse: 0.0122\n",
      "Epoch 410: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 2.9357e-04 - rmse: 0.0123 - val_loss: 3.1434e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 411/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7307e-04 - rmse: 0.0115\n",
      "Epoch 411: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.7224e-04 - rmse: 0.0114 - val_loss: 3.0326e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 412/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5579e-04 - rmse: 0.0107\n",
      "Epoch 412: val_loss improved from 0.00029 to 0.00028, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 2.6763e-04 - rmse: 0.0112 - val_loss: 2.7909e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 413/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5982e-04 - rmse: 0.0109\n",
      "Epoch 413: val_loss did not improve from 0.00028\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.4397e-04 - rmse: 0.0101 - val_loss: 2.8162e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 414/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5241e-04 - rmse: 0.0145\n",
      "Epoch 414: val_loss did not improve from 0.00028\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.7971e-04 - rmse: 0.0118 - val_loss: 3.0430e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 415/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9385e-04 - rmse: 0.0123\n",
      "Epoch 415: val_loss improved from 0.00028 to 0.00027, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 2.9895e-04 - rmse: 0.0125 - val_loss: 2.7398e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 416/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1840e-04 - rmse: 0.0088\n",
      "Epoch 416: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.5407e-04 - rmse: 0.0106 - val_loss: 2.8955e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 417/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5952e-04 - rmse: 0.0109\n",
      "Epoch 417: val_loss improved from 0.00027 to 0.00027, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 2.5815e-04 - rmse: 0.0108 - val_loss: 2.6941e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 418/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3053e-04 - rmse: 0.0094\n",
      "Epoch 418: val_loss improved from 0.00027 to 0.00027, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 2.3539e-04 - rmse: 0.0097 - val_loss: 2.6641e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9001e-04 - rmse: 0.0122\n",
      "Epoch 419: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.6479e-04 - rmse: 0.0111 - val_loss: 2.6716e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 420/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2018e-04 - rmse: 0.0089\n",
      "Epoch 420: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.4512e-04 - rmse: 0.0102 - val_loss: 2.6728e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 421/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4711e-04 - rmse: 0.0103\n",
      "Epoch 421: val_loss improved from 0.00027 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.5150e-04 - rmse: 0.0105 - val_loss: 2.6358e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 422/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3654e-04 - rmse: 0.0098\n",
      "Epoch 422: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 2.4080e-04 - rmse: 0.0100 - val_loss: 2.7028e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 423/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6845e-04 - rmse: 0.0113\n",
      "Epoch 423: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2.6497e-04 - rmse: 0.0111 - val_loss: 2.7927e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 424/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4874e-04 - rmse: 0.0104\n",
      "Epoch 424: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 2.6096e-04 - rmse: 0.0109 - val_loss: 2.7708e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 425/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2349e-04 - rmse: 0.0091\n",
      "Epoch 425: val_loss improved from 0.00026 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.5007e-04 - rmse: 0.0104 - val_loss: 2.6051e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 426/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4718e-04 - rmse: 0.0103\n",
      "Epoch 426: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.5105e-04 - rmse: 0.0105 - val_loss: 2.6641e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 427/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4280e-04 - rmse: 0.0101\n",
      "Epoch 427: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.3770e-04 - rmse: 0.0098 - val_loss: 2.7345e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 428/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8164e-04 - rmse: 0.0119\n",
      "Epoch 428: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6674e-04 - rmse: 0.0112 - val_loss: 2.7165e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 429/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3362e-04 - rmse: 0.0096\n",
      "Epoch 429: val_loss improved from 0.00026 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.6080e-04 - rmse: 0.0109 - val_loss: 2.5607e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 430/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3914e-04 - rmse: 0.0099\n",
      "Epoch 430: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.4426e-04 - rmse: 0.0102 - val_loss: 2.8575e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 431/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5533e-04 - rmse: 0.0107\n",
      "Epoch 431: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6703e-04 - rmse: 0.0112 - val_loss: 3.0167e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 432/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6944e-04 - rmse: 0.0113\n",
      "Epoch 432: val_loss improved from 0.00026 to 0.00025, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 2.7297e-04 - rmse: 0.0115 - val_loss: 2.4999e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 433/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2017e-04 - rmse: 0.0089\n",
      "Epoch 433: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.4465e-04 - rmse: 0.0102 - val_loss: 2.5931e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 434/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3871e-04 - rmse: 0.0099\n",
      "Epoch 434: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.4594e-04 - rmse: 0.0103 - val_loss: 2.6920e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 435/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2190e-04 - rmse: 0.0090\n",
      "Epoch 435: val_loss improved from 0.00025 to 0.00025, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 2.3581e-04 - rmse: 0.0097 - val_loss: 2.4986e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 436/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6569e-04 - rmse: 0.0112\n",
      "Epoch 436: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.4548e-04 - rmse: 0.0102 - val_loss: 2.5717e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 437/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3589e-04 - rmse: 0.0098\n",
      "Epoch 437: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.4149e-04 - rmse: 0.0100 - val_loss: 2.9868e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 438/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6160e-04 - rmse: 0.0110\n",
      "Epoch 438: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.4923e-04 - rmse: 0.0104 - val_loss: 2.7995e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 439/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8753e-04 - rmse: 0.0121\n",
      "Epoch 439: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.9169e-04 - rmse: 0.0123 - val_loss: 2.5207e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 440/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2835e-04 - rmse: 0.0094\n",
      "Epoch 440: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.3840e-04 - rmse: 0.0099 - val_loss: 2.8479e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 441/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7658e-04 - rmse: 0.0117\n",
      "Epoch 441: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.8523e-04 - rmse: 0.0120 - val_loss: 3.9977e-04 - val_rmse: 0.0161 - lr: 1.0000e-04\n",
      "Epoch 442/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4906e-04 - rmse: 0.0144\n",
      "Epoch 442: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.1622e-04 - rmse: 0.0133 - val_loss: 2.7812e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 443/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2669e-04 - rmse: 0.0093\n",
      "Epoch 443: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6836e-04 - rmse: 0.0113 - val_loss: 2.6526e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 444/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4422e-04 - rmse: 0.0102\n",
      "Epoch 444: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.5529e-04 - rmse: 0.0107 - val_loss: 3.4516e-04 - val_rmse: 0.0143 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4161e-04 - rmse: 0.0142\n",
      "Epoch 445: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.8811e-04 - rmse: 0.0122 - val_loss: 3.1516e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 446/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8827e-04 - rmse: 0.0122\n",
      "Epoch 446: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.5663e-04 - rmse: 0.0108 - val_loss: 2.5412e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 447/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5270e-04 - rmse: 0.0106\n",
      "Epoch 447: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.8431e-04 - rmse: 0.0120 - val_loss: 2.5071e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 448/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3305e-04 - rmse: 0.0096\n",
      "Epoch 448: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.4214e-04 - rmse: 0.0101 - val_loss: 3.5905e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 449/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3100e-04 - rmse: 0.0138\n",
      "Epoch 449: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.8058e-04 - rmse: 0.0118 - val_loss: 2.5224e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 450/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5915e-04 - rmse: 0.0109\n",
      "Epoch 450: val_loss improved from 0.00025 to 0.00024, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.3622e-04 - rmse: 0.0098 - val_loss: 2.3539e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 451/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3104e-04 - rmse: 0.0095\n",
      "Epoch 451: val_loss did not improve from 0.00024\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.2298e-04 - rmse: 0.0091 - val_loss: 2.4705e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 452/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1704e-04 - rmse: 0.0088\n",
      "Epoch 452: val_loss did not improve from 0.00024\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.3334e-04 - rmse: 0.0097 - val_loss: 2.5745e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 453/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6355e-04 - rmse: 0.0111\n",
      "Epoch 453: val_loss improved from 0.00024 to 0.00023, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 2.3001e-04 - rmse: 0.0095 - val_loss: 2.2977e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 454/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3757e-04 - rmse: 0.0099\n",
      "Epoch 454: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.5077e-04 - rmse: 0.0105 - val_loss: 2.3386e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 455/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1360e-04 - rmse: 0.0086\n",
      "Epoch 455: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.1189e-04 - rmse: 0.0085 - val_loss: 2.4446e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 456/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3242e-04 - rmse: 0.0096\n",
      "Epoch 456: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.3259e-04 - rmse: 0.0096 - val_loss: 2.3586e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 457/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1998e-04 - rmse: 0.0089\n",
      "Epoch 457: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.4478e-04 - rmse: 0.0102 - val_loss: 2.3458e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 458/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9583e-04 - rmse: 0.0075\n",
      "Epoch 458: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.3854e-04 - rmse: 0.0099 - val_loss: 2.5275e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 459/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3089e-04 - rmse: 0.0095\n",
      "Epoch 459: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.6577e-04 - rmse: 0.0112 - val_loss: 3.2793e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 460/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8157e-04 - rmse: 0.0119\n",
      "Epoch 460: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.5504e-04 - rmse: 0.0107 - val_loss: 2.7599e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 461/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6034e-04 - rmse: 0.0110\n",
      "Epoch 461: val_loss improved from 0.00023 to 0.00023, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 2.4625e-04 - rmse: 0.0103 - val_loss: 2.2614e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 462/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8323e-04 - rmse: 0.0066\n",
      "Epoch 462: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.3498e-04 - rmse: 0.0098 - val_loss: 2.3050e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 463/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2342e-04 - rmse: 0.0092\n",
      "Epoch 463: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.0880e-04 - rmse: 0.0083 - val_loss: 2.3321e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 464/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4948e-04 - rmse: 0.0105\n",
      "Epoch 464: val_loss improved from 0.00023 to 0.00023, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 2.2083e-04 - rmse: 0.0090 - val_loss: 2.2554e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 465/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1125e-04 - rmse: 0.0085\n",
      "Epoch 465: val_loss improved from 0.00023 to 0.00022, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.1810e-04 - rmse: 0.0089 - val_loss: 2.2356e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 466/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8009e-04 - rmse: 0.0064\n",
      "Epoch 466: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.1551e-04 - rmse: 0.0087 - val_loss: 2.3534e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 467/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1575e-04 - rmse: 0.0087\n",
      "Epoch 467: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.2761e-04 - rmse: 0.0094 - val_loss: 2.2591e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 468/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1274e-04 - rmse: 0.0086\n",
      "Epoch 468: val_loss improved from 0.00022 to 0.00022, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.3432e-04 - rmse: 0.0097 - val_loss: 2.1640e-04 - val_rmse: 0.0088 - lr: 1.0000e-04\n",
      "Epoch 469/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1659e-04 - rmse: 0.0088\n",
      "Epoch 469: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.2418e-04 - rmse: 0.0092 - val_loss: 2.2554e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 470/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8916e-04 - rmse: 0.0071\n",
      "Epoch 470: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.2443e-04 - rmse: 0.0092 - val_loss: 2.5210e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 471/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3122e-04 - rmse: 0.0096\n",
      "Epoch 471: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.4103e-04 - rmse: 0.0101 - val_loss: 3.3393e-04 - val_rmse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 472/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2292e-04 - rmse: 0.0136\n",
      "Epoch 472: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.7651e-04 - rmse: 0.0117 - val_loss: 2.7111e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 473/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2966e-04 - rmse: 0.0095\n",
      "Epoch 473: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.0068e-04 - rmse: 0.0127 - val_loss: 2.8433e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 474/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7834e-04 - rmse: 0.0118\n",
      "Epoch 474: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.6411e-04 - rmse: 0.0112 - val_loss: 2.8398e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 475/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5645e-04 - rmse: 0.0108\n",
      "Epoch 475: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.5882e-04 - rmse: 0.0109 - val_loss: 2.5469e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 476/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1560e-04 - rmse: 0.0087\n",
      "Epoch 476: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.2302e-04 - rmse: 0.0092 - val_loss: 2.4037e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 477/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2948e-04 - rmse: 0.0095\n",
      "Epoch 477: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.2870e-04 - rmse: 0.0095 - val_loss: 2.3089e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 478/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0800e-04 - rmse: 0.0083\n",
      "Epoch 478: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.0090e-04 - rmse: 0.0079 - val_loss: 2.3462e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 479/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3639e-04 - rmse: 0.0099\n",
      "Epoch 479: val_loss improved from 0.00022 to 0.00021, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 2.1202e-04 - rmse: 0.0085 - val_loss: 2.1369e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 480/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9693e-04 - rmse: 0.0076\n",
      "Epoch 480: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.0019e-04 - rmse: 0.0078 - val_loss: 2.1440e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 481/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0343e-04 - rmse: 0.0080\n",
      "Epoch 481: val_loss improved from 0.00021 to 0.00021, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 2.0361e-04 - rmse: 0.0080 - val_loss: 2.0622e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 482/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7708e-04 - rmse: 0.0062\n",
      "Epoch 482: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0095e-04 - rmse: 0.0079 - val_loss: 2.1784e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 483/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3544e-04 - rmse: 0.0098\n",
      "Epoch 483: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.1019e-04 - rmse: 0.0084 - val_loss: 2.2547e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 484/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0043e-04 - rmse: 0.0079\n",
      "Epoch 484: val_loss improved from 0.00021 to 0.00020, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.0679e-04 - rmse: 0.0082 - val_loss: 1.9934e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 485/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8620e-04 - rmse: 0.0069\n",
      "Epoch 485: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0202e-04 - rmse: 0.0080 - val_loss: 2.1105e-04 - val_rmse: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 486/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7783e-04 - rmse: 0.0063\n",
      "Epoch 486: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8136e-04 - rmse: 0.0065 - val_loss: 2.0654e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 487/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2677e-04 - rmse: 0.0094\n",
      "Epoch 487: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.1761e-04 - rmse: 0.0089 - val_loss: 2.0347e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 488/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8832e-04 - rmse: 0.0070\n",
      "Epoch 488: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0984e-04 - rmse: 0.0084 - val_loss: 2.0080e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 489/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8669e-04 - rmse: 0.0069\n",
      "Epoch 489: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.9656e-04 - rmse: 0.0076 - val_loss: 2.2502e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 490/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2211e-04 - rmse: 0.0091\n",
      "Epoch 490: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0790e-04 - rmse: 0.0083 - val_loss: 2.4035e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 491/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3265e-04 - rmse: 0.0097\n",
      "Epoch 491: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.2644e-04 - rmse: 0.0094 - val_loss: 2.4027e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 492/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2114e-04 - rmse: 0.0091\n",
      "Epoch 492: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.0387e-04 - rmse: 0.0081 - val_loss: 2.1898e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 493/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1247e-04 - rmse: 0.0086\n",
      "Epoch 493: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.1057e-04 - rmse: 0.0085 - val_loss: 2.0606e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 494/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2333e-04 - rmse: 0.0092\n",
      "Epoch 494: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2307e-04 - rmse: 0.0092 - val_loss: 2.1712e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 495/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3145e-04 - rmse: 0.0096\n",
      "Epoch 495: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.2021e-04 - rmse: 0.0090 - val_loss: 2.9597e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 496/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9423e-04 - rmse: 0.0125\n",
      "Epoch 496: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.5684e-04 - rmse: 0.0109 - val_loss: 2.4711e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4587e-04 - rmse: 0.0104\n",
      "Epoch 497: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2258e-04 - rmse: 0.0092 - val_loss: 2.0326e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 498/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8533e-04 - rmse: 0.0069\n",
      "Epoch 498: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.1761e-04 - rmse: 0.0089 - val_loss: 2.1444e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 499/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9148e-04 - rmse: 0.0073\n",
      "Epoch 499: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0810e-04 - rmse: 0.0084 - val_loss: 2.3248e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 500/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1917e-04 - rmse: 0.0090\n",
      "Epoch 500: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.2279e-04 - rmse: 0.0092 - val_loss: 2.1937e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 501/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1347e-04 - rmse: 0.0087\n",
      "Epoch 501: val_loss improved from 0.00020 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 2.0963e-04 - rmse: 0.0085 - val_loss: 1.9423e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 502/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7591e-04 - rmse: 0.0062\n",
      "Epoch 502: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0210e-04 - rmse: 0.0080 - val_loss: 1.9931e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 503/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1322e-04 - rmse: 0.0087\n",
      "Epoch 503: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.1970e-04 - rmse: 0.0090 - val_loss: 2.1895e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 504/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0436e-04 - rmse: 0.0081\n",
      "Epoch 504: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.9294e-04 - rmse: 0.0074 - val_loss: 2.2898e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 505/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2285e-04 - rmse: 0.0092\n",
      "Epoch 505: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.2921e-04 - rmse: 0.0096 - val_loss: 2.5545e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 506/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1755e-04 - rmse: 0.0134\n",
      "Epoch 506: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.4485e-04 - rmse: 0.0103 - val_loss: 3.2219e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 507/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1681e-04 - rmse: 0.0134\n",
      "Epoch 507: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.7484e-04 - rmse: 0.0117 - val_loss: 2.0424e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 508/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8780e-04 - rmse: 0.0071\n",
      "Epoch 508: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.3326e-04 - rmse: 0.0098 - val_loss: 2.5313e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 509/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2985e-04 - rmse: 0.0096\n",
      "Epoch 509: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.9324e-04 - rmse: 0.0125 - val_loss: 4.3124e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 510/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.2229e-04 - rmse: 0.0169\n",
      "Epoch 510: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.5347e-04 - rmse: 0.0147 - val_loss: 4.4080e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 511/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7933e-04 - rmse: 0.0155\n",
      "Epoch 511: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.0696e-04 - rmse: 0.0130 - val_loss: 3.8855e-04 - val_rmse: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 512/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8494e-04 - rmse: 0.0157\n",
      "Epoch 512: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.9791e-04 - rmse: 0.0127 - val_loss: 2.9372e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 513/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6996e-04 - rmse: 0.0115\n",
      "Epoch 513: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.7946e-04 - rmse: 0.0119 - val_loss: 2.4113e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 514/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3073e-04 - rmse: 0.0097\n",
      "Epoch 514: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.3983e-04 - rmse: 0.0101 - val_loss: 2.0562e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 515/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8970e-04 - rmse: 0.0072\n",
      "Epoch 515: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0388e-04 - rmse: 0.0081 - val_loss: 2.5633e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 516/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5688e-04 - rmse: 0.0109\n",
      "Epoch 516: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.4341e-04 - rmse: 0.0103 - val_loss: 2.4875e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 517/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4209e-04 - rmse: 0.0102\n",
      "Epoch 517: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2872e-04 - rmse: 0.0096 - val_loss: 2.3301e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 518/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2622e-04 - rmse: 0.0094\n",
      "Epoch 518: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0553e-04 - rmse: 0.0083 - val_loss: 2.1639e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 519/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1773e-04 - rmse: 0.0090\n",
      "Epoch 519: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0582e-04 - rmse: 0.0083 - val_loss: 1.9452e-04 - val_rmse: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 520/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8026e-04 - rmse: 0.0066\n",
      "Epoch 520: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.9507e-04 - rmse: 0.0076 - val_loss: 2.0233e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 521/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7887e-04 - rmse: 0.0064\n",
      "Epoch 521: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.8762e-04 - rmse: 0.0071 - val_loss: 1.9369e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 522/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9447e-04 - rmse: 0.0076\n",
      "Epoch 522: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.8352e-04 - rmse: 0.0068 - val_loss: 1.8676e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 523/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8504e-04 - rmse: 0.0069\n",
      "Epoch 523: val_loss improved from 0.00019 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 74ms/step - loss: 1.8234e-04 - rmse: 0.0067 - val_loss: 1.8316e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 524/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8305e-04 - rmse: 0.0068\n",
      "Epoch 524: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8743e-04 - rmse: 0.0071 - val_loss: 1.8612e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 525/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7645e-04 - rmse: 0.0063\n",
      "Epoch 525: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.8027e-04 - rmse: 0.0066 - val_loss: 1.8254e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 526/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6497e-04 - rmse: 0.0053\n",
      "Epoch 526: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.7268e-04 - rmse: 0.0060 - val_loss: 1.8084e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 527/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8146e-04 - rmse: 0.0067\n",
      "Epoch 527: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7643e-04 - rmse: 0.0063 - val_loss: 1.8957e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 528/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7599e-04 - rmse: 0.0062\n",
      "Epoch 528: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8828e-04 - rmse: 0.0072 - val_loss: 2.0023e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 529/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7372e-04 - rmse: 0.0061\n",
      "Epoch 529: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9947e-04 - rmse: 0.0079 - val_loss: 1.8659e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 530/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0338e-04 - rmse: 0.0082\n",
      "Epoch 530: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9436e-04 - rmse: 0.0076 - val_loss: 2.0074e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 531/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0528e-04 - rmse: 0.0083\n",
      "Epoch 531: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9740e-04 - rmse: 0.0078 - val_loss: 2.0325e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 532/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9754e-04 - rmse: 0.0078\n",
      "Epoch 532: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9567e-04 - rmse: 0.0077 - val_loss: 2.2475e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 533/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2362e-04 - rmse: 0.0093\n",
      "Epoch 533: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0944e-04 - rmse: 0.0085 - val_loss: 2.3757e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 534/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0419e-04 - rmse: 0.0082\n",
      "Epoch 534: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0495e-04 - rmse: 0.0083 - val_loss: 2.0106e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 535/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0092e-04 - rmse: 0.0080\n",
      "Epoch 535: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0384e-04 - rmse: 0.0082 - val_loss: 2.0600e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 536/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9570e-04 - rmse: 0.0077\n",
      "Epoch 536: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.1073e-04 - rmse: 0.0086 - val_loss: 1.9786e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 537/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9893e-04 - rmse: 0.0079\n",
      "Epoch 537: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8883e-04 - rmse: 0.0072 - val_loss: 1.9809e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 538/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9511e-04 - rmse: 0.0077\n",
      "Epoch 538: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8834e-04 - rmse: 0.0072 - val_loss: 1.9360e-04 - val_rmse: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 539/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7664e-04 - rmse: 0.0063\n",
      "Epoch 539: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.7602e-04 - rmse: 0.0063 - val_loss: 1.7894e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 540/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7393e-04 - rmse: 0.0061\n",
      "Epoch 540: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7659e-04 - rmse: 0.0063 - val_loss: 1.8325e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 541/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6293e-04 - rmse: 0.0051\n",
      "Epoch 541: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7629e-04 - rmse: 0.0063 - val_loss: 1.9536e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 542/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9873e-04 - rmse: 0.0079\n",
      "Epoch 542: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8375e-04 - rmse: 0.0069 - val_loss: 2.4056e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 543/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4639e-04 - rmse: 0.0105\n",
      "Epoch 543: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2249e-04 - rmse: 0.0093 - val_loss: 2.3398e-04 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 544/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1634e-04 - rmse: 0.0089\n",
      "Epoch 544: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.0148e-04 - rmse: 0.0081 - val_loss: 2.2126e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 545/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1911e-04 - rmse: 0.0091\n",
      "Epoch 545: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0672e-04 - rmse: 0.0084 - val_loss: 2.7003e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 546/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4958e-04 - rmse: 0.0106\n",
      "Epoch 546: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.1048e-04 - rmse: 0.0086 - val_loss: 1.9033e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 547/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8456e-04 - rmse: 0.0070\n",
      "Epoch 547: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0071e-04 - rmse: 0.0080 - val_loss: 1.8442e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 548/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7331e-04 - rmse: 0.0061\n",
      "Epoch 548: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0703e-04 - rmse: 0.0084 - val_loss: 1.8154e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 549/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8400e-04 - rmse: 0.0069\n",
      "Epoch 549: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9947e-04 - rmse: 0.0080 - val_loss: 2.3274e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 550/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3605e-04 - rmse: 0.0100\n",
      "Epoch 550: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.3552e-04 - rmse: 0.0100 - val_loss: 2.5815e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 551/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3122e-04 - rmse: 0.0098\n",
      "Epoch 551: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2338e-04 - rmse: 0.0093 - val_loss: 2.3814e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 552/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3424e-04 - rmse: 0.0099\n",
      "Epoch 552: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.1044e-04 - rmse: 0.0086 - val_loss: 2.2920e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 553/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3297e-04 - rmse: 0.0098\n",
      "Epoch 553: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0972e-04 - rmse: 0.0086 - val_loss: 2.0946e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 554/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1341e-04 - rmse: 0.0088\n",
      "Epoch 554: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8767e-04 - rmse: 0.0072 - val_loss: 1.9515e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 555/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0679e-04 - rmse: 0.0084\n",
      "Epoch 555: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8877e-04 - rmse: 0.0073 - val_loss: 1.8915e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 556/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9654e-04 - rmse: 0.0078\n",
      "Epoch 556: val_loss improved from 0.00018 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.8567e-04 - rmse: 0.0071 - val_loss: 1.7418e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 557/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7150e-04 - rmse: 0.0060\n",
      "Epoch 557: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7304e-04 - rmse: 0.0061 - val_loss: 1.8492e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 558/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8168e-04 - rmse: 0.0068\n",
      "Epoch 558: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7583e-04 - rmse: 0.0063 - val_loss: 1.7983e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 559/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8549e-04 - rmse: 0.0071\n",
      "Epoch 559: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7640e-04 - rmse: 0.0064 - val_loss: 1.8107e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 560/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8600e-04 - rmse: 0.0071\n",
      "Epoch 560: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7603e-04 - rmse: 0.0064 - val_loss: 1.7682e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 561/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7811e-04 - rmse: 0.0065\n",
      "Epoch 561: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8263e-04 - rmse: 0.0069 - val_loss: 1.8774e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 562/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6051e-04 - rmse: 0.0050\n",
      "Epoch 562: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8311e-04 - rmse: 0.0069 - val_loss: 2.1767e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 563/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3222e-04 - rmse: 0.0098\n",
      "Epoch 563: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0974e-04 - rmse: 0.0086 - val_loss: 2.2651e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 564/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0661e-04 - rmse: 0.0084\n",
      "Epoch 564: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0560e-04 - rmse: 0.0084 - val_loss: 2.2313e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 565/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2757e-04 - rmse: 0.0096\n",
      "Epoch 565: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.3606e-04 - rmse: 0.0100 - val_loss: 3.6751e-04 - val_rmse: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 566/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7608e-04 - rmse: 0.0155\n",
      "Epoch 566: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.8986e-04 - rmse: 0.0124 - val_loss: 2.9169e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 567/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8993e-04 - rmse: 0.0124\n",
      "Epoch 567: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.8160e-04 - rmse: 0.0121 - val_loss: 2.2440e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 568/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0412e-04 - rmse: 0.0083\n",
      "Epoch 568: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2157e-04 - rmse: 0.0093 - val_loss: 2.0072e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 569/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1516e-04 - rmse: 0.0089\n",
      "Epoch 569: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0353e-04 - rmse: 0.0083 - val_loss: 2.0337e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 570/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7122e-04 - rmse: 0.0060\n",
      "Epoch 570: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.8550e-04 - rmse: 0.0071 - val_loss: 1.7203e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 571/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7653e-04 - rmse: 0.0064\n",
      "Epoch 571: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8993e-04 - rmse: 0.0074 - val_loss: 1.7896e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 572/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6556e-04 - rmse: 0.0055\n",
      "Epoch 572: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7628e-04 - rmse: 0.0064 - val_loss: 1.7859e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 573/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6303e-04 - rmse: 0.0053\n",
      "Epoch 573: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6815e-04 - rmse: 0.0057 - val_loss: 1.8271e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 574/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8627e-04 - rmse: 0.0072\n",
      "Epoch 574: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.7414e-04 - rmse: 0.0063 - val_loss: 1.7164e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 575/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6911e-04 - rmse: 0.0058\n",
      "Epoch 575: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6665e-04 - rmse: 0.0056 - val_loss: 1.9191e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 576/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9467e-04 - rmse: 0.0077\n",
      "Epoch 576: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8215e-04 - rmse: 0.0069 - val_loss: 1.7786e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8356e-04 - rmse: 0.0070\n",
      "Epoch 577: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7466e-04 - rmse: 0.0063 - val_loss: 1.7788e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 578/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7103e-04 - rmse: 0.0060\n",
      "Epoch 578: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6813e-04 - rmse: 0.0058 - val_loss: 1.8678e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 579/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7677e-04 - rmse: 0.0065\n",
      "Epoch 579: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.8927e-04 - rmse: 0.0074 - val_loss: 1.8241e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 580/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7455e-04 - rmse: 0.0063\n",
      "Epoch 580: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.7929e-04 - rmse: 0.0067 - val_loss: 1.7093e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 581/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6488e-04 - rmse: 0.0055\n",
      "Epoch 581: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9148e-04 - rmse: 0.0075 - val_loss: 1.8933e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 582/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7054e-04 - rmse: 0.0060\n",
      "Epoch 582: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8521e-04 - rmse: 0.0071 - val_loss: 1.7139e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 583/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8119e-04 - rmse: 0.0068\n",
      "Epoch 583: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.8035e-04 - rmse: 0.0068 - val_loss: 1.7308e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 584/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8018e-04 - rmse: 0.0067\n",
      "Epoch 584: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.7077e-04 - rmse: 0.0060 - val_loss: 1.6955e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 585/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6493e-04 - rmse: 0.0055\n",
      "Epoch 585: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.6640e-04 - rmse: 0.0056 - val_loss: 1.6530e-04 - val_rmse: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 586/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5521e-04 - rmse: 0.0045\n",
      "Epoch 586: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6468e-04 - rmse: 0.0055 - val_loss: 1.6866e-04 - val_rmse: 0.0058 - lr: 1.0000e-04\n",
      "Epoch 587/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6401e-04 - rmse: 0.0054\n",
      "Epoch 587: val_loss improved from 0.00017 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.6578e-04 - rmse: 0.0056 - val_loss: 1.6368e-04 - val_rmse: 0.0054 - lr: 1.0000e-04\n",
      "Epoch 588/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6853e-04 - rmse: 0.0058\n",
      "Epoch 588: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.6410e-04 - rmse: 0.0054 - val_loss: 1.6183e-04 - val_rmse: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 589/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5287e-04 - rmse: 0.0043\n",
      "Epoch 589: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6665e-04 - rmse: 0.0057 - val_loss: 1.7813e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 590/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5314e-04 - rmse: 0.0043\n",
      "Epoch 590: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6863e-04 - rmse: 0.0058 - val_loss: 1.7201e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 591/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7159e-04 - rmse: 0.0061\n",
      "Epoch 591: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7573e-04 - rmse: 0.0064 - val_loss: 1.6508e-04 - val_rmse: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 592/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6629e-04 - rmse: 0.0057\n",
      "Epoch 592: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8698e-04 - rmse: 0.0073 - val_loss: 1.7631e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 593/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7103e-04 - rmse: 0.0061\n",
      "Epoch 593: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7793e-04 - rmse: 0.0066 - val_loss: 1.8767e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 594/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7551e-04 - rmse: 0.0064\n",
      "Epoch 594: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8232e-04 - rmse: 0.0069 - val_loss: 1.7592e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 595/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7095e-04 - rmse: 0.0061\n",
      "Epoch 595: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6488e-04 - rmse: 0.0055 - val_loss: 1.6883e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 596/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6258e-04 - rmse: 0.0053\n",
      "Epoch 596: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6877e-04 - rmse: 0.0059 - val_loss: 1.9612e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 597/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9858e-04 - rmse: 0.0080\n",
      "Epoch 597: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9052e-04 - rmse: 0.0075 - val_loss: 1.7958e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 598/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6779e-04 - rmse: 0.0058\n",
      "Epoch 598: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6572e-04 - rmse: 0.0056 - val_loss: 1.7183e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 599/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6349e-04 - rmse: 0.0054\n",
      "Epoch 599: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6352e-04 - rmse: 0.0054 - val_loss: 1.7630e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 600/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7865e-04 - rmse: 0.0067\n",
      "Epoch 600: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7341e-04 - rmse: 0.0063 - val_loss: 1.7185e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 601/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6822e-04 - rmse: 0.0059\n",
      "Epoch 601: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7206e-04 - rmse: 0.0062 - val_loss: 1.7324e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 602/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6752e-04 - rmse: 0.0058\n",
      "Epoch 602: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6820e-04 - rmse: 0.0059 - val_loss: 1.7414e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 603/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6891e-04 - rmse: 0.0059\n",
      "Epoch 603: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6603e-04 - rmse: 0.0057 - val_loss: 1.7415e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 604/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6140e-04 - rmse: 0.0052\n",
      "Epoch 604: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.7930e-04 - rmse: 0.0067 - val_loss: 1.5989e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 605/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6028e-04 - rmse: 0.0051\n",
      "Epoch 605: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6965e-04 - rmse: 0.0060 - val_loss: 1.8341e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 606/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8997e-04 - rmse: 0.0075\n",
      "Epoch 606: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7368e-04 - rmse: 0.0063 - val_loss: 1.6782e-04 - val_rmse: 0.0058 - lr: 1.0000e-04\n",
      "Epoch 607/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6614e-04 - rmse: 0.0057\n",
      "Epoch 607: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6582e-04 - rmse: 0.0057 - val_loss: 1.7439e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 608/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8194e-04 - rmse: 0.0069\n",
      "Epoch 608: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7711e-04 - rmse: 0.0066 - val_loss: 1.6417e-04 - val_rmse: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 609/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6066e-04 - rmse: 0.0052\n",
      "Epoch 609: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6421e-04 - rmse: 0.0055 - val_loss: 1.7072e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 610/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6982e-04 - rmse: 0.0060\n",
      "Epoch 610: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6289e-04 - rmse: 0.0054 - val_loss: 1.6525e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 611/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5906e-04 - rmse: 0.0050\n",
      "Epoch 611: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5839e-04 - rmse: 0.0050 - val_loss: 1.6055e-04 - val_rmse: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 612/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5696e-04 - rmse: 0.0048\n",
      "Epoch 612: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6030e-04 - rmse: 0.0052 - val_loss: 1.6609e-04 - val_rmse: 0.0057 - lr: 1.0000e-04\n",
      "Epoch 613/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6290e-04 - rmse: 0.0054\n",
      "Epoch 613: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6018e-04 - rmse: 0.0052 - val_loss: 1.6457e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 614/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5982e-04 - rmse: 0.0051\n",
      "Epoch 614: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6132e-04 - rmse: 0.0053 - val_loss: 1.8961e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 615/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9066e-04 - rmse: 0.0076\n",
      "Epoch 615: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7301e-04 - rmse: 0.0063 - val_loss: 1.6891e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 616/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6559e-04 - rmse: 0.0057\n",
      "Epoch 616: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7322e-04 - rmse: 0.0063 - val_loss: 1.6763e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 617/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6012e-04 - rmse: 0.0052\n",
      "Epoch 617: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6496e-04 - rmse: 0.0056 - val_loss: 1.7270e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 618/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7948e-04 - rmse: 0.0068\n",
      "Epoch 618: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.6411e-04 - rmse: 0.0056 - val_loss: 1.5696e-04 - val_rmse: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 619/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6670e-04 - rmse: 0.0058\n",
      "Epoch 619: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6079e-04 - rmse: 0.0052 - val_loss: 1.8158e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 620/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7322e-04 - rmse: 0.0063\n",
      "Epoch 620: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6725e-04 - rmse: 0.0058 - val_loss: 1.8016e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 621/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7742e-04 - rmse: 0.0067\n",
      "Epoch 621: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6486e-04 - rmse: 0.0056 - val_loss: 1.6602e-04 - val_rmse: 0.0057 - lr: 1.0000e-04\n",
      "Epoch 622/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6477e-04 - rmse: 0.0056\n",
      "Epoch 622: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6168e-04 - rmse: 0.0053 - val_loss: 1.9427e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 623/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9013e-04 - rmse: 0.0076\n",
      "Epoch 623: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7386e-04 - rmse: 0.0064 - val_loss: 1.7815e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 624/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7932e-04 - rmse: 0.0068\n",
      "Epoch 624: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7942e-04 - rmse: 0.0068 - val_loss: 1.7612e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 625/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7165e-04 - rmse: 0.0062\n",
      "Epoch 625: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6632e-04 - rmse: 0.0058 - val_loss: 1.7384e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 626/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0032e-04 - rmse: 0.0082\n",
      "Epoch 626: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1.9209e-04 - rmse: 0.0077 - val_loss: 1.5672e-04 - val_rmse: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 627/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5994e-04 - rmse: 0.0052\n",
      "Epoch 627: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7012e-04 - rmse: 0.0061 - val_loss: 1.7071e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 628/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7259e-04 - rmse: 0.0063\n",
      "Epoch 628: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6896e-04 - rmse: 0.0060 - val_loss: 1.8187e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 629/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6305e-04 - rmse: 0.0055\n",
      "Epoch 629: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6578e-04 - rmse: 0.0057 - val_loss: 1.6060e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 630/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5375e-04 - rmse: 0.0046\n",
      "Epoch 630: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5922e-04 - rmse: 0.0051 - val_loss: 1.6985e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 631/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6902e-04 - rmse: 0.0060\n",
      "Epoch 631: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6226e-04 - rmse: 0.0054 - val_loss: 1.6429e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 632/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6882e-04 - rmse: 0.0060\n",
      "Epoch 632: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6536e-04 - rmse: 0.0057 - val_loss: 1.8388e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 633/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7148e-04 - rmse: 0.0062\n",
      "Epoch 633: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7302e-04 - rmse: 0.0064 - val_loss: 1.6825e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 634/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6249e-04 - rmse: 0.0055\n",
      "Epoch 634: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6218e-04 - rmse: 0.0054 - val_loss: 1.6509e-04 - val_rmse: 0.0057 - lr: 1.0000e-04\n",
      "Epoch 635/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6601e-04 - rmse: 0.0058\n",
      "Epoch 635: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6594e-04 - rmse: 0.0058 - val_loss: 1.7164e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 636/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6231e-04 - rmse: 0.0055\n",
      "Epoch 636: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6259e-04 - rmse: 0.0055 - val_loss: 1.6796e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 637/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6008e-04 - rmse: 0.0052\n",
      "Epoch 637: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6659e-04 - rmse: 0.0058 - val_loss: 1.5913e-04 - val_rmse: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 638/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6824e-04 - rmse: 0.0060\n",
      "Epoch 638: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8125e-04 - rmse: 0.0070 - val_loss: 1.6303e-04 - val_rmse: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 639/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5839e-04 - rmse: 0.0051\n",
      "Epoch 639: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5717e-04 - rmse: 0.0050 - val_loss: 1.5838e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 640/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5600e-04 - rmse: 0.0049\n",
      "Epoch 640: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7290e-04 - rmse: 0.0064 - val_loss: 1.6551e-04 - val_rmse: 0.0058 - lr: 1.0000e-04\n",
      "Epoch 641/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6081e-04 - rmse: 0.0053\n",
      "Epoch 641: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7404e-04 - rmse: 0.0065 - val_loss: 1.8873e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 642/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7489e-04 - rmse: 0.0065\n",
      "Epoch 642: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7704e-04 - rmse: 0.0067 - val_loss: 1.6825e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 643/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5990e-04 - rmse: 0.0053\n",
      "Epoch 643: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6502e-04 - rmse: 0.0057 - val_loss: 1.9119e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 644/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7874e-04 - rmse: 0.0068\n",
      "Epoch 644: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.7695e-04 - rmse: 0.0067 - val_loss: 2.1028e-04 - val_rmse: 0.0088 - lr: 1.0000e-04\n",
      "Epoch 645/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0031e-04 - rmse: 0.0083\n",
      "Epoch 645: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8283e-04 - rmse: 0.0071 - val_loss: 1.6803e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 646/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6160e-04 - rmse: 0.0054\n",
      "Epoch 646: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7595e-04 - rmse: 0.0066 - val_loss: 1.7766e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 647/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7574e-04 - rmse: 0.0066\n",
      "Epoch 647: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6581e-04 - rmse: 0.0058 - val_loss: 1.8665e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 648/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7212e-04 - rmse: 0.0063\n",
      "Epoch 648: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.7434e-04 - rmse: 0.0065 - val_loss: 1.6258e-04 - val_rmse: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 649/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5433e-04 - rmse: 0.0047\n",
      "Epoch 649: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5979e-04 - rmse: 0.0053 - val_loss: 1.6171e-04 - val_rmse: 0.0055 - lr: 1.0000e-04\n",
      "Epoch 650/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6141e-04 - rmse: 0.0054\n",
      "Epoch 650: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6128e-04 - rmse: 0.0054 - val_loss: 1.6146e-04 - val_rmse: 0.0054 - lr: 1.0000e-04\n",
      "Epoch 651/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5395e-04 - rmse: 0.0047\n",
      "Epoch 651: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5293e-04 - rmse: 0.0046 - val_loss: 1.6692e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 652/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6278e-04 - rmse: 0.0056\n",
      "Epoch 652: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6948e-04 - rmse: 0.0061 - val_loss: 1.5775e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 653/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6604e-04 - rmse: 0.0058\n",
      "Epoch 653: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6325e-04 - rmse: 0.0056 - val_loss: 1.5781e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 654/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4476e-04 - rmse: 0.0036\n",
      "Epoch 654: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5913e-04 - rmse: 0.0052 - val_loss: 1.5761e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 655/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5272e-04 - rmse: 0.0046\n",
      "Epoch 655: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6482e-04 - rmse: 0.0057 - val_loss: 1.7703e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 656/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8584e-04 - rmse: 0.0074\n",
      "Epoch 656: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7037e-04 - rmse: 0.0062 - val_loss: 2.2396e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 657/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3235e-04 - rmse: 0.0100\n",
      "Epoch 657: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0388e-04 - rmse: 0.0085 - val_loss: 2.0651e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 658/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1120e-04 - rmse: 0.0089\n",
      "Epoch 658: val_loss improved from 0.00016 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.4141e-04 - rmse: 0.0105 - val_loss: 1.5137e-04 - val_rmse: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 659/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4966e-04 - rmse: 0.0042\n",
      "Epoch 659: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9090e-04 - rmse: 0.0077 - val_loss: 1.6121e-04 - val_rmse: 0.0054 - lr: 1.0000e-04\n",
      "Epoch 660/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5708e-04 - rmse: 0.0050\n",
      "Epoch 660: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.8696e-04 - rmse: 0.0074 - val_loss: 2.5275e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 661/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3846e-04 - rmse: 0.0103\n",
      "Epoch 661: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.2337e-04 - rmse: 0.0096 - val_loss: 3.4923e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 662/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1737e-04 - rmse: 0.0136\n",
      "Epoch 662: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.3740e-04 - rmse: 0.0103 - val_loss: 3.2100e-04 - val_rmse: 0.0138 - lr: 1.0000e-04\n",
      "Epoch 663/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7269e-04 - rmse: 0.0119\n",
      "Epoch 663: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.3427e-04 - rmse: 0.0101 - val_loss: 2.1116e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 664/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1035e-04 - rmse: 0.0089\n",
      "Epoch 664: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9197e-04 - rmse: 0.0078 - val_loss: 1.9169e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 665/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8299e-04 - rmse: 0.0072\n",
      "Epoch 665: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7957e-04 - rmse: 0.0069 - val_loss: 1.8081e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 666/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9234e-04 - rmse: 0.0078\n",
      "Epoch 666: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6719e-04 - rmse: 0.0060 - val_loss: 1.6832e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 667/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6132e-04 - rmse: 0.0055\n",
      "Epoch 667: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5779e-04 - rmse: 0.0051 - val_loss: 1.5867e-04 - val_rmse: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 668/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5670e-04 - rmse: 0.0050\n",
      "Epoch 668: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5467e-04 - rmse: 0.0048 - val_loss: 1.6210e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 669/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5546e-04 - rmse: 0.0049\n",
      "Epoch 669: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5406e-04 - rmse: 0.0048 - val_loss: 1.5152e-04 - val_rmse: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 670/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5200e-04 - rmse: 0.0046\n",
      "Epoch 670: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5493e-04 - rmse: 0.0049 - val_loss: 1.5307e-04 - val_rmse: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 671/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4646e-04 - rmse: 0.0039\n",
      "Epoch 671: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.5113e-04 - rmse: 0.0045 - val_loss: 1.4815e-04 - val_rmse: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 672/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4459e-04 - rmse: 0.0037\n",
      "Epoch 672: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4855e-04 - rmse: 0.0042 - val_loss: 1.5684e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 673/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5608e-04 - rmse: 0.0050\n",
      "Epoch 673: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5331e-04 - rmse: 0.0047 - val_loss: 1.5901e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 674/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5705e-04 - rmse: 0.0051\n",
      "Epoch 674: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5300e-04 - rmse: 0.0047 - val_loss: 1.5475e-04 - val_rmse: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 675/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5108e-04 - rmse: 0.0045\n",
      "Epoch 675: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4901e-04 - rmse: 0.0042 - val_loss: 1.5246e-04 - val_rmse: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 676/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4516e-04 - rmse: 0.0038\n",
      "Epoch 676: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5184e-04 - rmse: 0.0046 - val_loss: 1.5023e-04 - val_rmse: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 677/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4424e-04 - rmse: 0.0037\n",
      "Epoch 677: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5147e-04 - rmse: 0.0045 - val_loss: 1.6197e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 678/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7205e-04 - rmse: 0.0064\n",
      "Epoch 678: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5631e-04 - rmse: 0.0050 - val_loss: 1.5846e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 679/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5337e-04 - rmse: 0.0047\n",
      "Epoch 679: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5484e-04 - rmse: 0.0049 - val_loss: 1.5227e-04 - val_rmse: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 680/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4686e-04 - rmse: 0.0040\n",
      "Epoch 680: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5261e-04 - rmse: 0.0047 - val_loss: 1.5900e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 681/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5488e-04 - rmse: 0.0049\n",
      "Epoch 681: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5325e-04 - rmse: 0.0047 - val_loss: 1.7131e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 682/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7470e-04 - rmse: 0.0066\n",
      "Epoch 682: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8683e-04 - rmse: 0.0075 - val_loss: 1.5944e-04 - val_rmse: 0.0054 - lr: 1.0000e-04\n",
      "Epoch 683/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5345e-04 - rmse: 0.0048\n",
      "Epoch 683: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.7854e-04 - rmse: 0.0069 - val_loss: 1.7345e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 684/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7136e-04 - rmse: 0.0064\n",
      "Epoch 684: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6421e-04 - rmse: 0.0058 - val_loss: 1.5737e-04 - val_rmse: 0.0052 - lr: 1.0000e-04\n",
      "Epoch 685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6051e-04 - rmse: 0.0055\n",
      "Epoch 685: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6071e-04 - rmse: 0.0055 - val_loss: 1.7527e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 686/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6001e-04 - rmse: 0.0054\n",
      "Epoch 686: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6903e-04 - rmse: 0.0062 - val_loss: 1.9434e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 687/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8697e-04 - rmse: 0.0075\n",
      "Epoch 687: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7171e-04 - rmse: 0.0064 - val_loss: 1.6986e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 688/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6168e-04 - rmse: 0.0056\n",
      "Epoch 688: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6532e-04 - rmse: 0.0059 - val_loss: 1.8622e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 689/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7999e-04 - rmse: 0.0070\n",
      "Epoch 689: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6694e-04 - rmse: 0.0060 - val_loss: 1.5832e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 690/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5992e-04 - rmse: 0.0054\n",
      "Epoch 690: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5704e-04 - rmse: 0.0052 - val_loss: 1.5360e-04 - val_rmse: 0.0048 - lr: 1.0000e-04\n",
      "Epoch 691/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4848e-04 - rmse: 0.0043\n",
      "Epoch 691: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5968e-04 - rmse: 0.0054 - val_loss: 1.7222e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 692/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6732e-04 - rmse: 0.0061\n",
      "Epoch 692: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6075e-04 - rmse: 0.0055 - val_loss: 1.9446e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 693/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8765e-04 - rmse: 0.0076\n",
      "Epoch 693: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7444e-04 - rmse: 0.0066 - val_loss: 1.6176e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 694/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6193e-04 - rmse: 0.0056\n",
      "Epoch 694: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.5746e-04 - rmse: 0.0052 - val_loss: 1.4749e-04 - val_rmse: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 695/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4559e-04 - rmse: 0.0039\n",
      "Epoch 695: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4672e-04 - rmse: 0.0041 - val_loss: 1.5530e-04 - val_rmse: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 696/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6399e-04 - rmse: 0.0058\n",
      "Epoch 696: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5764e-04 - rmse: 0.0052 - val_loss: 1.5457e-04 - val_rmse: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 697/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5723e-04 - rmse: 0.0052\n",
      "Epoch 697: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5397e-04 - rmse: 0.0049 - val_loss: 1.6195e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 698/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6052e-04 - rmse: 0.0055\n",
      "Epoch 698: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6451e-04 - rmse: 0.0059 - val_loss: 1.5457e-04 - val_rmse: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 699/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5707e-04 - rmse: 0.0052\n",
      "Epoch 699: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8150e-04 - rmse: 0.0072 - val_loss: 1.8693e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 700/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7857e-04 - rmse: 0.0070\n",
      "Epoch 700: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8517e-04 - rmse: 0.0074 - val_loss: 3.2878e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 701/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1977e-04 - rmse: 0.0138\n",
      "Epoch 701: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.2921e-04 - rmse: 0.0100 - val_loss: 2.2464e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 702/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0468e-04 - rmse: 0.0086\n",
      "Epoch 702: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7253e-04 - rmse: 0.0065 - val_loss: 1.6509e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 703/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5883e-04 - rmse: 0.0054\n",
      "Epoch 703: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6661e-04 - rmse: 0.0061 - val_loss: 1.5036e-04 - val_rmse: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 704/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4569e-04 - rmse: 0.0040\n",
      "Epoch 704: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5144e-04 - rmse: 0.0046 - val_loss: 1.6113e-04 - val_rmse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 705/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6050e-04 - rmse: 0.0055\n",
      "Epoch 705: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5310e-04 - rmse: 0.0048 - val_loss: 1.6445e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 706/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7565e-04 - rmse: 0.0068\n",
      "Epoch 706: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7197e-04 - rmse: 0.0065 - val_loss: 1.8157e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 707/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7734e-04 - rmse: 0.0069\n",
      "Epoch 707: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8882e-04 - rmse: 0.0077 - val_loss: 1.6877e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 708/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6691e-04 - rmse: 0.0061\n",
      "Epoch 708: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5945e-04 - rmse: 0.0055 - val_loss: 1.5525e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 709/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5902e-04 - rmse: 0.0054\n",
      "Epoch 709: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5428e-04 - rmse: 0.0050 - val_loss: 1.5059e-04 - val_rmse: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 710/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4780e-04 - rmse: 0.0043\n",
      "Epoch 710: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4744e-04 - rmse: 0.0042 - val_loss: 1.5085e-04 - val_rmse: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 711/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5209e-04 - rmse: 0.0047\n",
      "Epoch 711: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4885e-04 - rmse: 0.0044 - val_loss: 1.5755e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 712/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5545e-04 - rmse: 0.0051\n",
      "Epoch 712: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 79ms/step - loss: 1.6771e-04 - rmse: 0.0062 - val_loss: 1.4638e-04 - val_rmse: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 713/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4964e-04 - rmse: 0.0045\n",
      "Epoch 713: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7863e-04 - rmse: 0.0070 - val_loss: 1.5333e-04 - val_rmse: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 714/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5141e-04 - rmse: 0.0047\n",
      "Epoch 714: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7428e-04 - rmse: 0.0067 - val_loss: 2.2143e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 715/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9625e-04 - rmse: 0.0082\n",
      "Epoch 715: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0117e-04 - rmse: 0.0085 - val_loss: 2.4789e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 716/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3077e-04 - rmse: 0.0101\n",
      "Epoch 716: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9178e-04 - rmse: 0.0079 - val_loss: 3.8361e-04 - val_rmse: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 717/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5269e-04 - rmse: 0.0149\n",
      "Epoch 717: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.7291e-04 - rmse: 0.0120 - val_loss: 2.5202e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 718/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3822e-04 - rmse: 0.0104\n",
      "Epoch 718: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.5923e-04 - rmse: 0.0114 - val_loss: 1.6832e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 719/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6566e-04 - rmse: 0.0060\n",
      "Epoch 719: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.0546e-04 - rmse: 0.0087 - val_loss: 1.6255e-04 - val_rmse: 0.0058 - lr: 1.0000e-04\n",
      "Epoch 720/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5753e-04 - rmse: 0.0053\n",
      "Epoch 720: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9541e-04 - rmse: 0.0081 - val_loss: 1.7506e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 721/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7202e-04 - rmse: 0.0065\n",
      "Epoch 721: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.3216e-04 - rmse: 0.0101 - val_loss: 2.2458e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 722/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2915e-04 - rmse: 0.0100\n",
      "Epoch 722: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7214e-04 - rmse: 0.0066 - val_loss: 1.6699e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 723/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6131e-04 - rmse: 0.0057\n",
      "Epoch 723: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5479e-04 - rmse: 0.0051 - val_loss: 1.6253e-04 - val_rmse: 0.0058 - lr: 1.0000e-04\n",
      "Epoch 724/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5707e-04 - rmse: 0.0053\n",
      "Epoch 724: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4953e-04 - rmse: 0.0045 - val_loss: 1.5494e-04 - val_rmse: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 725/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4932e-04 - rmse: 0.0045\n",
      "Epoch 725: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5173e-04 - rmse: 0.0048 - val_loss: 1.4853e-04 - val_rmse: 0.0044 - lr: 1.0000e-04\n",
      "Epoch 726/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5404e-04 - rmse: 0.0050\n",
      "Epoch 726: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4569e-04 - rmse: 0.0041 - val_loss: 1.4678e-04 - val_rmse: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 727/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4781e-04 - rmse: 0.0043\n",
      "Epoch 727: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4664e-04 - rmse: 0.0042 - val_loss: 1.5198e-04 - val_rmse: 0.0048 - lr: 1.0000e-04\n",
      "Epoch 728/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4903e-04 - rmse: 0.0045\n",
      "Epoch 728: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5184e-04 - rmse: 0.0048 - val_loss: 1.5432e-04 - val_rmse: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 729/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5175e-04 - rmse: 0.0048\n",
      "Epoch 729: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5356e-04 - rmse: 0.0050 - val_loss: 1.5673e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 730/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5028e-04 - rmse: 0.0046\n",
      "Epoch 730: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5916e-04 - rmse: 0.0055 - val_loss: 1.6938e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 731/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7324e-04 - rmse: 0.0067\n",
      "Epoch 731: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8493e-04 - rmse: 0.0075 - val_loss: 2.2906e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 732/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1553e-04 - rmse: 0.0093\n",
      "Epoch 732: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9303e-04 - rmse: 0.0080 - val_loss: 2.2009e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 733/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1174e-04 - rmse: 0.0091\n",
      "Epoch 733: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.8877e-04 - rmse: 0.0078 - val_loss: 2.0307e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 734/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2132e-04 - rmse: 0.0096\n",
      "Epoch 734: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.8335e-04 - rmse: 0.0124 - val_loss: 3.5484e-04 - val_rmse: 0.0150 - lr: 1.0000e-04\n",
      "Epoch 735/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0415e-04 - rmse: 0.0132\n",
      "Epoch 735: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.6844e-04 - rmse: 0.0118 - val_loss: 2.9242e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 736/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8451e-04 - rmse: 0.0125\n",
      "Epoch 736: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2104e-04 - rmse: 0.0096 - val_loss: 2.3467e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 737/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3412e-04 - rmse: 0.0103\n",
      "Epoch 737: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.4536e-04 - rmse: 0.0108 - val_loss: 1.8485e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 738/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7954e-04 - rmse: 0.0071\n",
      "Epoch 738: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9685e-04 - rmse: 0.0083 - val_loss: 1.7184e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 739/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6984e-04 - rmse: 0.0064\n",
      "Epoch 739: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7450e-04 - rmse: 0.0068 - val_loss: 1.6477e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 740/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5582e-04 - rmse: 0.0052\n",
      "Epoch 740: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5698e-04 - rmse: 0.0053 - val_loss: 1.7765e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8182e-04 - rmse: 0.0073\n",
      "Epoch 741: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6875e-04 - rmse: 0.0064 - val_loss: 1.5339e-04 - val_rmse: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 742/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5042e-04 - rmse: 0.0047\n",
      "Epoch 742: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7245e-04 - rmse: 0.0066 - val_loss: 1.8696e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 743/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7316e-04 - rmse: 0.0067\n",
      "Epoch 743: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.7700e-04 - rmse: 0.0070 - val_loss: 1.9111e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 744/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7956e-04 - rmse: 0.0072\n",
      "Epoch 744: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6132e-04 - rmse: 0.0058 - val_loss: 1.6772e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 745/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7134e-04 - rmse: 0.0066\n",
      "Epoch 745: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6978e-04 - rmse: 0.0064 - val_loss: 1.6596e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 746/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6072e-04 - rmse: 0.0057\n",
      "Epoch 746: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7754e-04 - rmse: 0.0070 - val_loss: 1.4889e-04 - val_rmse: 0.0046 - lr: 1.0000e-04\n",
      "Epoch 747/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4411e-04 - rmse: 0.0040\n",
      "Epoch 747: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6261e-04 - rmse: 0.0059 - val_loss: 1.7611e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 748/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7190e-04 - rmse: 0.0066\n",
      "Epoch 748: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6035e-04 - rmse: 0.0057 - val_loss: 1.6399e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 749/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6689e-04 - rmse: 0.0062\n",
      "Epoch 749: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5504e-04 - rmse: 0.0052 - val_loss: 1.5065e-04 - val_rmse: 0.0048 - lr: 1.0000e-04\n",
      "Epoch 750/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4506e-04 - rmse: 0.0041\n",
      "Epoch 750: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7214e-04 - rmse: 0.0066 - val_loss: 1.5213e-04 - val_rmse: 0.0049 - lr: 1.0000e-04\n",
      "Epoch 751/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4976e-04 - rmse: 0.0047\n",
      "Epoch 751: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5775e-04 - rmse: 0.0055 - val_loss: 1.5046e-04 - val_rmse: 0.0047 - lr: 1.0000e-04\n",
      "Epoch 752/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4254e-04 - rmse: 0.0038\n",
      "Epoch 752: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5551e-04 - rmse: 0.0053 - val_loss: 1.9331e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 753/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9189e-04 - rmse: 0.0080\n",
      "Epoch 753: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7572e-04 - rmse: 0.0069 - val_loss: 2.1387e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 754/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0085e-04 - rmse: 0.0085\n",
      "Epoch 754: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8944e-04 - rmse: 0.0078 - val_loss: 1.7581e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 755/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7427e-04 - rmse: 0.0068\n",
      "Epoch 755: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.9063e-04 - rmse: 0.0079 - val_loss: 1.7796e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 756/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6998e-04 - rmse: 0.0065\n",
      "Epoch 756: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5726e-04 - rmse: 0.0054 - val_loss: 1.9690e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 757/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8364e-04 - rmse: 0.0075\n",
      "Epoch 757: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7977e-04 - rmse: 0.0072 - val_loss: 1.8579e-04 - val_rmse: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 758/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7922e-04 - rmse: 0.0072\n",
      "Epoch 758: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 758: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.1320e-04 - rmse: 0.0092 - val_loss: 1.5603e-04 - val_rmse: 0.0053 - lr: 1.0000e-04\n",
      "Epoch 759/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5049e-04 - rmse: 0.0048\n",
      "Epoch 759: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5057e-04 - rmse: 0.0048 - val_loss: 1.6332e-04 - val_rmse: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 760/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5760e-04 - rmse: 0.0055\n",
      "Epoch 760: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.5284e-04 - rmse: 0.0050 - val_loss: 1.4630e-04 - val_rmse: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 761/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4361e-04 - rmse: 0.0040\n",
      "Epoch 761: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4785e-04 - rmse: 0.0045 - val_loss: 1.5442e-04 - val_rmse: 0.0052 - lr: 5.0000e-05\n",
      "Epoch 762/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6585e-04 - rmse: 0.0062\n",
      "Epoch 762: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5189e-04 - rmse: 0.0049 - val_loss: 1.5477e-04 - val_rmse: 0.0052 - lr: 5.0000e-05\n",
      "Epoch 763/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4718e-04 - rmse: 0.0044\n",
      "Epoch 763: val_loss improved from 0.00015 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 1.4308e-04 - rmse: 0.0039 - val_loss: 1.4377e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 764/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4429e-04 - rmse: 0.0041\n",
      "Epoch 764: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4418e-04 - rmse: 0.0041 - val_loss: 1.4674e-04 - val_rmse: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 765/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4258e-04 - rmse: 0.0039\n",
      "Epoch 765: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4253e-04 - rmse: 0.0039 - val_loss: 1.4704e-04 - val_rmse: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 766/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4440e-04 - rmse: 0.0041\n",
      "Epoch 766: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.4521e-04 - rmse: 0.0042 - val_loss: 1.4316e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 767/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3859e-04 - rmse: 0.0033\n",
      "Epoch 767: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 78ms/step - loss: 1.4157e-04 - rmse: 0.0037 - val_loss: 1.4295e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 768/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3997e-04 - rmse: 0.0035\n",
      "Epoch 768: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.4013e-04 - rmse: 0.0036 - val_loss: 1.4089e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 769/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4141e-04 - rmse: 0.0037\n",
      "Epoch 769: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4014e-04 - rmse: 0.0036 - val_loss: 1.4207e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 770/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4310e-04 - rmse: 0.0040\n",
      "Epoch 770: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4472e-04 - rmse: 0.0042 - val_loss: 1.4401e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 771/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3840e-04 - rmse: 0.0033\n",
      "Epoch 771: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.4211e-04 - rmse: 0.0038 - val_loss: 1.4073e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 772/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3793e-04 - rmse: 0.0032\n",
      "Epoch 772: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4174e-04 - rmse: 0.0038 - val_loss: 1.4292e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 773/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3887e-04 - rmse: 0.0034\n",
      "Epoch 773: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.4174e-04 - rmse: 0.0038 - val_loss: 1.4054e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 774/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3608e-04 - rmse: 0.0029\n",
      "Epoch 774: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 1.3752e-04 - rmse: 0.0032 - val_loss: 1.4034e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 775/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4648e-04 - rmse: 0.0044\n",
      "Epoch 775: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4146e-04 - rmse: 0.0038 - val_loss: 1.4105e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 776/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4206e-04 - rmse: 0.0038\n",
      "Epoch 776: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4017e-04 - rmse: 0.0036 - val_loss: 1.4075e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 777/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4567e-04 - rmse: 0.0043\n",
      "Epoch 777: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4072e-04 - rmse: 0.0037 - val_loss: 1.4190e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 778/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3625e-04 - rmse: 0.0030\n",
      "Epoch 778: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.3749e-04 - rmse: 0.0032 - val_loss: 1.4388e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 779/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4275e-04 - rmse: 0.0039\n",
      "Epoch 779: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4268e-04 - rmse: 0.0039 - val_loss: 1.4193e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 780/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4420e-04 - rmse: 0.0041\n",
      "Epoch 780: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3925e-04 - rmse: 0.0035 - val_loss: 1.4205e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 781/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4576e-04 - rmse: 0.0043\n",
      "Epoch 781: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3886e-04 - rmse: 0.0034 - val_loss: 1.4138e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 782/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4284e-04 - rmse: 0.0040\n",
      "Epoch 782: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3902e-04 - rmse: 0.0034 - val_loss: 1.4398e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 783/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3993e-04 - rmse: 0.0036\n",
      "Epoch 783: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4325e-04 - rmse: 0.0040 - val_loss: 1.4486e-04 - val_rmse: 0.0042 - lr: 5.0000e-05\n",
      "Epoch 784/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4451e-04 - rmse: 0.0042\n",
      "Epoch 784: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3937e-04 - rmse: 0.0035 - val_loss: 1.5590e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 785/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5079e-04 - rmse: 0.0049\n",
      "Epoch 785: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4421e-04 - rmse: 0.0041 - val_loss: 1.5177e-04 - val_rmse: 0.0050 - lr: 5.0000e-05\n",
      "Epoch 786/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5666e-04 - rmse: 0.0054\n",
      "Epoch 786: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4428e-04 - rmse: 0.0041 - val_loss: 1.5304e-04 - val_rmse: 0.0051 - lr: 5.0000e-05\n",
      "Epoch 787/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4974e-04 - rmse: 0.0048\n",
      "Epoch 787: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4395e-04 - rmse: 0.0041 - val_loss: 1.4327e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 788/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4048e-04 - rmse: 0.0037\n",
      "Epoch 788: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3952e-04 - rmse: 0.0035 - val_loss: 1.4389e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 789/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3993e-04 - rmse: 0.0036\n",
      "Epoch 789: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4078e-04 - rmse: 0.0037 - val_loss: 1.4772e-04 - val_rmse: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 790/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4287e-04 - rmse: 0.0040\n",
      "Epoch 790: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4104e-04 - rmse: 0.0037 - val_loss: 1.4789e-04 - val_rmse: 0.0046 - lr: 5.0000e-05\n",
      "Epoch 791/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4553e-04 - rmse: 0.0043\n",
      "Epoch 791: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4300e-04 - rmse: 0.0040 - val_loss: 1.4376e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 792/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4731e-04 - rmse: 0.0045\n",
      "Epoch 792: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4134e-04 - rmse: 0.0038 - val_loss: 1.4367e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 793/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4439e-04 - rmse: 0.0042\n",
      "Epoch 793: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4002e-04 - rmse: 0.0036 - val_loss: 1.4105e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3863e-04 - rmse: 0.0034\n",
      "Epoch 794: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3593e-04 - rmse: 0.0030 - val_loss: 1.4399e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 795/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4958e-04 - rmse: 0.0048\n",
      "Epoch 795: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4471e-04 - rmse: 0.0042 - val_loss: 1.4213e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 796/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4418e-04 - rmse: 0.0042\n",
      "Epoch 796: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4158e-04 - rmse: 0.0038 - val_loss: 1.4682e-04 - val_rmse: 0.0045 - lr: 5.0000e-05\n",
      "Epoch 797/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4013e-04 - rmse: 0.0036\n",
      "Epoch 797: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4014e-04 - rmse: 0.0036 - val_loss: 1.4523e-04 - val_rmse: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 798/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4839e-04 - rmse: 0.0046\n",
      "Epoch 798: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4247e-04 - rmse: 0.0039 - val_loss: 1.4516e-04 - val_rmse: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 799/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4223e-04 - rmse: 0.0039\n",
      "Epoch 799: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4184e-04 - rmse: 0.0039 - val_loss: 1.4586e-04 - val_rmse: 0.0044 - lr: 5.0000e-05\n",
      "Epoch 800/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4514e-04 - rmse: 0.0043\n",
      "Epoch 800: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4002e-04 - rmse: 0.0036 - val_loss: 1.4551e-04 - val_rmse: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 801/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4349e-04 - rmse: 0.0041\n",
      "Epoch 801: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4118e-04 - rmse: 0.0038 - val_loss: 1.4209e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 802/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3775e-04 - rmse: 0.0033\n",
      "Epoch 802: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3814e-04 - rmse: 0.0034 - val_loss: 1.4358e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 803/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4375e-04 - rmse: 0.0041\n",
      "Epoch 803: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4031e-04 - rmse: 0.0037 - val_loss: 1.4351e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 804/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4861e-04 - rmse: 0.0047\n",
      "Epoch 804: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4354e-04 - rmse: 0.0041 - val_loss: 1.4395e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 805/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3932e-04 - rmse: 0.0035\n",
      "Epoch 805: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 1.3781e-04 - rmse: 0.0033 - val_loss: 1.3984e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 806/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4905e-04 - rmse: 0.0047\n",
      "Epoch 806: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4191e-04 - rmse: 0.0039 - val_loss: 1.4025e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 807/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3666e-04 - rmse: 0.0031\n",
      "Epoch 807: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.3867e-04 - rmse: 0.0035 - val_loss: 1.3899e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 808/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3431e-04 - rmse: 0.0028\n",
      "Epoch 808: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3701e-04 - rmse: 0.0032 - val_loss: 1.3901e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 809/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3513e-04 - rmse: 0.0029\n",
      "Epoch 809: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 1.3867e-04 - rmse: 0.0035 - val_loss: 1.3837e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 810/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3562e-04 - rmse: 0.0030\n",
      "Epoch 810: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3885e-04 - rmse: 0.0035 - val_loss: 1.4010e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 811/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4182e-04 - rmse: 0.0039\n",
      "Epoch 811: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4082e-04 - rmse: 0.0038 - val_loss: 1.4060e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 812/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4155e-04 - rmse: 0.0039\n",
      "Epoch 812: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4170e-04 - rmse: 0.0039 - val_loss: 1.4125e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 813/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3765e-04 - rmse: 0.0033\n",
      "Epoch 813: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4277e-04 - rmse: 0.0040 - val_loss: 1.4196e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 814/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3842e-04 - rmse: 0.0034\n",
      "Epoch 814: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4060e-04 - rmse: 0.0037 - val_loss: 1.4060e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 815/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4017e-04 - rmse: 0.0037\n",
      "Epoch 815: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3788e-04 - rmse: 0.0034 - val_loss: 1.4203e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 816/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3757e-04 - rmse: 0.0033\n",
      "Epoch 816: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4004e-04 - rmse: 0.0037 - val_loss: 1.3959e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 817/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4004e-04 - rmse: 0.0037\n",
      "Epoch 817: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3837e-04 - rmse: 0.0034 - val_loss: 1.4333e-04 - val_rmse: 0.0041 - lr: 5.0000e-05\n",
      "Epoch 818/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3642e-04 - rmse: 0.0031\n",
      "Epoch 818: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4046e-04 - rmse: 0.0037 - val_loss: 1.4724e-04 - val_rmse: 0.0046 - lr: 5.0000e-05\n",
      "Epoch 819/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4184e-04 - rmse: 0.0039\n",
      "Epoch 819: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4304e-04 - rmse: 0.0041 - val_loss: 1.4190e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 820/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3961e-04 - rmse: 0.0036\n",
      "Epoch 820: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4002e-04 - rmse: 0.0037 - val_loss: 1.4089e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 821/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3832e-04 - rmse: 0.0034\n",
      "Epoch 821: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3665e-04 - rmse: 0.0032 - val_loss: 1.3839e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 822/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4534e-04 - rmse: 0.0043\n",
      "Epoch 822: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4021e-04 - rmse: 0.0037 - val_loss: 1.4059e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 823/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3503e-04 - rmse: 0.0029\n",
      "Epoch 823: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3498e-04 - rmse: 0.0029 - val_loss: 1.3982e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 824/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3729e-04 - rmse: 0.0033\n",
      "Epoch 824: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.3827e-04 - rmse: 0.0034 - val_loss: 1.3819e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 825/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3470e-04 - rmse: 0.0029\n",
      "Epoch 825: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3730e-04 - rmse: 0.0033 - val_loss: 1.3959e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 826/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3215e-04 - rmse: 0.0024\n",
      "Epoch 826: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.3629e-04 - rmse: 0.0032 - val_loss: 1.3765e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 827/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3672e-04 - rmse: 0.0032\n",
      "Epoch 827: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3703e-04 - rmse: 0.0033 - val_loss: 1.3825e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 828/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3612e-04 - rmse: 0.0031\n",
      "Epoch 828: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3623e-04 - rmse: 0.0031 - val_loss: 1.3856e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 829/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3893e-04 - rmse: 0.0036\n",
      "Epoch 829: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3788e-04 - rmse: 0.0034 - val_loss: 1.3964e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 830/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3313e-04 - rmse: 0.0026\n",
      "Epoch 830: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3638e-04 - rmse: 0.0032 - val_loss: 1.3828e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 831/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3772e-04 - rmse: 0.0034\n",
      "Epoch 831: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4030e-04 - rmse: 0.0037 - val_loss: 1.3979e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 832/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3641e-04 - rmse: 0.0032\n",
      "Epoch 832: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3492e-04 - rmse: 0.0029 - val_loss: 1.3822e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 833/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3639e-04 - rmse: 0.0032\n",
      "Epoch 833: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3761e-04 - rmse: 0.0034 - val_loss: 1.3920e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 834/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3421e-04 - rmse: 0.0028\n",
      "Epoch 834: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3458e-04 - rmse: 0.0029 - val_loss: 1.3899e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 835/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4185e-04 - rmse: 0.0040\n",
      "Epoch 835: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4169e-04 - rmse: 0.0039 - val_loss: 1.4222e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 836/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3769e-04 - rmse: 0.0034\n",
      "Epoch 836: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3779e-04 - rmse: 0.0034 - val_loss: 1.4211e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 837/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3928e-04 - rmse: 0.0036\n",
      "Epoch 837: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3871e-04 - rmse: 0.0035 - val_loss: 1.4119e-04 - val_rmse: 0.0039 - lr: 5.0000e-05\n",
      "Epoch 838/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3688e-04 - rmse: 0.0033\n",
      "Epoch 838: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3563e-04 - rmse: 0.0031 - val_loss: 1.3918e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 839/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4156e-04 - rmse: 0.0039\n",
      "Epoch 839: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3959e-04 - rmse: 0.0037 - val_loss: 1.3893e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 840/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3880e-04 - rmse: 0.0036\n",
      "Epoch 840: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3684e-04 - rmse: 0.0033 - val_loss: 1.3791e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 841/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3666e-04 - rmse: 0.0033\n",
      "Epoch 841: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3581e-04 - rmse: 0.0031 - val_loss: 1.3902e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 842/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4227e-04 - rmse: 0.0040\n",
      "Epoch 842: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3823e-04 - rmse: 0.0035 - val_loss: 1.3768e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 843/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3726e-04 - rmse: 0.0033\n",
      "Epoch 843: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3835e-04 - rmse: 0.0035 - val_loss: 1.4204e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 844/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3560e-04 - rmse: 0.0031\n",
      "Epoch 844: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3584e-04 - rmse: 0.0031 - val_loss: 1.3809e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 845/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3351e-04 - rmse: 0.0027\n",
      "Epoch 845: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3514e-04 - rmse: 0.0030 - val_loss: 1.3887e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 846/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4660e-04 - rmse: 0.0045\n",
      "Epoch 846: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4073e-04 - rmse: 0.0038 - val_loss: 1.3809e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 847/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3166e-04 - rmse: 0.0024\n",
      "Epoch 847: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 1.3402e-04 - rmse: 0.0028 - val_loss: 1.3734e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3585e-04 - rmse: 0.0031\n",
      "Epoch 848: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3551e-04 - rmse: 0.0031 - val_loss: 1.3910e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 849/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3432e-04 - rmse: 0.0029\n",
      "Epoch 849: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3611e-04 - rmse: 0.0032 - val_loss: 1.3781e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 850/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3460e-04 - rmse: 0.0029\n",
      "Epoch 850: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3499e-04 - rmse: 0.0030 - val_loss: 1.3804e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 851/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3960e-04 - rmse: 0.0037\n",
      "Epoch 851: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3590e-04 - rmse: 0.0032 - val_loss: 1.3770e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 852/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4102e-04 - rmse: 0.0039\n",
      "Epoch 852: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3770e-04 - rmse: 0.0034 - val_loss: 1.3874e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 853/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3849e-04 - rmse: 0.0036\n",
      "Epoch 853: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3712e-04 - rmse: 0.0034 - val_loss: 1.3790e-04 - val_rmse: 0.0035 - lr: 5.0000e-05\n",
      "Epoch 854/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3145e-04 - rmse: 0.0024\n",
      "Epoch 854: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3316e-04 - rmse: 0.0027 - val_loss: 1.3912e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 855/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4045e-04 - rmse: 0.0038\n",
      "Epoch 855: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3752e-04 - rmse: 0.0034 - val_loss: 1.3892e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 856/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4144e-04 - rmse: 0.0040\n",
      "Epoch 856: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3820e-04 - rmse: 0.0035 - val_loss: 1.4139e-04 - val_rmse: 0.0040 - lr: 5.0000e-05\n",
      "Epoch 857/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3449e-04 - rmse: 0.0030\n",
      "Epoch 857: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3921e-04 - rmse: 0.0037 - val_loss: 1.3859e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 858/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3694e-04 - rmse: 0.0033\n",
      "Epoch 858: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3896e-04 - rmse: 0.0036 - val_loss: 1.4408e-04 - val_rmse: 0.0043 - lr: 5.0000e-05\n",
      "Epoch 859/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3637e-04 - rmse: 0.0033\n",
      "Epoch 859: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3920e-04 - rmse: 0.0037 - val_loss: 1.3957e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 860/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3842e-04 - rmse: 0.0036\n",
      "Epoch 860: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3800e-04 - rmse: 0.0035 - val_loss: 1.3752e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 861/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3611e-04 - rmse: 0.0032\n",
      "Epoch 861: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 1.3729e-04 - rmse: 0.0034 - val_loss: 1.3647e-04 - val_rmse: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 862/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3559e-04 - rmse: 0.0031\n",
      "Epoch 862: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3778e-04 - rmse: 0.0035 - val_loss: 1.3874e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 863/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3481e-04 - rmse: 0.0030\n",
      "Epoch 863: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3694e-04 - rmse: 0.0034 - val_loss: 1.3708e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 864/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3467e-04 - rmse: 0.0030\n",
      "Epoch 864: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3616e-04 - rmse: 0.0032 - val_loss: 1.3867e-04 - val_rmse: 0.0036 - lr: 5.0000e-05\n",
      "Epoch 865/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3953e-04 - rmse: 0.0037\n",
      "Epoch 865: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3745e-04 - rmse: 0.0034 - val_loss: 1.3973e-04 - val_rmse: 0.0038 - lr: 5.0000e-05\n",
      "Epoch 866/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3163e-04 - rmse: 0.0025\n",
      "Epoch 866: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3461e-04 - rmse: 0.0030 - val_loss: 1.3894e-04 - val_rmse: 0.0037 - lr: 5.0000e-05\n",
      "Epoch 867/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4117e-04 - rmse: 0.0039\n",
      "Epoch 867: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.4298e-04 - rmse: 0.0042 - val_loss: 1.3625e-04 - val_rmse: 0.0033 - lr: 5.0000e-05\n",
      "Epoch 868/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3372e-04 - rmse: 0.0029\n",
      "Epoch 868: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 868: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4016e-04 - rmse: 0.0038 - val_loss: 1.3705e-04 - val_rmse: 0.0034 - lr: 5.0000e-05\n",
      "Epoch 869/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3208e-04 - rmse: 0.0026\n",
      "Epoch 869: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3806e-04 - rmse: 0.0035 - val_loss: 1.3763e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 870/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3461e-04 - rmse: 0.0030\n",
      "Epoch 870: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3552e-04 - rmse: 0.0032 - val_loss: 1.4056e-04 - val_rmse: 0.0039 - lr: 2.5000e-05\n",
      "Epoch 871/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3894e-04 - rmse: 0.0037\n",
      "Epoch 871: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3688e-04 - rmse: 0.0034 - val_loss: 1.3715e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 872/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3703e-04 - rmse: 0.0034\n",
      "Epoch 872: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 1.3472e-04 - rmse: 0.0030 - val_loss: 1.3611e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 873/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3254e-04 - rmse: 0.0027\n",
      "Epoch 873: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3519e-04 - rmse: 0.0031 - val_loss: 1.3886e-04 - val_rmse: 0.0037 - lr: 2.5000e-05\n",
      "Epoch 874/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3351e-04 - rmse: 0.0028\n",
      "Epoch 874: val_loss did not improve from 0.00014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3533e-04 - rmse: 0.0031 - val_loss: 1.3679e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 875/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3404e-04 - rmse: 0.0029\n",
      "Epoch 875: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3517e-04 - rmse: 0.0031 - val_loss: 1.3618e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 876/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3232e-04 - rmse: 0.0026\n",
      "Epoch 876: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3402e-04 - rmse: 0.0029 - val_loss: 1.3749e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 877/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3734e-04 - rmse: 0.0034\n",
      "Epoch 877: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.3489e-04 - rmse: 0.0031 - val_loss: 1.3593e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 878/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3274e-04 - rmse: 0.0027\n",
      "Epoch 878: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3462e-04 - rmse: 0.0030 - val_loss: 1.3608e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 879/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3625e-04 - rmse: 0.0033\n",
      "Epoch 879: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3453e-04 - rmse: 0.0030 - val_loss: 1.3612e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 880/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3632e-04 - rmse: 0.0033\n",
      "Epoch 880: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.3448e-04 - rmse: 0.0030 - val_loss: 1.3580e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 881/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3378e-04 - rmse: 0.0029\n",
      "Epoch 881: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3376e-04 - rmse: 0.0029 - val_loss: 1.3672e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 882/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3924e-04 - rmse: 0.0037\n",
      "Epoch 882: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3676e-04 - rmse: 0.0034 - val_loss: 1.3604e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 883/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3301e-04 - rmse: 0.0028\n",
      "Epoch 883: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3469e-04 - rmse: 0.0030 - val_loss: 1.3769e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 884/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3197e-04 - rmse: 0.0026\n",
      "Epoch 884: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3394e-04 - rmse: 0.0029 - val_loss: 1.3688e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 885/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3443e-04 - rmse: 0.0030\n",
      "Epoch 885: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3402e-04 - rmse: 0.0029 - val_loss: 1.3630e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 886/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4333e-04 - rmse: 0.0042\n",
      "Epoch 886: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3765e-04 - rmse: 0.0035 - val_loss: 1.4153e-04 - val_rmse: 0.0040 - lr: 2.5000e-05\n",
      "Epoch 887/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3691e-04 - rmse: 0.0034\n",
      "Epoch 887: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3488e-04 - rmse: 0.0031 - val_loss: 1.3889e-04 - val_rmse: 0.0037 - lr: 2.5000e-05\n",
      "Epoch 888/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3774e-04 - rmse: 0.0035\n",
      "Epoch 888: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3899e-04 - rmse: 0.0037 - val_loss: 1.3665e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 889/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3407e-04 - rmse: 0.0030\n",
      "Epoch 889: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3440e-04 - rmse: 0.0030 - val_loss: 1.3764e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 890/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4146e-04 - rmse: 0.0040\n",
      "Epoch 890: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3512e-04 - rmse: 0.0031 - val_loss: 1.3621e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 891/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3797e-04 - rmse: 0.0036\n",
      "Epoch 891: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3397e-04 - rmse: 0.0029 - val_loss: 1.3603e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 892/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3457e-04 - rmse: 0.0030\n",
      "Epoch 892: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3569e-04 - rmse: 0.0032 - val_loss: 1.3627e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 893/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3501e-04 - rmse: 0.0031\n",
      "Epoch 893: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3477e-04 - rmse: 0.0031 - val_loss: 1.3600e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 894/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3248e-04 - rmse: 0.0027\n",
      "Epoch 894: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3415e-04 - rmse: 0.0030 - val_loss: 1.3608e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 895/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3626e-04 - rmse: 0.0033\n",
      "Epoch 895: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3584e-04 - rmse: 0.0032 - val_loss: 1.3687e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 896/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3220e-04 - rmse: 0.0026\n",
      "Epoch 896: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3366e-04 - rmse: 0.0029 - val_loss: 1.3599e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 897/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3021e-04 - rmse: 0.0022\n",
      "Epoch 897: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3497e-04 - rmse: 0.0031 - val_loss: 1.3618e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 898/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3261e-04 - rmse: 0.0027\n",
      "Epoch 898: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3260e-04 - rmse: 0.0027 - val_loss: 1.3672e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 899/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4001e-04 - rmse: 0.0038\n",
      "Epoch 899: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3596e-04 - rmse: 0.0033 - val_loss: 1.3648e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 900/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3657e-04 - rmse: 0.0034\n",
      "Epoch 900: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3519e-04 - rmse: 0.0032 - val_loss: 1.3670e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 901/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3282e-04 - rmse: 0.0028\n",
      "Epoch 901: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 72ms/step - loss: 1.3348e-04 - rmse: 0.0029 - val_loss: 1.3575e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 902/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4063e-04 - rmse: 0.0039\n",
      "Epoch 902: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3596e-04 - rmse: 0.0033 - val_loss: 1.3571e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 903/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3401e-04 - rmse: 0.0030\n",
      "Epoch 903: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.3402e-04 - rmse: 0.0030 - val_loss: 1.3566e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 904/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3214e-04 - rmse: 0.0026\n",
      "Epoch 904: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3357e-04 - rmse: 0.0029 - val_loss: 1.3617e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 905/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3101e-04 - rmse: 0.0024\n",
      "Epoch 905: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3263e-04 - rmse: 0.0027 - val_loss: 1.3624e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 906/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4352e-04 - rmse: 0.0043\n",
      "Epoch 906: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3608e-04 - rmse: 0.0033 - val_loss: 1.3570e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 907/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3462e-04 - rmse: 0.0031\n",
      "Epoch 907: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3289e-04 - rmse: 0.0028 - val_loss: 1.3586e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 908/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3497e-04 - rmse: 0.0031\n",
      "Epoch 908: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3504e-04 - rmse: 0.0031 - val_loss: 1.3585e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 909/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3220e-04 - rmse: 0.0027\n",
      "Epoch 909: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3315e-04 - rmse: 0.0028 - val_loss: 1.3570e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 910/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3934e-04 - rmse: 0.0038\n",
      "Epoch 910: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3478e-04 - rmse: 0.0031 - val_loss: 1.3640e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 911/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3462e-04 - rmse: 0.0031\n",
      "Epoch 911: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3450e-04 - rmse: 0.0031 - val_loss: 1.3580e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 912/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3594e-04 - rmse: 0.0033\n",
      "Epoch 912: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 1.3383e-04 - rmse: 0.0030 - val_loss: 1.3566e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 913/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3260e-04 - rmse: 0.0027\n",
      "Epoch 913: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 1.3443e-04 - rmse: 0.0031 - val_loss: 1.3562e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 914/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3279e-04 - rmse: 0.0028\n",
      "Epoch 914: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3228e-04 - rmse: 0.0027 - val_loss: 1.3603e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 915/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3871e-04 - rmse: 0.0037\n",
      "Epoch 915: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.3446e-04 - rmse: 0.0031 - val_loss: 1.3556e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 916/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3664e-04 - rmse: 0.0034\n",
      "Epoch 916: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.3546e-04 - rmse: 0.0032 - val_loss: 1.3550e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 917/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3518e-04 - rmse: 0.0032\n",
      "Epoch 917: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.3456e-04 - rmse: 0.0031 - val_loss: 1.3537e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 918/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3050e-04 - rmse: 0.0023\n",
      "Epoch 918: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3240e-04 - rmse: 0.0027 - val_loss: 1.3564e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 919/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3378e-04 - rmse: 0.0030\n",
      "Epoch 919: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3594e-04 - rmse: 0.0033 - val_loss: 1.3740e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 920/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3130e-04 - rmse: 0.0025\n",
      "Epoch 920: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3423e-04 - rmse: 0.0030 - val_loss: 1.3573e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 921/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3421e-04 - rmse: 0.0030\n",
      "Epoch 921: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3370e-04 - rmse: 0.0029 - val_loss: 1.3592e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 922/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3558e-04 - rmse: 0.0032\n",
      "Epoch 922: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3551e-04 - rmse: 0.0032 - val_loss: 1.3589e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 923/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3180e-04 - rmse: 0.0026\n",
      "Epoch 923: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.3136e-04 - rmse: 0.0025 - val_loss: 1.3533e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 924/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3180e-04 - rmse: 0.0026\n",
      "Epoch 924: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3520e-04 - rmse: 0.0032 - val_loss: 1.3604e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 925/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3282e-04 - rmse: 0.0028\n",
      "Epoch 925: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3411e-04 - rmse: 0.0030 - val_loss: 1.3568e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 926/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3255e-04 - rmse: 0.0028\n",
      "Epoch 926: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3421e-04 - rmse: 0.0030 - val_loss: 1.3541e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 927/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3383e-04 - rmse: 0.0030\n",
      "Epoch 927: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3348e-04 - rmse: 0.0029 - val_loss: 1.3553e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 928/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3462e-04 - rmse: 0.0031\n",
      "Epoch 928: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.3400e-04 - rmse: 0.0030 - val_loss: 1.3516e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 929/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3379e-04 - rmse: 0.0030\n",
      "Epoch 929: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3356e-04 - rmse: 0.0029 - val_loss: 1.3602e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 930/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3624e-04 - rmse: 0.0034\n",
      "Epoch 930: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3330e-04 - rmse: 0.0029 - val_loss: 1.3597e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 931/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3873e-04 - rmse: 0.0037\n",
      "Epoch 931: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3477e-04 - rmse: 0.0031 - val_loss: 1.3523e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 932/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3122e-04 - rmse: 0.0025\n",
      "Epoch 932: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3525e-04 - rmse: 0.0032 - val_loss: 1.3609e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 933/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3670e-04 - rmse: 0.0034\n",
      "Epoch 933: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3362e-04 - rmse: 0.0030 - val_loss: 1.3615e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 934/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3728e-04 - rmse: 0.0035\n",
      "Epoch 934: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3646e-04 - rmse: 0.0034 - val_loss: 1.3744e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 935/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3343e-04 - rmse: 0.0029\n",
      "Epoch 935: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3474e-04 - rmse: 0.0031 - val_loss: 1.3756e-04 - val_rmse: 0.0036 - lr: 2.5000e-05\n",
      "Epoch 936/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3609e-04 - rmse: 0.0033\n",
      "Epoch 936: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3381e-04 - rmse: 0.0030 - val_loss: 1.3714e-04 - val_rmse: 0.0035 - lr: 2.5000e-05\n",
      "Epoch 937/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3700e-04 - rmse: 0.0035\n",
      "Epoch 937: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3418e-04 - rmse: 0.0031 - val_loss: 1.3604e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 938/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3378e-04 - rmse: 0.0030\n",
      "Epoch 938: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3379e-04 - rmse: 0.0030 - val_loss: 1.3538e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 939/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3535e-04 - rmse: 0.0032\n",
      "Epoch 939: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3533e-04 - rmse: 0.0032 - val_loss: 1.3599e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 940/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3513e-04 - rmse: 0.0032\n",
      "Epoch 940: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 1.3276e-04 - rmse: 0.0028 - val_loss: 1.3503e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 941/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3283e-04 - rmse: 0.0028\n",
      "Epoch 941: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3271e-04 - rmse: 0.0028 - val_loss: 1.3503e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 942/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3981e-04 - rmse: 0.0039\n",
      "Epoch 942: val_loss improved from 0.00014 to 0.00014, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.3500e-04 - rmse: 0.0032 - val_loss: 1.3503e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 943/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2923e-04 - rmse: 0.0021\n",
      "Epoch 943: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3284e-04 - rmse: 0.0028 - val_loss: 1.3522e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 944/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3503e-04 - rmse: 0.0032\n",
      "Epoch 944: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3449e-04 - rmse: 0.0031 - val_loss: 1.3612e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 945/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3224e-04 - rmse: 0.0027\n",
      "Epoch 945: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3367e-04 - rmse: 0.0030 - val_loss: 1.3513e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 946/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3560e-04 - rmse: 0.0033\n",
      "Epoch 946: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3495e-04 - rmse: 0.0032 - val_loss: 1.3533e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 947/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3035e-04 - rmse: 0.0024\n",
      "Epoch 947: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3462e-04 - rmse: 0.0031 - val_loss: 1.3741e-04 - val_rmse: 0.0036 - lr: 2.5000e-05\n",
      "Epoch 948/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3347e-04 - rmse: 0.0029\n",
      "Epoch 948: val_loss did not improve from 0.00014\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3282e-04 - rmse: 0.0028 - val_loss: 1.3555e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 949/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3595e-04 - rmse: 0.0033\n",
      "Epoch 949: val_loss improved from 0.00014 to 0.00013, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.3509e-04 - rmse: 0.0032 - val_loss: 1.3492e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 950/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2791e-04 - rmse: 0.0018\n",
      "Epoch 950: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3341e-04 - rmse: 0.0029 - val_loss: 1.3625e-04 - val_rmse: 0.0034 - lr: 2.5000e-05\n",
      "Epoch 951/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3316e-04 - rmse: 0.0029\n",
      "Epoch 951: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3264e-04 - rmse: 0.0028 - val_loss: 1.3549e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 952/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3176e-04 - rmse: 0.0027\n",
      "Epoch 952: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3449e-04 - rmse: 0.0031 - val_loss: 1.3538e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 953/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3091e-04 - rmse: 0.0025\n",
      "Epoch 953: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3320e-04 - rmse: 0.0029 - val_loss: 1.3514e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 954/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3342e-04 - rmse: 0.0030\n",
      "Epoch 954: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.3486e-04 - rmse: 0.0032 - val_loss: 1.3478e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 955/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2985e-04 - rmse: 0.0023\n",
      "Epoch 955: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 1.3274e-04 - rmse: 0.0028 - val_loss: 1.3466e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 956/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3020e-04 - rmse: 0.0023\n",
      "Epoch 956: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3187e-04 - rmse: 0.0027 - val_loss: 1.3522e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 957/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3351e-04 - rmse: 0.0030\n",
      "Epoch 957: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3403e-04 - rmse: 0.0031 - val_loss: 1.3503e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 958/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2827e-04 - rmse: 0.0019\n",
      "Epoch 958: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.3176e-04 - rmse: 0.0027 - val_loss: 1.3464e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 959/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3212e-04 - rmse: 0.0027\n",
      "Epoch 959: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3362e-04 - rmse: 0.0030 - val_loss: 1.3542e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 960/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3260e-04 - rmse: 0.0028\n",
      "Epoch 960: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 1.3355e-04 - rmse: 0.0030 - val_loss: 1.3457e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 961/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3336e-04 - rmse: 0.0030\n",
      "Epoch 961: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3285e-04 - rmse: 0.0029 - val_loss: 1.3467e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 962/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3549e-04 - rmse: 0.0033\n",
      "Epoch 962: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3251e-04 - rmse: 0.0028 - val_loss: 1.3488e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 963/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3350e-04 - rmse: 0.0030\n",
      "Epoch 963: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.3493e-04 - rmse: 0.0032 - val_loss: 1.3525e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 964/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3164e-04 - rmse: 0.0027\n",
      "Epoch 964: val_loss improved from 0.00013 to 0.00013, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_400kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 1.3253e-04 - rmse: 0.0028 - val_loss: 1.3449e-04 - val_rmse: 0.0031 - lr: 2.5000e-05\n",
      "Epoch 965/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3020e-04 - rmse: 0.0024\n",
      "Epoch 965: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3218e-04 - rmse: 0.0028 - val_loss: 1.3511e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 966/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4372e-04 - rmse: 0.0044\n",
      "Epoch 966: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.3525e-04 - rmse: 0.0033 - val_loss: 1.3543e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 967/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3140e-04 - rmse: 0.0026\n",
      "Epoch 967: val_loss did not improve from 0.00013\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3483e-04 - rmse: 0.0032 - val_loss: 1.3492e-04 - val_rmse: 0.0032 - lr: 2.5000e-05\n",
      "Epoch 968/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3370e-04 - rmse: 0.0030Restoring model weights from the end of the best epoch: 768.\n",
      "\n",
      "Epoch 968: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 968: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3274e-04 - rmse: 0.0029 - val_loss: 1.3541e-04 - val_rmse: 0.0033 - lr: 2.5000e-05\n",
      "Epoch 968: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "history = model.fit([x_time_train, x_coord_train], y_train, batch_size=batch_size,\n",
    "                    validation_data=[[x_time_val, x_coord_val], y_val],\n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN, validation_steps=VALIDATION_STEPS,\n",
    "                    epochs=10000, shuffle=True, callbacks=[es, ckpt, rp])\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:01:44.468318\n"
     ]
    }
   ],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fbce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = \"D:\\\\VAWT_data\\\\flap_unsteady\\\\result\\\\\"+\"20230102_AeroCNN1_Case13_WithParameters\\\\test\"+str(test_rate)+\"_val\"+str(val_rate)+\"_\"+str(n_kernels)+\"kernels_\"+str(n_layers)+\"layers_\"+ str(n_units) +\"units_CmPrediction\"\n",
    "if not os.path.exists(storage_dir):\n",
    "    os.makedirs(storage_dir)\n",
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2, label='Training loss')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation loss')\n",
    "plt.title('Training loss (mean squared error)\\nAeroCNN-I, optimal settings, $C_m$ prediction', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"TrainingLoss_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAE2CAYAAAB/dtUeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA9dElEQVR4nO3deXwU5f3A8c93N3cg4b4UjKCIiHihVduKFyretd61VWurtvaw1dqfrVW0h1rP1tseUrWK1ULrLXiAWhEFPEEQlHAfAQIhdzb7/f3xzIbNstlsspssmXzfr9e+svPMMzPPMzvZ787zzMwjqooxxhjTkkCmC2CMMWbnZoHCGGNMQhYojDHGJGSBwhhjTEIWKIwxxiRkgcIYY0xCXTZQiMgkEdGo1zoReV5ExnbQ9g4RkUlJ5p3slWlGnHn5IrLNm39RusuZChEpFJHfishiEakRkfUiMktELsl02dJJRH4kIgmvCxeRi2KOr+jXdZ1V1kwSkZHe/1mvmPTIvunRSeU40tvemA7ezgCvviUx6TvFfsikLhsoPFuBw7zXlcBIYIaI9OmAbR0C3NCG/JXAUSIyMCb95PQVKe3+DVwK3AucCPwE+NR7310dzfZjLPJ6JKMl6jwjccd8r5j0F3D7obqzC9TBBuDqWxKT3t32ww6yMl2AFIVU9V3v/bsiUgrMBk4AnshYqZzFQE/gLNwXb8S5wLPA+ZkoVEtEZE/geOBsVX06atZTIiIZKlZcIpKvqjWdtLn3VbUy2cwtlS2VMndyfVulqmVAWabLkWndaT909TOKWB95f4dGEkQk6J02rhCROhFZICI7fEmLyNki8omXZ6WI/F5Esrx5FwH3eO8jzQ8zkyjPU7jAENlGT9yv8ynxMovIaSIyV0Rqvaa0P4pIdtT8USIyxStftVeXK0UkEJUncpp+pIg8LSKVIvKliPywlbL28v6ui52hMbfvi8gRIvKRV855InK4iGyMbpoTkVIRuT1muWan6l5T171eU1e1iCwTkftEpChmORWRn4vI3SJSBnziped5+2il97l9JCInxiyb621ji4hsFpG7gGzSJEHZWkrvJyL/EJFNXp1nisi4mHWWisgdIvIbEVkFVLSxTMlu43ZvG+u84+SfIlLszT8SeM7LvsyrT6k3L/ZzLPGmzxWRR0SkQkRWicgF3vxrRGSNiJSJyK0xx2urx3SSdc726hP5P18jItNEJCcqzzBvW5u9bb0iIntF6oD3GQFvyPb/8/bsh7NF5CER2erthxtj6yMiZ4nIEnFNvG+IyAES0xwtIqeK+/+qEpFyEZkjIuPbsl/SRlW75AuYBGyMSdsLUNyv4kja74EG4DrcL+aHvTznReU5zkv7B+5s5BqgDnjQm98fuN3Lc6j3Gp2gbJOBucDeQBgY5qV/B1gDFHnruihqmbOBRuB+rzw/ALYAt0flOQa4ETgFOBLX3LYVuDYqz5Heupd4dZ4A/N1LOyRBmYtwzWXzvO3ntZBvCFAFvIFrRrsUWIY7/Z4Ula80uuxe2kVeOXpE7dcHgDOB8cAFwGfAKzHLKbAWF3hPAE700p8HNnj76jjgr0AI2D9q2buAWuAqYCIwFViFF/8S7I9IWYtxZ97RL0mibC2lv40Lxhd7n+ObwDZgj5h9txZ4FTgVOKON/xvJbmM1MMvLcynueHs66ni4yqvHN3DH/AEtfI4l3vRy4A+4Y+5J3PF8B/CMtw9+7eU7t53H9JgEdb7e22cXAkfg/p8mA/ne/D7ACuADb97J3n5aCeQDubizfAV+yPb/8/bsh1Kv3hOAW9jxO2mct28ix8bPgM+J+k4ARgD1wG245s8Tgd8A38jI920mNpqWgnuBgu3/vCOAGd6BkBt1cFQBN8Qs+yKwOGr6XeCNmDzXeB/mrt70j2jlyyVq2cnAXO/9R8AvorZ7N9Aj5qAQ3D/ZIzHr+S5QA/SNsw3x6v0r4Ms4/1Q3RaVl406Rb2ml3OfhgoV6B+mbwPdp/sX4R2ATUBCV9i1vmUlRaaW0EijibD8L+KqXZ1hUugIfxOQ9xksfH5P+Jtu/7Pp6+++XUfMDwKLWPsuossZ7HZmobAnKfEJsmYFC77N5KGbfraWFYN1Kuduyjc3Rn4X3OYaBvb3pk711lST6HNn+BflIVJ4i3A+0JUAwKv094KkWyt7aMZ0oUDwP3JFg/m+947ZPVFpvXFC6wpseE/v5tnM/PBqT70NgStT007i+v+j/q2to/p1wJrCprZ9/R726etNTX9zB2AAsBQ7A/fqq8+aPAQpwH0y0p4CR4q5yCAIHtpAngOusSsUU4FxxHezHEr/ZaSQwDPiXiGRFXsDrQJ5Xj0hTy40ishR3xtOAO2Pa3csfbXrkjapG/mF3TVRQVX0S2A0XoKZ45XqY5v09hwAzVDW6A29qovUmIiLfFpEPRKQSV5+3vVkjY7K+EDN9LO5X8/9i9tlruF9sAPvi9t9/Iwupajh6OglHAAfHvOa1UraW0g8BylR1VlR5qnBfcl+Lyfuaqta2oZzt2cYMbd7/MhX3ZX1wO7YLbt9HtlmBC06zVLUxKs9SYJfIRBuP6UQ+BC7ymrnGiuzQr3Ys7odkRdSxsg33WY4jvabHTC+k+f/ewcBz6kUEz7Mxy3wCFHtNiMeJSGGay9gmXT1QbMXt9EOBy4Ac4Imo9sDB3t/1MctFpnsD/XC/uFvKk+oVVFNwgehXwGrd3vkerZ/390W2B74GXJMObO9zuRW4GvflfSKu7r/z5uXFrHNLzHR9nDw7UNVNqvqIqn7H2+4juEC3n5dlEK65J3qZGtyZSJuIyDeAR3EXIJyF+xy/4c2OLWvs59PPK0tDzGsS2/fXIO/vhphlY6cT+UBV58a8trVStpbSB7eQdz07HmctrbM1bdlGS5/jYNpnS8x0fQtp0Z9tW47pRH4H3IdrNvoIWCkiP42a3w84hx2Pl6OI6tNMky0x07F1HsSOneDNplV1MXAaMBz3vbBRRJ4Qkf7pLWpy/HDV01zv/RwRqcF98ZyFOyNY680bgDvtjIhcsrrZezV4eWghT7up6jIReQ/XDnlbC9ki27gU13QWKxIwzgLuUdU/RmaIyEmplC8RVW0Q1/l7MTAK9w+4jph9JSL5uOa0aLW4wB0t9ovqLGCOqjZ1tCforNOY6c24NvbTE1Qh0jE/gOafY+xnnarYsrWUvraFbQ9kx+OspXW2pi3baOlzXEvnScsx7Z19XQ9cL+4KvsuBu0Vksaq+jKv7s7gmqFixgb+jrcP1z0XbIQCo6gvAC94FBifhmq3vIeoCmc7S1c8oYj0OLAB+6U1/iutkPSsm39nA56pa5p0Wz2shTxj3axfcrwJEpC2/ciLuwF058WgL8xfjvvRK4vx6nauqkSCXjzs9xytLkDQdNCLS0/uiiLWn9zfyK/V9YIKIFETlOSPOcqtwnfnRJsRMN6uP51tJFBdcM8cgoDLePvPyfIILWKdFFvLONk/bcXWdYg4wQESOiCpPAe5L4O0Wl+q4bUyQ5jeLnYELUJH9V+/9bc8xn6y0H9OqugR3llIHjPaSXwP2ARbEOV4We3laqm+698P7wCkxzWOntpRZVbeq6hPANLbXp1N19TOKZlRVReQPwD9F5BhVfU1E7gauE5EQ7h/gDNwp7nlRi94AvCIij+CaivbF/fL4i6qu8vIs8v7+VEReByqiDrDWyvUv4F8J5odF5CrgMXGXhr6EOziH434xn+n1CcwArvDaczcDV+Cu1kiHvYBnReTvwDu4ALs/7kqVD9n+JXO3t93nReRO3FVQ1+I6jaNNA+4RkV/h/jHOwP2jRpsB3Cciv8Z9wZ2I66ROxgzgFdwNlrfifiAUeWXOU9VrVXWTiDwM3Oh9/gtwnfNtuZP2YO9MNdoGVf2yDesAQFVfEZH/4e5N+T/cWe7VuC/Lls42m3iXar4BHKWqM9OwjRrcL9bbcM1NtwHTVHWhNz9yfF8mIlOAalX9hPRKyzEtItNwP/g+wNXrTNz325teljtxV9W9LiL34H6YDcRdbfe21z+3wlv2QhHZCjR4PzrSvR9uxR3vU7zvnL1xxyW4H6eIyGW4/tGXcVdK7on7MdvSj82Olene9Pa+iHN5rJcexF1q9krU9I24y+DqcR1L34qz3Dm4X6D1uF/DvweyouYL7oqfNbgPc2aCsk3Gu+qphfnNrnqKSp8IvIW7UqsC9wX9u0g5cAf2NG/eeq8836f5lRdHEucKEWAm8EyCMvUGbsIdwJtwgWIR7qDuE5P3SOBj3C+2D3FXKm2k+VVP2bh/znVAOfAnXNNadFmDuMuON3h1+jfwFS/PyVHrUuBHccqc6322S73PbR3uH+ukmDz34/qzynGn7j8ntaue/ppE2VpK74/7Zy/HfSnNAg6OyVNKzBVjXvqJ3npbvDS7jdu4A/d/tN475p4EesXkuwp3RV4IKI3ZN7FX+5zcWj2I+d8ghWM6Zr2/wP0Q3IprSpoDnBaTZwiuz2097tgtxbVC7BOV51u474/66GMkxf3QrM5e2tm447YW9yPsWG/Z0735h+Euhljj5VmG+1/MTfTZd9RLvEIZkxIR2Qjcq6qTMl0WvxKRG4EjVPWoNKyrFPfD4eqUC2ZSJu7mxMeA4aq6rLX8nc1XTU/G+NzhuLM008WJyAO4Zrdy3FWR1wEv7IxBAixQGNNlqGrsxQCm6+qLaxLti2vqfQp3091OyZqejDHGJOS3y2ONMcakmQUKY4wxCVmgMMYYk5AFCmOMMQlZoDAZIW6gmZ+JyHveAC813iAtP5OowWa6EhEZI9sHu4mkTRaRuS0vtcM6zpY4Y6m3dT3GpJNdHms6nYj0xg3KMwJ3p/T13qyJuIFeVpPgkSddzG9xj89I1tm4J51OTnE9xqSNBQrTqbwHoU3FPU7hUFVdFDX7ZRF5jOZP+u3MsgVxg+zUt5o5Sar6xc60HmPaw5qeTGe7EPfsnstjggQA6p7mmdLdqZFmGhE5XUQWiRvb+20RGZ0g3wLcM3W+4s37mojMEje28iYR+Yu4Mc+jl/+huLGeq0TkOeKM4xCvyUjcmONviBunequ4Ma0PEJHJwDeB8bJ9zOZJCdbT4jjvMfWbICIfe+V8W0RiH85oTEIWKExn+znwmaq2ZZS59tgN97iL3+LGQi7GPSE49lHRJbgH0d2Me+jeMhH5Ku6x1OtwTyG90pv3SGQhETkNN1DO87gn436CG5s8Ia//4jXcGCgX4h5G+RZu1Lff4p4O+wHuoXCH4cYBj7ee43B3887HPTb9HtxTYu+NyToM91TY3+OemDwAN5Ji7AhwxrTImp5MpxGR3XCPcL+uEzbXD/f00He8bc8DvsA98fPBqHx9gWNV9cOocj4JvKOq50SlrQZeE5Exqvop7vHrL6vqD7wsr4gbfex7rZTrZtwAUMfr9scivBy1nc1AQOOPhBjtJtwTjC+MrMP77r9ZRH6n2x+P3wf4qroxGiLjcUzDPVZ+hzM6Y+KxMwrTmfb1/n7aCdvaEAkSAKq6HDdewSEx+VbHBIkC3C/52PHL38adBRzk9WUcwI5jbyccO1zcuMdfAf6hKTw7R9o2zntpJEh4ImNNJBw/3ZhoFihMZyr2/rZ3POi2iDcu9gZ27EeILUtv3DgZ99N8bOU63BgbQ3HjPWTF2UZrY3H3xo1rkupQo20Z531LTJ7OGLXO+Iw1PZnOFPkiHdJaRhF5yHu7J2687l/h2tfPwH1RnxSvMzxKvHGjB+BGuYsW+8t+i5c2CTeofaw1QBluAJvYbbQ2Fnc5btCrHTq922gjHTjOuzGx7IzCdKbZuJHMLo43U0S+FjW5P250tmNwndH3AJ+o6qG4Jpd443RHGyAih0etexiuuea9RAupahXwLrCXxh+/fI26cdY/ZMextxOWyVv3HOA7CTqT62nl174mP867MWlhZxSm06hqpYj8EnhARP6LG9GrDHfj3Vm4Ma+/6nW47gEco6oqIgq8q6oveasK0Pqv5o24Mch/gws4N+HOaCYnUdRrcB3XYeAZ3NCaw4CTgF+r6ufAH4Cp3gA003BjL5+QxLr/D3ez4UvixvOuwvUpzFXV53EdzKeJyOm4IXnXqOqaOOtJZpx3Y9LCzihMp1LVB4HTce3ok3HjAl+NG4/4Z162vYClqlrpTe8HvBO1mv1wY3Ynshw3jvIk3BdpBe5Ko9okyvg2cASuiesx4Dlc8FiJ1w+gqtOAHwOnAP/BdW5fksS63wQmAAW48ZqfwgWZyJf7/cB03KW27+PGGY+3nunAucA4r3xX4sbA/lFrZTCmrWzgIrPTEZHzgPGqerk3/QjwX1X9jze9BhgZFUhil58MjFHVcZ1TYmP8zc4ozM5oP1wfQMQBkWkRGQRUtRQkjDHpZ2cUxnfsjMKY9LJAYYwxJiFrejLGGJPQTnt5bL9+/bSkpCTTxTDGmC5l3rx5G1W1fzrXudMGipKSEubOtQG9jDGmLURkebrXaU1PxhhjErJAYYwxJiELFMYYYxKyQGGMMSYhCxTGGGMSskBhjDEmIQsUxhhjEvJdoFiyfhtXPDGfZRurMl0UY4zxhZ32hrv2Ov+vcyjbVseysipe/OnXM10cY4zp8nx3RlG2rQ6AtVtrMlwSY4zxB98FiojcrGCmi2CMMb7g20CRl+3bqhljTKfy7bdpXradURhjTDr4NlDkWqAwxpi08G2gyMvybdWMMaZT+e7b9LYzxwKwS6/8DJfEGGP8wXeBYv9Fd/JQ9p3k1ZdnuijGGOMLvrvhbuCGN9kzuJS5DWWZLooxxviC784oGnL7AJBvZxTGGJMWvgsUoby+ABSELFAYY0w6+DBQuDOKwtCWzBbEGGN8wneBIuwFivxQRYZLYowx/uC7QKG5RQDkhSszXBJjjPEH/wWKvEigqM5wSYwxxh98FyhyCnsBkN2wLbMFMcYYn/BdoOjbpx8AWQ2VhBrDGS6NMcZ0fb4LFDmFvQHoQTUbvEGMjDHGtJ/vAgU5BQAUUEdNQ2OGC2OMMV2f/wJFtgsU+VJHrQUKY4xJmX8DBRYojDEmHZIKFCIyWkReE5FqEVkjIjeJSNIjA4lIQETmiYiKyMntL24SopqeahusM9sYY1LV6tNjRaQ38CqwEDgNGAHcgQsy1yW5ne8Bu7SzjG2T5cahyJd6ausbOmWTxhjjZ8mcUVwO5ANnqOoMVX0QuBH4uYgUtbawF2h+D/w6pZImKxCgXnIBaKi1m+6MMSZVyQSKicArqhr98KQpuOAxPonlfwv8D3it7cVrn/pAHgANtVWdtUljjPGtZALFKGBRdIKqrgCqvXktEpGxwMXA1e0tYHuEAu6MorHeAoUxxqQqmUDRG9gSJ73cm5fIPcB9qrq0jeVKSWMgB4BQnd1wZ4wxqUp2KFSNkyYtpLuZIucCewGnJFsYEbkUuBRg2LBhyS62g0igoLGm3eswxhjjJHNGUQ70ipNeTPwzDUQkG7gNuBUIiEgvINLxXSgiPeMtp6oPq+o4VR3Xv3//JIoWXyRQaEN9u9dhjDHGSSZQLCKmL0JEhgKFxPRdRCkEdgXuxAWacuAjb94U4IP2FDZZYa+PQkO1HbkZY4zpFpJpenoJ+IWI9FTVyLO7zwFqgFktLFMJHBWTNgh4EvgV8Ho7ypq0cKTpKWR9FMYYk6pkAsWDwE+AqSJyKzAcmATcGX3JrIgsBWap6iWqGgJmRq9EREq8t5+o6pzUi94yDUb6KKzpyRhjUtVqoFDVchE5BrgXeA7XL3EXLljErivpx3p0pHDQNT1hTU/GGJOypK56UtWFwNGt5ClpZX4p7kqpDhc5oxA7ozDGmJT57+mxbD+jEOujMMaYlPkyUGB9FMYYkza+DhQStkBhjDGp8mWgkGC2+xu2x4wbY0yqfBko8AKFNoYyXBBjjOn6fBkoAkF3MZeELVAYY0yqfBkoIk1PWNOTMcakzJ+BIivSR2FnFMYYkypfBopApDNbGzNcEmOM6fr8HSjsjMIYY1Lmy0Ah3n0UAeujMMaYlPkyUASzI01PdkZhjDGp8mWg2N70ZH0UxhiTKn8GCu+qp6CdURhjTMp8GSiCXqAIWKAwxpiU+TRQeJ3ZFiiMMSZlPg0UkTMK66MwxphU+TRQuDMK66MwxpjU+TNQZHuBAgsUxhiTKn8GiqarnsI0hjXDpTHGmK7Nl4GCgAsUWRKioTGc4cIYY0zX5tNA4cajyKbRAoUxxqTIn4HCG7goi0YaGq3pyRhjUuHPQOE1PQVpJGRnFMYYkxJ/BgrvWU/ZNFJvgcIYY1Liz0AR2N70FLKmJ2OMSYm/A4VYZ7YxxqTKn4HCa3qyzmxjjEmdPwNFIDpQ2BmFMcakwqeBIghANiFCYQsUxhiTiqQChYiMFpHXRKRaRNaIyE0iEmxlmX1E5GUvf52IrBCRv4rI4PQUPYFg5PLYMPUha3oyxphUZLWWQUR6A68CC4HTgBHAHbggc12CRYuBZcCjwBpgd+AG4CAROVi1Ax/tGth+eaydURhjTGpaDRTA5UA+cIaqVgAzRKQImCQif/TSdqCq7wDvRCXNFJFVwHRgLDA/taIn0NSZbc96MsaYVCXT9DQReCUmIEzBBY/xbdzeJu9vThuXa5tAkDBCUJSGkA1eZIwxqUgmUIwCFkUnqOoKoNqbl5CIBEQkR0T2Am4B3gfea0dZ2ySM60IJheo7elPGGONryQSK3sCWOOnl3rzWvAjU4YJNH+BkVe3w9qBGca1q4YaGjt6UMcb4WrKXx8a7dEhaSI/1Y+BQ4NtAD+AlEcmLl1FELhWRuSIyt6ysLMmixRf2AoWdURhjTGqSCRTlQK846cXEP9NoRlWXqOocVX0cOB44ADi/hbwPq+o4VR3Xv3//JIrWsrB39a42Wh+FMcakIplAsYiYvggRGQoUEtN30RpVXQ5sBoa3Zbn2aAoUYRs32xhjUpFMoHgJOF5EekalnQPUALPasjGvQ7sv7v6KDrX9jML6KIwxJhXJ3EfxIPATYKqI3Io7G5gE3Bl9yayILAVmqeol3vTtQAiYg2ui2hu4BvgCd3lth1ILFMYYkxatBgpVLReRY4B7gedwX/p34YJF7LqiH+sxF9eRfSmQB6wA/g3crKpVqRa8NdvPKKzpyRhjUpHMGQWquhA4upU8JTHTU+iEM4eWqHfVkwUKY4xJjT+fHkvUfRTWmW2MMSnxbaCI9FFgZxTGGJMS/waKgHVmG2NMOvg3UHhNT8+8X0rZtroMl8YYY7ouHwcKd0YRJMx9byzNcGmMMabr8m+gCLgzilxpoC5kY1IYY0x7+TZQIK5qj+fczMLVWzJbFmOM6cJ8Gygk6v3i1WW888XGjJXFGGO6Mt8GigDbnxpbRDXvfrEpQW5jjDEt8W+g0O2BoliqEJEEuY0xxrTEt4FCNPqMogqLE8YY0z6+DRREPbqjWKqYbU1PxhjTLj4OFNvPKAqpZc6yzU3Tj/xvGV+79XXWbq1ptsjWmgZUkxnd1Rhjug/fBop6spveF4i7MzsSBG58biGrymv406tLqG1wAeX90s3sd+N0bnxuYbP1bKtt4NaXF3H+X97lsXeXWyAxxnQ7ST1mvCuqC+Q1vS+gFoDv/P097jnvgKb0Ke+vZMr7K7lqwkg+XbMVgMnvlLJ43TYCAXjkokP448uLeezd5QC888Umbn1pEZePH877peX07ZHDhYeVMG95ORcdXsLMzzfQ0Kgcv8+gTqypMcZ0LN8Gilq2B4pB4pqd3lqykf1vmrFD3jtmfN5sevaXrj9j1udlfLRqS7N5lXUhbp++Pf/U+asBuOn57Wcis689mpWbazhk9z6pVcIYY3YCvm16GjJ8dNP7y7Je4OuBj9u8ju8/OpePV21t83KH3/I6Zz80m3/PW8XWGnt6rTGma/NtoOg18fpm04/l3MKxgXmdsu1IN8ZVT3/ElVM+6JRtGmNMR5GdtXN23LhxOnfu3JTWsXbmXxk886pmaaXhgbwb3psKCmkgSB+2sYkigoTZVcpYFB5GFXls1GLWaW8qKaCaXKo1jypyqSUHbWN8Pe+QYVzytd0p3VjFoOI8xuxSnFK9jDGmJSIyT1XHpXWdfg4Uq1ev5MMHv8tJwffSVCqnSnOpJpcy7c1i3ZV12ofV2o/lOpCl4V1YSx+aP22qudJbTkpreYwxJqIjAoVvO7MBhgzZla82XMnvGzayR2A1v5k4kj+8tIjBspkeVJNDiC30oC8VANSRTYmso55s+slW9ulZzZCCRtZu2EiB1FFAHQVSR6HUUUgd/aWC0SzfYbuVmseH4REs0BJWaz/+1XgkteQ2zb/71c+58tiRnbYfjDEmFb4+owA45o6ZfFFWBbhf8g/N+oJttSGmvL+SjZXu/or7zj+QK56YD8BJYwfz53MPoKKmgd6FOVTUNjB20vSm9QUIk08dBdSyq2xkz8Aq+rOVobKB3QPr2EdK6SG1zcrwZXgQvwp9j3fDo5ulv3H1kezerzDlOhpjTISdUbRDbBy8bPwIAMbv1Z9LH53LzWfsywljBvOn13rw+fpKjhk1gGBA6F2YA0BRXjZ/v2gc353sglaYAFXkU0U+ZdqbDxr3jN0iu8s6Jgbe48dZ08iXeoYH1jEl53d8FB7Os42H81zjYWygN0fdPpPjRg/kgQsOIhiwh1EZY3ZOvj+jOOeh2U2P74jtG1DVpqfKbqmu56NVW/n6Hv0IxPnSfmXBOt5ZupErjtqDv769jIff/LLZfJHmQen6k0dTXl3PsjVl/Lnkf1S+cTdFUg3AsvBAftzwY/pJBTPD+zGoKJ9Jp+7DCWPsRj1jTGqsM7sdVm6u5sbnFnDFUXtwwLDeaSgZVNWFuH36Yr5xwC5Mnb+aye+UcsnXdmeXXvn8+fUlTP3B4Qzv36PZMtNmLyDrnT9xyranmqVfXn8lL4cPAayT2xiTOgsUO6GGxjAfrdzCfkN7kR0MNDtLieed/81k5PRv009cB/q88J58s/5GwAKFMSZ1HREofHvDXWfJDgYYV9KH7KDbla0NkHT4V4/kJ4P/ycuNBwNwUGAJFwTdY0XeL92caFFjjMkICxQZ8PilX+fo61+mrHgsAD/PepreVHDWg7MzXDJjjNmRBYoMCASEnOws+v90FvN1JH2kkkuyXgJg+aaqDJfOGGOas0CRSYEAd/MtAH6U9V9+mfUkP3vqw8yWyRhjYiQVKERktIi8JiLVIrJGRG4SkWAryxwsIo+IyFJvucUicoOI5CVarrv5JDiayaHjAPhe8EUWrViX4RIZY0xzrQYKEekNvAoocBpwE3AVcGMri54DjABuBU4E7gN+DvwzhfL6zs8mjGRS6EJqNIdsaeTnWU9z43MLaAzvnFejGWO6n2TuzL4cyAfOUNUKYIaIFAGTROSPXlo8t6pqWdT0TBGpBR4Skd1UdceHJHVD3z50N44cOYBzb7+OaTk3cGFwOse/cwxfHdGPY0cPzHTxjDEmqaanicArMQFhCi54jG9poZggEREZnGFA0iX0ORFhWN8CDjp8Aq/lH0e2NPJEzu/56aNvsXZrTaaLZ4wxSQWKUcCi6ARVXQFUe/Pa4nAgDCxu43K+d/0po5nwo3sBGCTlXBB8lcNufj3DpTLGmOQCRW9gS5z0cm9eUkRkEPBr4LGWmqtE5FIRmSsic8vK4p2Q+FyPAXw8/HsAXJv9JM/l/IrLbnmISya/T9j6LIwxGZLs5bHxvqWkhfQdM4rkAP8CKoGftbgR1YdVdZyqjuvfv3+SRfOXggm/ZqsWALBvoJTf1vyB1xZt4PMN2zJcMmNMd5VMoCgHesVJLyb+mUYz4p5p8SiwD3Ciqpa3oXzdzh6D+9DzrAeapnvjAkSwlUeDGGNMR0kmUCwipi9CRIYChcT0XbTgLtxltaepajL5u73AmNN5InQ0AGUUI4QJWdOTMSZDkgkULwHHi0jPqLRzgBpgVqIFReRa4MfABar6drtL2Q2Nuvg+yrSIIbKZA2QpSzdUZrpIxphuKplA8SBQB0wVkWNF5FJgEnBndKe0dwf236Kmzwf+gGt2Wi0ih0a9umcHRBscOGIIZUMnAnBl1r/58ZPzM1wiY0x31Wqg8PoUjgGCwHO4O7LvAm6IyZrl5Yk4zvt7ETA75mUDLyRh5Dd+RaXmcUTwE8bKl7zw8dpMF8kY0w0lNWa2qi4Ejm4lT0nM9EW4IGHaKatvCTPD+3FycA7P5v6Gu//1AYx9JNPFMsZ0M/b02J3cs42HN72/MmtqBktijOmuLFDs5KaHD850EYwx3ZwFip1cQGBxeNem6beWdMM71o0xGWWBYic39Ydf5S8j7mmaXvTZpxksjTGmO7JAsZPbf2gvbr/waNYNmQDAijn/RdVuvjPGdB4LFF1E7p5HAbB/YClT56/OcGmMMd2JBYouovfIwwDYX5byygIbLtUY03ksUHQVA8cAMCKwlh6Lnubxd22AQGNM57BA0VVk5dAYzAPgiqz/ct1/rFPbGNM5LFB0ISuPd4/SKpKqDJfEGNOdWKDoQnrsfQwA/aWCHwSftaufjDGdwgJFF9KvZz4N3uO5fpk9hYqaUIZLZIzpDixQdDH1J97d9H7+Chss0BjT8SxQdDGFB53X9P6yye9ksCTGmO7CAkVXE9z+ZPgHsu/OXDmMMd2GBYouSBEA9gqszHBJjDHdgQWKrujb0wCo1ywq66xD2xjTsSxQdEHSfxQAPaSWDRW1GS6NMcbvLFB0Rbk9ACikhrJtdRkujDHG7yxQdEXZhQAUSh3rtlZnuDDGGL+zQNEVBQLUB/IBeOvTZRkujDHG7yxQdFFZEgbg0NIHMlwSY4zfWaDoogKNrm/izMYXqbIrn4wxHcgCRVd12v1NbzdYh7YxpgNZoOiqxpwBQL0GWW8d2saYDmSBoqvKzqcqUESONPLp519kujTGGB+zQNGFhXoMBmDtqi8zXBJjjJ9ZoOjCwj1doKjeUGqDGBljOowFii4sPGAfAEbUfMwd0z/PcGmMMX5lgaILk92+CsDesoJ731ia4dIYY/wqqUAhIqNF5DURqRaRNSJyk4gEW1kmR0RuE5G3RKRGRKxtJM0Kh+wFwKjACgKEM1waY4xftRooRKQ38CqgwGnATcBVwI2tLFoAfA+oBmwotg6Q27eErVl96SvbeKnnH2DbukwXyRjjQ8mcUVwO5ANnqOoMVX0QFyR+LiJFLS2kqluAPqp6PDAtHYU1MYJZVO57IQB7NSyEKednuEDGGD9KJlBMBF5R1YqotCm44DE+0YJql+J0vL7Dt79fPS9z5TDG+FYygWIUsCg6QVVX4JqURnVEoUzysnv0y3QRjDE+l0yg6A1siZNe7s1LGxG5VETmisjcsrKydK7atwp7WaAwxnSsZC+PjdeEJC2kt5uqPqyq41R1XP/+/dO5at8qLLb9ZIzpWMkEinKgV5z0YuKfaZjOVDgg0yUwxvhcMoFiETF9ESIyFCgkpu/CZEBOQaZLYIzxuWQCxUvA8SLSMyrtHKAGmNUhpTLt1hi2C82MMemVTKB4EKgDporIsSJyKTAJuDP6klkRWSoif4teUEQmisiZwP7e9Jnea7d0VcAAE34LwIfhEawqt7EpjDHpldVaBlUtF5FjgHuB53D9EnfhgkXsumIf6/EAEB0Unvb+XgxMbnNpTXzD3e0s2YTYVFXPbn0LM1wgY4yftBooAFR1IXB0K3lKkkkzHSCYC0AOITbW2vjZxpj0sqfH+kGee5LKnoHVVFTXZ7gwxhi/sUDhBz0GNb3tv/TpBBmNMabtLFD4QWD7x3jopzfAmg8yWBhjjN9YoPCJpUNO3T7x7E8yVxBjjO9YoPCJgrGnN70PhRoyVxBjjO9YoPCJfgMHN71fWt6YwZIYY/zGAoVP5Awe0/Q+v2ELoYeOhkUvZLBExhi/sEDhF3lF1Ox+PAC7BTaQtXaejXhnjEkLCxQ+kn/Y9zJdBGOMD1mg8JMBNuCgMSb9LFD4Sa9hmS6BMcaHLFD4zJcDT2g2XReyK6CMMamxQOEzhaf9sdn05ip79pMxJjUWKHxm4JDmQ30seHNqhkpijPELCxQ+d+y8H1K/dUP8mUtfhYo1nVsgY0yXY4HCj77z32aTpX8+kU2Vdc3zfDkLHv8meu+4TiyYMaYrskDhR7uPp2bExKbJkY1LeOmW89hww25Mu++XLF6+Gpa/A4DUV1mHtzEmIVHVTJchrnHjxuncuXMzXYwuTVWZf+tEDqqdnTDf/EP/xAHHX4iIdFLJjDEdRUTmqWpamwrsjMLHRISDfvIEGwP9EuY78N2fMntJC/0YxphuzwKF3xX0ofCqD3kwdHLCbG88+w82VNQSDis761mmMSYzsjJdANPx8gt70vf0W/jh1OFkEWYDvZiS87tmeX5d+Xt+eks5C/scS70GeOXKI8jLDgKwcnM1RXnZFBdkt23Dm7+EL16HAy+CoB1qxnRV1kfRzbz4yVp++M/5jJZS7ur1NP1qS+mr5Tvkq9Q8HgqdzMLdvsVrX9awe79C3rj6yLZt7OZhULcVJt4GX7kUwmGY9wjsPh767ZGeChljmumIPgoLFN3Qhopa+vfMdZ3XqjT858dkf/RYi/m/CA9mI8UAPKTfYN9hA1jbYx/IyuX3Z4wlO9hCC+YktwyjT4OzH4UPHof/XgGAXl+OBKzl05h0s0BhOkx9KMwrH3zB1GlPcVTgQ74VfJWgtH5sPBI6nrW7HMcx448hOPtP9C+bw/u7X8amNcu4bOvdTfka/281Dc98n7ylLwKw6tBJ7HrCzzqqOsZ0WxYoTIfbWtPAG4s2cPLYwSxeuZ5//OUOTgrM4dDAQnIllN6N3bAF7JJcY9LKAoXJqNcWrGHarLkcs2cRu7x1DYcEFqe0vs8mPsWogipk1EmQnZemUhrTvVmgMDuFrTUNHPTbGRwwrBc3njqGvrqRee/N5qWFZWyrquTU4GwGUs4BeWsJlhxG7pLEY3eXhgeyZv8fU7apnI1rVzBhaCPDvn4B7HEMVG1yZx1bV8Lg/TqphinYuBRWz4Mx37QrvUxGWKAwO41ttQ3kZQd36MhWVSpqQxTnR11Ku3kZVW/ey2dbhP0G5pA9576ktvFlwViGV3/cNB0iyIKv/JHR+x3Kmm0hqrZtZVT/XAJDD4ZAsI0VWAf/uhDGfReGHAB5xdBzYNvWEYfesTeybQ0cOwm+1s4+mHAYPnwchh/Z+YNRbVwCuT2h56D2r+OjKbBkBpx+P2Tlbk8v/R8U9of+I1Mvp2mRBQrjG29+uoxZ8z+l1+fP0JNq+sg2CqnlkMAiekpNm9ZVqXl8WnAwfXfbl5ysAHlaQ1FWI8uzhzN8wuXk5OSAKtRXwpLpsNtXCT9wOIGazU3r0Pw+yC+XwYJp8P7f4Iy/QNFg9Lkrqfz8LSrP+w+DhwxtvmFVWDYLhhwIeUXw5m3wurs/ZWPPvel31bvt2zkfTYFplxHOyiNw3fr2raM9asrhztEQboSrP4f8Xq0v8/K17inE33vVBVvYfrXbqffCgd9277etgzv2cu9/s8nOtjpQRwQK+7RMRhwxZneOGLM7cAqbq+pZtLaCBWsqWJcbZM6iFRSUvkpNCMb3WMnwqg+p1DyqyOegwOf0k4qm9VRpLj2klkNr3oJFbzXbxiiAudezUYuaLQM7PpJAajaz6M/fZNTmVwHY8tRlFJxyCznzHqEn0PPhMVR+Zzo9hn/FLbBtHbxzD8y+l0299qXv5S82BQmAfts+4/2Hr+Cgi+8ikJ3jEsNhWDMfBu4DEoAXr4YlM6gZdBCN/fehx4RrQYTQ2k/JAgKhWj5dXsaY3fqnvL+TsXDuG4xuqAagvvRdcvY+oZUlgHfvB0A/eQY5+BJobGia9ewbb3P4iNPpV9yTbQteoaeX/tar0/j68Welu/imAyV1RiEio4F7gMOALcBfgRtVNeFjR0WkGLgbOB33v/k88BNV3dTaNu2MwkRTVarqG1mweit/e3sZMxeuYsSAYpZuqODQwEJODMxhr8BKDgwsZZP2pK9sy3SRAWggm8YrP6WhfDWNT19Mr+rlAGza5Wj6rn69Wd6Ph5zFvuffjNy+/WbE5/pczMkXXk0duazcXMXQIYPJy81FVamrKKOm9H3yR00gLzdn+4rqtkGoHgr6wLJZrCjYh4IeRfQr9PKIwNLX0PcehoO/h+xxLJUv30SPOXc2reKtYT/g69+9pWlaVVlVXsOum/6H5PSA6o2w68FNZwkfjbicwPhfMKZ6DjLl/Kbl3sw9kiN+/jjcvGtT2jONR/DN8y+DoYcggSwaJp8KZYu4IjiJn3732+wzpDj1Hd+NZaTpSUR6AwuAhcCtwAjgDuAuVb2ulWVfBvYCrgbC3vLrVfXrrRXMAoVJRjjsjt/y6npe/HQdC1Zv5bARffl8/TZmfLwS2byU3LwC9imqobZyK3sHVrKXLOeDul1YXziKr4wcTM78v3NiwDUTVWgBRVLdbBt3ZH2fifXTGR1Y3un1i2dj4Z70q1rSNB2vzC2pJYcsDZEl4aa0z7SEvaV0h7yrj/4zg0aMhdoKPnvlr4zZ8GzCda/WvmzSIsYGljVL33LCffR6+YqkyvfP4ks5/0c3Idn5cTYw3wW/3iVJrau7ylSguBa4BthNVSu8tGuAScCgSFqc5Q4D3gHGq+qbXtohwBxggqq+mmi7FihMZ6oLNbJuay01DY3sOaAnL3+ymn7ZdezXL0DegN1ZtHYrD/zlQc7Km0PFtm2s0z5sHfgVTilR8iqWUbZ8Af+p2Z8fHD2KQV+7kIVvPMHyFcuZsOoesth+4j0n51Dya9czNrCMheHdyA80MlTW83LhaZxc+Ywri2ZxTcFN/KnmV5naHR3ivfAohhXUM6j2y1bzfpJ3IHWBAqpDQlGwgT5azrBadzl2GGG99iYrIISyerAlnMdnjUMYMqA/VG9mWP1ScsK1zGY/evYZQH5uNus2lJFdV05xboAehQXUNTRSkd2PXfoWs2nzJg7cOp0VPQ+kIm8wK9auZ1ifQvr0Kob83tTn9KK+rpastfMpl2JyB44kNwiVNXXk5ubQIDnUNjTSuyCboAhV1TXkBsNsbchiUK98kCAVm9ZRFKwjlNWDcHY+2Y011DeEILeIxqwCGsPQu0cu1XUN5ISq2GO/w8kqOaxd+zlTgeJNYI2qnhuVNgxYDpyqqs+1sNxNwKWqOigm/UtgmqpelWi7FijMzmpzVT0FOcGmhyYmoqqsXLeBD79YxfgDx1JckI2Gw3z06ScUDihhz4FFrvM4mMXaJR+wfM1aBu06gpIRe0HVJpbNn870uZ/R0GckZxUtpKImhK6Zz9DaJXwy+JssKlc0q4BDa2ayV92nbKQXm4P9GNm4FIA3c8czJLyWPRo+p54sPpK9GRJeQ32wB+tKTqVu+fuMC31ImRaze2A9OmhfKs54krqHJzAgtHaH+mwJ9qGOHAY2rmtKawjkUtcoZNNIrjQQkhyCZ/6FFZ+9T/jjp9k9sJ53guPo+62/sVu/nmy5/ziK69eRH64EYCnDeLLP5fxms78CYypm9DmPCT95sF3LZipQbADuV9VJMelVwCRVva2F5f4FDFDVI2PSXwBQ1ZMSbdcChTGdQ1Xdc7/CYdBw0xVJ9ds2sXZLFVk5+Qzp37f5s7lCdXy5vJRhJXuSFQyAusfTl21YQ//evZDcHm4dtTWsWF9Gya67unyJhOpYsexzVi1fwtYt5YQaGqisqaaiJkSoMUR50Wj27w85QShb/SXb6MmIXQdS+sUietWvo1fPQgqK+1NdVUldQyOfrizjkL41VIbzWFRWy0aKGdy7iDHZqwhWrGJhXT927VtEZYOwe48QxYEaykM5rK4S+mbVk0WIBg0Q1Abqw5BdV87GUCEDivOoDUFVSOgRbCTUUE9dqJEBPXNBAtQ1hKisrUcli6K8IFmEqc/uQZX0IKuhkmCoipzsbAg3EkYIhKoRXL1CKmxqyGHPw05lvwkXtOvzzFSgaAB+oap3x6SvAh5V1bg/A0RkBlClqqfHpD8ODFfVw+MscylwKcCwYcMOWr5852gTNsaYztIYVgJCu0eczOQId/GiibSQ3u7lVPVhVR2nquP69++cSwKNMWZnEgzITjcscTKBohzoFSe9GHepbFuX69XKcsYYY3YiyQSKRXj3LkWIyFCg0JuX9HKeUa0sZ4wxZieSTKB4CTheRHpGpZ0D1ACzWllukIh8LZIgIuOA4d48Y4wxXUAygeJBoA6YKiLHeh3Ok4A7o++hEJGlIvK3yLSqzgZeAR4VkTNE5HTgn8Dbrd1DYYwxZufRaqBQ1XLgGCAIPAfcCNwF3BCTNcvLE+1c3FnH34FHgXnAN1IrsjHGmM6U1EMBVXUhcHQreUripG0BLvZexhhjuiAb3d4YY0xCO+14FCJShntMSHv0AzamsThdidW9e7K6d0/x6r6bqqb1RrSdNlCkQkTmpvvOxK7C6m51726s7h1fd2t6MsYYk5AFCmOMMQn5NVA8nOkCZJDVvXuyundPnVJ3X/ZRGGOMSR+/nlEYY4xJE98EChEZLSKviUi1iKwRkZtEpPUhyHZiInKWiDwrIqtFpFJE5onIeTF5RER+JSIrRaRGRN4Ukf3jrKtL7x8R2cXbByoiPaLSfVl/EckSkf8TkSUiUiciq0Tkrpg8fq37uSIy3/u8V4vIoyIyJCZPl6+7iOwhIg+JyEci0igiM+PkSVs9k11XXOqNTNWVX0BvYA3wKjABuByoAn6X6bKlWK/ZwBPA2bg742/HjeXx46g81+Ie0Pgj4FjgRdx11YP8tH+8/bDOq38Pv9cfeMwr82XAeOAC4A8xeXxXd+BU7zO+F/fooAuAUmA+EPBT3YHTgJXA08BnwMw4edJWz2TW1WJZM72z0rTDr8WNf1EUlXYNUB2d1tVeQL84aU8Ay7z3ecBW4Pqo+YVAWfRB0tX3D/B1YDNwNVGBwq/1B04AGoDRCfL4te5TgHkxaZHgsbef6k7zwPdMbKBIZz2TXVdLL780PU0EXtGop9niDrh83K+xLklV491t+gEwwHt/OFAE/CtqmSrcwxsnRi3TZfePd/p8D3ATO96B6tf6fxd4Xd0z1lri17pn477Qom3x/kaGffNF3VU13EqWdNYz2XXF5ZdAscNgSKq6AhdR4w2e1JUdDkS+QEYBjcCSmDyf0bzeXXn/XI77NXRfnHl+rf9XgM9F5F4RqfDanafGtNP7te5/B74uIt8RkSIRGQn8DngjKnD6te6x0lnPZNcVl18CRW/iD69a7s3zBRE5BteuGfnS7A1UqmpjTNZyoEBEcqLybYmzyp16/4hIX+C3wM9VtSFOFr/WfxBwEbA/7lH9FwMHAdNEmgZT9mXdVfUFXN0fxp1ZLMYNX3BGVDZf1j2OdNYz2XXFldRjxruIeDeESAvpXY6IlOD6J/6rqpOjZrVU79h5XXH//B6Yo6ovJsjjx/qL9zpNVTcBiMha3NguRwOvefl8V3cROQo3WNqfcCNhDsQNlDZNRI6N+qLzXd1bkM56JruuHfglUJQDveKkFxM/0nYpItIH90+zAncVSEQ50FNEgjG/FHoB1VG/wrvc/hGRfXBt9UeISC8vucD7Wywijfi3/uXAl5Eg4XkbqAdG4wKFX+t+B/Csqv4ykiAiH+KaVk4DpuLfusdKZz2TXVdcfml6WkRMO5uIDMX16i+Ku0QXISIFwPNADnCS1wEVsQh3Wr5HzGKxbZZdcf/sievYnI07yMvZ3uS2CtfB7df6f9ZCugCRDlC/1n0U8GF0gqouxl3WOcJL8mvdY6WznsmuKy6/BIqXgONFpGdU2jm4g2tWZoqUOhHJwl1jvScwUVU3xGR5B6gAzopapgA4BbdPIrri/nkbOCrmdas370TgNvxb/+eBsSLSLyrtCFzg/Mib9mvdlwMHRieIyN64K3hKvSS/1j1WOuuZ7Lriy/S1xGm6Hrk3sBaYgbuR5FKgkp3kxpoU6vUwru3wJ8ChMa9c3X4NdTVwBe4GpRdwl5EO9Nv+wXVyNt1H4df64y5jXIE7mzoFOB93Y9aMmHx+rPtPcWdNd3jl/RauQ3sZUOinuuOaUs/0XrOBBVHTBemuZzLrarGsmd5Zadzpo4HXcVF0Le5qmWCmy5VinUq9L8Z4rxIvjwC/xjXH1ABvAQf4cf8QP1D4sv64JoIXcXfYlgOTgd4xeXxXd69OPwA+9uq+GngKGO63ugMlnfn/ney64r3s6bHGGGMS8ksfhTHGmA5igcIYY0xCFiiMMcYkZIHCGGNMQhYojDHGJGSBwhhjTEIWKIyvicgkccOnxntd0Poa0l4eFZEfdfZ2jUmFXx4KaEwiW3GjxsVa2tkFMaYrskBhuoOQqr6b6UIY01VZ05Pp1kSkxGsOOl9EHhORbSKyQURuiJP3aBGZIyK1IrJeRO4XkR4xefqKyEMistbLt1hEroxZVVBE/iAiZd627hOR3I6spzGpsDMK0y14T+JtRlVDUZO34Z7aeibuSa03iMhGVb3PW3408DLuwWvfBIYCtwDD8Zq1RCQfmIkb0/xG3OOb92DHRztfhXsuzwXAWOBm3FNT/5h6TY1JP3vWk/E1EZkE7HB24Nnd+7sM92TW46KW+wvuceZDVTUsIlNww5GOUm/gFxE5G/fAusNVdbaIXAY8AByoqh+2UB4F3lLVI6LS/gMMUtVD211RYzqQNT2Z7mArcHCc15qoPNNilpkKDAF29aYPAaZp89HB/g2EgK9500cDH7QUJKJMj5leGLUdY3Y61vRkuoOQqs6NN0MkMmQwsYNCRaYH48aGGAysj86gqo0isgno4yX1xT3iuTVbYqbrgbwkljMmI+yMwhhnQAvTa6P+NssjIkFccNjsJW3CBRRjfMUChTHON2Kmz8AFh1Xe9BzgG15wiM6ThRu2FeA14AARGduRBTWms1nTk+kOskQkXkfxyqj3+4jIQ7h+hyOAS4CfqmrYm/874APgPyLyAK5P4VbgFVWd7eV5FDfM5HSvE30xrsN8pKr+X5rrZEynsUBhuoNi3JjEsX4DPO69vwY4GRcoanFDSd4byaiqC0RkIvAHXEd3BfCkt1wkT62IHI27bPYm3NjXpcD96a2OMZ3LLo813ZqIlOAujz1FVZ/PcHGM2SlZH4UxxpiELFAYY4xJyJqejDHGJGRnFMYYYxKyQGGMMSYhCxTGGGMSskBhjDEmIQsUxhhjErJAYYwxJqH/B83YNPRZvz2VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.plot(hist['val_rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error, optimal settings\\n$C_m$ prediction', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2, label='Training RMSE')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation RMSE')\n",
    "plt.title('Root Mean Squared Error\\nAeroCNN-I, optimal settings\\n$C_m$ prediction', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"RMSE_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c76ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 8ms/step - loss: 1.3938e-04 - rmse: 0.0034\n"
     ]
    }
   ],
   "source": [
    "train_results = model.evaluate([x_time_train, x_coord_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b1d836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4089e-04 - rmse: 0.0037\n"
     ]
    }
   ],
   "source": [
    "val_results = model.evaluate([x_time_val, x_coord_val], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abc70d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4593e-04 - rmse: 0.0043\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate([x_time_test, x_coord_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "745feda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step\n",
      "7/7 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "decoded_train_ = model.predict([x_time_train, x_coord_train])\n",
    "decoded_val_ = model.predict([x_time_val, x_coord_val])\n",
    "decoded_test_ = model.predict([x_time_test, x_coord_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51faee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_index(y_total, y_partial):\n",
    "    return np.unique(np.where(np.isin(y_total, y_partial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e8e16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_absolute(y_pred, y_true):\n",
    "    return np.abs(y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aee7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize \n",
    "def denormalize(y):\n",
    "    return y*(np.max(cm)-np.min(cm))+np.min(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "946bb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_error(y_pred, y_real):\n",
    "    return np.sqrt(np.sum((y_pred - y_real)**2) / np.sum(y_real**2))\n",
    "\n",
    "def mape(y_pred, y_real):\n",
    "    return 100/len(y_real) * np.sum(np.abs((y_real-y_pred)/y_real))\n",
    "\n",
    "def smape(y_pred, y_real):\n",
    "    return 100*np.sum(np.abs(y_pred-y_real))/np.sum(y_real + y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb958632",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = define_index(y, y_train)\n",
    "index_val = define_index(y, y_val)\n",
    "index_test = define_index(y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007555383315804375\n",
      "0.285272643906697\n"
     ]
    }
   ],
   "source": [
    "l2_error_train = l2_error(decoded_train_, y_train)\n",
    "mape_train = smape(decoded_train_, y_train)\n",
    "print(l2_error_train)\n",
    "print(mape_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c63ffb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008152241550502428\n",
      "0.32105457641467094\n"
     ]
    }
   ],
   "source": [
    "l2_error_val = l2_error(decoded_val_, y_val)\n",
    "mape_val= smape(decoded_val_, y_val)\n",
    "print(l2_error_val)\n",
    "print(mape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3770434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008166531758332292\n",
      "0.26996062996809855\n"
     ]
    }
   ],
   "source": [
    "l2_error_test = l2_error(decoded_test_, y_test)\n",
    "mape_test= smape(decoded_test_, y_test)\n",
    "print(l2_error_test)\n",
    "print(mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "945ad132",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = denormalize(y_train)\n",
    "y_val = denormalize(y_val)\n",
    "y_test = denormalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93ca4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = denormalize(decoded_train_)\n",
    "decoded_val = denormalize(decoded_val_)\n",
    "decoded_test = denormalize(decoded_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55d01da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20230102\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "os.chdir(model_directory)\n",
    "model_name = \"20221230unsteady_AeroCNN1_Case15_val_\"+str(val_rate)+\"_test\"+str(test_rate)+ \"_\" + str(n_kernels)+\"kernels_\" + str(n_layers) +\"layers_\"+str(n_units)+\"units_CmPrediction.h5\"\n",
    "model.save(model_name, overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = error_absolute(decoded_train, y_train)\n",
    "error_val_abs = error_absolute(decoded_val, y_val)\n",
    "error_test_abs = error_absolute(decoded_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e21d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(x_time_train)):\n",
    "    l2_error_train_data = l2_error(decoded_train[i], y_train[i])\n",
    "    l2_error_train_list.append(l2_error_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "053a1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val_list = []\n",
    "for i in range(0, len(x_time_val)):\n",
    "    l2_error_val_data = l2_error(decoded_val[i], y_val[i])\n",
    "    l2_error_val_list.append(l2_error_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(x_time_test)):\n",
    "    l2_error_test_data = l2_error(decoded_test[i], y_test[i])\n",
    "    l2_error_test_list.append(l2_error_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e5afbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_train_list = []\n",
    "for i in range(0, len(x_time_train)):\n",
    "    mape_train_data = smape(decoded_train[i], y_train[i])\n",
    "    mape_train_list.append(mape_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fa71fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_val_list = []\n",
    "for i in range(0, len(x_time_val)):\n",
    "    mape_val_data = smape(decoded_val[i], y_val[i])\n",
    "    mape_val_list.append(mape_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2f0fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_test_list = []\n",
    "for i in range(0, len(x_time_test)):\n",
    "    mape_test_data = smape(decoded_test[i], y_test[i])\n",
    "    mape_test_list.append(mape_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f75a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plot(y_pred, y_real, dataset=\"train\"):\n",
    "    dictionary_name = {\"train\":\"training\", \"val\":\"validation\", \"test\":\"test\"}\n",
    "    dictionary_data = {\"train\":l2_error_train_list, \"val\":l2_error_val_list, \"test\":l2_error_test_list}\n",
    "    dictionary_error = {\"train\":l2_error_train, \"val\":l2_error_val, \"test\":l2_error_test}\n",
    "    plot_title = '$L_2$ error norm distribution - MLP, unsteady, '+ dictionary_name.get(dataset) +'.\\nValidation rate {0}, test rate {1}, {2} layers, {3} units ($C_m$)'.format(\n",
    "        val_rate, test_rate, n_layers, n_units)\n",
    "    plt.plot(np.linspace(1,y_real.shape[0],y_real.shape[0]),\n",
    "             dictionary_error.get(dataset)*np.ones(y_real.shape[0],), 'k', lw=2.5)\n",
    "    plt.scatter(np.linspace(1, y_real.shape[0], y_real.shape[0]), dictionary_data.get(dataset), c='b')\n",
    "    plt.xlabel('Index', fontsize=15)\n",
    "    plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "    plt.yscale('log')\n",
    "    plt.title(plot_title, fontsize=15)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd795141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_plot(decoded_train, y_train, dataset=\"train\")\n",
    "saveName = \"trainingErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d10cf447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_plot(decoded_val, y_val, dataset=\"val\")\n",
    "saveName = \"validationErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_plot(decoded_test, y_test, dataset=\"test\")\n",
    "saveName = \"testErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8978795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict([x_time, x_coord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "714cd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tTrain = x_time[index_train] + 10\n",
    "tVal = x_time[index_val] + 10\n",
    "tTest = x_time[index_test] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58d8635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9989935], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4a78a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007752121860396466\n"
     ]
    }
   ],
   "source": [
    "print(l2_error(predicted, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1d9be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each set of data in sorted order\n",
    "iTrain=[]\n",
    "iVal=[]\n",
    "iTest=[]\n",
    "for i, index in enumerate(index_train):\n",
    "    iTrain.append(y[index])\n",
    "for k , index in enumerate(index_val):\n",
    "    iVal.append(y[index])\n",
    "for j, index in enumerate(index_test):\n",
    "    iTest.append(y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ab1b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iTrain = np.array(iTrain)\n",
    "iVal = np.array(iVal)\n",
    "iTest = np.array(iTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d591456e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   ],\n",
       "       [0.001],\n",
       "       [0.002],\n",
       "       [0.003],\n",
       "       [0.004],\n",
       "       [0.005],\n",
       "       [0.006],\n",
       "       [0.007],\n",
       "       [0.008],\n",
       "       [0.009],\n",
       "       [0.01 ],\n",
       "       [0.011],\n",
       "       [0.012],\n",
       "       [0.013],\n",
       "       [0.014],\n",
       "       [0.015],\n",
       "       [0.016],\n",
       "       [0.017],\n",
       "       [0.018],\n",
       "       [0.019],\n",
       "       [0.02 ],\n",
       "       [0.021],\n",
       "       [0.022],\n",
       "       [0.023],\n",
       "       [0.024],\n",
       "       [0.025],\n",
       "       [0.026],\n",
       "       [0.027],\n",
       "       [0.028],\n",
       "       [0.029],\n",
       "       [0.03 ],\n",
       "       [0.031],\n",
       "       [0.032],\n",
       "       [0.033],\n",
       "       [0.034],\n",
       "       [0.035],\n",
       "       [0.036],\n",
       "       [0.037],\n",
       "       [0.038],\n",
       "       [0.039],\n",
       "       [0.04 ],\n",
       "       [0.041],\n",
       "       [0.042],\n",
       "       [0.043],\n",
       "       [0.044],\n",
       "       [0.045],\n",
       "       [0.046],\n",
       "       [0.047],\n",
       "       [0.048],\n",
       "       [0.049],\n",
       "       [0.05 ],\n",
       "       [0.051],\n",
       "       [0.052],\n",
       "       [0.053],\n",
       "       [0.054],\n",
       "       [0.055],\n",
       "       [0.056],\n",
       "       [0.057],\n",
       "       [0.058],\n",
       "       [0.059],\n",
       "       [0.06 ],\n",
       "       [0.061],\n",
       "       [0.062],\n",
       "       [0.063],\n",
       "       [0.064],\n",
       "       [0.065],\n",
       "       [0.066],\n",
       "       [0.067],\n",
       "       [0.068],\n",
       "       [0.069],\n",
       "       [0.07 ],\n",
       "       [0.071],\n",
       "       [0.072],\n",
       "       [0.073],\n",
       "       [0.074],\n",
       "       [0.075],\n",
       "       [0.076],\n",
       "       [0.077],\n",
       "       [0.078],\n",
       "       [0.079],\n",
       "       [0.08 ],\n",
       "       [0.081],\n",
       "       [0.082],\n",
       "       [0.083],\n",
       "       [0.084],\n",
       "       [0.085],\n",
       "       [0.086],\n",
       "       [0.087],\n",
       "       [0.088],\n",
       "       [0.089],\n",
       "       [0.09 ],\n",
       "       [0.091],\n",
       "       [0.092],\n",
       "       [0.093],\n",
       "       [0.094],\n",
       "       [0.095],\n",
       "       [0.096],\n",
       "       [0.097],\n",
       "       [0.098],\n",
       "       [0.099],\n",
       "       [0.1  ],\n",
       "       [0.101],\n",
       "       [0.102],\n",
       "       [0.103],\n",
       "       [0.104],\n",
       "       [0.105],\n",
       "       [0.106],\n",
       "       [0.107],\n",
       "       [0.108],\n",
       "       [0.109],\n",
       "       [0.11 ],\n",
       "       [0.111],\n",
       "       [0.112],\n",
       "       [0.113],\n",
       "       [0.114],\n",
       "       [0.115],\n",
       "       [0.116],\n",
       "       [0.117],\n",
       "       [0.118],\n",
       "       [0.119],\n",
       "       [0.12 ],\n",
       "       [0.121],\n",
       "       [0.122],\n",
       "       [0.123],\n",
       "       [0.124],\n",
       "       [0.125],\n",
       "       [0.126],\n",
       "       [0.127],\n",
       "       [0.128],\n",
       "       [0.129],\n",
       "       [0.13 ],\n",
       "       [0.131],\n",
       "       [0.132],\n",
       "       [0.133],\n",
       "       [0.134],\n",
       "       [0.135],\n",
       "       [0.136],\n",
       "       [0.137],\n",
       "       [0.138],\n",
       "       [0.139],\n",
       "       [0.14 ],\n",
       "       [0.141],\n",
       "       [0.142],\n",
       "       [0.143],\n",
       "       [0.144],\n",
       "       [0.145],\n",
       "       [0.146],\n",
       "       [0.147],\n",
       "       [0.148],\n",
       "       [0.149],\n",
       "       [0.15 ],\n",
       "       [0.151],\n",
       "       [0.152],\n",
       "       [0.153],\n",
       "       [0.154],\n",
       "       [0.155],\n",
       "       [0.156],\n",
       "       [0.157],\n",
       "       [0.158],\n",
       "       [0.159],\n",
       "       [0.16 ],\n",
       "       [0.161],\n",
       "       [0.162],\n",
       "       [0.163],\n",
       "       [0.164],\n",
       "       [0.165],\n",
       "       [0.166],\n",
       "       [0.167],\n",
       "       [0.168],\n",
       "       [0.169],\n",
       "       [0.17 ],\n",
       "       [0.171],\n",
       "       [0.172],\n",
       "       [0.173],\n",
       "       [0.174],\n",
       "       [0.175],\n",
       "       [0.176],\n",
       "       [0.177],\n",
       "       [0.178],\n",
       "       [0.179],\n",
       "       [0.18 ],\n",
       "       [0.181],\n",
       "       [0.182],\n",
       "       [0.183],\n",
       "       [0.184],\n",
       "       [0.185],\n",
       "       [0.186],\n",
       "       [0.187],\n",
       "       [0.188],\n",
       "       [0.189],\n",
       "       [0.19 ],\n",
       "       [0.191],\n",
       "       [0.192],\n",
       "       [0.193],\n",
       "       [0.194],\n",
       "       [0.195],\n",
       "       [0.196],\n",
       "       [0.197],\n",
       "       [0.198],\n",
       "       [0.199],\n",
       "       [0.2  ],\n",
       "       [0.201],\n",
       "       [0.202],\n",
       "       [0.203],\n",
       "       [0.204],\n",
       "       [0.205],\n",
       "       [0.206],\n",
       "       [0.207],\n",
       "       [0.208],\n",
       "       [0.209],\n",
       "       [0.21 ],\n",
       "       [0.211],\n",
       "       [0.212],\n",
       "       [0.213],\n",
       "       [0.214],\n",
       "       [0.215],\n",
       "       [0.216],\n",
       "       [0.217],\n",
       "       [0.218],\n",
       "       [0.219],\n",
       "       [0.22 ],\n",
       "       [0.221],\n",
       "       [0.222],\n",
       "       [0.223],\n",
       "       [0.224],\n",
       "       [0.225],\n",
       "       [0.226],\n",
       "       [0.227],\n",
       "       [0.228],\n",
       "       [0.229],\n",
       "       [0.23 ],\n",
       "       [0.231],\n",
       "       [0.232],\n",
       "       [0.233],\n",
       "       [0.234],\n",
       "       [0.235],\n",
       "       [0.236],\n",
       "       [0.237],\n",
       "       [0.238],\n",
       "       [0.239],\n",
       "       [0.24 ],\n",
       "       [0.241],\n",
       "       [0.242],\n",
       "       [0.243],\n",
       "       [0.244],\n",
       "       [0.245],\n",
       "       [0.246],\n",
       "       [0.247],\n",
       "       [0.248],\n",
       "       [0.249],\n",
       "       [0.25 ],\n",
       "       [0.251],\n",
       "       [0.252],\n",
       "       [0.253],\n",
       "       [0.254],\n",
       "       [0.255],\n",
       "       [0.256],\n",
       "       [0.257],\n",
       "       [0.258],\n",
       "       [0.259],\n",
       "       [0.26 ],\n",
       "       [0.261],\n",
       "       [0.262],\n",
       "       [0.263],\n",
       "       [0.264],\n",
       "       [0.265],\n",
       "       [0.266],\n",
       "       [0.267],\n",
       "       [0.268],\n",
       "       [0.269],\n",
       "       [0.27 ],\n",
       "       [0.271],\n",
       "       [0.272],\n",
       "       [0.273],\n",
       "       [0.274],\n",
       "       [0.275],\n",
       "       [0.276],\n",
       "       [0.277],\n",
       "       [0.278],\n",
       "       [0.279],\n",
       "       [0.28 ],\n",
       "       [0.281],\n",
       "       [0.282],\n",
       "       [0.283],\n",
       "       [0.284],\n",
       "       [0.285],\n",
       "       [0.286],\n",
       "       [0.287],\n",
       "       [0.288],\n",
       "       [0.289],\n",
       "       [0.29 ],\n",
       "       [0.291],\n",
       "       [0.292],\n",
       "       [0.293],\n",
       "       [0.294],\n",
       "       [0.295],\n",
       "       [0.296],\n",
       "       [0.297],\n",
       "       [0.298],\n",
       "       [0.299],\n",
       "       [0.3  ],\n",
       "       [0.301],\n",
       "       [0.302],\n",
       "       [0.303],\n",
       "       [0.304],\n",
       "       [0.305],\n",
       "       [0.306],\n",
       "       [0.307],\n",
       "       [0.308],\n",
       "       [0.309],\n",
       "       [0.31 ],\n",
       "       [0.311],\n",
       "       [0.312],\n",
       "       [0.313],\n",
       "       [0.314],\n",
       "       [0.315],\n",
       "       [0.316],\n",
       "       [0.317],\n",
       "       [0.318],\n",
       "       [0.319],\n",
       "       [0.32 ],\n",
       "       [0.321],\n",
       "       [0.322],\n",
       "       [0.323],\n",
       "       [0.324],\n",
       "       [0.325],\n",
       "       [0.326],\n",
       "       [0.327],\n",
       "       [0.328],\n",
       "       [0.329],\n",
       "       [0.33 ],\n",
       "       [0.331],\n",
       "       [0.332],\n",
       "       [0.333],\n",
       "       [0.334],\n",
       "       [0.335],\n",
       "       [0.336],\n",
       "       [0.337],\n",
       "       [0.338],\n",
       "       [0.339],\n",
       "       [0.34 ],\n",
       "       [0.341],\n",
       "       [0.342],\n",
       "       [0.343],\n",
       "       [0.344],\n",
       "       [0.345],\n",
       "       [0.346],\n",
       "       [0.347],\n",
       "       [0.348],\n",
       "       [0.349],\n",
       "       [0.35 ],\n",
       "       [0.351],\n",
       "       [0.352],\n",
       "       [0.353],\n",
       "       [0.354],\n",
       "       [0.355],\n",
       "       [0.356],\n",
       "       [0.357],\n",
       "       [0.358],\n",
       "       [0.359],\n",
       "       [0.36 ],\n",
       "       [0.361],\n",
       "       [0.362],\n",
       "       [0.363],\n",
       "       [0.364],\n",
       "       [0.365],\n",
       "       [0.366],\n",
       "       [0.367],\n",
       "       [0.368],\n",
       "       [0.369],\n",
       "       [0.37 ],\n",
       "       [0.371],\n",
       "       [0.372],\n",
       "       [0.373],\n",
       "       [0.374],\n",
       "       [0.375],\n",
       "       [0.376],\n",
       "       [0.377],\n",
       "       [0.378],\n",
       "       [0.379],\n",
       "       [0.38 ],\n",
       "       [0.381],\n",
       "       [0.382],\n",
       "       [0.383],\n",
       "       [0.384],\n",
       "       [0.385],\n",
       "       [0.386],\n",
       "       [0.387],\n",
       "       [0.388],\n",
       "       [0.389],\n",
       "       [0.39 ],\n",
       "       [0.391],\n",
       "       [0.392],\n",
       "       [0.393],\n",
       "       [0.394],\n",
       "       [0.395],\n",
       "       [0.396],\n",
       "       [0.397],\n",
       "       [0.398],\n",
       "       [0.399],\n",
       "       [0.4  ],\n",
       "       [0.401],\n",
       "       [0.402],\n",
       "       [0.403],\n",
       "       [0.404],\n",
       "       [0.405],\n",
       "       [0.406],\n",
       "       [0.407],\n",
       "       [0.408],\n",
       "       [0.409],\n",
       "       [0.41 ],\n",
       "       [0.411],\n",
       "       [0.412],\n",
       "       [0.413],\n",
       "       [0.414],\n",
       "       [0.415],\n",
       "       [0.416],\n",
       "       [0.417],\n",
       "       [0.418],\n",
       "       [0.419],\n",
       "       [0.42 ],\n",
       "       [0.421],\n",
       "       [0.422],\n",
       "       [0.423],\n",
       "       [0.424],\n",
       "       [0.425],\n",
       "       [0.426],\n",
       "       [0.427],\n",
       "       [0.428],\n",
       "       [0.429],\n",
       "       [0.43 ],\n",
       "       [0.431],\n",
       "       [0.432],\n",
       "       [0.433],\n",
       "       [0.434],\n",
       "       [0.435],\n",
       "       [0.436],\n",
       "       [0.437],\n",
       "       [0.438],\n",
       "       [0.439],\n",
       "       [0.44 ],\n",
       "       [0.441],\n",
       "       [0.442],\n",
       "       [0.443],\n",
       "       [0.444],\n",
       "       [0.445],\n",
       "       [0.446],\n",
       "       [0.447],\n",
       "       [0.448],\n",
       "       [0.449],\n",
       "       [0.45 ],\n",
       "       [0.451],\n",
       "       [0.452],\n",
       "       [0.453],\n",
       "       [0.454],\n",
       "       [0.455],\n",
       "       [0.456],\n",
       "       [0.457],\n",
       "       [0.458],\n",
       "       [0.459],\n",
       "       [0.46 ],\n",
       "       [0.461],\n",
       "       [0.462],\n",
       "       [0.463],\n",
       "       [0.464],\n",
       "       [0.465],\n",
       "       [0.466],\n",
       "       [0.467],\n",
       "       [0.468],\n",
       "       [0.469],\n",
       "       [0.47 ],\n",
       "       [0.471],\n",
       "       [0.472],\n",
       "       [0.473],\n",
       "       [0.474],\n",
       "       [0.475],\n",
       "       [0.476],\n",
       "       [0.477],\n",
       "       [0.478],\n",
       "       [0.479],\n",
       "       [0.48 ],\n",
       "       [0.481],\n",
       "       [0.482],\n",
       "       [0.483],\n",
       "       [0.484],\n",
       "       [0.485],\n",
       "       [0.486],\n",
       "       [0.487],\n",
       "       [0.488],\n",
       "       [0.489],\n",
       "       [0.49 ],\n",
       "       [0.491],\n",
       "       [0.492],\n",
       "       [0.493],\n",
       "       [0.494],\n",
       "       [0.495],\n",
       "       [0.496],\n",
       "       [0.497],\n",
       "       [0.498],\n",
       "       [0.499],\n",
       "       [0.5  ],\n",
       "       [0.501],\n",
       "       [0.502],\n",
       "       [0.503],\n",
       "       [0.504],\n",
       "       [0.505],\n",
       "       [0.506],\n",
       "       [0.507],\n",
       "       [0.508],\n",
       "       [0.509],\n",
       "       [0.51 ],\n",
       "       [0.511],\n",
       "       [0.512],\n",
       "       [0.513],\n",
       "       [0.514],\n",
       "       [0.515],\n",
       "       [0.516],\n",
       "       [0.517],\n",
       "       [0.518],\n",
       "       [0.519],\n",
       "       [0.52 ],\n",
       "       [0.521],\n",
       "       [0.522],\n",
       "       [0.523],\n",
       "       [0.524],\n",
       "       [0.525],\n",
       "       [0.526],\n",
       "       [0.527],\n",
       "       [0.528],\n",
       "       [0.529],\n",
       "       [0.53 ],\n",
       "       [0.531],\n",
       "       [0.532],\n",
       "       [0.533],\n",
       "       [0.534],\n",
       "       [0.535],\n",
       "       [0.536],\n",
       "       [0.537],\n",
       "       [0.538],\n",
       "       [0.539],\n",
       "       [0.54 ],\n",
       "       [0.541],\n",
       "       [0.542],\n",
       "       [0.543],\n",
       "       [0.544],\n",
       "       [0.545],\n",
       "       [0.546],\n",
       "       [0.547],\n",
       "       [0.548],\n",
       "       [0.549],\n",
       "       [0.55 ],\n",
       "       [0.551],\n",
       "       [0.552],\n",
       "       [0.553],\n",
       "       [0.554],\n",
       "       [0.555],\n",
       "       [0.556],\n",
       "       [0.557],\n",
       "       [0.558],\n",
       "       [0.559],\n",
       "       [0.56 ],\n",
       "       [0.561],\n",
       "       [0.562],\n",
       "       [0.563],\n",
       "       [0.564],\n",
       "       [0.565],\n",
       "       [0.566],\n",
       "       [0.567],\n",
       "       [0.568],\n",
       "       [0.569],\n",
       "       [0.57 ],\n",
       "       [0.571],\n",
       "       [0.572],\n",
       "       [0.573],\n",
       "       [0.574],\n",
       "       [0.575],\n",
       "       [0.576],\n",
       "       [0.577],\n",
       "       [0.578],\n",
       "       [0.579],\n",
       "       [0.58 ],\n",
       "       [0.581],\n",
       "       [0.582],\n",
       "       [0.583],\n",
       "       [0.584],\n",
       "       [0.585],\n",
       "       [0.586],\n",
       "       [0.587],\n",
       "       [0.588],\n",
       "       [0.589],\n",
       "       [0.59 ],\n",
       "       [0.591],\n",
       "       [0.592],\n",
       "       [0.593],\n",
       "       [0.594],\n",
       "       [0.595],\n",
       "       [0.596],\n",
       "       [0.597],\n",
       "       [0.598],\n",
       "       [0.599],\n",
       "       [0.6  ],\n",
       "       [0.601],\n",
       "       [0.602],\n",
       "       [0.603],\n",
       "       [0.604],\n",
       "       [0.605],\n",
       "       [0.606],\n",
       "       [0.607],\n",
       "       [0.608],\n",
       "       [0.609],\n",
       "       [0.61 ],\n",
       "       [0.611],\n",
       "       [0.612],\n",
       "       [0.613],\n",
       "       [0.614],\n",
       "       [0.615],\n",
       "       [0.616],\n",
       "       [0.617],\n",
       "       [0.618],\n",
       "       [0.619],\n",
       "       [0.62 ],\n",
       "       [0.621],\n",
       "       [0.622],\n",
       "       [0.623],\n",
       "       [0.624],\n",
       "       [0.625],\n",
       "       [0.626],\n",
       "       [0.627],\n",
       "       [0.628],\n",
       "       [0.629],\n",
       "       [0.63 ],\n",
       "       [0.631],\n",
       "       [0.632],\n",
       "       [0.633],\n",
       "       [0.634],\n",
       "       [0.635],\n",
       "       [0.636],\n",
       "       [0.637],\n",
       "       [0.638],\n",
       "       [0.639],\n",
       "       [0.64 ],\n",
       "       [0.641],\n",
       "       [0.642],\n",
       "       [0.643],\n",
       "       [0.644],\n",
       "       [0.645],\n",
       "       [0.646],\n",
       "       [0.647],\n",
       "       [0.648],\n",
       "       [0.649],\n",
       "       [0.65 ],\n",
       "       [0.651],\n",
       "       [0.652],\n",
       "       [0.653],\n",
       "       [0.654],\n",
       "       [0.655],\n",
       "       [0.656],\n",
       "       [0.657],\n",
       "       [0.658],\n",
       "       [0.659],\n",
       "       [0.66 ],\n",
       "       [0.661],\n",
       "       [0.662],\n",
       "       [0.663],\n",
       "       [0.664],\n",
       "       [0.665],\n",
       "       [0.666],\n",
       "       [0.667],\n",
       "       [0.668],\n",
       "       [0.669],\n",
       "       [0.67 ],\n",
       "       [0.671],\n",
       "       [0.672],\n",
       "       [0.673],\n",
       "       [0.674],\n",
       "       [0.675],\n",
       "       [0.676],\n",
       "       [0.677],\n",
       "       [0.678],\n",
       "       [0.679],\n",
       "       [0.68 ],\n",
       "       [0.681],\n",
       "       [0.682],\n",
       "       [0.683],\n",
       "       [0.684],\n",
       "       [0.685],\n",
       "       [0.686],\n",
       "       [0.687],\n",
       "       [0.688],\n",
       "       [0.689],\n",
       "       [0.69 ],\n",
       "       [0.691],\n",
       "       [0.692],\n",
       "       [0.693],\n",
       "       [0.694],\n",
       "       [0.695],\n",
       "       [0.696],\n",
       "       [0.697],\n",
       "       [0.698],\n",
       "       [0.699],\n",
       "       [0.7  ],\n",
       "       [0.701],\n",
       "       [0.702],\n",
       "       [0.703],\n",
       "       [0.704],\n",
       "       [0.705],\n",
       "       [0.706],\n",
       "       [0.707],\n",
       "       [0.708],\n",
       "       [0.709],\n",
       "       [0.71 ],\n",
       "       [0.711],\n",
       "       [0.712],\n",
       "       [0.713],\n",
       "       [0.714],\n",
       "       [0.715],\n",
       "       [0.716],\n",
       "       [0.717],\n",
       "       [0.718],\n",
       "       [0.719],\n",
       "       [0.72 ],\n",
       "       [0.721],\n",
       "       [0.722],\n",
       "       [0.723],\n",
       "       [0.724],\n",
       "       [0.725],\n",
       "       [0.726],\n",
       "       [0.727],\n",
       "       [0.728],\n",
       "       [0.729],\n",
       "       [0.73 ],\n",
       "       [0.731],\n",
       "       [0.732],\n",
       "       [0.733],\n",
       "       [0.734],\n",
       "       [0.735],\n",
       "       [0.736],\n",
       "       [0.737],\n",
       "       [0.738],\n",
       "       [0.739],\n",
       "       [0.74 ],\n",
       "       [0.741],\n",
       "       [0.742],\n",
       "       [0.743],\n",
       "       [0.744],\n",
       "       [0.745],\n",
       "       [0.746],\n",
       "       [0.747],\n",
       "       [0.748],\n",
       "       [0.749],\n",
       "       [0.75 ],\n",
       "       [0.751],\n",
       "       [0.752],\n",
       "       [0.753],\n",
       "       [0.754],\n",
       "       [0.755],\n",
       "       [0.756],\n",
       "       [0.757],\n",
       "       [0.758],\n",
       "       [0.759],\n",
       "       [0.76 ],\n",
       "       [0.761],\n",
       "       [0.762],\n",
       "       [0.763],\n",
       "       [0.764],\n",
       "       [0.765],\n",
       "       [0.766],\n",
       "       [0.767],\n",
       "       [0.768],\n",
       "       [0.769],\n",
       "       [0.77 ],\n",
       "       [0.771],\n",
       "       [0.772],\n",
       "       [0.773],\n",
       "       [0.774],\n",
       "       [0.775],\n",
       "       [0.776],\n",
       "       [0.777],\n",
       "       [0.778],\n",
       "       [0.779],\n",
       "       [0.78 ],\n",
       "       [0.781],\n",
       "       [0.782],\n",
       "       [0.783],\n",
       "       [0.784],\n",
       "       [0.785],\n",
       "       [0.786],\n",
       "       [0.787],\n",
       "       [0.788],\n",
       "       [0.789],\n",
       "       [0.79 ],\n",
       "       [0.791],\n",
       "       [0.792],\n",
       "       [0.793],\n",
       "       [0.794],\n",
       "       [0.795],\n",
       "       [0.796],\n",
       "       [0.797],\n",
       "       [0.798],\n",
       "       [0.799],\n",
       "       [0.8  ],\n",
       "       [0.801],\n",
       "       [0.802],\n",
       "       [0.803],\n",
       "       [0.804],\n",
       "       [0.805],\n",
       "       [0.806],\n",
       "       [0.807],\n",
       "       [0.808],\n",
       "       [0.809],\n",
       "       [0.81 ],\n",
       "       [0.811],\n",
       "       [0.812],\n",
       "       [0.813],\n",
       "       [0.814],\n",
       "       [0.815],\n",
       "       [0.816],\n",
       "       [0.817],\n",
       "       [0.818],\n",
       "       [0.819],\n",
       "       [0.82 ],\n",
       "       [0.821],\n",
       "       [0.822],\n",
       "       [0.823],\n",
       "       [0.824],\n",
       "       [0.825],\n",
       "       [0.826],\n",
       "       [0.827],\n",
       "       [0.828],\n",
       "       [0.829],\n",
       "       [0.83 ],\n",
       "       [0.831],\n",
       "       [0.832],\n",
       "       [0.833],\n",
       "       [0.834],\n",
       "       [0.835],\n",
       "       [0.836],\n",
       "       [0.837],\n",
       "       [0.838],\n",
       "       [0.839],\n",
       "       [0.84 ],\n",
       "       [0.841],\n",
       "       [0.842],\n",
       "       [0.843],\n",
       "       [0.844],\n",
       "       [0.845],\n",
       "       [0.846],\n",
       "       [0.847],\n",
       "       [0.848],\n",
       "       [0.849],\n",
       "       [0.85 ],\n",
       "       [0.851],\n",
       "       [0.852],\n",
       "       [0.853],\n",
       "       [0.854],\n",
       "       [0.855],\n",
       "       [0.856],\n",
       "       [0.857],\n",
       "       [0.858],\n",
       "       [0.859],\n",
       "       [0.86 ],\n",
       "       [0.861],\n",
       "       [0.862],\n",
       "       [0.863],\n",
       "       [0.864],\n",
       "       [0.865],\n",
       "       [0.866],\n",
       "       [0.867],\n",
       "       [0.868],\n",
       "       [0.869],\n",
       "       [0.87 ],\n",
       "       [0.871],\n",
       "       [0.872],\n",
       "       [0.873],\n",
       "       [0.874],\n",
       "       [0.875],\n",
       "       [0.876],\n",
       "       [0.877],\n",
       "       [0.878],\n",
       "       [0.879],\n",
       "       [0.88 ],\n",
       "       [0.881],\n",
       "       [0.882],\n",
       "       [0.883],\n",
       "       [0.884],\n",
       "       [0.885],\n",
       "       [0.886],\n",
       "       [0.887],\n",
       "       [0.888],\n",
       "       [0.889],\n",
       "       [0.89 ],\n",
       "       [0.891],\n",
       "       [0.892],\n",
       "       [0.893],\n",
       "       [0.894],\n",
       "       [0.895],\n",
       "       [0.896],\n",
       "       [0.897],\n",
       "       [0.898],\n",
       "       [0.899],\n",
       "       [0.9  ],\n",
       "       [0.901],\n",
       "       [0.902],\n",
       "       [0.903],\n",
       "       [0.904],\n",
       "       [0.905],\n",
       "       [0.906],\n",
       "       [0.907],\n",
       "       [0.908],\n",
       "       [0.909],\n",
       "       [0.91 ],\n",
       "       [0.911],\n",
       "       [0.912],\n",
       "       [0.913],\n",
       "       [0.914],\n",
       "       [0.915],\n",
       "       [0.916],\n",
       "       [0.917],\n",
       "       [0.918],\n",
       "       [0.919],\n",
       "       [0.92 ],\n",
       "       [0.921],\n",
       "       [0.922],\n",
       "       [0.923],\n",
       "       [0.924],\n",
       "       [0.925],\n",
       "       [0.926],\n",
       "       [0.927],\n",
       "       [0.928],\n",
       "       [0.929],\n",
       "       [0.93 ],\n",
       "       [0.931],\n",
       "       [0.932],\n",
       "       [0.933],\n",
       "       [0.934],\n",
       "       [0.935],\n",
       "       [0.936],\n",
       "       [0.937],\n",
       "       [0.938],\n",
       "       [0.939],\n",
       "       [0.94 ],\n",
       "       [0.941],\n",
       "       [0.942],\n",
       "       [0.943],\n",
       "       [0.944],\n",
       "       [0.945],\n",
       "       [0.946],\n",
       "       [0.947],\n",
       "       [0.948],\n",
       "       [0.949],\n",
       "       [0.95 ],\n",
       "       [0.951],\n",
       "       [0.952],\n",
       "       [0.953],\n",
       "       [0.954],\n",
       "       [0.955],\n",
       "       [0.956],\n",
       "       [0.957],\n",
       "       [0.958],\n",
       "       [0.959],\n",
       "       [0.96 ],\n",
       "       [0.961],\n",
       "       [0.962],\n",
       "       [0.963],\n",
       "       [0.964],\n",
       "       [0.965],\n",
       "       [0.966],\n",
       "       [0.967],\n",
       "       [0.968],\n",
       "       [0.969],\n",
       "       [0.97 ],\n",
       "       [0.971],\n",
       "       [0.972],\n",
       "       [0.973],\n",
       "       [0.974],\n",
       "       [0.975],\n",
       "       [0.976],\n",
       "       [0.977],\n",
       "       [0.978],\n",
       "       [0.979],\n",
       "       [0.98 ],\n",
       "       [0.981],\n",
       "       [0.982],\n",
       "       [0.983],\n",
       "       [0.984],\n",
       "       [0.985],\n",
       "       [0.986],\n",
       "       [0.987],\n",
       "       [0.988],\n",
       "       [0.989],\n",
       "       [0.99 ],\n",
       "       [0.991],\n",
       "       [0.992],\n",
       "       [0.993],\n",
       "       [0.994],\n",
       "       [0.995],\n",
       "       [0.996],\n",
       "       [0.997],\n",
       "       [0.998],\n",
       "       [0.999]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87c41222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cm_trainTestSplit_Plot(i, Cm, cm, tTrain, tVal, tTest, iTrain, iVal, iTest):\n",
    "    \n",
    "    title_0_Cm = 'Gurney flap not attached (NACA0018)\\n$C_m$ prediction, $L_2$ error=%.4f' % l2_error_Cm    \n",
    "    title_n_Cm = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_m$ prediction, $L_2$ error=%.4f'%(l2_error_Cm)\n",
    "    \n",
    "    if i==0:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    else:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    \n",
    "    # Cm graph plot\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm), 'k--', label='Predicted value')\n",
    "    plt.scatter(tTrain, denormalize(iTrain), color='b', label='Training set')\n",
    "    plt.scatter(tVal, denormalize(iVal), color='g', label='Validation set')\n",
    "    plt.scatter(tTest,denormalize(iTest), color='r', label='Test set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([-0.05, 0.22])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "893cf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf177275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error of Cm: 0.0078\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = [0.03]\n",
    "beta = [90]\n",
    "for i in range(0,1):\n",
    "    #Index from each dataset in sorted order\n",
    "    iTrain_ = []\n",
    "    iVal_ = []\n",
    "    iTest_ = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    t_train = []\n",
    "    t_val = []\n",
    "    t_test = []\n",
    "    \n",
    "    predictedValue = predicted[t_len*i:t_len*(i+1),:]\n",
    "    y_corres = y[t_len*i:t_len*(i+1),:]\n",
    "    \n",
    "    l2_error_Cm = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    print('L2 error of Cm: {0:0.4f}'.format(l2_error_Cm))\n",
    "    \n",
    "    cm_ = predictedValue#denormalize(predictedValue)\n",
    "    Cm = y_corres#denormalize(y_corres)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        iTrain_.append(predicted[index])\n",
    "    for jj, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        iVal_.append(predicted[index])    \n",
    "    for kk, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & (index_test>=i*t_len))]):\n",
    "        iTest_.append(predicted[index])\n",
    "        \n",
    "#     iTrain = denormalize(np.array(iTrain))\n",
    "#     iTest = denormalize(np.array(iTest))\n",
    "#     iVal = denormalize(np.array(iVal))\n",
    "    iTrain_ = np.array(iTrain_)\n",
    "    iVal_ = np.array(iVal_)\n",
    "    iTest_ = np.array(iTest_)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        t_train.append(t[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        t_val.append(t[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & ((index_test>=i*t_len)))]):\n",
    "        t_test.append(t[index])\n",
    "        \n",
    "    tTrain = np.array(t_train)\n",
    "    tVal = np.array(t_val)\n",
    "    tTest = np.array(t_test)\n",
    "        \n",
    "    Cm_trainTestSplit_Plot(i, Cm, cm_, tTrain, tVal, tTest, iTrain_, iVal_, iTest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7eb11de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cm_trainTestSplit_Plot2(i, Cm, cm, tTrain, tVal, tTest, iTrain, iVal, iTest):\n",
    "    \n",
    "    title_0_Cm = 'Gurney flap not attached (NACA0018)\\n$C_m$ prediction, $L_2$ error=%.4f' % l2_error_Cm    \n",
    "    title_n_Cm = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_m$ prediction, $L_2$ error=%.4f'%(l2_error_Cm)\n",
    "    \n",
    "    if i==0:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    else:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    \n",
    "    # Cm graph plot\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm), 'r--', label='Predicted value')\n",
    "#     plt.scatter(tTrain, denormalize(iTrain), color='b', label='Training set')\n",
    "#     plt.scatter(tVal, denormalize(iVal), color='g', label='Validation set')\n",
    "#     plt.scatter(tTest,denormalize(iTest), color='r', label='Test set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b2cc294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error of Cm: 0.0078\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    #Index from each dataset\n",
    "    iTrain_ = []\n",
    "    iVal_ = []\n",
    "    iTest_ = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    t_train = []\n",
    "    t_val = []\n",
    "    t_test = []\n",
    "    \n",
    "    predictedValue = predicted[t_len*i:t_len*(i+1),:]\n",
    "    y_corres = y[t_len*i:t_len*(i+1),:]\n",
    "    \n",
    "    l2_error_Cm = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    print('L2 error of Cm: {0:0.4f}'.format(l2_error_Cm))\n",
    "    \n",
    "    cm_ = predictedValue#denormalize(predictedValue)\n",
    "    Cm = y_corres#denormalize(y_corres)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        iTrain_.append(predicted[index])\n",
    "    for jj, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        iVal_.append(predicted[index])    \n",
    "    for kk, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & (index_test>=i*t_len))]):\n",
    "        iTest_.append(predicted[index])\n",
    "        \n",
    "#     iTrain = denormalize(np.array(iTrain))\n",
    "#     iTest = denormalize(np.array(iTest))\n",
    "#     iVal = denormalize(np.array(iVal))\n",
    "    iTrain_ = np.array(iTrain_)\n",
    "    iVal_ = np.array(iVal_)\n",
    "    iTest_ = np.array(iTest_)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        t_train.append(t[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        t_val.append(t[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & ((index_test>=i*t_len)))]):\n",
    "        t_test.append(t[index])\n",
    "        \n",
    "    tTrain = np.array(t_train)\n",
    "    tVal = np.array(t_val)\n",
    "    tTest = np.array(t_test)\n",
    "        \n",
    "    Cm_trainTestSplit_Plot2(i, Cm, cm_, tTrain, tVal, tTest, iTrain_, iVal_, iTest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b420f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error of Cm: 0.0078\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEwCAYAAACkMUZEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABRtElEQVR4nO2deXwURfbAvy8XEG4CooAEdHURuUEQQQ4VRBHFC4+ooCIi3uuFZkVWl10PdL1QBFdRyU9UFHDFgxWDHKIcKyoiCAIJh3KEm4SEJPX7o3rCMEySyZyZzPt+Pv1Jurqq+lV3T7+uqlfviTEGRVEURSmPuEgLoCiKokQHqjAURVEUn1CFoSiKoviEKgxFURTFJ1RhKIqiKD6hCkNRFEXxCVUYiqIoik+owlAURVF8QhVGmBCRwSIyR0RyRKRARLaIyDQR6RFp2YKJiIxx2lYsIlOcbVmk5XJHRIaIyDBf04N43pBdCxFpIyJGRPpEUIbWIjJXRHJFZKuIPC4i8YGWE5ErROQb57dzSETWiMhfRSQpQHnbisinTr05IjJDRI4LsM7BIvKjiOSLyAYR+YuXPH5dp8qAKowwICL/Aj4EtgDDgfOA0UBtYKGInBxB8YKGiHQB/ga8DPQAnoisRKUyBBhWgXSlHESkPvAlYIBLgMeB+7DPQ6DlUoBM7G/nAuANIB14LgB5mzp1GiANuA3oBdwbQJ09gI+AJcAgR86nROQetzx+XafKQkKkBajqiMglwD3AjcaYKR6H3xGRQUBegOeIB+KNMQWB1BMEWjl/Jxhj9gGISATFUcLISKAGcJlz7/8rInWAsSLytOt58KecMeY1jzKZTp7bReRO459/o7uAfc558wFE5CbsR5y/jAEWGmOGO/tzHAUxRkRecX6f/l6nSoH2MELPPcBSL8oCAGPMf4wxWwFEZJ6ITHc/LiJ9nKGGNm5pU0RkmdP9/Rk4BHRzS+/ndIsPishCETndo86eIvK10yXOEZHJIlLb7fhAZ0ippUe5lk76xZ7tEJEpwDvO7t6yhkdEpLuIfOx0xw+KyAoRSfOsz62Nq52hiIUi0tpbnb7W7ch5OdDbkdGIyNjS0n2V18nXS0QyReSAiOx17mdHL/kCuj9OnlEissmp4z/ACWVdl4rK4AcXAF94vPCmYV+OvUNQLgcIZEhqIDDDTVnUB3oCSwOoswO29+DOHKA+0N3Z97e9lQJVGCFERBKwD8qcEFTfAnga+CdwIbDBSW8OPAOMA64BjgPeF+dT3+k2zwX+AK7AKrQLgTfd6v4c2AoM9TjnMGAH8KkXeZ4A/u78fw623f8rRfZUYBF2iGEQdrjuTRG5xku+55y6rwXqAl+ISPVS6vWl7iewQxHfOzJ2B14vI90neR3lOBc4jL1uVwELgKYe8gV8f5xe6wTgE+Ay4Cfs8IevlCeDiEhCeZtHna2A1e4JxphsIJcjPU9v+FxOROJFJFlEemJ7CK/607sQkZrAacBSEaktImdjn/nNwHtOHn+uQXXAs5ef7/w9raLtrZQYY3QL0QY0xo5V3uqRLtjhQNcmTvo8YLpH3j5OHW3c0qY4aR088k4BCoFT3NIGO3lbOfsLgEyPcud4OcffsUpI3GTeCIwvo73DnHpqeci0rIwyrmvxGvCVlzae5ZaW6rRvpI/Xv7S6pwPzvOT3mu5jnYuBZa7rVUrZoNwf7Bj5Zx55Jjt5+pQjvy8yuO5jmZtHvYeBe7ycbzPwjzLk8bkctiftOv9bQJyfv8vuTh1/BnY5/x8CzvTyLFfkGiwHPvRIe8jJ+0gg16mybNrDCC2uAXzPr6D7sA+Oa7vdj7q3GGNWeEnfaIxZ67a/yvnbTESSsT+W9z2+khY6cnR2K/cG9gXdx9nv6+y790T8QkTqi8iLIpLFkWswAjjVI+t2Y8w3rh1jTBb2R9k1CHUHTV7ni7Ub8JZxfv1lEND9ETtf1RGY5VHvRxVoUqkyOH//A5zhw+aJt7ZLKen+lDsLOBv7+7kEa1zhDx2AA8B6bC9uJPbjaLaIHO/k8ecaTAQuEZFbnGfmfEdWgCK3fP5ep4ijk96hZSe2S9rMI/0dbG8C/B8z3VZK+h6PfVcXuTp2LDUeeMXZPDnR9Y8xZr2IzANuxA7V3AgsMcb87Ke87kwBzsQOA63CTj7ehn0JuLPdS9ntlD1e72vdwZS3PvYH/7sPde3x2K/o/WmE/d16Xhtv18ofGcB+de+tQH0Au4F6XtLrejmfX+WMMa4hzoUishN4S0SeNcb8VkFZOwI/GGMOA18BX4nIV8Cv2HmE9/DvGrwBtAdeBSZhh5keAl7iyO/V3+tUKVCFEUKMMYUishjoj7WgcKVvw3mA5GgrokMcO5HXoLTq/RBpj1NuLN7nIbZ67L8OTBaRh7Fj5fcdW6RiOPMPA4E7jDET3dK99Xa92cQfB3hVWhWsO5jy7gaKqeDEsxf2UP792YEdUvK8NgGtH/BgKL71JN0f3tUcO+dwIlATjzF7D/wt51IeLYGKKowOwHceaYecv64Xe4WvgTGmCLhDRB7FfiRu4EjbvnX++tveSoEqjNDzPDBTRK43xrxTTt7NWFtwd/oFSxBjzEER+Rb4szHmcR+KfISdXJ2GNZCYFgQxqmG/ol2TgTgWQBdzrBI8TkTOcg1LiUhzoBOl/5B9rbuAI1/TlJNebp3Odf0OuEFEXvZhWMorvt4fEVmB7d1MdEu+zJ9zloJrOKYifAY8ICK1jTH7nbSrsCbjX4egnGvB64aKCOkM6bXBttGdNGyvYqGz7881AMAYsxv7EYGIjAK+Mca4lIG/7a0UqMIIMcaYWSLyPDBFRPpiH8Sd2MVILmVwwPk7A7hZ7EK/2dh5g/ODLNKDwFwRKcZO8u7HWs0MBNKNMb+6yX5IRDKwcyzvGmP2BHpyY8xeEVmKtU3fh/0yH43t/tfxyL4Tu1blUewP6nHs0MuUAOtejR1rHoxV0luNNW32mu5jnaOxJpWficgk4CB2PmKZMeaTClwiX+7PP4CPRORV7DPTGxhQgXOUiTEmB2u2WhEmYi2XPhKRp4CTsD2l58yRNTk3YIdtTnbmo3wt9zn22v6MnQvoge3tvuc+HOVYqmUCfY0x80qRsxXWhPVBEckBfsGa06YDtxljCv29BiJyplPXCuyzcQ3299uzItepUhPpWfdY2YBLgf9iv2IOY4cXPgQu8Mj3MLAJ+6KYypEvWU8rqWMsj7ylY81vDXCRW1o3rBnhPuyLbRXWfLWulzrPc8qf50Mbh+GDlRTwJ+zY8UEgG/uSHAvs9CyH/XL+FfuFv8j9OpQigy91N8S+aF0WMmPLSS+3Tidfb2A+dux6D/bl1SEU9we4A6vUcrHDV/3x3UqqXBn8fMZbO9cpDzuf8wR2Qann89GiguWeAFZiP6z2YIej7gQSPeq50Km/dRkypmF7km8713cvdrjo8iD8xjtj5yQPOHXPBtpW9DpV5s1lMqkoXhGRp7Fd5pbGmOIwnncKVjl0Cdc5lehGRP4G9DLG9C0jzzNAf2NM+/BJVnXQISnFKyLyZ+yX0G3A38KpLBTFT86ifP9SHbGLMxU/UIWhlMZr2KGRj4EXIyyLopSLMcYXA5H22BXyih/okJSiKIriE7rSW1EURfEJVRiKoiiKT6jCUBRFUXxCFYaiKIriE6owFEVRFJ9QhaEoiqL4hCqMKEREEkXkXhFZIjYUaJ6ILHfSAglbGTFEpI14hHUVJ0xrBeoYIiLDvKRXqJ5QISIviUhpbuljEhFpLSJzxYaj3SoijzsOAoNS1sc88+RIWF7PrbtbvqtF5H9iQ/BuEZG3RaRJcK5EdKAL96IMsbGHvwROxvrZd7lNvwB4EtgCvB8Z6YLOE1hHcb4yBOsPakqA9YSKtthwqgpHPcursN53TwaexX7I/jXQshWofxTHOr58HLsqfKlT18XAu1jvzQ9gXdn/HfhERLrEjCeESDuz0s33Det7PxPrsKyVl+NdsD6fIiFbPJAUQPk2+OA8r5w6yg2xGuH7txP4VwTP7/UeBeHe+VUe62hzN1DHLe1BrEPFOoGW9bd+bEyaXdiY4a60acByj3wux6CnRfrZCtemQ1LRxVBsyNSR5oh//RKMMcuMMRWKD+CJa/hGRAaLyGoROSQiC0WkdRn5fsYGoOnmHOspIl87wwA5IjLZiSHhXn6UiGwSkYMi8h+8BB/yNpQkIr1EJNMZFtjrDCd0dJwVXg70dhtOGFtGPUNE5CcRyXfkGCc2HKpn+/qJyI+OnAtF5HQ/r2sTrEv7oPUwyrvOpd2jcu5dmdelrHr9aMIFwBfmaLfe07C9wd5BKOtv/QOw0Q/fdUtL5NgIfHucv0KMoAojuvgL8IsxxjOec7BJxTpxewK4Fhs+8gux0efcaQE8DfwT61p6g4j0AOYCf2DjJd/jHCsJeiQil2C79p9g3Zf/hI2TUCbO/MZcrHv4oVgvuguApo6smVjHct2d7fVS6umPDcP5P+xQxUvA/RwbI7o58AwwDhvb4DhsvG1/XhBtnb9BURi+XGeHFnjco9LSK3BdSisv4haLvLTNrY5WeESZM8ZkY3sAR0Wl84IvZf2t/2rs0O4Ct7Q3gLNF5AYRqSMip2KHpDKNMau8VVIliXQXRzffNuxL3GCD6ITyPFOc85zlce5CbM/GM18Hj/ILsD8i97RzcIvpASwBPvPIMxmPISk8YjcAi7ExMqQU2b0OSXmp51svMj6IDc7TzK1MIXCKW57BjozHDAf6cF3vd+pPDtJ98uU6l3aPSksv97qUU36Yk17m5pb/MHCPl7ZtBv5RTvvLLetP/UAyNhbNs16OpWF7U662LALqBeN+RsumPYzowfWFujIM59punLCoAMZGR1sOdPXIt8UYs8K1IyLJ2C/79z2+KBdif7ydHQuVjoBnL+mjsgQSkZrYYY+3jPPr9Qfn/J2ADzwOvYftcXd3S9tojFnrtu/6kmzmx6nbAuuNMbleZDpRrCXPLyLys4g8XVYvxpfr7Jb9qHtUWnoFr0tp9brCmpa3uePtXkop6Z74Urai9Q8CanH0cBRio2VOBF7ARsK8GmgAzBAfrbqqAmolFT3Udf6GwyxzeylpnvMMnrLUx06AvuJsnpwINMI+d57n8HZOz7oFO+EfCA2x49Gesrv2G7il7fHIU+D89RYPvDzKspAqBB4yxiwTaxb9X+xQ3Yel5PflOrso7XnxTK/IdSmt3l0cO85fFruBel7S63LstfenrD/1Xw2sM8Z4mmE/C3xsjHnIlSA2tvpq7PBdmR88VQVVGNGD64Vart23iLzm/HsKdqz2Eez4+2XYF/ZA42XS3I3jSkn72SPN8yttj5M2Fhs21JOtwA7sC9LzHN7O6c5ubDztYybHK8hO7Fe45/kaO393BVj/MThfoKdhv8CPwRjzO44iNMYUiMiPHP3S92QP5V/nkupLqcMzvaLXxVu9Qzl2DsUbrt7TajzmEkTkRKAmHnMPXvClbIXqF5G62Inyp72crxUevQ5jzBoRycOa68YEOiQVPSzGxgm+0dtBEXEPNN8BGy/4XOyk9UvAT8aYM7FDDpeVc67jROQst7qbY4crlpRVyBhzEDsO/mdjLbY8t63GmCJgBfarzJ0yZXLq/g64oYzhmgLK+fp3zr8cuNLj0BCsQlpcVnk/OcWRq9wJbxFJwc6VfFFaHl+uc0UFDNJ1qeiQ1GfA+R4WdFdhn92vyzmXL2UrWv+lQDU8FINDFvY3UIKInIa1uNpYjqxVBu1hRAnGmAMi8hDwqojMAt7Bfq2fjP2R1wF6iEgc8CfgXGOMEREDfGuM+cypKo7yv6J3Au+IyKPYH9fj2B7OFB9EfRCYKyLF2Eno/Vhro4HYCftfgX8AH4nIq8AMrInjAB/qHo1diPWZiEwCDmLH1pcZYz7BGR4QkcHYic2tpbw8H8Nafb2JNbNsi7WymmyM2eyDHCU4lluZQF9jzLxSsrnmn5o5srnzg3FMoUWkGvaaPW+M+aWcU/tynStKQNfFGJMD5FTgfBOBu7DPwlPASdhe03PGzRRWRG7AWimd7Myn+VrWp/rduBp7P7xd+4nAv0RkK1YRNcYumt2I915e1STSs+66VWzDfpkvAA442yrsw9zVOX4a8J1b/ruwMbld+1/gZgHlpf4pWEuky4BfgXysNUgbb/lKqaMb8Dm2R3TQkfE5oK5bnjuwL/Vc7A+uP+VYSTlpvYH5Trk92Jd1B+dYQ6wC2uXUNbaMeq7CfvEXOHKMAxLKOXcLp96L3NIudNJal3FNH6d0q6GLnTzx2Bf/cxV4Fsq8zqXdo3LuXZnXpbzyfjzPrYGvsB8mv2MVVLxHnmHOtWrhR9ly87g9O4eB0aXIKdj49j8613oL1iDgpFD+3ivbpiFaqxgicg3Q2xgz0tl/E5hljJnp7G8FTjXGHCil/BSscugSHomjGxH5G9DLGNM3wHpexyqNm4z+KJVKis5hVD3aY+cIXHR07YvI8cDB0pSF4hdnYb/q/cZZhHcz1rXL9yKyQkTuCoZwihJMtIehHIX2MBRFKQ1VGIqiKIpP6JCUoiiK4hNV1qy2YcOGpkWLFn6XP3jwIDVr1gyeQFFArLU51toL2uZYIZA2L1++fKcxppG3Y1VWYbRo0YJly/wPsjZv3jz69OkTPIGigFhrc6y1F7TNsUIgbRaRrNKO6ZCUoiiK4hOqMBRFURSfUIWhKIqi+ESVncNQFCW0HD58mM2bN3Po0KFIi1ImdevW5ZdfynPNVbXwpc3Vq1enWbNmJCYm+lyvKgxFUfxi8+bN1K5dmxYtWuBf1NrwsH//fmrXrl1+xipEeW02xpCTk8PmzZtp2bKlz/XqkJQSGjIyoEULiIuzfzMyIi2REmQOHTpESkpKpVYWindEhJSUlAr3DlVhKMElIwOqVYPrroOsLDDG/r3uOqs8Ro2KtIRKEFFlEb34c+90SEoJDhkZcPfdkJODwUY6+hzrA7oHNopTkjHw6qs2/yveIosqilKZ0R6GEjgZGTBiBOTksAYb0ag78DfgdWyIwEbALFf+SZMiIqZS9di2bRvXXnstJ510Ep07d6Z79+7MmDEjrDJs3LiRNm3aeE3/v//7P7/qfP7558nNzS3Zr1Wrlt/yBRNVGErgpKdDbi4LgXbAD9iITmuBT4DzsBF+BjvpFBXpvIYSMMYYBg8eTK9evVi/fj3Lly9n2rRpbN58bHDAwsLCsMtXlsIoTx5PhVFZ0CEpJXCys/kFOAcbsmwscKtz6E/YmKGfO39HAXWBa7KybK8EIC0tvPIqVYKvvvqKpKQkRo4cWZKWmprKnXfeCcCUKVOYPXs2Bw4cID8/n+nTp3PTTTexfv16kpOTmTRpEu3atWPs2LHUqlWL+++/H4A2bdrwySefAHDBBRfQs2dPvvnmG5o2bcqsWbOoUaMGy5cv56abbiI5OZmePXt6lW/06NH88ssvdOjQgaFDh1K/fn1mz57NoUOHOHjwIGPGjGH8+PEl57rjjjvo0qUL+/btY+vWrfTt25eGDRuSmZkJQHp6Op988gk1atRg1qxZNG7cOGTXtjRUYSgBU3DiiZydnc1h4ClssGlPBmBjwz6Mnc9oBJyXm2t7J6owop577rmHFStWBLXODh068Pzzz5d6/Oeff6ZTp05l1rF48WIWLVpUokg6duzIzJkz+eqrr7jhhhvKlXnt2rW8++67TJ48mSFDhvDhhx9y3XXXceONN/LSSy/Ru3dvHnjgAa9ln3zyyaMUwpQpU1i8eDE//vgjDRo0YN68eV7L3XXXXTz33HNkZmbSsGFDwDoTPPPMMxk3bhwPPvggkydP5q9//WuZsocCHZJSAuaGE04gBzvk5E1ZuDgPG4z7T8AV2IDcZGeHWDolVrj99ttp3749Z5xxRklav379aNCgAQALFy7k+uuvB+Ccc84hJyeHvXv3lllny5Yt6dChAwCdO3dm48aN7N27lz179tC7d2+Akjp9wV2eipCUlMRFF110lByRQHsYSkD8+uuvfLB0KY3r1uX9unVh0yZo3hzGjTu659CiBWRlUQO4CXgEGALMad48InIrwaWsnkCoOP300/nwww9L9idMmMDOnTvp0uVIsEh3F9/egsWJCAkJCRQXF5ekua9NqFatWsn/8fHx5OXlYYzx25zYXZ6yzutJYmJiyTnj4+MjMicD2sNQAmT06NEkJyezYvVqErOyoLgYNm48dphp3DhITrZlgBOA/wK/3nFHmCVWqgrnnHMOhw4d4lWXqTaUOVHcq1cvMhxDi3nz5tGwYUPq1KlDixYt+N///gfA//73PzZs2FDmeevVq0fdunVZuHAhQEmdntSuXZv9+/eXWk9qaiqrVq0iPz+fvXv3MnfuXJ/LRgpVGErFcVZxvyvCjBkzeOD88zn++OPLLpOWZs1pU1MREV5rZOOzpL33XhgEVqoiIsLMmTP5+uuvadmyJV27dmXo0KE89dRTXvOPHTuWZcuW0a5dO0aPHs1bb70FwOWXX86uXbvo0KEDr776Kqeeemq5537zzTe5/fbb6d69OzVq1PCap127diQkJNC+fXv+9a9/HXP8xBNPZMiQIbRr1460tDQ6duxYcmzEiBFccMEF9O3b15dLET6MMVVy69y5swmEzMzMgMpHIz61eepUY5KSjAHTFAxgNiYk2PQK0qJFCwOYVatWVVzYIKD3ODAidd8qyr59+yItQtjxtc3e7iGwzJTyXtUehlIx7r4bCgr4D0dWcacWFtr0CvLiiy8iIowZMybYUiqKEgJUYSgVIycHAJch4ese6RVh0KBB3H///UyfPp1Vq1YFRTxFUUKHKgylwmQBa4A/A60CrOv+++8nPj6eJ554InDBFEUJKaowFN/JyAARXDYpj7gfS0nxq8pGjRpRs2ZNpk+fTkFBQaASKooSQlRhKL6RkQE33USxMXyEnbu4wXUsMRFeeMGvakWEoUOHUlhYyDPPPBMkYRVFCQWqMBTfcCa7Z2KdCrp8RREXB2++GZB7j3HjxllT29deC1xORVFChioMxTecSe1Hnd2BrvTi4oB9QdWuXZs2bdqwadMm1q9fH1BdSmwRHx9Phw4daNOmDVdeeWVAHl6HDRvG9OnTARg+fHiZhhjz5s3jm2++qfA5WrRowc6dO/2WMdj1VBRVGIrPHAR+AZoDFfeGUzYuT6HeFjgpSmnUqFGDFStWsHLlSpKSkpg4ceJRx4uKivyq9/XXX6d169alHvdXYUQ7qjAU30hJ4VnsSr0bPNKDwXXXXceZZ57JrFmzyM/PD0qdSmxx9tlns27dOubNm0ffvn259tpradu2LUVFRTzwwAOcccYZtGvXrmTo0xjDHXfcQevWrRk4cCDbt28vqatPnz4sW7YMgM8//5xOnTrRvn17zj33XDZu3MjEiRP517/+RYcOHViwYAE7duzg8ssv54wzzuCMM85g0aJFAOTk5NC/f386duzIrbfe6tWf1auvvsqDDx5x2zllypQSF+2DBw+mc+fOnH766UzyEnjMM3jT+PHjGTt2LAC//fYbAwYMoHPnzpx99tmsXr06wCuszgcVX3nhBd687joEN4+0AUx2exIXF8cjjzzCxRdfzJw5cxg0aFBQ6lXCR58+fY5JGzJkCKNGjSI3N5cLL7zwmOPDhg1j2LBh7Ny5kyuuuOKoY6W5//ZGYWEhn332GQMGDABgyZIlrFy5kpYtW/Liiy9St25dli5dSn5+Pj169KB///58//33rFmzhp9++olt27bRunVrbrrppqPq3bFjB7fccgvz58+nZcuW7Nq1iwYNGjBy5MijYmhce+213HvvvfTs2ZPs7GzOP/98fvnlF/72t7/Rs2dPxowZw+zZs72+9K+44gq6d+/O008/DcB7771Heno6AG+88QYNGjQgLy+PM844g8svv5wUHz/SRowYwcSJEznllFP47rvvGDVqFF999ZXP19QbqjAUn9h1wQVsBP6ckEDtoiLvHmkDpGvXrogI//znP1VhKD6Rl5dX4n787LPP5uabb+abb76ha9eutGzZErCBllatWlUyP7F3717Wrl3L/Pnzueaaa4iPj6dJkyacc845x9T/7bff0qtXr5K6SnNN/uWXXx4157Fv3z7279/P/Pnz+eijjwAYOHAg9evXP6Zso0aNOOmkk/j222855ZRTWLNmDT169ACsNwRXyNlNmzaxdu1anxTGgQMH+Oabb7jyyitL0oLRc1eFofjEl19+CcCYt96Ca68NyTkaN25c8iVYVFREfHx8SM6jhIayegTJycllHm/YsGGFehQuXHMYnni6NX/ppZc4//zzj8rz6aefluum3Pjoyry4uJjFixd7dUToS/mrrrqK999/n1atWnHppZciIsybN48vv/ySxYsXk5ycTJ8+fY5xgV6ai/Ti4mLq1asX9KBWOoeh+MTMmTNp1KgRV111VUjPM6BVKwoLC5mZkKBxv5WgcO655/Lqq69y+PBhwMZwOXjwIL169WLatGkUFRXx+++/l4RCdad79+58/fXXJS7Pd+3aBRzrfrx///68/PLLJfuuF7W7S/XPPvuM3bt3e5XxsssuY+bMmbz77rslv7G9e/dSv359kpOTWb16Nd9+++0x5Ro3bsz27dvJyckhPz+/JLpfnTp1aNmyJR988AFgFd8PP/zg+0UrBVUYSrkcPHiQ6dOn061bt9B+9Wdk8ND33wPwEoAr7rcqDSUAhg4dSuvWrenUqRNt2rTh1ltvpbCwkEsvvZRTTjmFtm3bctttt5VE0HOnUaNGTJo0icsuu4z27duXvMwHDRrEjBkzSia9X3zxxRLX6a1bty6x1nrssceYP38+nTp1Ys6cOTQvJWBY/fr1ad26NVlZWXTt2hWAAQMGUFhYSLt27Xj00Uc588wzjymXmJjImDFj6NatGxdddBGtWh1x1pORkcG///1v2rdvz+mnn86sWbMCvpYRd0Meqk3dm1ec0tr85JNPGsA8/PDDoRUgNdUYMHXAVANTDMaATQ8Beo8DQ92bV17UvbkSMd5zghzde++9oT2RE9/7WiAfWO6RrihKZFGFoZRJcXExK1eupGHDhjRyouSFDKe7/g+gFjDZI11RlMgSVoUhIgNEZI2IrBOR0V6OtxKRxSKSLyL3exzbKCI/icgKEVkWPqljm/nz53P48GHOPvvs0J/MiftdH+gOzABMjRo2XVGUiBM2hSEi8cAE4AKgNXCNiHiuvd8F3AWML6WavsaYDsaYLqGTVCkhI4NvLr0UgMvmzw/95LNb3O9DwA5g5aOPBnWth6Io/hPOHkZXYJ0xZr0xpgCYBlzinsEYs90YsxQ4HEa5FG9kZMCIERzaswcBrsjJCY/FUloabNzIta/aqBuTf/89tOdTFMVnwrlwrymwyW1/M9CtAuUNMEdEDPCaMeaYNfYiMgIYAdY+2Z+FQC4OHDgQUPlo5Kg279oFjz/OzJdf5pTCQr69554j6WG4LieeeCIA06dP57LLLgvJOWL+HgdI3bp1j1qLUFkpKiqKCjmDia9tPnToUMWeh9LMp4K9AVcCr7vtXw+8VErescD9HmlNnL/HAT8Avco6n5rVVpyj2ixifrBK2lzpMm8FY0TCJk/T+vWNgDnkMq2dOjWo9cf8PQ6QSJvV7ty507Rv3960b9/eNG7c2DRp0qRkPz8/vyRfaSammZmZZtGiRQHLsXv3bjNhwoSA6wkmVcGsdjNwott+M2Crr4WNMVudv9ux86FdgyqdcjTNm+Pqwl3okR4WMjI4b98+DPAJ6CI+5RhSUlJYsWIFK1asYOTIkdx7770l+0lJSeWWD5aL8j179vDKK68EXE80EE6FsRQ4RURaikgScDXwsS8FRaSmiNR2/Q/0B1aGTNJYJyMDDhzgC0CwNwqA5OTwWSylp/P3oiLqAdNdabm54HjxVKKQjAzr7iUuLmRuX5YvX07v3r3p3Lkz559/Pr87c2AvvvgirVu3pl27dlx99dVeXZS78/XXX9OhQwc6dOhAx44dS4Z3nnnmmRI36Y899hgAo0eP5rfffqNDhw488MADQW9TZSJscxjGmEIRuQP4AogH3jDG/CwiI53jE0XkeGAZUAcoFpF7sBZVDYEZjhOvBOD/jDGfh0v2mMKZ7C7OzWUD0ASoDjbuxQsvhM9iKTubZsAg4HPs2Jg46UoU4jxXuCLiuXqMELRnyhjDnXfeyaxZs2jUqFGJm/AXXniBJ598kg0bNlCtWjX27NlDvXr1jnFR7s748eOZMGECPXr04MCBA1SvXp05c+awdu1alixZgjGGiy++mPnz5/Pkk0+ycuXKoDv6q4yE1VutMeZT4FOPtIlu//+BHaryZB/QPrTSKYD9gs/N5XOgCCjxrlOrVnjNW5s3h6wsGuKY1wJtAUpxL61Ucpzn6ihcPcYgPVf5+fmsXLmSfv36AXbi94QTTgCgXbt2pKWlMXjwYAYPHlxuXT169OAvf/kLaWlpXHbZZTRr1ow5c+YwZ84cOnbsCFgDgrVr15bqH6oqoiu9laNxvuBXOLsjPNLDxrhxkJhIC2f3LVf6/v06jxGNlPb8BPG5MsZw+umnl8xj/PTTT8yZMweA2bNnc/vtt7N8+XI6d+5MYWFhmXWNHj2a119/nby8PM4880xWr16NMYaHH364pP5169Zx8803B03+aEAVhnI0ztfS99iuXi+P9LCRlgZ16uD69vzMlV5QoPMY0Uhpz08Qn6tq1aqxY8cOFi9eDMDhw4f5+eefKS4uZtOmTfTt25enn36aPXv2cODAgWNclLvz22+/0bZtWx566CG6dOnC6tWrOf/883njjTc4cOAAAFu2bGH79u1l1lPVUIWhHM2FF5IH/Bc7HCUQ3slud3btIgU7gfUrdh4D0HmMaMRx+3IUQX6u4uLimD59Og899BDt27enQ4cOfPPNNxQVFXHdddfRtm1bOnbsyL333ku9evWOcVHuzvPPP0+bNm1o3749NWrU4IILLqB///5ce+21dO/enbZt23LFFVewf/9+UlJS6NGjB23atKnyk94Rd0Meqk3XYVSczA8/NCY52bzprL+407Xu4rbbIiOQ4+78IkeeJUF2dx6T9ziS6zCmTrX3TiQk62pKQ92bl05lXoehVHa2bIHcXD50dm8C+4r+9NMyCoUQ56vUZdb7CUSut6MEjuP2heJi+1d9hEUdqjCUIxQUANauORHo4EqP1BCQ44zw2gYNaIMdJsNLzGRFUcKDKgzlCElJFAHboMQ6CYh4PAo5dIgLsSs/88PlBFHxCTuCoUQj/tw7VRjKEZo2ZXZSEgbo6UqL9BCQY7+/AygEvgNd8V1JqF69Ojk5Oao0ohBjDDk5OVSvXr1C5cK6cE+p5DRowNrLL4d33+UOgNRUqywiOdbsDIf1BN4EPsQx9VVLqYjTrFkzNm/ezI4dOyItSpkcOnSowi/GaMeXNlevXp1mzbytky4dVRjKUSzMy+Okk06i02+/RVoUi7PiezBwM/C1e7oSURITE2nZsmWkxSiXefPmlazOjhVC1WYdklJKKC4u5osvvqB1a89AiBHEsZRqgHUwthYiP0ymKDGKKgylhJUrV5KXl0e1atUiLcoR3MK2tgFygdVjx6pJpqJEAFUYSgmuyFuhinDnN479/oMzZyIi/Hv79khLpCgxiSoMpYRff/0VgIEDB0ZYEu9ccuAAPZKSWDx+fMjiKSiKUjqqMJQStm7dSlJSEnXr1o20KMfixFNolZ/PMqBII/ApSthRhaEA1i573759NGnSJNKieMdZj7EWyAdWga7HUJQwowpDAWD79u0UFRUxfPjwSIviHWfdxQBnd5ZHuqIooUcVhgLAokWLADjnnHMiLEkpOOsurnR2P/ZIVxQl9KjCUAB46qmniIuLo1OnTpEWxTvOeoyTgFrA/4B9NWroegxFCSOqMBQAfvjhB2rVqlW51mC446zHkNRUumLjjX931126HkNRwogqDIWNGzeSn5/PSSedFGlRysZZjzHOCcH5fYMGERZIUWILVRgKGY5pateuXSMsiW+ceeaZNG/enO+//z7SoihKTKEKQ+GLL74AoF+/fhGWxHcaNWpEZmZmpMVQlJhCFYbCtm3bqFOnDg0bNoy0KD6Tm5vLtm3b2L17d6RFUZSYQRVGjFNUVMQff/zBNddcE2lRKsSFF14IwCuvvBJhSRQldlCFEctkZPBDs2bs27ePntOnw65dkZbIZ6699loA3n///QhLoiixgyqMWMXxzTT+jz8AODUnB7KyosY3U/v27UlMTGTdunWRFkVRYgZVGLGK45tpKSBAF4Di4qjxzRQfH8+f/vQncnNz2a7uzhUlLKjCiFUcH0zZQCPcHoQo8s30/PPPA3bRoaIooUcVRqzSvDm/AwVAa4/0aKFz584ArFixIrKCKEqMoAojVhk3jsykJABKvEfFxUWVb6aUzz+nlgivPfigBlRSlDCgCiOG2Z+YCEAfgJQUSE2NHt9MzqR9ijH8BmzTgEqKEnJUYcQizst2x8GDAJwNkJcXUZEqjDNpf66z+xVoQCVFCTGqMGIR52U7B2gF1AP7st2yJaJiVQhncv5SZ/czj3RFUYKPKoxYJDubAmABkOieXlAQGXn8wZmc7+vsLvVIVxQl+KjCiEWaN+dT59/u7unOJHhU4ARUqgm0AHYDJCdH1aS9okQbYVUYIjJARNaIyDoRGe3leCsRWSwi+SJyf0XKKhVg3Dg+jo8HYLArLTkZmjaNlEQVxwmoRGoqQ4EdwMEXX4yeSXtFiULCpjBEJB6YAFyANf2/RkRae2TbBdwFjPejrOIraWl817gxAP3AWkdNmgTRFpDICajU87//pRj4KJp6SIoShYSzh9EVWGeMWW+MKQCmAZe4ZzDGbDfGLAUOV7SsUjE27N5N/fr1STAGNm6M6i9zV+Cnp556KsKSKErVJiGM52oKbHLb3wx0C2ZZERkBjABo3Lgx8+bN80tQgAMHDgRUvjJz8OBB8vLy6N2791FtjOY216pVi7Vr11ZI/mhur79om2ODULU5nApDvKSZYJY1xkwCJgF06dLF9OnTx2fhPJk3bx6BlK/MfPnllwDce++9R7Uxmtt8+umn891339G+fXvq16/vU5lobq+/aJtjg1C1OZxDUpuBE932mwFbw1BW8eDDDz8Ejvhiqgr06tULgBkzZkRYEkWpuoRTYSwFThGRliKSBFwNfByGsooHn376KXFxcT5/iUcDroiBH3zwQYQlUZSqS9iGpIwxhSJyB/AFEA+8YYz5WURGOscnisjxwDKgDlAsIvcArY0x+7yVDZfsVY1t27aRkpJCXFzVWYbTsWNHTjrpJNavXx9pURSlyhLOOQyMMZ9CyZoxV9pEt///wA43+VRWqTiHDx8mPz+f1NTUSIsSdG7s1IlHp09nvwi1U1PtIr4otv5SlMpG1fnEVHxi4cKFAJx22mkRliTIZGRw6qxZAGSCDTer3msVJaiowogx/vOf/wDQr1+/CEsSZNLTOeGwXb4zzZWm3msVJaiowogxatSoQVxcHIMHD460KMElK4seWPvrxR7piqIEB1UYMYZrrULt2rUjLUpwiY8nDkgFsoB8t3RFUYKDKowYIj8/n/nz59OyZctIixJ8iooAOB+7onOmR7qiKIGjCiOGmD17NocPH6ZRo0aRFiX4OFZfVzq7JeZ0IjrxrShBQhVGDOGa8L7kkirot3HcOBChL5AMlAy4GaMT34oSJFRhxBDfffcdUAUtpMCutzCGOKAjbhH4QCe+FSVIqMKIITZu3GhdmieEdb1m+HCGpboBS4CFrnQdllKUoKAKI0bYvXs3eXl5tGrVKtKihA5nWOpcZ3eyK12HpRQlKKjCiBGWLFkCwN/+9rcISxJCnGGp/tj1GN+5H8vOjoxMilKFUIURIyxZsgQRoVs3X2NWRSmpqSQADbDrMUqItvCzilIJUYURI8yYMYPq1atTp06dSIsSWsaNg8REWgOHgC2u9P37dR5DUQJEFUYskJHB+hUrSMjLgxYtqvaLMy0N6tThHGe3ZOK7oEDnMRQlQPxSGCLSWkQuEBGvrsiVSkRGBkW33MI+Y2gMseHFNSeH65x/jxqWUvNaRQkIf3sYf8OujRohIm8FUR4l2KSn821eHga7PgGo+l5c4+P5E9ADeNsjXVEU//HXIP+/xpj3gfeDKYwSArKz+cj590KP9CqL4z+qGbAIyAaau6UriuIf/vYwzhKRj0Rksoj8JagSKcGlefOSYZlLPdKrLM4CPleP6l2PdEVR/MNfhbHSGHMZcBswN4jyKMFm3Dj2xMXRCajrSktOttZEVZVx4yA5mauc3TlQ9dusKGHAX4VxkYjcCZxkjPkhmAIpweXwkCF8m5jImbVqWRcZqakwaVLVjnWdlgaTJtEiNZUk4Me4uKrfZkUJA+UqDBF5VETu80i+ClgLXCYik70UUyoJn376KQfz86l2yy1QXAwbN8bGizMtDTZupMWpp7KzuJh9gwZFWiJFiXp86WFcD7zqnmCM2YadUxRjzC2hEEwJDrNmzQLg3HPPLSdn1WTYsGHAEdfuiqL4jy8KI88Yk+sl/W0oMXdXKiMZGSx55x0A+t92W9Vee1EK999/PzVq1GDZsmWRFkVRoh6fFIaInOCZaIwpAAqDL5ISFDIyYMQINhcWUhtI3LSp6i/Y80JiYiIdO3Zk3rx5kRZFUaIeXxTGs8AsETnKJlFEjgOKQyKVEjjp6RTn5rIPON6VVtUX7JXCoUOHWLFiBQcPHoy0KIoS1ZSrMIwxHwATgOUi8omI/F1E/oFdEzU+1AIqfpKdzX7sDe7skR5r9O7dG4Dp06dHWBJFiW58Mqs1xrwFtMSu7E7EOgK9xhgTW+Mb0UTz5qwBioDLPNJjjWuuuQY4YgCgKIp/+LwOwxiz3xjztjHmIWPM48YYnUWszIwbx8dOKNburrQYXbzWZc0a4oGlM2ZUfW+9ihJC1L15VSUtjUk1apAENIuVBXveyMhAbr2VJsBWoCgWvPUqSohQhVFFKS4uZueBAzT/059ia8GeJ+npkJvLEKyFxgqI2cl/RQkUVRhVlIULF2KMoUuXLpEWJbI4k/zpQA2gxBe/xsZQlAqjCqOK8uGHHwIwcODACEsSYZxJ/vrAaUDJtLcI7NoVIaEUJTpRhVFFWbRoEQCXXnppOTmrOOPGWeWAXWWaDewBMAa2bCm9nKIox6AKo4pSXFxMq1atqFmzZqRFiSxpaVY5AC5vWiWrMQoKIiGRokQtqjCqKL///jtnnXVWpMWoHDiBk1yOz2a60pOSIiCMokQvqjCqGhkZZDdrxh9//EHKBx+o+SiUBFTqiI1JvAzsmpSmTSMrl6JEGWFVGCIyQETWiMg6ERnt5biIyIvO8R9FpJPbsY0i8pOIrBARXTToDcfh4AfO2Hyt/ft1zQGUBFSS1FRaANuBw6+8Ag0aRFgwRYkuwqYwRCQe65PqAqA1cI2ItPbIdgFwirONwCMOB9DXGNPBGBPjtqKl4Kw5mOPsXgq65sCFE1DpkTfewADfn3ZapCVSlKgjnD2MrsA6Y8x6xzX6NOASjzyXAG8by7dAPW+u1ZVScNYc/Igdemnjka7AgAEDALtORVGUihFOhdEU2OS2v9lJ8zWPAeaIyHIRGREyKaOZ5s0pAkrCIbqlK5YTTjiB+vXr8/zzz0daFKWqkZFhfZXFxUHDhlCrljXpFrH7VWBoOCGM5xIvaaYCeXoYY7Y6cTj+KyKrjTHzjypsFckIgMaNGwcUNOfAgQPRF3Tnuef4+euvMS++SIt27Zh3ww324U1NBR/aEpVt9oPGjRuzevVqli9fHmlRwk6s3GN3gt7mXbvsGp6CAmtp5zKe2L4d7ryz9HJ//AHPPnukTAjn0EJ2n40xYdmwTlO/cNt/GHjYI89rWLfprv01wAle6hoL3F/W+Tp37mwCITMzM6DykWLGPfcYwHwOxqSmGjN1qs9lo7XNFeWNN94wgLnwwgsjLUrYiZV77E5Q2jx1qv09gTEi9q9rS042JiXF5IJZD2YmmDvANANTHUwqmL+A2e1ZpgK/zYoSSJuBZaaU92o4h6SWAqeISEsRSQKuBj72yPMxcINjLXUmsNcY87uI1BSR2gAiUhPoD6wMo+xRw6KEBJKSkuidlxe7DgfL4ZJL7NRZLPYwFB/xHF666SYOZ2XxOXCzMbQEkoHqQLXcXBJyckgGTgIGAxOx4+lFQBbwHNAQuB3IBWuMct11kJBgh6yixO1+2BSGMaYQuAP4AvgFeN8Y87OIjBSRkU62T4H1wDpgMjDKSW8MLBSRH4AlwGxjzOfhkj2aePfdd0lNTaV69eqRFqXS0qBBA06oV49t27ZxMIp+rCHB88XYsKH9v0ULGDXqyLFYuEauayEC118PWVnsN4apOTn0LyigNtaMczrQBSgADgO1gFSgI3ArsADYh1UWBVi3+g9gnV++ApwMjAFWARQV2XNnZdlzjnK98ioppXU9on2LxSGp/Px8A5iOHTv6VT4a2+wXU6eaW+PjDWA+DdMQQWUhMzPTtjMlxRgwxWC+B/MamPFgngHzIZiN7sMn3q7RbbcZEx9/9PEKDoGGi5Ln2n1YySW7I/PeSZPMtMREcxOYS8F0AZNk509Ltngw54M55LT3NzAFrranpNjr4+26OVsxmAVgerrV+Wcw/3HPJxKUaxiqIamIv9hDtcWiwpg7d64BzA033OBX+Whss1+kppqDYBLj4839ni+8Kk7mhx8ak5hoCsC8BeZ4j5ei+9YSzNlg0sD8HcxHYNY1aWKKRo4s88VY8kK+7TZ7UteLWiQ8SsVDmWWOH3/svAOYZWCuA3MiGHHaLGBaO4qhI5geYO4CsxDM4dLa6lKk7u1MSTGmZs1SFcdMMKe5XesTwHwXxOdQFYYqjHJJT083gJkwYYJf5aOxzX7hvDzatWxp2np+3VVVnJdZ5vjxZgmYU50X1fFgTgfzAJhHwYwCMwzMC2AGO1/VnookDkwj50VbH0xDMC2cL+ebwLzkfElvA2POPdf7l3dKytGKw63X4/W4j+3z9oL+8umnzUowk8EMcZRfX6cdLiXRFMwVYN50XujlKkSXAvJVAZYi309gznLkSMDpbQThOVSFoQqjXHr27GkA8+uvv/pVPhrb7BfOD/fkJk0MYHYG8cuuUuFh2bMbTLdWrQxg6jhfuUXlvBgPOy//V8DcDeaSGjXMADAjwdwIpgFHvs69bUmOUjoDzNVgHgfzFZh8zy/zxMRjz5+U5PPLuKhGDbMZ2wuaDOYxMOeAqQ1GRI6Rq72j3D4EU+iLgkhMtEos0F7S1KleFegsbI+mGphFjRv7V7cboVIY4VyHoYSYzZs3U61aNf70pz9FWpTKzbhxMGIE7Vq25LetW3kfuC052aZXFRy/YuTmcgi42xjeAApXr+Y44B2sqWF5JAA9nY3kZBsXfujQI5O12MndnViroPXYieD62EndZ4BdwB9YM0kXAjTJzWX39ddTR4QGxcU0Bk7ATh63BuIKCjh4zz3gGHAkJCSQk5NDQUEBubm5rFu3jgULFrBl1Sr2FhdT7FF/Q6xVT5OUFE7buZPTgDOB84DjPBuakgJ5edZ6qaQSsa/z1FT7bATD4tBVR3r6UVEfLwbOAs4Aztu9m7VbttC0MjrHLE2TRPsWaz2M4uJi06xZM3PllVf6XUe0tTkgpk41/x492gCmu69fstGAM36/ETuRfReYGs5XdSKYIb17lz7kUrPm0V/Rt93mfe7httvK/yL30lNZCmYCmH86PYAhYFKcr+qyeimlbQkJCQanfalgeoO5Hcw8jkxMG5w5jLLk8zYHEa4JfI9zPnX11QYwf/7zn01xcbHf1WoPQymTrKwsNm/eTK9evSItSnSQlkbLzExqvfwyywsKMNde69XNQFQxahTfvfoqY6DEAWUycCrQD3gMWDZoEPL110eXS0mBF17w/Qv6lVfs30mTjuppeOXcc2HxYhJyc+mCNUc9CidWCVlZ7AdWYyMjxgE7gLm1a8PNNyMiFBUVUa9ePXr16kWXLl2oWbMmxcXFJJ16asVjtMfFQXHxsb2HcK9bSks76pwPAu+vXcvy5csZP348DzzwQHjlKY/SNEm0b7HWwxg+fLgBzKJFi/yuI9raHCiZmZnm/PPPN4BZsGBBpMUJmKVxcaYaRyaqn+LYOYqSr+1QmBG7Wyd5Wkm5T2h7+7IPcA6jLJPWzPHjjzGjrcxs2bLFxMfHm8TERLNjxw6/6qgKK72VEDJ//nxEhK5du0ZalKjikUceAeDLL7+MsCSBsXPnTq4qLqYIqAt8jl0sdtQP3IltTmqq7R0E+2v6lVeg0JlCLiw80hNJS4OdO2HqVHtukaNlSEuDN9+0PR0XKSnwxhu+yejEOzmq7qlTj6iMzp2PyBUF3g+aNGnCo48+yuHDh7n00ksjLc5RqMKoImRnZ5OSkkJCgo4yVoRevXpxxhlnMGfOnPIzV1KK33mHC5o2JRs7nJMBnI+HJ8/UVHjnHfvyjNRL04lJQnHxsTK4lIrrJb9zZ8VkLKvuKGTMmDGcc845LFy4sFK54leFUQU4cOAAhw4dItU1HqxUiLPPPpvFixezYcOGSItScTIy+GT4cJYVFHAcMAgY4JnnttuqxEs0lhARPv74Y5o3b86tt95Kfn5+pEUCVGFUCb755hsATj/99AhLEp2c5kTfe+qppyIsiR+kpzO+oIBU4Aes07sS4uOtsnANDSlRRc2aNXnsscdYtWoVw4cPj7Q4gCqMKsEvv/wCwIUXXhhhSaKTG2+8kfj4eKZNm0ZReVY/lYzvsrJYANyJXXfQxHVA5Oh5BCUquf7666lTowYZU6eyshI4ylSFUQXYvn07CQkJDBw4MNKiRCXx8fGcc8457N27l9mzZ0daHJ8xxnBnUhIAaz0PapTFKkHi++/zdlERBhu/2mRl2QWZEVIaqjCqAHPnzqVLly7UqlUr0qJELffeey8AL7zwQoQl8Z2vv/6apQUF1AD+6n6gqq1aj2XS07mkoIAzsKvoXwK7Gj09PSLiqMKIcrZs2cJ3331HnTp1Ii1KVNO/f39q1qzJ4sWLKSwsjLQ4PnHPPfcA8MJNN9HMm7mqEv1kZwMwA/uyfghY5pYeblRhRDkZTte0T58+kRUkyomPj+eNG28kLy+PrxMTIz5WXB7z5s3jhx9+4OSTT2b4669XKZNSxQ1naLEpVmk0Aq4F8k88MSLiqMKIcj7/3AYeTNOXRGBkZDDo3/+mJvAuWFcTERwrLo9p06YB9oNBJOqdmiilMW6cHWLEOih8HTtf9Y/OnSMijiqMKGfNmjUkJibSXCc5AyM9nRp5eRwPvIX1wBrJseKyyM/PZ8aMGVx00UV069Yt0uIoocRjFXunZs2olpDAuI8/Zv369WEXRxVGlLNjxw4aNmwYaTGiH2dMuDd2tfSbHumVgowMdpx4Iv2rV2f79u3c0bp1pCVSwoHbKvaGmzYxYOBAioqKIrI2QxVGFHPo0CEA/coMBk4P7TFn93lXeoMGERDGCxkZmFtuYdjmzcwH+gL9X3qp0g6ZKaHj5ZdfJikpiczMzJIh6XChCiOKWbJkCYcPH2bo0KGRFiX6GTcOEhNpDjTHBv/ZC7B/f+V4Kaenk5GXx6dYH1GTAcnLq5RDZkpoadasGY89Zj9thg8fHla3Iaowopi3334bEVELqWCQlgaOafItWP/g4wAKCirFS3lTVha3A/HA5cDJrgOVachMCRv33XcfTZs2ZcuWLYwdOzZs51WFEcVMmzaN2rVrU69evUiLUjXYtQuA+4EGwBJXeiRfyhkZ0KIF9wKHsJPxD7sfV2OHmKRatWr8+OOPXNm1K68+9RQHwuQ2RBVGlLJ582YOHjxIu3btIi1K1cF5+VYHbgfmY+NUR+ylPGoUXH89ZGWVxLYYDHRyHdcV3TFNg88+474ffmCvMXbOLQym4KowopQ33ngDgEGDBkVYkiqEm817GnZY6pH4+Mi8lDMyYOJEdhnDVmAIdu5ivOu4ruhW0tM5PT+feOBJwmMKrgojSsnMzATghhtuiLAkVQg3m/dTgWQR3hOh8Kqrwi9LejqFxtAfaIONb52JM3choiu6FcjOphZwKXAQeNotPVSowohSVq9eTWJiIscff3ykRalaODbvYgzX3HQTBYWFPPfcc+GXIzubUcByYB/wAVBiPK3zFgqUPAevY1/kT2F7xaF8PlRhRBvOJGijP/6gnWtfCQnPPvssIhJ2hZGbm8ugatWYDCQD3wIljutFdN5CsThDqHWBC7Bm4GMSEkL6fKjCiCYyMmDECHZkZbESGHz4cKX2dxTt1K1blx49erBt2zbmzp0blnMWFhYyZMgQPjl0iASssujiOigCI0fqUJRicRtC/T8gCcioXz+kz4cqjGgiPR1yc3ka2/XsB5XW31FV4cUXX0REeCVMkev+9a9/MXv2bOrXr8/TaWm0dXdb/s47GkFPORpnCLWOMYweM4YNO3aQrXMYClAymfUe9sad4ZGuBJ+OHTsyfPhwZs+ezbZt20J6rnXr1jFmzBgGDx7Mhg0buPvtt9VtueIzw4YNA+CJJ55gw4YNITmHKoxoonlzCrFrA1rgdvN0EjSkPPDAA+Tn5/PQySdDXFzIFkilp6djjOG5556jbt26xMXpz1PxnZYtW9K9e3cyMjLIy8sLyTn0ifTAGMNXX31FQUFBpEU5lnHjmJGUhAHOdaXp4q2Qc8qSJRwPvH3wINuNCckCqZ9++on333+f/Px8li5dGrR6ldhi2LBh5OXlER8fH5L6VWF4sOTxxzn33HOZPXFi5Yu6lpbGf86wA1FXgS7eChfp6fwVO290nSstiHNHxpiSmOIDBgzgyiuvDEq9Suxx5ZVXkpSUxJdffhmS+lVhuJORQdennqIL8MXSpZUy6tq64mIAeuTl6bh2uHDWRBwH/Bf41S09IBwT6Rfj4pg7dy7JSUm8+eabGkFP8Zv69etz9dVXh6x+VRjupKdj8vJoAazZvJktYL8k7747snK5kZCQQNu2balevXqkRYkdmjdHgEnO7tVu6X7jmEjnZmXxiJP0JnB8mMx3larLW2+9xe233x6SusOqMERkgIisEZF1IjLay3ERkRed4z+KSCdfywaF7GwEWOnsfuJKz8mpFL2MnJwcFi1axCWXXBJpUWILZ4HUJcApwArgf9WqBTZ35JhITwZygRuBIZXElbqilEbYFIaIxAMTsIsSWwPXiIhnjMkLsL/JU4ARwKsVKBs4zpfkWGd3svuxSvBDfuCBByguLqZfv36RFiW2cFsgtQBoFBfHyKZNKQqk65+dzQGs07jewBtu6YpSWQlnD6MrsM4Ys94YUwBMAzw/lS8B3jaWb4F6InKCj2UDx/livAKoXaMGy6kkMREc5syZQ3x8PD179oy0KLGHs0CqsTH86513WLp+Pffff7//9TVvztXAHxwJC+tKV5TKSjgVRlNgk9v+ZifNlzy+lA2ctDRISSEeuPH88wFKxpcj/UPOz89ny5YtnHzyyWqfH2Guvvpq6tSpw/PPP8+8efP8quOboUOZDTQG+rgS1URaqeQkhPFc3kw/jI95fCmLiIzADmXRuHFj/37MkyZBVhZ9jjuO//vqKxbl5TFn3DiSTj4Z/Hw5BIMFCxYAcOqpp/r9kiqPAwcOhKzuykgg7R07dix/+ctfOO+883jwwQfp16+fz9ZNBw4c4OpnnwXg4Tvv5OvUVEhKgqZNoUGDkD5nsXaPQdscVIwxYdmA7sAXbvsPAw975HkNuMZtfw1wgi9lPbfOnTsbv5k61WS++KL51Col85/77vO/riAxdOhQA5hPPvkkZOfIzMwMWd2VkUDb+8ILLxicZ6Rv374mNzfXp3J9+vQxgLn++usDOr8/xNo9NkbbXFGAZaaU92o4xzaWAqeISEsRScJaJ37skedj4AbHWupMYK8x5ncfywaPtDRo25Zz8/OpW6MGf3/ppZC6hCgTx1Z/81tvkQCcu317eM+vlMpdd93FhAkTABsyNyHBdtgLCwtL7pvnc7N69Wrmz59PvXr1mDx5cik1K0rlJGwKwxhTCNwBfAH8ArxvjPlZREaKyEgn26fAemAd1khpVFllQy1z0gcf0D4/n+8KCpgaIpcQZeLY6hdlZfEjcDlQ/Y47KoWJr2IZNWoUTzzxBGvXrmXQoEEsXryYk44/nnduugmTlQVuz82qp5+mX79+NGjQgAULFlCtWrVIi68oFaO0rke0bwENSRmnS5eaajY6Qw5/tj99u6WmBlS3z6SmGgNmpiPD+yE+f6x13YPZ3smTJ5v4+HiTkpJiWiYkGMD0APM9mFwwL4GpLWKOP/54s2LFiqCdt6LE2j02RttcUagkQ1LRR3Y2qdhFIWuAbLf0cJ0fwGU30yfc51d8Zvjw4SxZsoTU1FQ2FBaSBHwHdATqAXcCZxrD4j/+YGqvXsx9+OFIiqsofqEKoywcU9oHnN3hHunhOv8vQG2gUbjPr1SITp06sWzZMuYcdxy3YBcPnYBdafoVdjy1MTB+3z6WPPkkjBoVQWkVpeKowigLxyXEcKzjuflAYY0a4bOVHzeOjdWrcwD4sytNbfUrNSJCv+ee4+XkZBYBW4H/AX2BL7HmfgA1ASZO1PkoJapQhVEWjksISU3lBSAf+Pruu8PnITYtjWecVd03gbozjxbcXIkgUrKI6BDgitlXF+yMVCVwOaMovqIKozwclxCX5OZSq1YtXt+4kUOHDoXt9DNXrSIuLo7hBQXqzjyacJ4biout4gAGYefCXsdavAE6H6VEFaowfKRGjRr06dOHadOmMWnSpPILBIG9e/eyY8cOLr74YhITE8NyTiUEjBsHzirwOsDNQC3XMZ2PUqIIVRgV4K9//SsAY8aMoaioKOTnmzVrFocPH+ZhtaiJbtLSYOTIEqVRgs5HKVGGKowK0K1bN84++2z27t3Le++9F/Lz/fvf/6ZGjRp06dIl5OdSQswrr8A775TMa+h8lBKNqMKoII88Yv3XPjp0KEYkNO5CMjLIb96chfPnUzc/n7h33w1u/UpkcJ/X0PkoJQpRhVFB+u3YQV1gQ2Ehq8C6fbj++uDZ1I8aBddfz7ObNlEMXFtcXOniiiuKEpuowqgg8Y8+yr1YXx2rXYnGBMemPiMDXn0VjGEi1qf7Y2Djiqv5paIoEUYVRkXJziYdaAU8Axx2pQfDpv7uuwH4DRstqi3WqsZ1XkVRlEiiCqOiNG9OAjAS6ytooPuxQF/qOTkAuKbT7/E4r6IoSiRRhVFRHJv6G4B44L/AWtexIL3UV2Ht9K/3PK+iKEoEUYVRURyb+voiJat1/wmB29S7AuwA07CODkvi59asqRY1iqJEHFUY/uDY1P/l+OMBeBv4/amnAnupO/MftwBFwDD3Y6+95n+9iqIoQUIVhr+kpdHt99/p0KEDRcCTa9eWW6RMsrPZDSzCesZt73EuRVGUSKMKI0AmTpxIUlISmzZtCqyi5s15FmuuO9I93XFcpyiKEmlUYQRIt27duP/++5k5cyYrV670r5KMDIr27eMF7A1xBWxSX0OKolQmVGEEgfvuu4/q1atz3nnnVdz1eUYGjBjBmN27OQDcgOPJNCVFfQ0pilKpUIURBBo0aMAVV1zBtm3bePDBBytWOD2d/bm5/BsbyrNkertWLVUWiqJUKlRhBIkJEyZQvXp1JkyYwNatW30vmJ3NFGwktolAklu6oihKZUIVRpCoXbs2zzzzDMXFxQzs3t16sY2LK92bbUYGtGjBImO4G0gFerof15XdiqJUMlRhBJHbb7+d05o0YUV2Ni9nZVn/UllZx3qbdTzSFmZlcSHWMmoKlMR+1sluRVEqI6owgoiI8LUIDbGrvze6Drh7mx01qsQj7WBgH3aRXh9XXg2soyhKJSWh/CxKRWi0dStzgd7YIaZ/4viEys62vYyJEwG4CJgNnIDbRLeIDayjKIpSCdEeRrBp3px2wBfYiewbgCHAD40bYx55hGxjuAerLE4EfsFtolvnLRRFqcSowgg248ZBcjJdgY+BmsAHQIc//iAuO5tU4AXgVmA9UNdVTkTnLRRFqdSowgg2aWl2DiI1lQtE2N28Oa8PH06fPn04LTGRoViPtBPxGA8cOVLnLRRFqdToHEYoSEsrefknAjc7m2tVN7m5R/KKWGXxyisREFRRFMV3tIcRTtx6H4jYv++8o8pCUZSoQHsY4cat96EoihJNaA9DURRF8QlVGIqiKIpPqMJQFEVRfEIVhqIoiuITqjAURVEUn1CFoSiKoviEGGMiLUNIEJEdQFYAVTQEdgZJnGgh1toca+0FbXOsEEibU40xjbwdqLIKI1BEZJkxpkuk5QgnsdbmWGsvaJtjhVC1WYekFEVRFJ9QhaEoiqL4hCqM0pkUaQEiQKy1OdbaC9rmWCEkbdY5DEVRFMUntIehKIqi+ETMKQwReUNEtovISre0BiLyXxFZ6/ytX0rZASKyRkTWicjo8EntP/62V0ROFJFMEflFRH4WkbvDK7n/BHKPnbzxIvK9iHwSHokDJ8Dnup6ITBeR1c797h4+yf0nwDbf6zzXK0XkXRGpHj7J/aeUNl/ptKVYREq1jArG+yvmFAYwBRjgkTYamGuMOQWY6+wfhYjEAxOAC4DWwDUi0jq0ogaFKfjRXqAQuM8YcxpwJnB7lLQX/G+zi7ux4dajiSn43+YXgM+NMa2A9kRP26fg32+5KXAX0MUY0waIB64OrahBYwrHtnklcBkwv7RCwXp/xZzCMMbMB3Z5JF8CvOX8/xYw2EvRrsA6Y8x6Y0wBMM0pV6nxt73GmN+NMf9z/t+PfYk0DZ2kwSOAe4yINAMGAq+HSr5Q4G+bRaQO0Av4t1NPgTFmT8gEDSKB3GdsLKAaIpIAJANbQyFjsPHWZmPML8aYNeUUDcr7K+YURik0Nsb8DvZFCRznJU9TYJPb/mai5AXqBV/aW4KItAA6At+FXrSQ4WubnwceBIrDJFco8aXNJwE7gDedYbjXRaRmOIUMMuW22RizBRgPZAO/A3uNMXPCKmX4Ccr7SxWG74iXtCpvYiYitYAPgXuMMfsiLU8oEZGLgO3GmOWRliWMJACdgFeNMR2Bg5Q9XBf1OPMalwAtgSZATRG5LrJShZygvL9UYVi2icgJAM7f7V7ybAZOdNtvRpR0Y73gS3sRkUSsssgwxnwURvlCgS9t7gFcLCIbsV32c0RkavhEDDq+PtebjTGu3uN0rAKJVnxp83nABmPMDmPMYeAj4KwwyhgJgvL+UoVh+RgY6vw/FJjlJc9S4BQRaSkiSdhJso/DJF+wKbe9IiLYce1fjDHPhVG2UFFum40xDxtjmhljWmDv71fGmGj+8vSlzX8Am0Tkz07SucCq8IgXEnz5LWcDZ4pIsvOcn0v0TPT7S3DeX8aYmNqAd7HjloexWvdmIAVrUbHW+dvAydsE+NSt7IXAr8BvQHqk2xLK9gI9sV3WH4EVznZhpNsT6nvsVkcf4JNItyUcbQY6AMucez0TqB/p9oShzX8DVmMtjN4BqkW6PQG0+VLn/3xgG/BFKW0O+P2lK70VRVEUn9AhKUVRFMUnVGEoiqIoPqEKQ1EURfEJVRiKoiiKT6jCUBRFUXwiIdICKEpVQkSKgJ+wv60NwPUmSnwzKUp5aA9DUYJLnjGmg7FeUHcBt0daIEUJFqowFCV0LMZx8CYiJ4vI5yKyXEQWiEgrEakrIhtFJM7JkywimxyXLIpS6VCFoSghwIk/cC5H3C9MAu40xnQG7gdeMcbsBX4Aejt5BmFX6R4Ot7yK4gs6h6EowaWGiKwAWgDLgf86Hn/PAj6wrosAqOb8fQ+4CsjE+vd5JZzCKkpFUNcgihJEROSAMaaWiNQFPgE+wEZJW2OMOcFL/lrAz9h4IyuAlsaYovBJrCi+o0NSihICnOGmu7DDT3nABhG5EqwnYBFp7+Q7ACzBhkn9RJWFUplRhaEoIcIY8z12juJqIA24WUR+wPYo3MNjvgdc5/xFRLqISFSFiFViAx2SUhRFUXxCexiKoiiKT6jCUBRFUXxCFYaiKIriE6owFEVRFJ9QhaEoiqL4hCoMRVEUxSdUYSiKoig+oQpDURRF8Yn/B8S4V5j4uEZ2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    #Index from each dataset\n",
    "    iTrain_ = []\n",
    "    iVal_ = []\n",
    "    iTest_ = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    t_train = []\n",
    "    t_val = []\n",
    "    t_test = []\n",
    "    title_n_Cm = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_m$ prediction, $L_2$ error=%.4f'%(l2_error_Cm)\n",
    "    \n",
    "    title_Cm = title_n_Cm\n",
    "    savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "\n",
    "    predictedValue = predicted[t_len*i:t_len*(i+1),:]\n",
    "    y_corres = y[t_len*i:t_len*(i+1),:]\n",
    "    \n",
    "    l2_error_Cm = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    print('L2 error of Cm: {0:0.4f}'.format(l2_error_Cm))\n",
    "    \n",
    "    cm_ = predictedValue#denormalize(predictedValue)\n",
    "    Cm = y_corres#denormalize(y_corres)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        iTrain_.append(predicted[index])\n",
    "    for jj, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        iVal_.append(predicted[index])    \n",
    "    for kk, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & (index_test>=i*t_len))]):\n",
    "        iTest_.append(predicted[index])\n",
    "        \n",
    "#     iTrain = denormalize(np.array(iTrain))\n",
    "#     iTest = denormalize(np.array(iTest))\n",
    "#     iVal = denormalize(np.array(iVal))\n",
    "    iTrain_ = np.array(iTrain_)\n",
    "    iVal_ = np.array(iVal_)\n",
    "    iTest_ = np.array(iTest_)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        t_train.append(t[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        t_val.append(t[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & ((index_test>=i*t_len)))]):\n",
    "        t_test.append(t[index])\n",
    "        \n",
    "    tTrain = np.array(t_train)\n",
    "    tVal = np.array(t_val)\n",
    "    tTest = np.array(t_test)\n",
    "\n",
    "    # Cm graph plot\n",
    "    ## Training dataset\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm_), 'k--', label='Predicted value')\n",
    "    #plt.scatter(tTrain, iTrain, color='b', label='Training set')\n",
    "    #plt.scatter(tVal, iVal, color='g', label='Validation set')\n",
    "    plt.scatter(tTrain, denormalize(iTrain_), color='b', label='Training set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    #plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Validation dataset\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm_), 'k--', label='Predicted value')\n",
    "    plt.scatter(tVal, denormalize(iVal_), color='g', label='Validation set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    #plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Test dataset\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm_), 'k--', label='Predicted value')\n",
    "    plt.scatter(tTest, denormalize(iTest_), color='r', label='Test set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    #plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f20d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "47c328a4527b1c811974d07e6cb5295efd3040c2b3e7cb17d9e712631aaeff5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
