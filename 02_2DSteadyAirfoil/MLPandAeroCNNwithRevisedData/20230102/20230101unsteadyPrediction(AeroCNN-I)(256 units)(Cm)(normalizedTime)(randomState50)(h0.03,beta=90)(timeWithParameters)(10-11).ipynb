{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of the steady-state simulation - Case 2: AeroCNN-I\n",
    "##\n",
    "## 1. Train/Validation/Test dataset ratio = 0.7/0.2/0.1\n",
    "## 2. Using CNN structure to extract geometry features (characteristics)\n",
    "## 3. The time interval used to train is revolution 10 to 11.\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from scipy import interpolate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining parameters and hyperparameters of the model\n",
    "\n",
    "n_kernels=200 # Number of filters (kernels) in Convolutional layer\n",
    "n_units=256 # Number of units in the hidden layer of the MLP network\n",
    "n_layers=5\n",
    "input_size = 110 # Size of input for the network (110 coefficients and 3 other parameters, time, h, beta)\n",
    "lr = 1e-04 # Learning rate of the network\n",
    "test_rate = 0.1 # Defines the ratio of test dataset\n",
    "val_rate = 0.2 # Defines the ratio of validation dataset\n",
    "batch_size = 200 # Mini-batch size\n",
    "l2_regularizer=1e-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0439fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of revolution\n",
    "t_lower = 10 # Lower limit of the interval of time\n",
    "t_upper = 11 # Upper limit of the interval of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing working directory\n",
    "\n",
    "main_directory = 'D:\\\\VAWT_data\\\\flap_steady\\\\flap_steady'\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ec4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case number: NACA 0018 without Gurney flap - case 0\n",
    "# the others, which are Case 1,2,4,5,7,8,13,14,15,16,17,18,19,20,21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb294db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic parameters\n",
    "\n",
    "c = 1 # Chord length\n",
    "h = np.array([0.01, 0.02, 0.03]) * c # Height of the Gurney flaps\n",
    "thickness = 0.02 * h # Thickness of the Gurney flaps\n",
    "beta = np.linspace(30, 90, 5).reshape((5,1))\n",
    "\n",
    "beta = beta[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18aaa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.reshape((-1,1))\n",
    "thickness = thickness.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9745480",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interval = 0.001\n",
    "t_len = int((t_upper-t_lower) / t_interval)\n",
    "\n",
    "n_beta = len(beta)# Number of the Gurney flap inclination\n",
    "n_h = len(h) # Number of the height of the Gurney flaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d7f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Input dataset\n",
    "# Defining time as input\n",
    "\n",
    "main_directory = 'D:\\\\VAWT_data'\n",
    "cm_dir = main_directory + \"\\\\blade_1_cm_data\"\n",
    "cm_list = os.listdir(cm_dir)\n",
    "os.chdir(cm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5014fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_target = [file for file in cm_list if file.endswith('.csv')]\n",
    "cm_target = sorted(cm_target, key=lambda s: int(re.search(r'\\d+',s).group()))\n",
    "cm_target = [cm_target[-8],]\n",
    "n_data = len(cm_target) # Number of txt files from which the aerodynamic coefficients are extracted\n",
    "n_cases = n_data * t_len # Total number of cases(Number of geometries * Number of angles of attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d3bbcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['case15cm_blade1.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62d3c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create input and output data\n",
    "### This function is the main framework where data are reordered with respect to the shape the NNs require.\n",
    "### Each input features are made by calling the corresponding functions, which generate the data,\n",
    "### e.g., time, cm, h, beta, coordinates of airfoil and Gurney flaps, etc.\n",
    "def genereate_input_output(cm_target, n_beta, t_len, normalize:bool=False):\n",
    "    \n",
    "    input_time_cm = time_and_cm(cm_target)\n",
    "    t = input_time_cm[:,0].reshape((-1, 1))\n",
    "    cm = input_time_cm[:,1].reshape((-1, 1))\n",
    "    \n",
    "    #hh = generate_h(n_beta, t_len, normalize)\n",
    "    #bb = generate_beta(n_beta, t_len, normalize)\n",
    "    total_coords = generate_coordinates(n_cases)\n",
    "    \n",
    "    # Concatenate data for input dataset\n",
    "    x_time = t\n",
    "    x_coord = total_coords.reshape((t_len,2,55,1))\n",
    "    \n",
    "    # Generating output dataset (depending on whether the data be normalized or not)\n",
    "    if normalize==True:\n",
    "        y = (cm-np.min(cm))/(np.max(cm)-np.min(cm))\n",
    "    else:\n",
    "        y = cm\n",
    "    print(\"Dimension - x_time: \", x_time.shape)\n",
    "    print(\"Dimension - x_coordinates: \", x_coord.shape)\n",
    "    print(\"Dimension - y: \", y.shape)\n",
    "    \n",
    "    return x_time, x_coord, y, t, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa96208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating time for input, and Cm (moment coefficient) for output\n",
    "def time_and_cm(cm_target):\n",
    "    cm_df = pd.DataFrame()\n",
    "    for i, file in enumerate(cm_target):\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        data = pd.read_csv(file, header=None)\n",
    "        df = pd.concat([df, data], axis=0)\n",
    "        \n",
    "        time = df.iloc[:,0].values\n",
    "        cm = df.iloc[:,1].values\n",
    "        \n",
    "        time_beUsed = time[np.where(np.logical_and(time>=t_lower, time<t_upper))]\n",
    "        cm_beUsed = cm[np.where(np.logical_and(time>=t_lower, time<t_upper))]\n",
    "        \n",
    "        # Handle the time that is duplicated because of digits\n",
    "        # Also, outliers are regulated at the second conditional statement.\n",
    "        time_beUsed = handler_time(time_beUsed)\n",
    "        cm_beUsed = handler_cm(cm_beUsed)\n",
    "        \n",
    "        linear_func = interpolate.interp1d(time_beUsed, cm_beUsed,\n",
    "                                           bounds_error=False,kind='quadratic',\n",
    "                                           fill_value='extrapolate')\n",
    "        time_interp = np.arange(10, 11, t_interval).reshape((-1,1))\n",
    "        cm_interp=linear_func(time_interp).reshape((-1,1))\n",
    "        \n",
    "        cm_df = pd.concat([cm_df, pd.DataFrame(np.hstack((time_interp, cm_interp)))], axis=0)\n",
    "    \n",
    "    input_time_cm = cm_df.iloc[:,:].values\n",
    "    print(\"Dimension - time and Cm: \", input_time_cm.shape)\n",
    "    return input_time_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c96f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling duplicated time value\n",
    "def handler_time(time_beUsed):\n",
    "    for i in range(len(time_beUsed)):\n",
    "        if time_beUsed[i]==time_beUsed[i-1]:\n",
    "            time_beUsed[i] += 0.0005\n",
    "            \n",
    "    return time_beUsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d715ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outlier, (if there are)\n",
    "def handler_cm(cm_beUsed):\n",
    "    period = int(len(cm_beUsed) / 5)\n",
    "    for i in range(len(cm_beUsed)):\n",
    "        if np.abs(cm_beUsed[i]-cm_beUsed[i-1])>0.3:\n",
    "            cm_beUsed[i-1] = cm_beUsed[i-1 + period]\n",
    "            \n",
    "    return cm_beUsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "937cc8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining beta, the Gurney flap inclination\n",
    "## In case of mere NACA0018, the bb in those indexes are considered as zero.\n",
    "def generate_beta(n_beta=n_beta, t_len=t_len, normalize=True):\n",
    "\n",
    "#     beta_0 = np.zeros((t_len,1)) # Values for sheer NACA0018\n",
    "    b_ = np.ones((t_len,1)) # Template for the inclination for a single h and single beta\n",
    "    bb_imp = np.zeros((t_len*n_beta,1))\n",
    "\n",
    "    for j in range(n_beta):\n",
    "        b_imp = b_ * beta[j]\n",
    "        bb_imp[t_len*j:t_len*(j+1),:] = b_imp[:,:]\n",
    "\n",
    "    bb_imp = bb_imp.reshape((-1,1))\n",
    "    bb = bb_imp\n",
    "    if normalize==True:\n",
    "        bb = bb / np.max(beta)\n",
    "    \n",
    "    print(\"Dimension - inclination(beta): \", bb.shape)\n",
    "\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6302058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Gurney flap height\n",
    "## In case of mere NACA0018, the hh in those indexes are considered as zero.\n",
    "def generate_h(n_beta=n_beta, t_len=t_len, normalize:bool=True):\n",
    "    #hh = np.concatenate((np.zeros(t_len), h[0]*np.ones(n_beta*t_len), h[1]*np.ones(n_beta*t_len), h[2]*np.ones(n_beta*t_len)))\n",
    "    hh = h[0]*np.ones(n_beta*t_len)\n",
    "    hh = hh.reshape((-1,1))\n",
    "    \n",
    "    if normalize==True:\n",
    "        hh = hh / np.max(h)\n",
    "    \n",
    "    print(\"Dimension - heights of Gurney flaps: \", hh.shape)\n",
    "    return hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2d882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generates coordinate data of NACA0018 airfoil and Gurney flaps\n",
    "## AeroCNN-1: coordinates are replaced with grid data of 2*50 shape.\n",
    "def generate_coordinates(n_cases):\n",
    "    origin_coord = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\\\\airfoil15\"\n",
    "\n",
    "    csv_file_name = origin_coord + '\\\\airfoilOut15.txt'\n",
    "    data = pd.read_csv(csv_file_name, header=None)\n",
    "    baseline_coord_high = data.iloc[0,:] # 1*50\n",
    "    baseline_coord_low = data.iloc[1,:] # 1*50\n",
    "    baseline_coord = np.vstack((baseline_coord_high, baseline_coord_low)).reshape((2,-1)) # 2*50\n",
    "    airfoil_coord = np.repeat(baseline_coord, n_cases, axis=0)\n",
    "    print(\"Dimension - airfoil coordinates: \", airfoil_coord.shape)\n",
    "    \n",
    "    flap_coords= coord_with_flaps(n_cases)\n",
    "    total_coords = np.hstack((airfoil_coord, flap_coords))\n",
    "    \n",
    "    print(\"Dimension - total coordinates: \", total_coords.shape)\n",
    "    \n",
    "    return total_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a25f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data of Gurney flap coordinates\n",
    "def coord_with_flaps(n_cases):\n",
    "    flap_left = np.zeros((15,5))\n",
    "    flap_right = np.zeros((15,5))\n",
    "\n",
    "    for i in range(n_h):\n",
    "        # Defining coordinates of the flaps with respect to beta=90 degree.\n",
    "        yLeft = np.linspace(-h[i]/5, -h[i], 5).reshape((-1,1))\n",
    "        yRight = np.linspace(-h[i]/5, -h[i], 5).reshape((-1,1))\n",
    "        xLeft = 0.5*np.ones((5,1)) - 0.02*h[i]\n",
    "        xRight = 0.5*np.ones((5,1))\n",
    "\n",
    "        for j, betaValue in enumerate(beta):\n",
    "            # Rotating transformation\n",
    "            rotateTransf = np.array([[np.cos(90-betaValue), -np.sin(90-betaValue)],\n",
    "                                     [np.sin(90-betaValue), np.cos(90-betaValue)]])\n",
    "            rotateTransf = rotateTransf.reshape((2,2))\n",
    "\n",
    "            LeftImp = np.hstack((xLeft-0.5, yLeft))\n",
    "            RightImp = np.hstack((xRight-0.5, yRight))\n",
    "\n",
    "            rotatedFlapLeft = rotateTransf @ LeftImp.T # shape: 2*5 (x-coordinates on first row, y-coordinates on second row)\n",
    "            rotatedFlapRight = rotateTransf @ RightImp.T\n",
    "\n",
    "            # All we need is the y-coordinates of the flaps\n",
    "            flap_left[5*i+j,:] = rotatedFlapLeft[1,:]\n",
    "            flap_right[5*i+j,:] = rotatedFlapRight[1,:]\n",
    "    \n",
    "    # flap_coords = np.hstack((flap_left, np.flip(flap_right, axis=1)))\n",
    "    flap_coords = np.vstack((flap_left, flap_right))\n",
    "    flap_coords2 = np.zeros((n_cases*2,5))\n",
    "    \n",
    "    for i in range(t_len, n_cases):\n",
    "        flap_coords2[i,:] = flap_coords[i%15,:]\n",
    "    print(\"Dimension - coord with flaps: \", flap_coords2.shape)\n",
    "    \n",
    "    return flap_coords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc16d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension - time and Cm:  (1000, 2)\n",
      "Dimension - airfoil coordinates:  (2000, 50)\n",
      "Dimension - coord with flaps:  (2000, 5)\n",
      "Dimension - total coordinates:  (2000, 55)\n",
      "Dimension - x_time:  (1000, 1)\n",
      "Dimension - x_coordinates:  (1000, 2, 55, 1)\n",
      "Dimension - y:  (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Generating x, y and cm (for denormalizing)\n",
    "x_time, x_coord, y, t, cm = genereate_input_output(cm_target, n_beta, t_len, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766ff9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[:,0] -= 10\n",
    "# x[:,0] /= 5\n",
    "x_time -= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7444ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(x_time, x_coord, y, cm, test_rate, random_state=1, **kwargs):\n",
    "    if kwargs.get('validation')==True:\n",
    "        val_rate = kwargs.get('val_rate')\n",
    "        x_time_all, x_time_test, x_coord_all, x_coord_test, y_all, y_test, cm_all, cm_test = train_test_split(x_time, x_coord, y, cm, test_size=test_rate, random_state=kwargs.get('random_state'))\n",
    "        x_time_train, x_time_val, x_coord_train, x_coord_val, y_train, y_val, cm_train, cm_val = train_test_split(x_time_all, x_coord_all, y_all, cm_all,\n",
    "                                                                                                                  test_size=val_rate/(1-test_rate),\n",
    "                                                                                                                  random_state=kwargs.get('random_state'))\n",
    "        return x_time_train, x_time_val, x_time_test, x_coord_train, x_coord_val, x_coord_test, y_train, y_val, y_test, cm_train, cm_val, cm_test\n",
    "    else:\n",
    "        x_time_train, x_time_test, x_coord_train, x_coord_test, y_train, y_test, cm_train, cm_test = train_test_split(x_time, x_coord, y, cm, test_size=test_rate, random_state=kwargs.get('random_state'))\n",
    "        return x_time_train, x_time_test, x_coord_train, x_coord_test, y_train, y_test, cm_train, cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time_train, x_time_val, x_time_test, x_coord_train, x_coord_val, x_coord_test, y_train, y_val, y_test, cm_train, cm_val, cm_test = dataset_split(x_time,x_coord, y, cm, test_rate, val_rate=val_rate,\n",
    "                                                                                                                                                   validation=True, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_aerocnn1_model(num_layer:int = 1): # This function can only generate model with at least 3 hidden layers\n",
    "    input_time = tf.keras.Input(shape=1)\n",
    "    input_coord = tf.keras.Input(shape=(2,55,1))\n",
    "    \n",
    "    # The convolutional layer\n",
    "    x_conv1 = tf.keras.layers.Conv2D(filters=n_kernels, kernel_size=(2,2), strides=1,\n",
    "                                     padding='same', activation='relu',\n",
    "                                     name='convLayer')(input_coord)\n",
    "    x_pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))(x_conv1)\n",
    "    \n",
    "    x_flat = tf.keras.layers.Flatten()(x_pool)\n",
    "    x_concat = tf.keras.layers.Concatenate()([x_flat, input_time])\n",
    "\n",
    "    # The first hidden layer\n",
    "    x_fc = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc1',\n",
    "                                kernel_regularizer=regularizers.l2(l2_regularizer))(x_concat)\n",
    "    \n",
    "    # The other hidden layers, which will be placed between the first hidden layer and the last hidden layer.\n",
    "    # The number of layers that the user desires is input of this function.\n",
    "    for i in range(0, num_layer-2):\n",
    "        x_fc = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc%d' % (i+2),\n",
    "                                     kernel_regularizer=regularizers.l2(l2_regularizer))(x_fc)\n",
    "    \n",
    "    # The last hidden layer\n",
    "    x_fc_final = tf.keras.layers.Dense(units=n_units, activation='relu', name='fc%d' % num_layer,\n",
    "                                       kernel_regularizer=regularizers.l2(l2_regularizer))(x_fc)\n",
    "\n",
    "    # The output layer\n",
    "    output_data = tf.keras.layers.Dense(units=1, activation='linear', name='outputLayer')(x_fc_final)\n",
    "    \n",
    "    # MLP(FC layer)-based\n",
    "    model = tf.keras.Model([input_time, input_coord], output_data)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2, 55, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " convLayer (Conv2D)             (None, 2, 55, 200)   1000        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 27, 200)   0           ['convLayer[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 5400)         0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5401)         0           ['flatten[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " fc1 (Dense)                    (None, 256)          1382912     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 256)          65792       ['fc1[0][0]']                    \n",
      "                                                                                                  \n",
      " fc3 (Dense)                    (None, 256)          65792       ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      " fc4 (Dense)                    (None, 256)          65792       ['fc3[0][0]']                    \n",
      "                                                                                                  \n",
      " fc5 (Dense)                    (None, 256)          65792       ['fc4[0][0]']                    \n",
      "                                                                                                  \n",
      " outputLayer (Dense)            (None, 1)            257         ['fc5[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,647,337\n",
      "Trainable params: 1,647,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_aerocnn1_model(num_layer=n_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360fbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20230102\\\\Case15\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74b6c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = model_directory + \"20230102unsteady_AeroCNN1_Case15_val_\"+str(val_rate) + \"_test\"+str(test_rate)+ \"_\" +str(n_kernels)+ \"kernels_\" +str(n_layers)+\"FClayers_\"+ str(n_units) +\"units_checkpoint.h5\"\n",
    "\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(ckpt_name, monitor=\"val_loss\", mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, min_delta=1e-05,\n",
    "                                      restore_best_weights=True, verbose=1)\n",
    "rp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=100, factor=0.5,\n",
    "                                          min_delta = 1e-05, min_lr=1e-05, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4cc904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = len(x_time_train)//batch_size\n",
    "VALIDATION_STEPS = len(x_time_val)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/3 [=========>....................] - ETA: 10s - loss: 0.2285 - rmse: 0.4778\n",
      "Epoch 1: val_loss improved from inf to 0.21426, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 6s 199ms/step - loss: 0.2204 - rmse: 0.4693 - val_loss: 0.2143 - val_rmse: 0.4627 - lr: 1.0000e-04\n",
      "Epoch 2/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1643 - rmse: 0.4052\n",
      "Epoch 2: val_loss improved from 0.21426 to 0.20497, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1891 - rmse: 0.4347 - val_loss: 0.2050 - val_rmse: 0.4526 - lr: 1.0000e-04\n",
      "Epoch 3/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1999 - rmse: 0.4469\n",
      "Epoch 3: val_loss improved from 0.20497 to 0.19411, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1967 - rmse: 0.4433 - val_loss: 0.1941 - val_rmse: 0.4404 - lr: 1.0000e-04\n",
      "Epoch 4/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1989 - rmse: 0.4458\n",
      "Epoch 4: val_loss improved from 0.19411 to 0.18073, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1848 - rmse: 0.4297 - val_loss: 0.1807 - val_rmse: 0.4249 - lr: 1.0000e-04\n",
      "Epoch 5/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1702 - rmse: 0.4124\n",
      "Epoch 5: val_loss improved from 0.18073 to 0.16416, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1637 - rmse: 0.4044 - val_loss: 0.1642 - val_rmse: 0.4050 - lr: 1.0000e-04\n",
      "Epoch 6/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1803 - rmse: 0.4244\n",
      "Epoch 6: val_loss improved from 0.16416 to 0.14397, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1474 - rmse: 0.3838 - val_loss: 0.1440 - val_rmse: 0.3792 - lr: 1.0000e-04\n",
      "Epoch 7/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1435 - rmse: 0.3786\n",
      "Epoch 7: val_loss improved from 0.14397 to 0.12030, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1372 - rmse: 0.3702 - val_loss: 0.1203 - val_rmse: 0.3466 - lr: 1.0000e-04\n",
      "Epoch 8/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.1055 - rmse: 0.3246\n",
      "Epoch 8: val_loss improved from 0.12030 to 0.09509, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1056 - rmse: 0.3247 - val_loss: 0.0951 - val_rmse: 0.3081 - lr: 1.0000e-04\n",
      "Epoch 9/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0913 - rmse: 0.3019\n",
      "Epoch 9: val_loss improved from 0.09509 to 0.07354, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0839 - rmse: 0.2895 - val_loss: 0.0735 - val_rmse: 0.2709 - lr: 1.0000e-04\n",
      "Epoch 10/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569 - rmse: 0.2382\n",
      "Epoch 10: val_loss improved from 0.07354 to 0.06502, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0614 - rmse: 0.2475 - val_loss: 0.0650 - val_rmse: 0.2547 - lr: 1.0000e-04\n",
      "Epoch 11/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0690 - rmse: 0.2623\n",
      "Epoch 11: val_loss did not improve from 0.06502\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0637 - rmse: 0.2520 - val_loss: 0.0704 - val_rmse: 0.2650 - lr: 1.0000e-04\n",
      "Epoch 12/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0666 - rmse: 0.2578\n",
      "Epoch 12: val_loss did not improve from 0.06502\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0691 - rmse: 0.2626 - val_loss: 0.0709 - val_rmse: 0.2659 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0726 - rmse: 0.2692\n",
      "Epoch 13: val_loss improved from 0.06502 to 0.06482, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0661 - rmse: 0.2568 - val_loss: 0.0648 - val_rmse: 0.2543 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0560 - rmse: 0.2363\n",
      "Epoch 14: val_loss improved from 0.06482 to 0.06288, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0563 - rmse: 0.2369 - val_loss: 0.0629 - val_rmse: 0.2505 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0604 - rmse: 0.2455\n",
      "Epoch 15: val_loss did not improve from 0.06288\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0604 - rmse: 0.2455 - val_loss: 0.0640 - val_rmse: 0.2527 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0621 - rmse: 0.2488\n",
      "Epoch 16: val_loss did not improve from 0.06288\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0615 - rmse: 0.2478 - val_loss: 0.0650 - val_rmse: 0.2547 - lr: 1.0000e-04\n",
      "Epoch 17/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0556 - rmse: 0.2355\n",
      "Epoch 17: val_loss did not improve from 0.06288\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0576 - rmse: 0.2396 - val_loss: 0.0650 - val_rmse: 0.2547 - lr: 1.0000e-04\n",
      "Epoch 18/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0846 - rmse: 0.2906\n",
      "Epoch 18: val_loss did not improve from 0.06288\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0681 - rmse: 0.2607 - val_loss: 0.0634 - val_rmse: 0.2515 - lr: 1.0000e-04\n",
      "Epoch 19/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569 - rmse: 0.2381\n",
      "Epoch 19: val_loss improved from 0.06288 to 0.06273, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0557 - rmse: 0.2357 - val_loss: 0.0627 - val_rmse: 0.2502 - lr: 1.0000e-04\n",
      "Epoch 20/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0549 - rmse: 0.2340\n",
      "Epoch 20: val_loss did not improve from 0.06273\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0596 - rmse: 0.2439 - val_loss: 0.0629 - val_rmse: 0.2506 - lr: 1.0000e-04\n",
      "Epoch 21/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0597 - rmse: 0.2441\n",
      "Epoch 21: val_loss did not improve from 0.06273\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0618 - rmse: 0.2483 - val_loss: 0.0632 - val_rmse: 0.2512 - lr: 1.0000e-04\n",
      "Epoch 22/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0449 - rmse: 0.2116\n",
      "Epoch 22: val_loss did not improve from 0.06273\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0544 - rmse: 0.2329 - val_loss: 0.0632 - val_rmse: 0.2511 - lr: 1.0000e-04\n",
      "Epoch 23/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0578 - rmse: 0.2401\n",
      "Epoch 23: val_loss improved from 0.06273 to 0.06268, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0605 - rmse: 0.2456 - val_loss: 0.0627 - val_rmse: 0.2501 - lr: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0659 - rmse: 0.2564\n",
      "Epoch 24: val_loss improved from 0.06268 to 0.06262, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0602 - rmse: 0.2451 - val_loss: 0.0626 - val_rmse: 0.2499 - lr: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0553 - rmse: 0.2349\n",
      "Epoch 25: val_loss did not improve from 0.06262\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0599 - rmse: 0.2445 - val_loss: 0.0627 - val_rmse: 0.2502 - lr: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0532 - rmse: 0.2304\n",
      "Epoch 26: val_loss did not improve from 0.06262\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0571 - rmse: 0.2387 - val_loss: 0.0628 - val_rmse: 0.2503 - lr: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0599 - rmse: 0.2445\n",
      "Epoch 27: val_loss did not improve from 0.06262\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0633 - rmse: 0.2514 - val_loss: 0.0627 - val_rmse: 0.2501 - lr: 1.0000e-04\n",
      "Epoch 28/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0539 - rmse: 0.2317\n",
      "Epoch 28: val_loss improved from 0.06262 to 0.06253, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0556 - rmse: 0.2355 - val_loss: 0.0625 - val_rmse: 0.2498 - lr: 1.0000e-04\n",
      "Epoch 29/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0581 - rmse: 0.2407\n",
      "Epoch 29: val_loss improved from 0.06253 to 0.06246, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0597 - rmse: 0.2439 - val_loss: 0.0625 - val_rmse: 0.2496 - lr: 1.0000e-04\n",
      "Epoch 30/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0539 - rmse: 0.2318\n",
      "Epoch 30: val_loss improved from 0.06246 to 0.06241, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0550 - rmse: 0.2342 - val_loss: 0.0624 - val_rmse: 0.2495 - lr: 1.0000e-04\n",
      "Epoch 31/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0629 - rmse: 0.2506\n",
      "Epoch 31: val_loss improved from 0.06241 to 0.06239, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0649 - rmse: 0.2544 - val_loss: 0.0624 - val_rmse: 0.2495 - lr: 1.0000e-04\n",
      "Epoch 32/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0530 - rmse: 0.2299\n",
      "Epoch 32: val_loss improved from 0.06239 to 0.06237, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0554 - rmse: 0.2351 - val_loss: 0.0624 - val_rmse: 0.2494 - lr: 1.0000e-04\n",
      "Epoch 33/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0597 - rmse: 0.2441\n",
      "Epoch 33: val_loss improved from 0.06237 to 0.06233, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0585 - rmse: 0.2415 - val_loss: 0.0623 - val_rmse: 0.2494 - lr: 1.0000e-04\n",
      "Epoch 34/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0607 - rmse: 0.2460\n",
      "Epoch 34: val_loss improved from 0.06233 to 0.06229, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0610 - rmse: 0.2467 - val_loss: 0.0623 - val_rmse: 0.2493 - lr: 1.0000e-04\n",
      "Epoch 35/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0544 - rmse: 0.2329\n",
      "Epoch 35: val_loss improved from 0.06229 to 0.06227, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0559 - rmse: 0.2360 - val_loss: 0.0623 - val_rmse: 0.2492 - lr: 1.0000e-04\n",
      "Epoch 36/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0530 - rmse: 0.2298\n",
      "Epoch 36: val_loss improved from 0.06227 to 0.06225, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0597 - rmse: 0.2440 - val_loss: 0.0622 - val_rmse: 0.2492 - lr: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0489 - rmse: 0.2208\n",
      "Epoch 37: val_loss improved from 0.06225 to 0.06220, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0573 - rmse: 0.2390 - val_loss: 0.0622 - val_rmse: 0.2491 - lr: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0611 - rmse: 0.2469\n",
      "Epoch 38: val_loss did not improve from 0.06220\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0611 - rmse: 0.2469 - val_loss: 0.0622 - val_rmse: 0.2491 - lr: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0556 - rmse: 0.2355\n",
      "Epoch 39: val_loss did not improve from 0.06220\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0599 - rmse: 0.2444 - val_loss: 0.0622 - val_rmse: 0.2491 - lr: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0557 - rmse: 0.2357\n",
      "Epoch 40: val_loss improved from 0.06220 to 0.06212, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0565 - rmse: 0.2374 - val_loss: 0.0621 - val_rmse: 0.2489 - lr: 1.0000e-04\n",
      "Epoch 41/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0581 - rmse: 0.2407\n",
      "Epoch 41: val_loss improved from 0.06212 to 0.06208, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0565 - rmse: 0.2374 - val_loss: 0.0621 - val_rmse: 0.2489 - lr: 1.0000e-04\n",
      "Epoch 42/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0707 - rmse: 0.2656\n",
      "Epoch 42: val_loss improved from 0.06208 to 0.06206, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0605 - rmse: 0.2456 - val_loss: 0.0621 - val_rmse: 0.2488 - lr: 1.0000e-04\n",
      "Epoch 43/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0566 - rmse: 0.2375\n",
      "Epoch 43: val_loss improved from 0.06206 to 0.06201, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0632 - rmse: 0.2510 - val_loss: 0.0620 - val_rmse: 0.2487 - lr: 1.0000e-04\n",
      "Epoch 44/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0509 - rmse: 0.2253\n",
      "Epoch 44: val_loss improved from 0.06201 to 0.06197, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0543 - rmse: 0.2328 - val_loss: 0.0620 - val_rmse: 0.2486 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0568 - rmse: 0.2379\n",
      "Epoch 45: val_loss did not improve from 0.06197\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0574 - rmse: 0.2392 - val_loss: 0.0621 - val_rmse: 0.2488 - lr: 1.0000e-04\n",
      "Epoch 46/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0657 - rmse: 0.2561\n",
      "Epoch 46: val_loss did not improve from 0.06197\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0640 - rmse: 0.2526 - val_loss: 0.0620 - val_rmse: 0.2487 - lr: 1.0000e-04\n",
      "Epoch 47/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0452 - rmse: 0.2123\n",
      "Epoch 47: val_loss improved from 0.06197 to 0.06191, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0539 - rmse: 0.2319 - val_loss: 0.0619 - val_rmse: 0.2485 - lr: 1.0000e-04\n",
      "Epoch 48/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0617 - rmse: 0.2480\n",
      "Epoch 48: val_loss improved from 0.06191 to 0.06181, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0587 - rmse: 0.2419 - val_loss: 0.0618 - val_rmse: 0.2483 - lr: 1.0000e-04\n",
      "Epoch 49/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0586 - rmse: 0.2418\n",
      "Epoch 49: val_loss did not improve from 0.06181\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0605 - rmse: 0.2456 - val_loss: 0.0618 - val_rmse: 0.2484 - lr: 1.0000e-04\n",
      "Epoch 50/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0455 - rmse: 0.2129\n",
      "Epoch 50: val_loss improved from 0.06181 to 0.06177, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0555 - rmse: 0.2353 - val_loss: 0.0618 - val_rmse: 0.2482 - lr: 1.0000e-04\n",
      "Epoch 51/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0576 - rmse: 0.2397\n",
      "Epoch 51: val_loss improved from 0.06177 to 0.06167, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0560 - rmse: 0.2364 - val_loss: 0.0617 - val_rmse: 0.2480 - lr: 1.0000e-04\n",
      "Epoch 52/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0642 - rmse: 0.2531\n",
      "Epoch 52: val_loss improved from 0.06167 to 0.06165, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0606 - rmse: 0.2459 - val_loss: 0.0616 - val_rmse: 0.2480 - lr: 1.0000e-04\n",
      "Epoch 53/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569 - rmse: 0.2383\n",
      "Epoch 53: val_loss improved from 0.06165 to 0.06161, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0603 - rmse: 0.2453 - val_loss: 0.0616 - val_rmse: 0.2479 - lr: 1.0000e-04\n",
      "Epoch 54/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0452 - rmse: 0.2122\n",
      "Epoch 54: val_loss improved from 0.06161 to 0.06161, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0565 - rmse: 0.2373 - val_loss: 0.0616 - val_rmse: 0.2479 - lr: 1.0000e-04\n",
      "Epoch 55/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0524 - rmse: 0.2286\n",
      "Epoch 55: val_loss improved from 0.06161 to 0.06153, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0557 - rmse: 0.2357 - val_loss: 0.0615 - val_rmse: 0.2478 - lr: 1.0000e-04\n",
      "Epoch 56/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0605 - rmse: 0.2457\n",
      "Epoch 56: val_loss improved from 0.06153 to 0.06147, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0596 - rmse: 0.2438 - val_loss: 0.0615 - val_rmse: 0.2476 - lr: 1.0000e-04\n",
      "Epoch 57/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0600 - rmse: 0.2446\n",
      "Epoch 57: val_loss improved from 0.06147 to 0.06139, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0563 - rmse: 0.2369 - val_loss: 0.0614 - val_rmse: 0.2475 - lr: 1.0000e-04\n",
      "Epoch 58/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0586 - rmse: 0.2418\n",
      "Epoch 58: val_loss improved from 0.06139 to 0.06129, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0586 - rmse: 0.2418 - val_loss: 0.0613 - val_rmse: 0.2473 - lr: 1.0000e-04\n",
      "Epoch 59/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0636 - rmse: 0.2518\n",
      "Epoch 59: val_loss improved from 0.06129 to 0.06128, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0604 - rmse: 0.2454 - val_loss: 0.0613 - val_rmse: 0.2472 - lr: 1.0000e-04\n",
      "Epoch 60/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0563 - rmse: 0.2369\n",
      "Epoch 60: val_loss did not improve from 0.06128\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0566 - rmse: 0.2377 - val_loss: 0.0613 - val_rmse: 0.2473 - lr: 1.0000e-04\n",
      "Epoch 61/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0562 - rmse: 0.2368\n",
      "Epoch 61: val_loss improved from 0.06128 to 0.06113, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0562 - rmse: 0.2368 - val_loss: 0.0611 - val_rmse: 0.2469 - lr: 1.0000e-04\n",
      "Epoch 62/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0669 - rmse: 0.2583\n",
      "Epoch 62: val_loss improved from 0.06113 to 0.06101, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0627 - rmse: 0.2501 - val_loss: 0.0610 - val_rmse: 0.2467 - lr: 1.0000e-04\n",
      "Epoch 63/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0544 - rmse: 0.2329\n",
      "Epoch 63: val_loss improved from 0.06101 to 0.06091, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0552 - rmse: 0.2346 - val_loss: 0.0609 - val_rmse: 0.2465 - lr: 1.0000e-04\n",
      "Epoch 64/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0534 - rmse: 0.2308\n",
      "Epoch 64: val_loss improved from 0.06091 to 0.06081, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0566 - rmse: 0.2375 - val_loss: 0.0608 - val_rmse: 0.2463 - lr: 1.0000e-04\n",
      "Epoch 65/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0535 - rmse: 0.2309\n",
      "Epoch 65: val_loss improved from 0.06081 to 0.06080, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0594 - rmse: 0.2433 - val_loss: 0.0608 - val_rmse: 0.2463 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0456 - rmse: 0.2132\n",
      "Epoch 66: val_loss improved from 0.06080 to 0.06063, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0570 - rmse: 0.2384 - val_loss: 0.0606 - val_rmse: 0.2459 - lr: 1.0000e-04\n",
      "Epoch 67/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0551 - rmse: 0.2343\n",
      "Epoch 67: val_loss improved from 0.06063 to 0.06052, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0557 - rmse: 0.2358 - val_loss: 0.0605 - val_rmse: 0.2457 - lr: 1.0000e-04\n",
      "Epoch 68/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0553 - rmse: 0.2348\n",
      "Epoch 68: val_loss improved from 0.06052 to 0.06045, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0567 - rmse: 0.2378 - val_loss: 0.0604 - val_rmse: 0.2456 - lr: 1.0000e-04\n",
      "Epoch 69/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0567 - rmse: 0.2378\n",
      "Epoch 69: val_loss improved from 0.06045 to 0.06037, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0565 - rmse: 0.2374 - val_loss: 0.0604 - val_rmse: 0.2454 - lr: 1.0000e-04\n",
      "Epoch 70/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0603 - rmse: 0.2453\n",
      "Epoch 70: val_loss improved from 0.06037 to 0.06035, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0557 - rmse: 0.2358 - val_loss: 0.0603 - val_rmse: 0.2453 - lr: 1.0000e-04\n",
      "Epoch 71/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0559 - rmse: 0.2362\n",
      "Epoch 71: val_loss improved from 0.06035 to 0.06010, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0586 - rmse: 0.2417 - val_loss: 0.0601 - val_rmse: 0.2449 - lr: 1.0000e-04\n",
      "Epoch 72/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0520 - rmse: 0.2276\n",
      "Epoch 72: val_loss improved from 0.06010 to 0.05995, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0573 - rmse: 0.2390 - val_loss: 0.0600 - val_rmse: 0.2445 - lr: 1.0000e-04\n",
      "Epoch 73/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0577 - rmse: 0.2399\n",
      "Epoch 73: val_loss did not improve from 0.05995\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0550 - rmse: 0.2342 - val_loss: 0.0601 - val_rmse: 0.2448 - lr: 1.0000e-04\n",
      "Epoch 74/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0685 - rmse: 0.2615\n",
      "Epoch 74: val_loss did not improve from 0.05995\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0639 - rmse: 0.2524 - val_loss: 0.0600 - val_rmse: 0.2447 - lr: 1.0000e-04\n",
      "Epoch 75/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0466 - rmse: 0.2156\n",
      "Epoch 75: val_loss improved from 0.05995 to 0.05956, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0521 - rmse: 0.2280 - val_loss: 0.0596 - val_rmse: 0.2437 - lr: 1.0000e-04\n",
      "Epoch 76/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0546 - rmse: 0.2332\n",
      "Epoch 76: val_loss improved from 0.05956 to 0.05941, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0558 - rmse: 0.2359 - val_loss: 0.0594 - val_rmse: 0.2434 - lr: 1.0000e-04\n",
      "Epoch 77/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0578 - rmse: 0.2402\n",
      "Epoch 77: val_loss improved from 0.05941 to 0.05927, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0565 - rmse: 0.2373 - val_loss: 0.0593 - val_rmse: 0.2432 - lr: 1.0000e-04\n",
      "Epoch 78/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0549 - rmse: 0.2340\n",
      "Epoch 78: val_loss improved from 0.05927 to 0.05913, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0542 - rmse: 0.2325 - val_loss: 0.0591 - val_rmse: 0.2429 - lr: 1.0000e-04\n",
      "Epoch 79/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569 - rmse: 0.2382\n",
      "Epoch 79: val_loss improved from 0.05913 to 0.05885, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0547 - rmse: 0.2335 - val_loss: 0.0589 - val_rmse: 0.2423 - lr: 1.0000e-04\n",
      "Epoch 80/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0579 - rmse: 0.2404\n",
      "Epoch 80: val_loss improved from 0.05885 to 0.05864, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0584 - rmse: 0.2413 - val_loss: 0.0586 - val_rmse: 0.2418 - lr: 1.0000e-04\n",
      "Epoch 81/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0526 - rmse: 0.2290\n",
      "Epoch 81: val_loss improved from 0.05864 to 0.05851, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0581 - rmse: 0.2408 - val_loss: 0.0585 - val_rmse: 0.2416 - lr: 1.0000e-04\n",
      "Epoch 82/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0401 - rmse: 0.2000\n",
      "Epoch 82: val_loss improved from 0.05851 to 0.05830, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0512 - rmse: 0.2259 - val_loss: 0.0583 - val_rmse: 0.2411 - lr: 1.0000e-04\n",
      "Epoch 83/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0552 - rmse: 0.2346\n",
      "Epoch 83: val_loss improved from 0.05830 to 0.05794, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0568 - rmse: 0.2380 - val_loss: 0.0579 - val_rmse: 0.2404 - lr: 1.0000e-04\n",
      "Epoch 84/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0570 - rmse: 0.2384\n",
      "Epoch 84: val_loss improved from 0.05794 to 0.05774, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0545 - rmse: 0.2332 - val_loss: 0.0577 - val_rmse: 0.2400 - lr: 1.0000e-04\n",
      "Epoch 85/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0507 - rmse: 0.2249\n",
      "Epoch 85: val_loss did not improve from 0.05774\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0539 - rmse: 0.2318 - val_loss: 0.0579 - val_rmse: 0.2403 - lr: 1.0000e-04\n",
      "Epoch 86/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0622 - rmse: 0.2492\n",
      "Epoch 86: val_loss did not improve from 0.05774\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0559 - rmse: 0.2361 - val_loss: 0.0580 - val_rmse: 0.2404 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0546 - rmse: 0.2333\n",
      "Epoch 87: val_loss improved from 0.05774 to 0.05698, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0547 - rmse: 0.2335 - val_loss: 0.0570 - val_rmse: 0.2384 - lr: 1.0000e-04\n",
      "Epoch 88/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0551 - rmse: 0.2344\n",
      "Epoch 88: val_loss improved from 0.05698 to 0.05672, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0539 - rmse: 0.2319 - val_loss: 0.0567 - val_rmse: 0.2379 - lr: 1.0000e-04\n",
      "Epoch 89/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0538 - rmse: 0.2315\n",
      "Epoch 89: val_loss improved from 0.05672 to 0.05637, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0524 - rmse: 0.2285 - val_loss: 0.0564 - val_rmse: 0.2371 - lr: 1.0000e-04\n",
      "Epoch 90/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0620 - rmse: 0.2487\n",
      "Epoch 90: val_loss improved from 0.05637 to 0.05595, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0547 - rmse: 0.2336 - val_loss: 0.0559 - val_rmse: 0.2362 - lr: 1.0000e-04\n",
      "Epoch 91/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0595 - rmse: 0.2437\n",
      "Epoch 91: val_loss improved from 0.05595 to 0.05560, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0545 - rmse: 0.2331 - val_loss: 0.0556 - val_rmse: 0.2355 - lr: 1.0000e-04\n",
      "Epoch 92/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0474 - rmse: 0.2174\n",
      "Epoch 92: val_loss improved from 0.05560 to 0.05517, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0515 - rmse: 0.2265 - val_loss: 0.0552 - val_rmse: 0.2346 - lr: 1.0000e-04\n",
      "Epoch 93/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0551 - rmse: 0.2345\n",
      "Epoch 93: val_loss improved from 0.05517 to 0.05474, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0529 - rmse: 0.2296 - val_loss: 0.0547 - val_rmse: 0.2336 - lr: 1.0000e-04\n",
      "Epoch 94/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0484 - rmse: 0.2196\n",
      "Epoch 94: val_loss improved from 0.05474 to 0.05435, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0517 - rmse: 0.2270 - val_loss: 0.0543 - val_rmse: 0.2328 - lr: 1.0000e-04\n",
      "Epoch 95/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0511 - rmse: 0.2258\n",
      "Epoch 95: val_loss improved from 0.05435 to 0.05379, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0497 - rmse: 0.2225 - val_loss: 0.0538 - val_rmse: 0.2316 - lr: 1.0000e-04\n",
      "Epoch 96/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0528 - rmse: 0.2294\n",
      "Epoch 96: val_loss improved from 0.05379 to 0.05336, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0524 - rmse: 0.2286 - val_loss: 0.0534 - val_rmse: 0.2307 - lr: 1.0000e-04\n",
      "Epoch 97/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0608 - rmse: 0.2462\n",
      "Epoch 97: val_loss improved from 0.05336 to 0.05282, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0519 - rmse: 0.2276 - val_loss: 0.0528 - val_rmse: 0.2295 - lr: 1.0000e-04\n",
      "Epoch 98/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0446 - rmse: 0.2109\n",
      "Epoch 98: val_loss improved from 0.05282 to 0.05237, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0472 - rmse: 0.2170 - val_loss: 0.0524 - val_rmse: 0.2285 - lr: 1.0000e-04\n",
      "Epoch 99/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0532 - rmse: 0.2303\n",
      "Epoch 99: val_loss improved from 0.05237 to 0.05191, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0520 - rmse: 0.2278 - val_loss: 0.0519 - val_rmse: 0.2275 - lr: 1.0000e-04\n",
      "Epoch 100/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0427 - rmse: 0.2062\n",
      "Epoch 100: val_loss improved from 0.05191 to 0.05174, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0491 - rmse: 0.2212 - val_loss: 0.0517 - val_rmse: 0.2271 - lr: 1.0000e-04\n",
      "Epoch 101/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0521 - rmse: 0.2279\n",
      "Epoch 101: val_loss improved from 0.05174 to 0.05067, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0485 - rmse: 0.2198 - val_loss: 0.0507 - val_rmse: 0.2248 - lr: 1.0000e-04\n",
      "Epoch 102/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0482 - rmse: 0.2192\n",
      "Epoch 102: val_loss improved from 0.05067 to 0.05029, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0482 - rmse: 0.2192 - val_loss: 0.0503 - val_rmse: 0.2239 - lr: 1.0000e-04\n",
      "Epoch 103/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0510 - rmse: 0.2255\n",
      "Epoch 103: val_loss did not improve from 0.05029\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0500 - rmse: 0.2234 - val_loss: 0.0513 - val_rmse: 0.2263 - lr: 1.0000e-04\n",
      "Epoch 104/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0510 - rmse: 0.2255\n",
      "Epoch 104: val_loss improved from 0.05029 to 0.05019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0480 - rmse: 0.2187 - val_loss: 0.0502 - val_rmse: 0.2237 - lr: 1.0000e-04\n",
      "Epoch 105/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0539 - rmse: 0.2318\n",
      "Epoch 105: val_loss improved from 0.05019 to 0.04846, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0475 - rmse: 0.2175 - val_loss: 0.0485 - val_rmse: 0.2198 - lr: 1.0000e-04\n",
      "Epoch 106/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0463 - rmse: 0.2148\n",
      "Epoch 106: val_loss improved from 0.04846 to 0.04786, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0466 - rmse: 0.2155 - val_loss: 0.0479 - val_rmse: 0.2184 - lr: 1.0000e-04\n",
      "Epoch 107/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0504 - rmse: 0.2241\n",
      "Epoch 107: val_loss improved from 0.04786 to 0.04732, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0476 - rmse: 0.2177 - val_loss: 0.0473 - val_rmse: 0.2172 - lr: 1.0000e-04\n",
      "Epoch 108/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0452 - rmse: 0.2122\n",
      "Epoch 108: val_loss improved from 0.04732 to 0.04709, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0445 - rmse: 0.2106 - val_loss: 0.0471 - val_rmse: 0.2167 - lr: 1.0000e-04\n",
      "Epoch 109/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0441 - rmse: 0.2096\n",
      "Epoch 109: val_loss improved from 0.04709 to 0.04654, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0448 - rmse: 0.2113 - val_loss: 0.0465 - val_rmse: 0.2154 - lr: 1.0000e-04\n",
      "Epoch 110/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0478 - rmse: 0.2182\n",
      "Epoch 110: val_loss improved from 0.04654 to 0.04620, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0447 - rmse: 0.2111 - val_loss: 0.0462 - val_rmse: 0.2146 - lr: 1.0000e-04\n",
      "Epoch 111/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0446 - rmse: 0.2107\n",
      "Epoch 111: val_loss improved from 0.04620 to 0.04428, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0438 - rmse: 0.2090 - val_loss: 0.0443 - val_rmse: 0.2101 - lr: 1.0000e-04\n",
      "Epoch 112/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0344 - rmse: 0.1850\n",
      "Epoch 112: val_loss improved from 0.04428 to 0.04364, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0428 - rmse: 0.2066 - val_loss: 0.0436 - val_rmse: 0.2086 - lr: 1.0000e-04\n",
      "Epoch 113/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0469 - rmse: 0.2163\n",
      "Epoch 113: val_loss improved from 0.04364 to 0.04299, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0428 - rmse: 0.2065 - val_loss: 0.0430 - val_rmse: 0.2070 - lr: 1.0000e-04\n",
      "Epoch 114/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0406 - rmse: 0.2011\n",
      "Epoch 114: val_loss did not improve from 0.04299\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0406 - rmse: 0.2011 - val_loss: 0.0433 - val_rmse: 0.2078 - lr: 1.0000e-04\n",
      "Epoch 115/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0423 - rmse: 0.2053\n",
      "Epoch 115: val_loss improved from 0.04299 to 0.04217, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 219ms/step - loss: 0.0408 - rmse: 0.2016 - val_loss: 0.0422 - val_rmse: 0.2050 - lr: 1.0000e-04\n",
      "Epoch 116/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0385 - rmse: 0.1960\n",
      "Epoch 116: val_loss improved from 0.04217 to 0.04096, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0422 - rmse: 0.2052 - val_loss: 0.0410 - val_rmse: 0.2020 - lr: 1.0000e-04\n",
      "Epoch 117/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0396 - rmse: 0.1985\n",
      "Epoch 117: val_loss improved from 0.04096 to 0.04031, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0396 - rmse: 0.1985 - val_loss: 0.0403 - val_rmse: 0.2004 - lr: 1.0000e-04\n",
      "Epoch 118/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0390 - rmse: 0.1972\n",
      "Epoch 118: val_loss improved from 0.04031 to 0.03932, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0390 - rmse: 0.1972 - val_loss: 0.0393 - val_rmse: 0.1979 - lr: 1.0000e-04\n",
      "Epoch 119/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0388 - rmse: 0.1967\n",
      "Epoch 119: val_loss improved from 0.03932 to 0.03840, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0377 - rmse: 0.1938 - val_loss: 0.0384 - val_rmse: 0.1956 - lr: 1.0000e-04\n",
      "Epoch 120/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0436 - rmse: 0.2085\n",
      "Epoch 120: val_loss improved from 0.03840 to 0.03753, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 1s 343ms/step - loss: 0.0389 - rmse: 0.1968 - val_loss: 0.0375 - val_rmse: 0.1933 - lr: 1.0000e-04\n",
      "Epoch 121/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0365 - rmse: 0.1907\n",
      "Epoch 121: val_loss improved from 0.03753 to 0.03669, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0365 - rmse: 0.1907 - val_loss: 0.0367 - val_rmse: 0.1911 - lr: 1.0000e-04\n",
      "Epoch 122/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0344 - rmse: 0.1850\n",
      "Epoch 122: val_loss improved from 0.03669 to 0.03596, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0344 - rmse: 0.1850 - val_loss: 0.0360 - val_rmse: 0.1892 - lr: 1.0000e-04\n",
      "Epoch 123/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0343 - rmse: 0.1849\n",
      "Epoch 123: val_loss did not improve from 0.03596\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0372 - rmse: 0.1924 - val_loss: 0.0362 - val_rmse: 0.1899 - lr: 1.0000e-04\n",
      "Epoch 124/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0357 - rmse: 0.1886\n",
      "Epoch 124: val_loss improved from 0.03596 to 0.03501, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0360 - rmse: 0.1895 - val_loss: 0.0350 - val_rmse: 0.1867 - lr: 1.0000e-04\n",
      "Epoch 125/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0350 - rmse: 0.1867\n",
      "Epoch 125: val_loss improved from 0.03501 to 0.03453, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0350 - rmse: 0.1867 - val_loss: 0.0345 - val_rmse: 0.1854 - lr: 1.0000e-04\n",
      "Epoch 126/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0319 - rmse: 0.1783\n",
      "Epoch 126: val_loss improved from 0.03453 to 0.03237, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0319 - rmse: 0.1783 - val_loss: 0.0324 - val_rmse: 0.1795 - lr: 1.0000e-04\n",
      "Epoch 127/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0273 - rmse: 0.1649\n",
      "Epoch 127: val_loss improved from 0.03237 to 0.03188, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0326 - rmse: 0.1801 - val_loss: 0.0319 - val_rmse: 0.1781 - lr: 1.0000e-04\n",
      "Epoch 128/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0335 - rmse: 0.1826\n",
      "Epoch 128: val_loss improved from 0.03188 to 0.03046, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0309 - rmse: 0.1753 - val_loss: 0.0305 - val_rmse: 0.1741 - lr: 1.0000e-04\n",
      "Epoch 129/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0303 - rmse: 0.1736\n",
      "Epoch 129: val_loss improved from 0.03046 to 0.02945, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0303 - rmse: 0.1736 - val_loss: 0.0295 - val_rmse: 0.1712 - lr: 1.0000e-04\n",
      "Epoch 130/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0287 - rmse: 0.1690\n",
      "Epoch 130: val_loss improved from 0.02945 to 0.02847, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0287 - rmse: 0.1690 - val_loss: 0.0285 - val_rmse: 0.1683 - lr: 1.0000e-04\n",
      "Epoch 131/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0310 - rmse: 0.1756\n",
      "Epoch 131: val_loss improved from 0.02847 to 0.02739, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0285 - rmse: 0.1684 - val_loss: 0.0274 - val_rmse: 0.1650 - lr: 1.0000e-04\n",
      "Epoch 132/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0262 - rmse: 0.1614\n",
      "Epoch 132: val_loss improved from 0.02739 to 0.02630, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0273 - rmse: 0.1648 - val_loss: 0.0263 - val_rmse: 0.1617 - lr: 1.0000e-04\n",
      "Epoch 133/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0249 - rmse: 0.1572\n",
      "Epoch 133: val_loss improved from 0.02630 to 0.02553, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0249 - rmse: 0.1572 - val_loss: 0.0255 - val_rmse: 0.1593 - lr: 1.0000e-04\n",
      "Epoch 134/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0281 - rmse: 0.1672\n",
      "Epoch 134: val_loss improved from 0.02553 to 0.02381, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0281 - rmse: 0.1672 - val_loss: 0.0238 - val_rmse: 0.1538 - lr: 1.0000e-04\n",
      "Epoch 135/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0195 - rmse: 0.1393\n",
      "Epoch 135: val_loss improved from 0.02381 to 0.02317, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0218 - rmse: 0.1470 - val_loss: 0.0232 - val_rmse: 0.1517 - lr: 1.0000e-04\n",
      "Epoch 136/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0218 - rmse: 0.1470\n",
      "Epoch 136: val_loss improved from 0.02317 to 0.02262, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0221 - rmse: 0.1482 - val_loss: 0.0226 - val_rmse: 0.1499 - lr: 1.0000e-04\n",
      "Epoch 137/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0216 - rmse: 0.1463\n",
      "Epoch 137: val_loss improved from 0.02262 to 0.02085, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0216 - rmse: 0.1463 - val_loss: 0.0208 - val_rmse: 0.1439 - lr: 1.0000e-04\n",
      "Epoch 138/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0199 - rmse: 0.1405\n",
      "Epoch 138: val_loss improved from 0.02085 to 0.01981, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0199 - rmse: 0.1405 - val_loss: 0.0198 - val_rmse: 0.1402 - lr: 1.0000e-04\n",
      "Epoch 139/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0226 - rmse: 0.1499\n",
      "Epoch 139: val_loss improved from 0.01981 to 0.01755, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0186 - rmse: 0.1357 - val_loss: 0.0175 - val_rmse: 0.1319 - lr: 1.0000e-04\n",
      "Epoch 140/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0176 - rmse: 0.1323\n",
      "Epoch 140: val_loss improved from 0.01755 to 0.01615, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0177 - rmse: 0.1326 - val_loss: 0.0161 - val_rmse: 0.1265 - lr: 1.0000e-04\n",
      "Epoch 141/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0159 - rmse: 0.1253\n",
      "Epoch 141: val_loss improved from 0.01615 to 0.01464, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0159 - rmse: 0.1253 - val_loss: 0.0146 - val_rmse: 0.1204 - lr: 1.0000e-04\n",
      "Epoch 142/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0173 - rmse: 0.1309\n",
      "Epoch 142: val_loss improved from 0.01464 to 0.01377, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0173 - rmse: 0.1309 - val_loss: 0.0138 - val_rmse: 0.1167 - lr: 1.0000e-04\n",
      "Epoch 143/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0145 - rmse: 0.1198\n",
      "Epoch 143: val_loss improved from 0.01377 to 0.01226, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0143 - rmse: 0.1189 - val_loss: 0.0123 - val_rmse: 0.1101 - lr: 1.0000e-04\n",
      "Epoch 144/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0127 - rmse: 0.1119\n",
      "Epoch 144: val_loss improved from 0.01226 to 0.01187, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0123 - rmse: 0.1101 - val_loss: 0.0119 - val_rmse: 0.1083 - lr: 1.0000e-04\n",
      "Epoch 145/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0116 - rmse: 0.1069\n",
      "Epoch 145: val_loss improved from 0.01187 to 0.01102, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0116 - rmse: 0.1069 - val_loss: 0.0110 - val_rmse: 0.1043 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0107 - rmse: 0.1028\n",
      "Epoch 146: val_loss improved from 0.01102 to 0.00978, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0107 - rmse: 0.1028 - val_loss: 0.0098 - val_rmse: 0.0981 - lr: 1.0000e-04\n",
      "Epoch 147/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0087 - rmse: 0.0924\n",
      "Epoch 147: val_loss improved from 0.00978 to 0.00921, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0091 - rmse: 0.0948 - val_loss: 0.0092 - val_rmse: 0.0952 - lr: 1.0000e-04\n",
      "Epoch 148/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082 - rmse: 0.0899\n",
      "Epoch 148: val_loss improved from 0.00921 to 0.00775, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0086 - rmse: 0.0918 - val_loss: 0.0077 - val_rmse: 0.0872 - lr: 1.0000e-04\n",
      "Epoch 149/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0077 - rmse: 0.0868\n",
      "Epoch 149: val_loss improved from 0.00775 to 0.00717, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0077 - rmse: 0.0868 - val_loss: 0.0072 - val_rmse: 0.0838 - lr: 1.0000e-04\n",
      "Epoch 150/10000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0064 - rmse: 0.0790\n",
      "Epoch 150: val_loss did not improve from 0.00717\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0064 - rmse: 0.0790 - val_loss: 0.0086 - val_rmse: 0.0918 - lr: 1.0000e-04\n",
      "Epoch 151/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0104 - rmse: 0.1010\n",
      "Epoch 151: val_loss improved from 0.00717 to 0.00627, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0080 - rmse: 0.0886 - val_loss: 0.0063 - val_rmse: 0.0782 - lr: 1.0000e-04\n",
      "Epoch 152/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069 - rmse: 0.0821\n",
      "Epoch 152: val_loss did not improve from 0.00627\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0073 - rmse: 0.0843 - val_loss: 0.0072 - val_rmse: 0.0839 - lr: 1.0000e-04\n",
      "Epoch 153/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0063 - rmse: 0.0784\n",
      "Epoch 153: val_loss did not improve from 0.00627\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0057 - rmse: 0.0748 - val_loss: 0.0063 - val_rmse: 0.0785 - lr: 1.0000e-04\n",
      "Epoch 154/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067 - rmse: 0.0808\n",
      "Epoch 154: val_loss improved from 0.00627 to 0.00540, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0052 - rmse: 0.0713 - val_loss: 0.0054 - val_rmse: 0.0725 - lr: 1.0000e-04\n",
      "Epoch 155/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0057 - rmse: 0.0746\n",
      "Epoch 155: val_loss improved from 0.00540 to 0.00460, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0047 - rmse: 0.0675 - val_loss: 0.0046 - val_rmse: 0.0667 - lr: 1.0000e-04\n",
      "Epoch 156/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0042 - rmse: 0.0634\n",
      "Epoch 156: val_loss improved from 0.00460 to 0.00406, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0043 - rmse: 0.0647 - val_loss: 0.0041 - val_rmse: 0.0625 - lr: 1.0000e-04\n",
      "Epoch 157/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0042 - rmse: 0.0638\n",
      "Epoch 157: val_loss improved from 0.00406 to 0.00395, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0039 - rmse: 0.0608 - val_loss: 0.0039 - val_rmse: 0.0616 - lr: 1.0000e-04\n",
      "Epoch 158/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0032 - rmse: 0.0548\n",
      "Epoch 158: val_loss improved from 0.00395 to 0.00315, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0035 - rmse: 0.0581 - val_loss: 0.0032 - val_rmse: 0.0548 - lr: 1.0000e-04\n",
      "Epoch 159/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0027 - rmse: 0.0504\n",
      "Epoch 159: val_loss did not improve from 0.00315\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0036 - rmse: 0.0585 - val_loss: 0.0033 - val_rmse: 0.0558 - lr: 1.0000e-04\n",
      "Epoch 160/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0034 - rmse: 0.0570\n",
      "Epoch 160: val_loss improved from 0.00315 to 0.00308, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0035 - rmse: 0.0581 - val_loss: 0.0031 - val_rmse: 0.0541 - lr: 1.0000e-04\n",
      "Epoch 161/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0024 - rmse: 0.0478\n",
      "Epoch 161: val_loss improved from 0.00308 to 0.00293, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0035 - rmse: 0.0578 - val_loss: 0.0029 - val_rmse: 0.0528 - lr: 1.0000e-04\n",
      "Epoch 162/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0025 - rmse: 0.0489\n",
      "Epoch 162: val_loss did not improve from 0.00293\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0035 - rmse: 0.0582 - val_loss: 0.0035 - val_rmse: 0.0578 - lr: 1.0000e-04\n",
      "Epoch 163/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0033 - rmse: 0.0558\n",
      "Epoch 163: val_loss did not improve from 0.00293\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0036 - rmse: 0.0589 - val_loss: 0.0031 - val_rmse: 0.0540 - lr: 1.0000e-04\n",
      "Epoch 164/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0032 - rmse: 0.0551\n",
      "Epoch 164: val_loss improved from 0.00293 to 0.00258, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0029 - rmse: 0.0524 - val_loss: 0.0026 - val_rmse: 0.0493 - lr: 1.0000e-04\n",
      "Epoch 165/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0027 - rmse: 0.0504\n",
      "Epoch 165: val_loss did not improve from 0.00258\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0028 - rmse: 0.0511 - val_loss: 0.0026 - val_rmse: 0.0496 - lr: 1.0000e-04\n",
      "Epoch 166/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0401\n",
      "Epoch 166: val_loss improved from 0.00258 to 0.00241, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0025 - rmse: 0.0487 - val_loss: 0.0024 - val_rmse: 0.0476 - lr: 1.0000e-04\n",
      "Epoch 167/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0020 - rmse: 0.0426\n",
      "Epoch 167: val_loss improved from 0.00241 to 0.00238, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0022 - rmse: 0.0458 - val_loss: 0.0024 - val_rmse: 0.0472 - lr: 1.0000e-04\n",
      "Epoch 168/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0023 - rmse: 0.0466\n",
      "Epoch 168: val_loss improved from 0.00238 to 0.00227, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0024 - rmse: 0.0472 - val_loss: 0.0023 - val_rmse: 0.0460 - lr: 1.0000e-04\n",
      "Epoch 169/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0400\n",
      "Epoch 169: val_loss did not improve from 0.00227\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0024 - rmse: 0.0476 - val_loss: 0.0024 - val_rmse: 0.0474 - lr: 1.0000e-04\n",
      "Epoch 170/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0438\n",
      "Epoch 170: val_loss improved from 0.00227 to 0.00222, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0021 - rmse: 0.0442 - val_loss: 0.0022 - val_rmse: 0.0455 - lr: 1.0000e-04\n",
      "Epoch 171/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0020 - rmse: 0.0429\n",
      "Epoch 171: val_loss did not improve from 0.00222\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0026 - rmse: 0.0491 - val_loss: 0.0024 - val_rmse: 0.0471 - lr: 1.0000e-04\n",
      "Epoch 172/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0023 - rmse: 0.0465\n",
      "Epoch 172: val_loss improved from 0.00222 to 0.00217, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0021 - rmse: 0.0444 - val_loss: 0.0022 - val_rmse: 0.0450 - lr: 1.0000e-04\n",
      "Epoch 173/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0022 - rmse: 0.0450\n",
      "Epoch 173: val_loss improved from 0.00217 to 0.00213, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0022 - rmse: 0.0453 - val_loss: 0.0021 - val_rmse: 0.0446 - lr: 1.0000e-04\n",
      "Epoch 174/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0025 - rmse: 0.0484\n",
      "Epoch 174: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0022 - rmse: 0.0457 - val_loss: 0.0023 - val_rmse: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 175/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0020 - rmse: 0.0432\n",
      "Epoch 175: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0023 - rmse: 0.0466 - val_loss: 0.0023 - val_rmse: 0.0460 - lr: 1.0000e-04\n",
      "Epoch 176/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0024 - rmse: 0.0477\n",
      "Epoch 176: val_loss did not improve from 0.00213\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0022 - rmse: 0.0448 - val_loss: 0.0024 - val_rmse: 0.0472 - lr: 1.0000e-04\n",
      "Epoch 177/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0418\n",
      "Epoch 177: val_loss improved from 0.00213 to 0.00207, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0022 - rmse: 0.0451 - val_loss: 0.0021 - val_rmse: 0.0438 - lr: 1.0000e-04\n",
      "Epoch 178/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0025 - rmse: 0.0480\n",
      "Epoch 178: val_loss improved from 0.00207 to 0.00204, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0025 - rmse: 0.0486 - val_loss: 0.0020 - val_rmse: 0.0435 - lr: 1.0000e-04\n",
      "Epoch 179/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0365\n",
      "Epoch 179: val_loss improved from 0.00204 to 0.00204, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0021 - rmse: 0.0439 - val_loss: 0.0020 - val_rmse: 0.0435 - lr: 1.0000e-04\n",
      "Epoch 180/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0442\n",
      "Epoch 180: val_loss did not improve from 0.00204\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - rmse: 0.0451 - val_loss: 0.0021 - val_rmse: 0.0438 - lr: 1.0000e-04\n",
      "Epoch 181/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0022 - rmse: 0.0451\n",
      "Epoch 181: val_loss did not improve from 0.00204\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0021 - rmse: 0.0441 - val_loss: 0.0021 - val_rmse: 0.0441 - lr: 1.0000e-04\n",
      "Epoch 182/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0438\n",
      "Epoch 182: val_loss improved from 0.00204 to 0.00193, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0018 - rmse: 0.0407 - val_loss: 0.0019 - val_rmse: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 183/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0023 - rmse: 0.0466\n",
      "Epoch 183: val_loss improved from 0.00193 to 0.00181, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0023 - rmse: 0.0459 - val_loss: 0.0018 - val_rmse: 0.0407 - lr: 1.0000e-04\n",
      "Epoch 184/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0389\n",
      "Epoch 184: val_loss did not improve from 0.00181\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - rmse: 0.0399 - val_loss: 0.0019 - val_rmse: 0.0416 - lr: 1.0000e-04\n",
      "Epoch 185/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0382\n",
      "Epoch 185: val_loss did not improve from 0.00181\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0016 - rmse: 0.0386 - val_loss: 0.0019 - val_rmse: 0.0416 - lr: 1.0000e-04\n",
      "Epoch 186/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0032 - rmse: 0.0552\n",
      "Epoch 186: val_loss did not improve from 0.00181\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0022 - rmse: 0.0457 - val_loss: 0.0019 - val_rmse: 0.0420 - lr: 1.0000e-04\n",
      "Epoch 187/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0393\n",
      "Epoch 187: val_loss improved from 0.00181 to 0.00180, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0018 - rmse: 0.0410 - val_loss: 0.0018 - val_rmse: 0.0406 - lr: 1.0000e-04\n",
      "Epoch 188/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0437\n",
      "Epoch 188: val_loss improved from 0.00180 to 0.00176, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0018 - rmse: 0.0400 - val_loss: 0.0018 - val_rmse: 0.0402 - lr: 1.0000e-04\n",
      "Epoch 189/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0022 - rmse: 0.0458\n",
      "Epoch 189: val_loss improved from 0.00176 to 0.00172, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0020 - rmse: 0.0431 - val_loss: 0.0017 - val_rmse: 0.0397 - lr: 1.0000e-04\n",
      "Epoch 190/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.3227e-04 - rmse: 0.0280\n",
      "Epoch 190: val_loss did not improve from 0.00172\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0018 - rmse: 0.0401 - val_loss: 0.0017 - val_rmse: 0.0398 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0355\n",
      "Epoch 191: val_loss did not improve from 0.00172\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - rmse: 0.0389 - val_loss: 0.0018 - val_rmse: 0.0404 - lr: 1.0000e-04\n",
      "Epoch 192/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0393\n",
      "Epoch 192: val_loss did not improve from 0.00172\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0018 - rmse: 0.0403 - val_loss: 0.0019 - val_rmse: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 193/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0413\n",
      "Epoch 193: val_loss did not improve from 0.00172\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0018 - rmse: 0.0408 - val_loss: 0.0018 - val_rmse: 0.0408 - lr: 1.0000e-04\n",
      "Epoch 194/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0395\n",
      "Epoch 194: val_loss did not improve from 0.00172\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0019 - rmse: 0.0419 - val_loss: 0.0019 - val_rmse: 0.0422 - lr: 1.0000e-04\n",
      "Epoch 195/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0402\n",
      "Epoch 195: val_loss improved from 0.00172 to 0.00170, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0019 - rmse: 0.0420 - val_loss: 0.0017 - val_rmse: 0.0394 - lr: 1.0000e-04\n",
      "Epoch 196/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0331\n",
      "Epoch 196: val_loss did not improve from 0.00170\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0015 - rmse: 0.0374 - val_loss: 0.0017 - val_rmse: 0.0399 - lr: 1.0000e-04\n",
      "Epoch 197/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0413\n",
      "Epoch 197: val_loss improved from 0.00170 to 0.00162, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0019 - rmse: 0.0413 - val_loss: 0.0016 - val_rmse: 0.0384 - lr: 1.0000e-04\n",
      "Epoch 198/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0299\n",
      "Epoch 198: val_loss did not improve from 0.00162\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0016 - rmse: 0.0376 - val_loss: 0.0017 - val_rmse: 0.0389 - lr: 1.0000e-04\n",
      "Epoch 199/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0380\n",
      "Epoch 199: val_loss did not improve from 0.00162\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0016 - rmse: 0.0383 - val_loss: 0.0018 - val_rmse: 0.0405 - lr: 1.0000e-04\n",
      "Epoch 200/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0348\n",
      "Epoch 200: val_loss improved from 0.00162 to 0.00161, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 190ms/step - loss: 0.0019 - rmse: 0.0416 - val_loss: 0.0016 - val_rmse: 0.0383 - lr: 1.0000e-04\n",
      "Epoch 201/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0438\n",
      "Epoch 201: val_loss did not improve from 0.00161\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0017 - rmse: 0.0393 - val_loss: 0.0016 - val_rmse: 0.0385 - lr: 1.0000e-04\n",
      "Epoch 202/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0378\n",
      "Epoch 202: val_loss did not improve from 0.00161\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0015 - rmse: 0.0367 - val_loss: 0.0017 - val_rmse: 0.0389 - lr: 1.0000e-04\n",
      "Epoch 203/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0020 - rmse: 0.0434\n",
      "Epoch 203: val_loss improved from 0.00161 to 0.00156, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0018 - rmse: 0.0401 - val_loss: 0.0016 - val_rmse: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 204/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0021 - rmse: 0.0439\n",
      "Epoch 204: val_loss did not improve from 0.00156\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - rmse: 0.0394 - val_loss: 0.0017 - val_rmse: 0.0390 - lr: 1.0000e-04\n",
      "Epoch 205/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0371\n",
      "Epoch 205: val_loss improved from 0.00156 to 0.00152, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0014 - rmse: 0.0360 - val_loss: 0.0015 - val_rmse: 0.0370 - lr: 1.0000e-04\n",
      "Epoch 206/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0032 - rmse: 0.0551\n",
      "Epoch 206: val_loss did not improve from 0.00152\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0022 - rmse: 0.0455 - val_loss: 0.0017 - val_rmse: 0.0388 - lr: 1.0000e-04\n",
      "Epoch 207/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0341\n",
      "Epoch 207: val_loss did not improve from 0.00152\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0015 - rmse: 0.0374 - val_loss: 0.0017 - val_rmse: 0.0390 - lr: 1.0000e-04\n",
      "Epoch 208/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0360\n",
      "Epoch 208: val_loss did not improve from 0.00152\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0016 - rmse: 0.0386 - val_loss: 0.0016 - val_rmse: 0.0382 - lr: 1.0000e-04\n",
      "Epoch 209/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0356\n",
      "Epoch 209: val_loss improved from 0.00152 to 0.00150, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0016 - rmse: 0.0385 - val_loss: 0.0015 - val_rmse: 0.0367 - lr: 1.0000e-04\n",
      "Epoch 210/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0402\n",
      "Epoch 210: val_loss did not improve from 0.00150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0018 - rmse: 0.0400 - val_loss: 0.0015 - val_rmse: 0.0371 - lr: 1.0000e-04\n",
      "Epoch 211/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0417\n",
      "Epoch 211: val_loss did not improve from 0.00150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0017 - rmse: 0.0400 - val_loss: 0.0015 - val_rmse: 0.0373 - lr: 1.0000e-04\n",
      "Epoch 212/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0400\n",
      "Epoch 212: val_loss did not improve from 0.00150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0018 - rmse: 0.0409 - val_loss: 0.0016 - val_rmse: 0.0383 - lr: 1.0000e-04\n",
      "Epoch 213/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0380\n",
      "Epoch 213: val_loss did not improve from 0.00150\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0017 - rmse: 0.0394 - val_loss: 0.0016 - val_rmse: 0.0386 - lr: 1.0000e-04\n",
      "Epoch 214/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0402\n",
      "Epoch 214: val_loss did not improve from 0.00150\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0019 - rmse: 0.0413 - val_loss: 0.0016 - val_rmse: 0.0386 - lr: 1.0000e-04\n",
      "Epoch 215/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0387\n",
      "Epoch 215: val_loss did not improve from 0.00150\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0017 - rmse: 0.0393 - val_loss: 0.0016 - val_rmse: 0.0382 - lr: 1.0000e-04\n",
      "Epoch 216/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0367\n",
      "Epoch 216: val_loss improved from 0.00150 to 0.00144, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0017 - rmse: 0.0390 - val_loss: 0.0014 - val_rmse: 0.0360 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0408\n",
      "Epoch 217: val_loss did not improve from 0.00144\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0016 - rmse: 0.0378 - val_loss: 0.0015 - val_rmse: 0.0371 - lr: 1.0000e-04\n",
      "Epoch 218/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0423\n",
      "Epoch 218: val_loss did not improve from 0.00144\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0015 - rmse: 0.0371 - val_loss: 0.0015 - val_rmse: 0.0365 - lr: 1.0000e-04\n",
      "Epoch 219/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0018 - rmse: 0.0405\n",
      "Epoch 219: val_loss did not improve from 0.00144\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0016 - rmse: 0.0379 - val_loss: 0.0015 - val_rmse: 0.0367 - lr: 1.0000e-04\n",
      "Epoch 220/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0339\n",
      "Epoch 220: val_loss did not improve from 0.00144\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0015 - rmse: 0.0374 - val_loss: 0.0015 - val_rmse: 0.0369 - lr: 1.0000e-04\n",
      "Epoch 221/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0390\n",
      "Epoch 221: val_loss did not improve from 0.00144\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0015 - rmse: 0.0371 - val_loss: 0.0015 - val_rmse: 0.0365 - lr: 1.0000e-04\n",
      "Epoch 222/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0330\n",
      "Epoch 222: val_loss improved from 0.00144 to 0.00142, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0014 - rmse: 0.0354 - val_loss: 0.0014 - val_rmse: 0.0357 - lr: 1.0000e-04\n",
      "Epoch 223/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0356\n",
      "Epoch 223: val_loss improved from 0.00142 to 0.00140, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0014 - rmse: 0.0355 - val_loss: 0.0014 - val_rmse: 0.0354 - lr: 1.0000e-04\n",
      "Epoch 224/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0363\n",
      "Epoch 224: val_loss did not improve from 0.00140\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0015 - rmse: 0.0367 - val_loss: 0.0014 - val_rmse: 0.0360 - lr: 1.0000e-04\n",
      "Epoch 225/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0858e-04 - rmse: 0.0276\n",
      "Epoch 225: val_loss improved from 0.00140 to 0.00139, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0014 - rmse: 0.0350 - val_loss: 0.0014 - val_rmse: 0.0352 - lr: 1.0000e-04\n",
      "Epoch 226/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0016 - rmse: 0.0387\n",
      "Epoch 226: val_loss did not improve from 0.00139\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0015 - rmse: 0.0372 - val_loss: 0.0014 - val_rmse: 0.0353 - lr: 1.0000e-04\n",
      "Epoch 227/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0370\n",
      "Epoch 227: val_loss did not improve from 0.00139\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0328 - val_loss: 0.0014 - val_rmse: 0.0360 - lr: 1.0000e-04\n",
      "Epoch 228/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0329\n",
      "Epoch 228: val_loss improved from 0.00139 to 0.00136, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0016 - rmse: 0.0381 - val_loss: 0.0014 - val_rmse: 0.0349 - lr: 1.0000e-04\n",
      "Epoch 229/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0364\n",
      "Epoch 229: val_loss did not improve from 0.00136\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0014 - rmse: 0.0355 - val_loss: 0.0014 - val_rmse: 0.0351 - lr: 1.0000e-04\n",
      "Epoch 230/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0327\n",
      "Epoch 230: val_loss improved from 0.00136 to 0.00133, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0012 - rmse: 0.0321 - val_loss: 0.0013 - val_rmse: 0.0344 - lr: 1.0000e-04\n",
      "Epoch 231/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0019 - rmse: 0.0422\n",
      "Epoch 231: val_loss improved from 0.00133 to 0.00132, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0015 - rmse: 0.0367 - val_loss: 0.0013 - val_rmse: 0.0343 - lr: 1.0000e-04\n",
      "Epoch 232/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0363\n",
      "Epoch 232: val_loss did not improve from 0.00132\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0014 - rmse: 0.0350 - val_loss: 0.0013 - val_rmse: 0.0345 - lr: 1.0000e-04\n",
      "Epoch 233/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0343\n",
      "Epoch 233: val_loss improved from 0.00132 to 0.00132, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0013 - rmse: 0.0340 - val_loss: 0.0013 - val_rmse: 0.0342 - lr: 1.0000e-04\n",
      "Epoch 234/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0369\n",
      "Epoch 234: val_loss did not improve from 0.00132\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0013 - rmse: 0.0342 - val_loss: 0.0013 - val_rmse: 0.0342 - lr: 1.0000e-04\n",
      "Epoch 235/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0322\n",
      "Epoch 235: val_loss improved from 0.00132 to 0.00127, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0014 - rmse: 0.0348 - val_loss: 0.0013 - val_rmse: 0.0336 - lr: 1.0000e-04\n",
      "Epoch 236/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0334\n",
      "Epoch 236: val_loss did not improve from 0.00127\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0013 - rmse: 0.0337 - val_loss: 0.0013 - val_rmse: 0.0338 - lr: 1.0000e-04\n",
      "Epoch 237/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0373\n",
      "Epoch 237: val_loss improved from 0.00127 to 0.00127, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0013 - rmse: 0.0333 - val_loss: 0.0013 - val_rmse: 0.0335 - lr: 1.0000e-04\n",
      "Epoch 238/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0363\n",
      "Epoch 238: val_loss did not improve from 0.00127\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0013 - rmse: 0.0338 - val_loss: 0.0013 - val_rmse: 0.0340 - lr: 1.0000e-04\n",
      "Epoch 239/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0357\n",
      "Epoch 239: val_loss improved from 0.00127 to 0.00127, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0013 - rmse: 0.0347 - val_loss: 0.0013 - val_rmse: 0.0335 - lr: 1.0000e-04\n",
      "Epoch 240/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0358\n",
      "Epoch 240: val_loss improved from 0.00127 to 0.00119, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0013 - rmse: 0.0336 - val_loss: 0.0012 - val_rmse: 0.0323 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0346\n",
      "Epoch 241: val_loss did not improve from 0.00119\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0013 - rmse: 0.0333 - val_loss: 0.0012 - val_rmse: 0.0325 - lr: 1.0000e-04\n",
      "Epoch 242/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0347\n",
      "Epoch 242: val_loss did not improve from 0.00119\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0013 - rmse: 0.0338 - val_loss: 0.0013 - val_rmse: 0.0338 - lr: 1.0000e-04\n",
      "Epoch 243/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0304\n",
      "Epoch 243: val_loss did not improve from 0.00119\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0011 - rmse: 0.0315 - val_loss: 0.0013 - val_rmse: 0.0339 - lr: 1.0000e-04\n",
      "Epoch 244/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0393\n",
      "Epoch 244: val_loss did not improve from 0.00119\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0014 - rmse: 0.0354 - val_loss: 0.0013 - val_rmse: 0.0333 - lr: 1.0000e-04\n",
      "Epoch 245/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0350\n",
      "Epoch 245: val_loss improved from 0.00119 to 0.00115, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0013 - rmse: 0.0339 - val_loss: 0.0012 - val_rmse: 0.0317 - lr: 1.0000e-04\n",
      "Epoch 246/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0298\n",
      "Epoch 246: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0012 - rmse: 0.0327 - val_loss: 0.0012 - val_rmse: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 247/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0321\n",
      "Epoch 247: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0014 - rmse: 0.0357 - val_loss: 0.0013 - val_rmse: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 248/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0337\n",
      "Epoch 248: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0010 - rmse: 0.0297 - val_loss: 0.0012 - val_rmse: 0.0331 - lr: 1.0000e-04\n",
      "Epoch 249/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0334\n",
      "Epoch 249: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0013 - rmse: 0.0332 - val_loss: 0.0013 - val_rmse: 0.0340 - lr: 1.0000e-04\n",
      "Epoch 250/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0305\n",
      "Epoch 250: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0012 - rmse: 0.0329 - val_loss: 0.0012 - val_rmse: 0.0332 - lr: 1.0000e-04\n",
      "Epoch 251/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0306\n",
      "Epoch 251: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0325 - val_loss: 0.0013 - val_rmse: 0.0334 - lr: 1.0000e-04\n",
      "Epoch 252/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0322\n",
      "Epoch 252: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0329 - val_loss: 0.0012 - val_rmse: 0.0318 - lr: 1.0000e-04\n",
      "Epoch 253/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0017 - rmse: 0.0390\n",
      "Epoch 253: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0012 - rmse: 0.0326 - val_loss: 0.0012 - val_rmse: 0.0325 - lr: 1.0000e-04\n",
      "Epoch 254/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0302\n",
      "Epoch 254: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0012 - rmse: 0.0320 - val_loss: 0.0012 - val_rmse: 0.0322 - lr: 1.0000e-04\n",
      "Epoch 255/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0339\n",
      "Epoch 255: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0322 - val_loss: 0.0012 - val_rmse: 0.0332 - lr: 1.0000e-04\n",
      "Epoch 256/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0353\n",
      "Epoch 256: val_loss did not improve from 0.00115\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0327 - val_loss: 0.0013 - val_rmse: 0.0335 - lr: 1.0000e-04\n",
      "Epoch 257/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0015 - rmse: 0.0366\n",
      "Epoch 257: val_loss improved from 0.00115 to 0.00113, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0013 - rmse: 0.0334 - val_loss: 0.0011 - val_rmse: 0.0313 - lr: 1.0000e-04\n",
      "Epoch 258/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.0601e-04 - rmse: 0.0257\n",
      "Epoch 258: val_loss did not improve from 0.00113\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0013 - rmse: 0.0340 - val_loss: 0.0012 - val_rmse: 0.0320 - lr: 1.0000e-04\n",
      "Epoch 259/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.4568e-04 - rmse: 0.0283\n",
      "Epoch 259: val_loss did not improve from 0.00113\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0011 - rmse: 0.0309 - val_loss: 0.0012 - val_rmse: 0.0323 - lr: 1.0000e-04\n",
      "Epoch 260/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0332\n",
      "Epoch 260: val_loss did not improve from 0.00113\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0011 - rmse: 0.0303 - val_loss: 0.0012 - val_rmse: 0.0317 - lr: 1.0000e-04\n",
      "Epoch 261/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.5651e-04 - rmse: 0.0267\n",
      "Epoch 261: val_loss improved from 0.00113 to 0.00105, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0011 - rmse: 0.0307 - val_loss: 0.0010 - val_rmse: 0.0301 - lr: 1.0000e-04\n",
      "Epoch 262/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0316\n",
      "Epoch 262: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0012 - rmse: 0.0327 - val_loss: 0.0012 - val_rmse: 0.0321 - lr: 1.0000e-04\n",
      "Epoch 263/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0298\n",
      "Epoch 263: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0010 - rmse: 0.0295 - val_loss: 0.0012 - val_rmse: 0.0323 - lr: 1.0000e-04\n",
      "Epoch 264/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.4484e-04 - rmse: 0.0283\n",
      "Epoch 264: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0011 - rmse: 0.0313 - val_loss: 0.0012 - val_rmse: 0.0320 - lr: 1.0000e-04\n",
      "Epoch 265/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0014 - rmse: 0.0349\n",
      "Epoch 265: val_loss improved from 0.00105 to 0.00105, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0011 - rmse: 0.0311 - val_loss: 0.0010 - val_rmse: 0.0300 - lr: 1.0000e-04\n",
      "Epoch 266/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0314\n",
      "Epoch 266: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0012 - rmse: 0.0322 - val_loss: 0.0011 - val_rmse: 0.0301 - lr: 1.0000e-04\n",
      "Epoch 267/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0314\n",
      "Epoch 267: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.9794e-04 - rmse: 0.0292 - val_loss: 0.0011 - val_rmse: 0.0301 - lr: 1.0000e-04\n",
      "Epoch 268/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 9.8846e-04 - rmse: 0.0290\n",
      "Epoch 268: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0011 - rmse: 0.0310 - val_loss: 0.0011 - val_rmse: 0.0301 - lr: 1.0000e-04\n",
      "Epoch 269/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0304\n",
      "Epoch 269: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0011 - rmse: 0.0308 - val_loss: 0.0011 - val_rmse: 0.0305 - lr: 1.0000e-04\n",
      "Epoch 270/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.9955e-04 - rmse: 0.0256\n",
      "Epoch 270: val_loss did not improve from 0.00105\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0011 - rmse: 0.0317 - val_loss: 0.0011 - val_rmse: 0.0302 - lr: 1.0000e-04\n",
      "Epoch 271/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3131e-04 - rmse: 0.0220\n",
      "Epoch 271: val_loss improved from 0.00105 to 0.00101, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 8.6808e-04 - rmse: 0.0269 - val_loss: 0.0010 - val_rmse: 0.0295 - lr: 1.0000e-04\n",
      "Epoch 272/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.0468e-04 - rmse: 0.0257\n",
      "Epoch 272: val_loss improved from 0.00101 to 0.00099, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 9.8349e-04 - rmse: 0.0289 - val_loss: 9.8996e-04 - val_rmse: 0.0291 - lr: 1.0000e-04\n",
      "Epoch 273/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.4363e-04 - rmse: 0.0223\n",
      "Epoch 273: val_loss improved from 0.00099 to 0.00096, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0011 - rmse: 0.0304 - val_loss: 9.6358e-04 - val_rmse: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 274/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.5966e-04 - rmse: 0.0248\n",
      "Epoch 274: val_loss improved from 0.00096 to 0.00094, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 9.8531e-04 - rmse: 0.0290 - val_loss: 9.3832e-04 - val_rmse: 0.0282 - lr: 1.0000e-04\n",
      "Epoch 275/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0299\n",
      "Epoch 275: val_loss did not improve from 0.00094\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.5965e-04 - rmse: 0.0285 - val_loss: 9.7872e-04 - val_rmse: 0.0289 - lr: 1.0000e-04\n",
      "Epoch 276/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0293\n",
      "Epoch 276: val_loss did not improve from 0.00094\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.6815e-04 - rmse: 0.0287 - val_loss: 0.0010 - val_rmse: 0.0296 - lr: 1.0000e-04\n",
      "Epoch 277/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.7942e-04 - rmse: 0.0271\n",
      "Epoch 277: val_loss did not improve from 0.00094\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.3261e-04 - rmse: 0.0281 - val_loss: 9.8779e-04 - val_rmse: 0.0290 - lr: 1.0000e-04\n",
      "Epoch 278/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - rmse: 0.0325\n",
      "Epoch 278: val_loss did not improve from 0.00094\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0011 - rmse: 0.0304 - val_loss: 0.0010 - val_rmse: 0.0293 - lr: 1.0000e-04\n",
      "Epoch 279/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.6138e-04 - rmse: 0.0268\n",
      "Epoch 279: val_loss did not improve from 0.00094\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 8.3139e-04 - rmse: 0.0262 - val_loss: 9.8322e-04 - val_rmse: 0.0289 - lr: 1.0000e-04\n",
      "Epoch 280/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.7656e-04 - rmse: 0.0270\n",
      "Epoch 280: val_loss improved from 0.00094 to 0.00093, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0010 - rmse: 0.0294 - val_loss: 9.3286e-04 - val_rmse: 0.0281 - lr: 1.0000e-04\n",
      "Epoch 281/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0302\n",
      "Epoch 281: val_loss did not improve from 0.00093\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.6986e-04 - rmse: 0.0287 - val_loss: 9.4325e-04 - val_rmse: 0.0282 - lr: 1.0000e-04\n",
      "Epoch 282/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.6035e-04 - rmse: 0.0248\n",
      "Epoch 282: val_loss improved from 0.00093 to 0.00090, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 7.1181e-04 - rmse: 0.0238 - val_loss: 9.0181e-04 - val_rmse: 0.0275 - lr: 1.0000e-04\n",
      "Epoch 283/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0013 - rmse: 0.0339\n",
      "Epoch 283: val_loss did not improve from 0.00090\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0012 - rmse: 0.0331 - val_loss: 9.6404e-04 - val_rmse: 0.0286 - lr: 1.0000e-04\n",
      "Epoch 284/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.3545e-04 - rmse: 0.0263\n",
      "Epoch 284: val_loss did not improve from 0.00090\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.1791e-04 - rmse: 0.0259 - val_loss: 9.2242e-04 - val_rmse: 0.0279 - lr: 1.0000e-04\n",
      "Epoch 285/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0950e-04 - rmse: 0.0276\n",
      "Epoch 285: val_loss did not improve from 0.00090\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 9.0411e-04 - rmse: 0.0275 - val_loss: 9.1593e-04 - val_rmse: 0.0278 - lr: 1.0000e-04\n",
      "Epoch 286/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.6915e-04 - rmse: 0.0287\n",
      "Epoch 286: val_loss improved from 0.00090 to 0.00090, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 9.5965e-04 - rmse: 0.0285 - val_loss: 8.9843e-04 - val_rmse: 0.0274 - lr: 1.0000e-04\n",
      "Epoch 287/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.8836e-04 - rmse: 0.0254\n",
      "Epoch 287: val_loss did not improve from 0.00090\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 9.3557e-04 - rmse: 0.0281 - val_loss: 9.1045e-04 - val_rmse: 0.0277 - lr: 1.0000e-04\n",
      "Epoch 288/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.4435e-04 - rmse: 0.0264\n",
      "Epoch 288: val_loss did not improve from 0.00090\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.5063e-04 - rmse: 0.0266 - val_loss: 9.2882e-04 - val_rmse: 0.0280 - lr: 1.0000e-04\n",
      "Epoch 289/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.5022e-04 - rmse: 0.0284\n",
      "Epoch 289: val_loss improved from 0.00090 to 0.00087, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 9.1681e-04 - rmse: 0.0278 - val_loss: 8.6699e-04 - val_rmse: 0.0269 - lr: 1.0000e-04\n",
      "Epoch 290/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.4495e-04 - rmse: 0.0283\n",
      "Epoch 290: val_loss did not improve from 0.00087\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9.9967e-04 - rmse: 0.0292 - val_loss: 8.9645e-04 - val_rmse: 0.0274 - lr: 1.0000e-04\n",
      "Epoch 291/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.7788e-04 - rmse: 0.0271\n",
      "Epoch 291: val_loss did not improve from 0.00087\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.9986e-04 - rmse: 0.0275 - val_loss: 9.7531e-04 - val_rmse: 0.0288 - lr: 1.0000e-04\n",
      "Epoch 292/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.6590e-04 - rmse: 0.0249\n",
      "Epoch 292: val_loss did not improve from 0.00087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 28ms/step - loss: 8.3189e-04 - rmse: 0.0262 - val_loss: 8.8783e-04 - val_rmse: 0.0273 - lr: 1.0000e-04\n",
      "Epoch 293/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.5853e-04 - rmse: 0.0267\n",
      "Epoch 293: val_loss did not improve from 0.00087\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.9517e-04 - rmse: 0.0274 - val_loss: 8.8647e-04 - val_rmse: 0.0272 - lr: 1.0000e-04\n",
      "Epoch 294/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.3179e-04 - rmse: 0.0242\n",
      "Epoch 294: val_loss did not improve from 0.00087\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.7591e-04 - rmse: 0.0270 - val_loss: 8.6952e-04 - val_rmse: 0.0269 - lr: 1.0000e-04\n",
      "Epoch 295/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.5684e-04 - rmse: 0.0267\n",
      "Epoch 295: val_loss improved from 0.00087 to 0.00083, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 7.8422e-04 - rmse: 0.0253 - val_loss: 8.3322e-04 - val_rmse: 0.0262 - lr: 1.0000e-04\n",
      "Epoch 296/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.5302e-04 - rmse: 0.0225\n",
      "Epoch 296: val_loss improved from 0.00083 to 0.00081, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 9.1826e-04 - rmse: 0.0278 - val_loss: 8.1153e-04 - val_rmse: 0.0258 - lr: 1.0000e-04\n",
      "Epoch 297/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.8844e-04 - rmse: 0.0254\n",
      "Epoch 297: val_loss did not improve from 0.00081\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.5688e-04 - rmse: 0.0267 - val_loss: 8.1553e-04 - val_rmse: 0.0259 - lr: 1.0000e-04\n",
      "Epoch 298/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.4280e-04 - rmse: 0.0245\n",
      "Epoch 298: val_loss did not improve from 0.00081\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 8.0842e-04 - rmse: 0.0258 - val_loss: 8.9732e-04 - val_rmse: 0.0274 - lr: 1.0000e-04\n",
      "Epoch 299/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.9823e-04 - rmse: 0.0256\n",
      "Epoch 299: val_loss did not improve from 0.00081\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 8.8710e-04 - rmse: 0.0272 - val_loss: 9.0273e-04 - val_rmse: 0.0275 - lr: 1.0000e-04\n",
      "Epoch 300/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.2307e-04 - rmse: 0.0260\n",
      "Epoch 300: val_loss did not improve from 0.00081\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 7.9692e-04 - rmse: 0.0255 - val_loss: 8.3697e-04 - val_rmse: 0.0263 - lr: 1.0000e-04\n",
      "Epoch 301/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.0873e-04 - rmse: 0.0215\n",
      "Epoch 301: val_loss improved from 0.00081 to 0.00077, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 7.6257e-04 - rmse: 0.0249 - val_loss: 7.7282e-04 - val_rmse: 0.0251 - lr: 1.0000e-04\n",
      "Epoch 302/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0301\n",
      "Epoch 302: val_loss did not improve from 0.00077\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 8.7817e-04 - rmse: 0.0271 - val_loss: 8.1072e-04 - val_rmse: 0.0258 - lr: 1.0000e-04\n",
      "Epoch 303/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.9679e-04 - rmse: 0.0274\n",
      "Epoch 303: val_loss did not improve from 0.00077\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.1861e-04 - rmse: 0.0260 - val_loss: 8.0971e-04 - val_rmse: 0.0258 - lr: 1.0000e-04\n",
      "Epoch 304/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.9919e-04 - rmse: 0.0256\n",
      "Epoch 304: val_loss did not improve from 0.00077\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.6475e-04 - rmse: 0.0249 - val_loss: 7.9693e-04 - val_rmse: 0.0255 - lr: 1.0000e-04\n",
      "Epoch 305/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.8815e-04 - rmse: 0.0254\n",
      "Epoch 305: val_loss improved from 0.00077 to 0.00076, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 7.2920e-04 - rmse: 0.0242 - val_loss: 7.6300e-04 - val_rmse: 0.0249 - lr: 1.0000e-04\n",
      "Epoch 306/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - rmse: 0.0303\n",
      "Epoch 306: val_loss did not improve from 0.00076\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.5596e-04 - rmse: 0.0267 - val_loss: 7.8089e-04 - val_rmse: 0.0252 - lr: 1.0000e-04\n",
      "Epoch 307/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.0255e-04 - rmse: 0.0236\n",
      "Epoch 307: val_loss improved from 0.00076 to 0.00075, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 7.4621e-04 - rmse: 0.0245 - val_loss: 7.4902e-04 - val_rmse: 0.0246 - lr: 1.0000e-04\n",
      "Epoch 308/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.3483e-04 - rmse: 0.0243\n",
      "Epoch 308: val_loss improved from 0.00075 to 0.00074, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 7.6707e-04 - rmse: 0.0250 - val_loss: 7.3895e-04 - val_rmse: 0.0244 - lr: 1.0000e-04\n",
      "Epoch 309/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.6319e-04 - rmse: 0.0268\n",
      "Epoch 309: val_loss did not improve from 0.00074\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.7587e-04 - rmse: 0.0251 - val_loss: 7.6782e-04 - val_rmse: 0.0250 - lr: 1.0000e-04\n",
      "Epoch 310/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3909e-04 - rmse: 0.0222\n",
      "Epoch 310: val_loss did not improve from 0.00074\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.6686e-04 - rmse: 0.0249 - val_loss: 7.6116e-04 - val_rmse: 0.0248 - lr: 1.0000e-04\n",
      "Epoch 311/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.3257e-04 - rmse: 0.0221\n",
      "Epoch 311: val_loss did not improve from 0.00074\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.0742e-04 - rmse: 0.0237 - val_loss: 7.4637e-04 - val_rmse: 0.0245 - lr: 1.0000e-04\n",
      "Epoch 312/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.9223e-04 - rmse: 0.0234\n",
      "Epoch 312: val_loss improved from 0.00074 to 0.00072, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 7.4686e-04 - rmse: 0.0245 - val_loss: 7.2158e-04 - val_rmse: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 313/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.6907e-04 - rmse: 0.0250\n",
      "Epoch 313: val_loss did not improve from 0.00072\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.9862e-04 - rmse: 0.0256 - val_loss: 8.2323e-04 - val_rmse: 0.0261 - lr: 1.0000e-04\n",
      "Epoch 314/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.9488e-04 - rmse: 0.0235\n",
      "Epoch 314: val_loss did not improve from 0.00072\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.4943e-04 - rmse: 0.0246 - val_loss: 7.5548e-04 - val_rmse: 0.0247 - lr: 1.0000e-04\n",
      "Epoch 315/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0047e-04 - rmse: 0.0275\n",
      "Epoch 315: val_loss did not improve from 0.00072\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 7.1761e-04 - rmse: 0.0239 - val_loss: 8.9124e-04 - val_rmse: 0.0273 - lr: 1.0000e-04\n",
      "Epoch 316/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0010 - rmse: 0.0294\n",
      "Epoch 316: val_loss did not improve from 0.00072\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.7709e-04 - rmse: 0.0271 - val_loss: 7.5014e-04 - val_rmse: 0.0246 - lr: 1.0000e-04\n",
      "Epoch 317/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 6.7610e-04 - rmse: 0.0231\n",
      "Epoch 317: val_loss improved from 0.00072 to 0.00072, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 6.9246e-04 - rmse: 0.0234 - val_loss: 7.1945e-04 - val_rmse: 0.0240 - lr: 1.0000e-04\n",
      "Epoch 318/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.7802e-04 - rmse: 0.0289\n",
      "Epoch 318: val_loss improved from 0.00072 to 0.00071, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 6.7724e-04 - rmse: 0.0231 - val_loss: 7.0621e-04 - val_rmse: 0.0237 - lr: 1.0000e-04\n",
      "Epoch 319/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.0494e-04 - rmse: 0.0276\n",
      "Epoch 319: val_loss did not improve from 0.00071\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 8.3777e-04 - rmse: 0.0263 - val_loss: 8.0195e-04 - val_rmse: 0.0256 - lr: 1.0000e-04\n",
      "Epoch 320/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.2222e-04 - rmse: 0.0260\n",
      "Epoch 320: val_loss did not improve from 0.00071\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.7056e-04 - rmse: 0.0250 - val_loss: 7.3746e-04 - val_rmse: 0.0244 - lr: 1.0000e-04\n",
      "Epoch 321/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.0338e-04 - rmse: 0.0214\n",
      "Epoch 321: val_loss improved from 0.00071 to 0.00070, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 6.7436e-04 - rmse: 0.0230 - val_loss: 7.0101e-04 - val_rmse: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 322/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.2919e-04 - rmse: 0.0280\n",
      "Epoch 322: val_loss did not improve from 0.00070\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.9768e-04 - rmse: 0.0256 - val_loss: 7.6046e-04 - val_rmse: 0.0248 - lr: 1.0000e-04\n",
      "Epoch 323/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.9148e-04 - rmse: 0.0212\n",
      "Epoch 323: val_loss did not improve from 0.00070\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.3699e-04 - rmse: 0.0222 - val_loss: 7.1743e-04 - val_rmse: 0.0239 - lr: 1.0000e-04\n",
      "Epoch 324/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.9829e-04 - rmse: 0.0275\n",
      "Epoch 324: val_loss improved from 0.00070 to 0.00068, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 7.4813e-04 - rmse: 0.0246 - val_loss: 6.8372e-04 - val_rmse: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 325/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.5356e-04 - rmse: 0.0266\n",
      "Epoch 325: val_loss did not improve from 0.00068\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.8203e-04 - rmse: 0.0232 - val_loss: 7.0197e-04 - val_rmse: 0.0236 - lr: 1.0000e-04\n",
      "Epoch 326/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.4414e-04 - rmse: 0.0224\n",
      "Epoch 326: val_loss improved from 0.00068 to 0.00066, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 7.9112e-04 - rmse: 0.0254 - val_loss: 6.6316e-04 - val_rmse: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 327/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9105e-04 - rmse: 0.0157\n",
      "Epoch 327: val_loss improved from 0.00066 to 0.00064, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 4.8740e-04 - rmse: 0.0185 - val_loss: 6.3656e-04 - val_rmse: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 328/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.7301e-04 - rmse: 0.0230\n",
      "Epoch 328: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 7.2547e-04 - rmse: 0.0241 - val_loss: 6.6049e-04 - val_rmse: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 329/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.5077e-04 - rmse: 0.0246\n",
      "Epoch 329: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.5289e-04 - rmse: 0.0226 - val_loss: 6.9245e-04 - val_rmse: 0.0234 - lr: 1.0000e-04\n",
      "Epoch 330/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.8782e-04 - rmse: 0.0273\n",
      "Epoch 330: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 7.2704e-04 - rmse: 0.0242 - val_loss: 6.9243e-04 - val_rmse: 0.0234 - lr: 1.0000e-04\n",
      "Epoch 331/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.1057e-04 - rmse: 0.0238\n",
      "Epoch 331: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.8519e-04 - rmse: 0.0233 - val_loss: 6.7670e-04 - val_rmse: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 332/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.8701e-04 - rmse: 0.0211\n",
      "Epoch 332: val_loss did not improve from 0.00064\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.1009e-04 - rmse: 0.0216 - val_loss: 6.4805e-04 - val_rmse: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 333/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.4926e-04 - rmse: 0.0225\n",
      "Epoch 333: val_loss improved from 0.00064 to 0.00063, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 6.2660e-04 - rmse: 0.0220 - val_loss: 6.3469e-04 - val_rmse: 0.0222 - lr: 1.0000e-04\n",
      "Epoch 334/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.0909e-04 - rmse: 0.0238\n",
      "Epoch 334: val_loss did not improve from 0.00063\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 6.6084e-04 - rmse: 0.0227 - val_loss: 6.4425e-04 - val_rmse: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 335/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.1051e-04 - rmse: 0.0216\n",
      "Epoch 335: val_loss did not improve from 0.00063\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 6.4408e-04 - rmse: 0.0224 - val_loss: 6.4606e-04 - val_rmse: 0.0224 - lr: 1.0000e-04\n",
      "Epoch 336/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.6040e-04 - rmse: 0.0227\n",
      "Epoch 336: val_loss improved from 0.00063 to 0.00060, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 6.0434e-04 - rmse: 0.0215 - val_loss: 6.0240e-04 - val_rmse: 0.0214 - lr: 1.0000e-04\n",
      "Epoch 337/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5410e-04 - rmse: 0.0203\n",
      "Epoch 337: val_loss did not improve from 0.00060\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 6.4402e-04 - rmse: 0.0224 - val_loss: 6.1018e-04 - val_rmse: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 338/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.0812e-04 - rmse: 0.0163\n",
      "Epoch 338: val_loss improved from 0.00060 to 0.00057, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 5.8807e-04 - rmse: 0.0211 - val_loss: 5.7042e-04 - val_rmse: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 339/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4618e-04 - rmse: 0.0201\n",
      "Epoch 339: val_loss did not improve from 0.00057\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 6.0316e-04 - rmse: 0.0214 - val_loss: 5.9499e-04 - val_rmse: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 340/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.7687e-04 - rmse: 0.0208\n",
      "Epoch 340: val_loss did not improve from 0.00057\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.5038e-04 - rmse: 0.0202 - val_loss: 5.9945e-04 - val_rmse: 0.0214 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4723e-04 - rmse: 0.0201\n",
      "Epoch 341: val_loss did not improve from 0.00057\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.8935e-04 - rmse: 0.0211 - val_loss: 5.7906e-04 - val_rmse: 0.0209 - lr: 1.0000e-04\n",
      "Epoch 342/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4143e-04 - rmse: 0.0200\n",
      "Epoch 342: val_loss did not improve from 0.00057\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 6.0952e-04 - rmse: 0.0216 - val_loss: 6.2019e-04 - val_rmse: 0.0218 - lr: 1.0000e-04\n",
      "Epoch 343/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4128e-04 - rmse: 0.0200\n",
      "Epoch 343: val_loss did not improve from 0.00057\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.4225e-04 - rmse: 0.0200 - val_loss: 5.7488e-04 - val_rmse: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 344/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.8259e-04 - rmse: 0.0232\n",
      "Epoch 344: val_loss improved from 0.00057 to 0.00055, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 6.0250e-04 - rmse: 0.0214 - val_loss: 5.4858e-04 - val_rmse: 0.0201 - lr: 1.0000e-04\n",
      "Epoch 345/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1427e-04 - rmse: 0.0193\n",
      "Epoch 345: val_loss improved from 0.00055 to 0.00054, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 5.2666e-04 - rmse: 0.0196 - val_loss: 5.3954e-04 - val_rmse: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 346/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8.4139e-04 - rmse: 0.0264\n",
      "Epoch 346: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 6.0362e-04 - rmse: 0.0215 - val_loss: 5.6692e-04 - val_rmse: 0.0206 - lr: 1.0000e-04\n",
      "Epoch 347/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5380e-04 - rmse: 0.0203\n",
      "Epoch 347: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.8582e-04 - rmse: 0.0210 - val_loss: 5.8760e-04 - val_rmse: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 348/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9950e-04 - rmse: 0.0189\n",
      "Epoch 348: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.7137e-04 - rmse: 0.0207 - val_loss: 5.4007e-04 - val_rmse: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 349/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.9555e-04 - rmse: 0.0213\n",
      "Epoch 349: val_loss did not improve from 0.00054\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.5551e-04 - rmse: 0.0203 - val_loss: 5.6465e-04 - val_rmse: 0.0205 - lr: 1.0000e-04\n",
      "Epoch 350/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5604e-04 - rmse: 0.0203\n",
      "Epoch 350: val_loss improved from 0.00054 to 0.00052, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 5.8178e-04 - rmse: 0.0209 - val_loss: 5.1739e-04 - val_rmse: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 351/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9934e-04 - rmse: 0.0189\n",
      "Epoch 351: val_loss improved from 0.00052 to 0.00050, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 4.6611e-04 - rmse: 0.0180 - val_loss: 5.0473e-04 - val_rmse: 0.0190 - lr: 1.0000e-04\n",
      "Epoch 352/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.8315e-04 - rmse: 0.0232\n",
      "Epoch 352: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.6913e-04 - rmse: 0.0206 - val_loss: 5.3553e-04 - val_rmse: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 353/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.2577e-04 - rmse: 0.0168\n",
      "Epoch 353: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 5.1086e-04 - rmse: 0.0192 - val_loss: 5.4004e-04 - val_rmse: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 354/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.6509e-04 - rmse: 0.0229\n",
      "Epoch 354: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.9122e-04 - rmse: 0.0212 - val_loss: 5.5325e-04 - val_rmse: 0.0203 - lr: 1.0000e-04\n",
      "Epoch 355/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4399e-04 - rmse: 0.0174\n",
      "Epoch 355: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.1233e-04 - rmse: 0.0192 - val_loss: 5.2011e-04 - val_rmse: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 356/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3325e-04 - rmse: 0.0198\n",
      "Epoch 356: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.0225e-04 - rmse: 0.0190 - val_loss: 5.1590e-04 - val_rmse: 0.0193 - lr: 1.0000e-04\n",
      "Epoch 357/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.2599e-04 - rmse: 0.0220\n",
      "Epoch 357: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.4031e-04 - rmse: 0.0199 - val_loss: 5.2103e-04 - val_rmse: 0.0195 - lr: 1.0000e-04\n",
      "Epoch 358/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.1477e-04 - rmse: 0.0165\n",
      "Epoch 358: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 5.1011e-04 - rmse: 0.0192 - val_loss: 5.2393e-04 - val_rmse: 0.0195 - lr: 1.0000e-04\n",
      "Epoch 359/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1749e-04 - rmse: 0.0194\n",
      "Epoch 359: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.7792e-04 - rmse: 0.0183 - val_loss: 5.0992e-04 - val_rmse: 0.0192 - lr: 1.0000e-04\n",
      "Epoch 360/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.6669e-04 - rmse: 0.0229\n",
      "Epoch 360: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.5685e-04 - rmse: 0.0204 - val_loss: 5.4406e-04 - val_rmse: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 361/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.7482e-04 - rmse: 0.0182\n",
      "Epoch 361: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.2805e-04 - rmse: 0.0196 - val_loss: 5.2123e-04 - val_rmse: 0.0195 - lr: 1.0000e-04\n",
      "Epoch 362/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.4717e-04 - rmse: 0.0201\n",
      "Epoch 362: val_loss did not improve from 0.00050\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.0690e-04 - rmse: 0.0191 - val_loss: 5.0841e-04 - val_rmse: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 363/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9681e-04 - rmse: 0.0188\n",
      "Epoch 363: val_loss improved from 0.00050 to 0.00046, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 5.1650e-04 - rmse: 0.0193 - val_loss: 4.6013e-04 - val_rmse: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 364/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.1858e-04 - rmse: 0.0194\n",
      "Epoch 364: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.0080e-04 - rmse: 0.0189 - val_loss: 5.0986e-04 - val_rmse: 0.0192 - lr: 1.0000e-04\n",
      "Epoch 365/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.0154e-04 - rmse: 0.0190\n",
      "Epoch 365: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6896e-04 - rmse: 0.0181 - val_loss: 4.9677e-04 - val_rmse: 0.0188 - lr: 1.0000e-04\n",
      "Epoch 366/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3178e-04 - rmse: 0.0197\n",
      "Epoch 366: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.9872e-04 - rmse: 0.0189 - val_loss: 4.6288e-04 - val_rmse: 0.0179 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3181e-04 - rmse: 0.0197\n",
      "Epoch 367: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 5.1790e-04 - rmse: 0.0194 - val_loss: 4.9472e-04 - val_rmse: 0.0188 - lr: 1.0000e-04\n",
      "Epoch 368/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4793e-04 - rmse: 0.0175\n",
      "Epoch 368: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 5.0449e-04 - rmse: 0.0190 - val_loss: 5.5784e-04 - val_rmse: 0.0204 - lr: 1.0000e-04\n",
      "Epoch 369/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.4422e-04 - rmse: 0.0224\n",
      "Epoch 369: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.1724e-04 - rmse: 0.0194 - val_loss: 5.3804e-04 - val_rmse: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 370/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.8972e-04 - rmse: 0.0186\n",
      "Epoch 370: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.1881e-04 - rmse: 0.0194 - val_loss: 5.8731e-04 - val_rmse: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 371/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.7188e-04 - rmse: 0.0207\n",
      "Epoch 371: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.6002e-04 - rmse: 0.0204 - val_loss: 5.0731e-04 - val_rmse: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 372/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6.1540e-04 - rmse: 0.0218\n",
      "Epoch 372: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 5.3461e-04 - rmse: 0.0198 - val_loss: 5.7178e-04 - val_rmse: 0.0207 - lr: 1.0000e-04\n",
      "Epoch 373/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.2347e-04 - rmse: 0.0195\n",
      "Epoch 373: val_loss did not improve from 0.00046\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 5.4350e-04 - rmse: 0.0200 - val_loss: 5.0859e-04 - val_rmse: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 374/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7677e-04 - rmse: 0.0153\n",
      "Epoch 374: val_loss improved from 0.00046 to 0.00045, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 4.4560e-04 - rmse: 0.0174 - val_loss: 4.4750e-04 - val_rmse: 0.0175 - lr: 1.0000e-04\n",
      "Epoch 375/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3193e-04 - rmse: 0.0197\n",
      "Epoch 375: val_loss improved from 0.00045 to 0.00043, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 5.0592e-04 - rmse: 0.0191 - val_loss: 4.3420e-04 - val_rmse: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 376/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8651e-04 - rmse: 0.0156\n",
      "Epoch 376: val_loss improved from 0.00043 to 0.00041, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 4.2054e-04 - rmse: 0.0167 - val_loss: 4.1416e-04 - val_rmse: 0.0165 - lr: 1.0000e-04\n",
      "Epoch 377/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8502e-04 - rmse: 0.0156\n",
      "Epoch 377: val_loss did not improve from 0.00041\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.5204e-04 - rmse: 0.0176 - val_loss: 4.2062e-04 - val_rmse: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 378/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.5306e-04 - rmse: 0.0203\n",
      "Epoch 378: val_loss did not improve from 0.00041\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.7111e-04 - rmse: 0.0181 - val_loss: 4.5002e-04 - val_rmse: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 379/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4754e-04 - rmse: 0.0175\n",
      "Epoch 379: val_loss did not improve from 0.00041\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.4162e-04 - rmse: 0.0173 - val_loss: 4.5903e-04 - val_rmse: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 380/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.8513e-04 - rmse: 0.0185\n",
      "Epoch 380: val_loss did not improve from 0.00041\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.0184e-04 - rmse: 0.0161 - val_loss: 4.4339e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 381/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9988e-04 - rmse: 0.0189\n",
      "Epoch 381: val_loss improved from 0.00041 to 0.00039, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 4.4506e-04 - rmse: 0.0174 - val_loss: 3.9401e-04 - val_rmse: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 382/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.1020e-04 - rmse: 0.0164\n",
      "Epoch 382: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.1287e-04 - rmse: 0.0165 - val_loss: 4.1722e-04 - val_rmse: 0.0166 - lr: 1.0000e-04\n",
      "Epoch 383/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8830e-04 - rmse: 0.0157\n",
      "Epoch 383: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.5676e-04 - rmse: 0.0177 - val_loss: 5.1916e-04 - val_rmse: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 384/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.2696e-04 - rmse: 0.0196\n",
      "Epoch 384: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.9976e-04 - rmse: 0.0189 - val_loss: 5.5449e-04 - val_rmse: 0.0203 - lr: 1.0000e-04\n",
      "Epoch 385/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.2811e-04 - rmse: 0.0197\n",
      "Epoch 385: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.7670e-04 - rmse: 0.0183 - val_loss: 4.7078e-04 - val_rmse: 0.0181 - lr: 1.0000e-04\n",
      "Epoch 386/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9383e-04 - rmse: 0.0188\n",
      "Epoch 386: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.5814e-04 - rmse: 0.0178 - val_loss: 4.0278e-04 - val_rmse: 0.0162 - lr: 1.0000e-04\n",
      "Epoch 387/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.7881e-04 - rmse: 0.0209\n",
      "Epoch 387: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.7174e-04 - rmse: 0.0182 - val_loss: 4.1358e-04 - val_rmse: 0.0165 - lr: 1.0000e-04\n",
      "Epoch 388/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.7686e-04 - rmse: 0.0183\n",
      "Epoch 388: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.3284e-04 - rmse: 0.0171 - val_loss: 4.4320e-04 - val_rmse: 0.0174 - lr: 1.0000e-04\n",
      "Epoch 389/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.8965e-04 - rmse: 0.0187\n",
      "Epoch 389: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.3087e-04 - rmse: 0.0170 - val_loss: 4.0904e-04 - val_rmse: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 390/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2184e-04 - rmse: 0.0134\n",
      "Epoch 390: val_loss improved from 0.00039 to 0.00039, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 3.8458e-04 - rmse: 0.0156 - val_loss: 3.8800e-04 - val_rmse: 0.0157 - lr: 1.0000e-04\n",
      "Epoch 391/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.3352e-04 - rmse: 0.0171\n",
      "Epoch 391: val_loss improved from 0.00039 to 0.00039, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 3.8652e-04 - rmse: 0.0157 - val_loss: 3.8614e-04 - val_rmse: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 392/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8216e-04 - rmse: 0.0155\n",
      "Epoch 392: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.3061e-04 - rmse: 0.0170 - val_loss: 4.3563e-04 - val_rmse: 0.0172 - lr: 1.0000e-04\n",
      "Epoch 393/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9182e-04 - rmse: 0.0158\n",
      "Epoch 393: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.1562e-04 - rmse: 0.0166 - val_loss: 4.4003e-04 - val_rmse: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 394/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4673e-04 - rmse: 0.0175\n",
      "Epoch 394: val_loss did not improve from 0.00039\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.1440e-04 - rmse: 0.0165 - val_loss: 3.9481e-04 - val_rmse: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 395/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7193e-04 - rmse: 0.0152\n",
      "Epoch 395: val_loss improved from 0.00039 to 0.00036, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 3.8536e-04 - rmse: 0.0156 - val_loss: 3.6497e-04 - val_rmse: 0.0150 - lr: 1.0000e-04\n",
      "Epoch 396/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5696e-04 - rmse: 0.0147\n",
      "Epoch 396: val_loss improved from 0.00036 to 0.00036, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 4.0161e-04 - rmse: 0.0161 - val_loss: 3.5686e-04 - val_rmse: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 397/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7652e-04 - rmse: 0.0153\n",
      "Epoch 397: val_loss did not improve from 0.00036\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8836e-04 - rmse: 0.0157 - val_loss: 4.1598e-04 - val_rmse: 0.0166 - lr: 1.0000e-04\n",
      "Epoch 398/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8941e-04 - rmse: 0.0158\n",
      "Epoch 398: val_loss did not improve from 0.00036\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.9098e-04 - rmse: 0.0158 - val_loss: 3.7859e-04 - val_rmse: 0.0154 - lr: 1.0000e-04\n",
      "Epoch 399/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7310e-04 - rmse: 0.0152\n",
      "Epoch 399: val_loss did not improve from 0.00036\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.7637e-04 - rmse: 0.0153 - val_loss: 3.5760e-04 - val_rmse: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 400/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6507e-04 - rmse: 0.0150\n",
      "Epoch 400: val_loss improved from 0.00036 to 0.00035, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 3.5218e-04 - rmse: 0.0145 - val_loss: 3.5154e-04 - val_rmse: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 401/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6411e-04 - rmse: 0.0149\n",
      "Epoch 401: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.7001e-04 - rmse: 0.0151 - val_loss: 3.8124e-04 - val_rmse: 0.0155 - lr: 1.0000e-04\n",
      "Epoch 402/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.4438e-04 - rmse: 0.0174\n",
      "Epoch 402: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.0941e-04 - rmse: 0.0164 - val_loss: 3.9233e-04 - val_rmse: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 403/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7975e-04 - rmse: 0.0155\n",
      "Epoch 403: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.6908e-04 - rmse: 0.0151 - val_loss: 4.2273e-04 - val_rmse: 0.0168 - lr: 1.0000e-04\n",
      "Epoch 404/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9475e-04 - rmse: 0.0159\n",
      "Epoch 404: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8551e-04 - rmse: 0.0156 - val_loss: 3.5852e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 405/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.9276e-04 - rmse: 0.0159\n",
      "Epoch 405: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.7408e-04 - rmse: 0.0153 - val_loss: 3.8582e-04 - val_rmse: 0.0157 - lr: 1.0000e-04\n",
      "Epoch 406/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5458e-04 - rmse: 0.0146\n",
      "Epoch 406: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.6282e-04 - rmse: 0.0149 - val_loss: 3.7252e-04 - val_rmse: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 407/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6374e-04 - rmse: 0.0149\n",
      "Epoch 407: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.5784e-04 - rmse: 0.0147 - val_loss: 4.1287e-04 - val_rmse: 0.0165 - lr: 1.0000e-04\n",
      "Epoch 408/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.6123e-04 - rmse: 0.0179\n",
      "Epoch 408: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.1767e-04 - rmse: 0.0166 - val_loss: 3.9713e-04 - val_rmse: 0.0160 - lr: 1.0000e-04\n",
      "Epoch 409/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6496e-04 - rmse: 0.0150\n",
      "Epoch 409: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.7169e-04 - rmse: 0.0152 - val_loss: 4.1147e-04 - val_rmse: 0.0165 - lr: 1.0000e-04\n",
      "Epoch 410/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.9880e-04 - rmse: 0.0189\n",
      "Epoch 410: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.2592e-04 - rmse: 0.0169 - val_loss: 3.9862e-04 - val_rmse: 0.0161 - lr: 1.0000e-04\n",
      "Epoch 411/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7907e-04 - rmse: 0.0154\n",
      "Epoch 411: val_loss did not improve from 0.00035\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.5657e-04 - rmse: 0.0147 - val_loss: 3.6259e-04 - val_rmse: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 412/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.0524e-04 - rmse: 0.0163\n",
      "Epoch 412: val_loss improved from 0.00035 to 0.00033, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 3.9249e-04 - rmse: 0.0159 - val_loss: 3.2654e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 413/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6391e-04 - rmse: 0.0149\n",
      "Epoch 413: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.7691e-04 - rmse: 0.0154 - val_loss: 3.6092e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 414/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4949e-04 - rmse: 0.0145\n",
      "Epoch 414: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.7481e-04 - rmse: 0.0153 - val_loss: 3.6415e-04 - val_rmse: 0.0150 - lr: 1.0000e-04\n",
      "Epoch 415/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5356e-04 - rmse: 0.0146\n",
      "Epoch 415: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.4373e-04 - rmse: 0.0143 - val_loss: 3.5108e-04 - val_rmse: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 416/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1580e-04 - rmse: 0.0132\n",
      "Epoch 416: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.6255e-04 - rmse: 0.0149 - val_loss: 3.4327e-04 - val_rmse: 0.0142 - lr: 1.0000e-04\n",
      "Epoch 417/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5439e-04 - rmse: 0.0146\n",
      "Epoch 417: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.4254e-04 - rmse: 0.0142 - val_loss: 3.4681e-04 - val_rmse: 0.0144 - lr: 1.0000e-04\n",
      "Epoch 418/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0125e-04 - rmse: 0.0127\n",
      "Epoch 418: val_loss did not improve from 0.00033\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.1386e-04 - rmse: 0.0132 - val_loss: 3.3483e-04 - val_rmse: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 419/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3451e-04 - rmse: 0.0139\n",
      "Epoch 419: val_loss improved from 0.00033 to 0.00031, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 3.4016e-04 - rmse: 0.0141 - val_loss: 3.1488e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 420/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0659e-04 - rmse: 0.0129\n",
      "Epoch 420: val_loss did not improve from 0.00031\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.2338e-04 - rmse: 0.0135 - val_loss: 3.2016e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 421/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2324e-04 - rmse: 0.0135\n",
      "Epoch 421: val_loss did not improve from 0.00031\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.1165e-04 - rmse: 0.0131 - val_loss: 3.1707e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 422/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6081e-04 - rmse: 0.0149\n",
      "Epoch 422: val_loss did not improve from 0.00031\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.4165e-04 - rmse: 0.0142 - val_loss: 3.3770e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 423/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9140e-04 - rmse: 0.0123\n",
      "Epoch 423: val_loss improved from 0.00031 to 0.00031, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 3.1055e-04 - rmse: 0.0131 - val_loss: 3.1215e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 424/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8733e-04 - rmse: 0.0121\n",
      "Epoch 424: val_loss did not improve from 0.00031\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.3278e-04 - rmse: 0.0139 - val_loss: 3.5376e-04 - val_rmse: 0.0146 - lr: 1.0000e-04\n",
      "Epoch 425/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8033e-04 - rmse: 0.0155\n",
      "Epoch 425: val_loss did not improve from 0.00031\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.3613e-04 - rmse: 0.0140 - val_loss: 3.1599e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 426/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1876e-04 - rmse: 0.0134\n",
      "Epoch 426: val_loss did not improve from 0.00031\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.2527e-04 - rmse: 0.0136 - val_loss: 3.2778e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 427/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3837e-04 - rmse: 0.0141\n",
      "Epoch 427: val_loss improved from 0.00031 to 0.00030, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 3.2399e-04 - rmse: 0.0136 - val_loss: 3.0018e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 428/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8666e-04 - rmse: 0.0121\n",
      "Epoch 428: val_loss did not improve from 0.00030\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.1041e-04 - rmse: 0.0131 - val_loss: 3.3868e-04 - val_rmse: 0.0141 - lr: 1.0000e-04\n",
      "Epoch 429/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4840e-04 - rmse: 0.0144\n",
      "Epoch 429: val_loss did not improve from 0.00030\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.3224e-04 - rmse: 0.0139 - val_loss: 3.2520e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 430/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1343e-04 - rmse: 0.0132\n",
      "Epoch 430: val_loss did not improve from 0.00030\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.1969e-04 - rmse: 0.0134 - val_loss: 3.1365e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 431/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1045e-04 - rmse: 0.0131\n",
      "Epoch 431: val_loss did not improve from 0.00030\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.1548e-04 - rmse: 0.0133 - val_loss: 3.1924e-04 - val_rmse: 0.0134 - lr: 1.0000e-04\n",
      "Epoch 432/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4881e-04 - rmse: 0.0145\n",
      "Epoch 432: val_loss improved from 0.00030 to 0.00029, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 3.3269e-04 - rmse: 0.0139 - val_loss: 2.9110e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 433/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8354e-04 - rmse: 0.0120\n",
      "Epoch 433: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.9628e-04 - rmse: 0.0125 - val_loss: 3.2712e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 434/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2428e-04 - rmse: 0.0136\n",
      "Epoch 434: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.4582e-04 - rmse: 0.0144 - val_loss: 3.1784e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 435/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9264e-04 - rmse: 0.0124\n",
      "Epoch 435: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.0236e-04 - rmse: 0.0128 - val_loss: 3.0009e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 436/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0641e-04 - rmse: 0.0129\n",
      "Epoch 436: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.9045e-04 - rmse: 0.0123 - val_loss: 2.9770e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 437/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3162e-04 - rmse: 0.0139\n",
      "Epoch 437: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.0922e-04 - rmse: 0.0130 - val_loss: 2.9672e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 438/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3710e-04 - rmse: 0.0099\n",
      "Epoch 438: val_loss did not improve from 0.00029\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.8902e-04 - rmse: 0.0122 - val_loss: 3.0826e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 439/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8964e-04 - rmse: 0.0122\n",
      "Epoch 439: val_loss improved from 0.00029 to 0.00027, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 3.1200e-04 - rmse: 0.0131 - val_loss: 2.7225e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 440/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5912e-04 - rmse: 0.0109\n",
      "Epoch 440: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.8629e-04 - rmse: 0.0121 - val_loss: 2.7253e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 441/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2895e-04 - rmse: 0.0138\n",
      "Epoch 441: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.8771e-04 - rmse: 0.0122 - val_loss: 2.8854e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 442/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7309e-04 - rmse: 0.0116\n",
      "Epoch 442: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.7443e-04 - rmse: 0.0116 - val_loss: 2.7536e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 443/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1552e-04 - rmse: 0.0133\n",
      "Epoch 443: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.8397e-04 - rmse: 0.0120 - val_loss: 2.9784e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0472e-04 - rmse: 0.0129\n",
      "Epoch 444: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.8278e-04 - rmse: 0.0120 - val_loss: 2.7500e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 445/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0604e-04 - rmse: 0.0129\n",
      "Epoch 445: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.8322e-04 - rmse: 0.0120 - val_loss: 2.7700e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 446/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4022e-04 - rmse: 0.0100\n",
      "Epoch 446: val_loss improved from 0.00027 to 0.00027, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 2.7803e-04 - rmse: 0.0118 - val_loss: 2.6653e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 447/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6275e-04 - rmse: 0.0111\n",
      "Epoch 447: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7538e-04 - rmse: 0.0117 - val_loss: 2.7068e-04 - val_rmse: 0.0115 - lr: 1.0000e-04\n",
      "Epoch 448/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5145e-04 - rmse: 0.0106\n",
      "Epoch 448: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7696e-04 - rmse: 0.0117 - val_loss: 2.6977e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 449/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7300e-04 - rmse: 0.0116\n",
      "Epoch 449: val_loss did not improve from 0.00027\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.6900e-04 - rmse: 0.0114 - val_loss: 2.7422e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 450/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6708e-04 - rmse: 0.0113\n",
      "Epoch 450: val_loss improved from 0.00027 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 2.6086e-04 - rmse: 0.0110 - val_loss: 2.6437e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 451/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6976e-04 - rmse: 0.0114\n",
      "Epoch 451: val_loss improved from 0.00026 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.6685e-04 - rmse: 0.0113 - val_loss: 2.6432e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 452/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4916e-04 - rmse: 0.0105\n",
      "Epoch 452: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7789e-04 - rmse: 0.0118 - val_loss: 2.8007e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 453/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7116e-04 - rmse: 0.0115\n",
      "Epoch 453: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.8817e-04 - rmse: 0.0122 - val_loss: 2.9489e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 454/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2345e-04 - rmse: 0.0092\n",
      "Epoch 454: val_loss improved from 0.00026 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.5585e-04 - rmse: 0.0108 - val_loss: 2.6055e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 455/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7343e-04 - rmse: 0.0116\n",
      "Epoch 455: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.9467e-04 - rmse: 0.0125 - val_loss: 2.8835e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 456/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7293e-04 - rmse: 0.0116\n",
      "Epoch 456: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.8376e-04 - rmse: 0.0120 - val_loss: 2.8404e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 457/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4573e-04 - rmse: 0.0103\n",
      "Epoch 457: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.7984e-04 - rmse: 0.0119 - val_loss: 3.1250e-04 - val_rmse: 0.0132 - lr: 1.0000e-04\n",
      "Epoch 458/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.2636e-04 - rmse: 0.0137\n",
      "Epoch 458: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.9876e-04 - rmse: 0.0126 - val_loss: 2.7778e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 459/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1887e-04 - rmse: 0.0134\n",
      "Epoch 459: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.0517e-04 - rmse: 0.0129 - val_loss: 2.8839e-04 - val_rmse: 0.0122 - lr: 1.0000e-04\n",
      "Epoch 460/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4133e-04 - rmse: 0.0142\n",
      "Epoch 460: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.0376e-04 - rmse: 0.0128 - val_loss: 3.2268e-04 - val_rmse: 0.0136 - lr: 1.0000e-04\n",
      "Epoch 461/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8796e-04 - rmse: 0.0122\n",
      "Epoch 461: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.8463e-04 - rmse: 0.0121 - val_loss: 2.8115e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 462/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8367e-04 - rmse: 0.0120\n",
      "Epoch 462: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.8470e-04 - rmse: 0.0121 - val_loss: 2.9029e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 463/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7233e-04 - rmse: 0.0116\n",
      "Epoch 463: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7543e-04 - rmse: 0.0117 - val_loss: 2.6883e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 464/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5206e-04 - rmse: 0.0107\n",
      "Epoch 464: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.8972e-04 - rmse: 0.0123 - val_loss: 3.0058e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 465/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7498e-04 - rmse: 0.0117\n",
      "Epoch 465: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.7367e-04 - rmse: 0.0116 - val_loss: 3.1585e-04 - val_rmse: 0.0133 - lr: 1.0000e-04\n",
      "Epoch 466/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8474e-04 - rmse: 0.0157\n",
      "Epoch 466: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.0123e-04 - rmse: 0.0128 - val_loss: 2.6082e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 467/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6121e-04 - rmse: 0.0111\n",
      "Epoch 467: val_loss did not improve from 0.00026\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7705e-04 - rmse: 0.0118 - val_loss: 2.7571e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 468/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6569e-04 - rmse: 0.0113\n",
      "Epoch 468: val_loss improved from 0.00026 to 0.00026, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 2.7869e-04 - rmse: 0.0118 - val_loss: 2.5808e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 469/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6735e-04 - rmse: 0.0114\n",
      "Epoch 469: val_loss improved from 0.00026 to 0.00025, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 75ms/step - loss: 2.7100e-04 - rmse: 0.0115 - val_loss: 2.5139e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 470/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4192e-04 - rmse: 0.0102\n",
      "Epoch 470: val_loss improved from 0.00025 to 0.00025, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.6581e-04 - rmse: 0.0113 - val_loss: 2.4837e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 471/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4061e-04 - rmse: 0.0101\n",
      "Epoch 471: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.4797e-04 - rmse: 0.0105 - val_loss: 2.5329e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 472/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3553e-04 - rmse: 0.0099\n",
      "Epoch 472: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.6128e-04 - rmse: 0.0111 - val_loss: 2.7388e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 473/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7433e-04 - rmse: 0.0117\n",
      "Epoch 473: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.6338e-04 - rmse: 0.0112 - val_loss: 2.7274e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 474/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7965e-04 - rmse: 0.0119\n",
      "Epoch 474: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.7816e-04 - rmse: 0.0118 - val_loss: 2.6583e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 475/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5417e-04 - rmse: 0.0108\n",
      "Epoch 475: val_loss improved from 0.00025 to 0.00025, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.7531e-04 - rmse: 0.0117 - val_loss: 2.4632e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 476/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3298e-04 - rmse: 0.0097\n",
      "Epoch 476: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7739e-04 - rmse: 0.0118 - val_loss: 2.5217e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 477/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5752e-04 - rmse: 0.0109\n",
      "Epoch 477: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.6975e-04 - rmse: 0.0115 - val_loss: 2.6370e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 478/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8945e-04 - rmse: 0.0123\n",
      "Epoch 478: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.5506e-04 - rmse: 0.0108 - val_loss: 2.6732e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 479/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8652e-04 - rmse: 0.0122\n",
      "Epoch 479: val_loss did not improve from 0.00025\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5470e-04 - rmse: 0.0108 - val_loss: 2.4733e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 480/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6174e-04 - rmse: 0.0111\n",
      "Epoch 480: val_loss improved from 0.00025 to 0.00024, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.5726e-04 - rmse: 0.0109 - val_loss: 2.3887e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 481/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5240e-04 - rmse: 0.0107\n",
      "Epoch 481: val_loss improved from 0.00024 to 0.00023, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 2.3414e-04 - rmse: 0.0098 - val_loss: 2.3478e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 482/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6587e-04 - rmse: 0.0113\n",
      "Epoch 482: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4233e-04 - rmse: 0.0102 - val_loss: 2.3544e-04 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 483/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3067e-04 - rmse: 0.0096\n",
      "Epoch 483: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5322e-04 - rmse: 0.0107 - val_loss: 2.5316e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 484/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6531e-04 - rmse: 0.0113\n",
      "Epoch 484: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4633e-04 - rmse: 0.0104 - val_loss: 2.3928e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 485/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4661e-04 - rmse: 0.0104\n",
      "Epoch 485: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.5070e-04 - rmse: 0.0106 - val_loss: 2.7960e-04 - val_rmse: 0.0119 - lr: 1.0000e-04\n",
      "Epoch 486/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6871e-04 - rmse: 0.0114\n",
      "Epoch 486: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.5580e-04 - rmse: 0.0109 - val_loss: 2.6488e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 487/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6746e-04 - rmse: 0.0114\n",
      "Epoch 487: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.6239e-04 - rmse: 0.0112 - val_loss: 2.6765e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 488/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9299e-04 - rmse: 0.0125\n",
      "Epoch 488: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7730e-04 - rmse: 0.0118 - val_loss: 2.6268e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 489/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6385e-04 - rmse: 0.0112\n",
      "Epoch 489: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.4990e-04 - rmse: 0.0106 - val_loss: 2.4861e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 490/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8338e-04 - rmse: 0.0121\n",
      "Epoch 490: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.6019e-04 - rmse: 0.0111 - val_loss: 2.4804e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 491/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5099e-04 - rmse: 0.0107\n",
      "Epoch 491: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5733e-04 - rmse: 0.0109 - val_loss: 2.4604e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 492/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6662e-04 - rmse: 0.0114\n",
      "Epoch 492: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7429e-04 - rmse: 0.0117 - val_loss: 2.6701e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 493/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6907e-04 - rmse: 0.0115\n",
      "Epoch 493: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.9114e-04 - rmse: 0.0124 - val_loss: 3.3206e-04 - val_rmse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 494/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0195e-04 - rmse: 0.0128\n",
      "Epoch 494: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.7347e-04 - rmse: 0.0117 - val_loss: 2.6689e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 495/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7723e-04 - rmse: 0.0118\n",
      "Epoch 495: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7319e-04 - rmse: 0.0117 - val_loss: 2.5479e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6393e-04 - rmse: 0.0113\n",
      "Epoch 496: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7079e-04 - rmse: 0.0116 - val_loss: 2.4101e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 497/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4771e-04 - rmse: 0.0105\n",
      "Epoch 497: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.8004e-04 - rmse: 0.0119 - val_loss: 3.0186e-04 - val_rmse: 0.0128 - lr: 1.0000e-04\n",
      "Epoch 498/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.6743e-04 - rmse: 0.0152\n",
      "Epoch 498: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.8151e-04 - rmse: 0.0120 - val_loss: 2.5177e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 499/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7640e-04 - rmse: 0.0118\n",
      "Epoch 499: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5935e-04 - rmse: 0.0111 - val_loss: 2.8339e-04 - val_rmse: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 500/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7125e-04 - rmse: 0.0116\n",
      "Epoch 500: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.6058e-04 - rmse: 0.0111 - val_loss: 2.9256e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 501/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.1718e-04 - rmse: 0.0134\n",
      "Epoch 501: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.9383e-04 - rmse: 0.0125 - val_loss: 2.6170e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 502/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2603e-04 - rmse: 0.0094\n",
      "Epoch 502: val_loss improved from 0.00023 to 0.00023, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 2.4440e-04 - rmse: 0.0104 - val_loss: 2.3108e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 503/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3752e-04 - rmse: 0.0100\n",
      "Epoch 503: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5211e-04 - rmse: 0.0107 - val_loss: 2.4854e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 504/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4394e-04 - rmse: 0.0103\n",
      "Epoch 504: val_loss did not improve from 0.00023\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.5963e-04 - rmse: 0.0111 - val_loss: 2.3197e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 505/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3251e-04 - rmse: 0.0098\n",
      "Epoch 505: val_loss improved from 0.00023 to 0.00022, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 2.3870e-04 - rmse: 0.0101 - val_loss: 2.1790e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 506/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0899e-04 - rmse: 0.0085\n",
      "Epoch 506: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2509e-04 - rmse: 0.0094 - val_loss: 2.3039e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 507/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0488e-04 - rmse: 0.0082\n",
      "Epoch 507: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3810e-04 - rmse: 0.0101 - val_loss: 2.6015e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 508/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6169e-04 - rmse: 0.0112\n",
      "Epoch 508: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5038e-04 - rmse: 0.0107 - val_loss: 2.5721e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 509/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3020e-04 - rmse: 0.0097\n",
      "Epoch 509: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4194e-04 - rmse: 0.0103 - val_loss: 2.6000e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 510/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6632e-04 - rmse: 0.0114\n",
      "Epoch 510: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.6847e-04 - rmse: 0.0115 - val_loss: 3.2529e-04 - val_rmse: 0.0137 - lr: 1.0000e-04\n",
      "Epoch 511/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7963e-04 - rmse: 0.0120\n",
      "Epoch 511: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7147e-04 - rmse: 0.0116 - val_loss: 2.4302e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 512/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3577e-04 - rmse: 0.0100\n",
      "Epoch 512: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.4407e-04 - rmse: 0.0104 - val_loss: 2.3711e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 513/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3242e-04 - rmse: 0.0098\n",
      "Epoch 513: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4089e-04 - rmse: 0.0102 - val_loss: 2.4869e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 514/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5767e-04 - rmse: 0.0110\n",
      "Epoch 514: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3715e-04 - rmse: 0.0100 - val_loss: 2.3654e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 515/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3421e-04 - rmse: 0.0099\n",
      "Epoch 515: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.3830e-04 - rmse: 0.0101 - val_loss: 2.4763e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 516/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4472e-04 - rmse: 0.0104\n",
      "Epoch 516: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5927e-04 - rmse: 0.0111 - val_loss: 2.4741e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 517/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4797e-04 - rmse: 0.0106\n",
      "Epoch 517: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3400e-04 - rmse: 0.0099 - val_loss: 2.3658e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 518/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6485e-04 - rmse: 0.0113\n",
      "Epoch 518: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.4211e-04 - rmse: 0.0103 - val_loss: 2.2515e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 519/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2665e-04 - rmse: 0.0095\n",
      "Epoch 519: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.3909e-04 - rmse: 0.0101 - val_loss: 2.3255e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 520/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4177e-04 - rmse: 0.0103\n",
      "Epoch 520: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.4072e-04 - rmse: 0.0102 - val_loss: 2.6172e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 521/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7172e-04 - rmse: 0.0116\n",
      "Epoch 521: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.5152e-04 - rmse: 0.0107 - val_loss: 2.3979e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 522/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3769e-04 - rmse: 0.0101\n",
      "Epoch 522: val_loss did not improve from 0.00022\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2207e-04 - rmse: 0.0093 - val_loss: 2.2690e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2848e-04 - rmse: 0.0096\n",
      "Epoch 523: val_loss improved from 0.00022 to 0.00021, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.4179e-04 - rmse: 0.0103 - val_loss: 2.0951e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 524/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0871e-04 - rmse: 0.0085\n",
      "Epoch 524: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3770e-04 - rmse: 0.0101 - val_loss: 2.4292e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 525/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3661e-04 - rmse: 0.0100\n",
      "Epoch 525: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4204e-04 - rmse: 0.0103 - val_loss: 2.7254e-04 - val_rmse: 0.0117 - lr: 1.0000e-04\n",
      "Epoch 526/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5796e-04 - rmse: 0.0110\n",
      "Epoch 526: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.5120e-04 - rmse: 0.0107 - val_loss: 2.6540e-04 - val_rmse: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 527/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7709e-04 - rmse: 0.0119\n",
      "Epoch 527: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.4797e-04 - rmse: 0.0106 - val_loss: 2.4968e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 528/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6577e-04 - rmse: 0.0114\n",
      "Epoch 528: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5124e-04 - rmse: 0.0107 - val_loss: 2.4474e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 529/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5009e-04 - rmse: 0.0107\n",
      "Epoch 529: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3533e-04 - rmse: 0.0100 - val_loss: 2.3662e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 530/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4730e-04 - rmse: 0.0106\n",
      "Epoch 530: val_loss improved from 0.00021 to 0.00021, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 2.3525e-04 - rmse: 0.0100 - val_loss: 2.0710e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 531/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1064e-04 - rmse: 0.0086\n",
      "Epoch 531: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1974e-04 - rmse: 0.0092 - val_loss: 2.2046e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 532/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2931e-04 - rmse: 0.0097\n",
      "Epoch 532: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1931e-04 - rmse: 0.0091 - val_loss: 2.2334e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 533/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0794e-04 - rmse: 0.0085\n",
      "Epoch 533: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1673e-04 - rmse: 0.0090 - val_loss: 2.1096e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 534/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2342e-04 - rmse: 0.0094\n",
      "Epoch 534: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.2573e-04 - rmse: 0.0095 - val_loss: 2.3020e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 535/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2227e-04 - rmse: 0.0093\n",
      "Epoch 535: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2633e-04 - rmse: 0.0095 - val_loss: 2.1939e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 536/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1800e-04 - rmse: 0.0091\n",
      "Epoch 536: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1606e-04 - rmse: 0.0090 - val_loss: 2.1501e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 537/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1911e-04 - rmse: 0.0091\n",
      "Epoch 537: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1768e-04 - rmse: 0.0091 - val_loss: 2.1161e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 538/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9850e-04 - rmse: 0.0079\n",
      "Epoch 538: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0547e-04 - rmse: 0.0084 - val_loss: 2.1156e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 539/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1208e-04 - rmse: 0.0087\n",
      "Epoch 539: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1427e-04 - rmse: 0.0089 - val_loss: 2.0980e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 540/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0513e-04 - rmse: 0.0083\n",
      "Epoch 540: val_loss did not improve from 0.00021\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1778e-04 - rmse: 0.0091 - val_loss: 2.2129e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 541/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3464e-04 - rmse: 0.0100\n",
      "Epoch 541: val_loss improved from 0.00021 to 0.00020, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 2.1585e-04 - rmse: 0.0090 - val_loss: 2.0225e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 542/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8781e-04 - rmse: 0.0072\n",
      "Epoch 542: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0165e-04 - rmse: 0.0081 - val_loss: 2.0880e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 543/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1916e-04 - rmse: 0.0091\n",
      "Epoch 543: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0044e-04 - rmse: 0.0081 - val_loss: 2.1523e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 544/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1899e-04 - rmse: 0.0091\n",
      "Epoch 544: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2037e-04 - rmse: 0.0092 - val_loss: 2.1753e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 545/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0961e-04 - rmse: 0.0086\n",
      "Epoch 545: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.1485e-04 - rmse: 0.0089 - val_loss: 2.1654e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 546/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0964e-04 - rmse: 0.0086\n",
      "Epoch 546: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0995e-04 - rmse: 0.0086 - val_loss: 2.1911e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 547/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1509e-04 - rmse: 0.0089\n",
      "Epoch 547: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1393e-04 - rmse: 0.0089 - val_loss: 2.0562e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 548/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0004e-04 - rmse: 0.0080\n",
      "Epoch 548: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0711e-04 - rmse: 0.0085 - val_loss: 2.2160e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 549/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0935e-04 - rmse: 0.0086\n",
      "Epoch 549: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1384e-04 - rmse: 0.0089 - val_loss: 2.1450e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9043e-04 - rmse: 0.0074\n",
      "Epoch 550: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1022e-04 - rmse: 0.0087 - val_loss: 2.3266e-04 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 551/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2855e-04 - rmse: 0.0097\n",
      "Epoch 551: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.3683e-04 - rmse: 0.0101 - val_loss: 2.5673e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 552/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4313e-04 - rmse: 0.0104\n",
      "Epoch 552: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.2716e-04 - rmse: 0.0096 - val_loss: 2.6055e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 553/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7060e-04 - rmse: 0.0116\n",
      "Epoch 553: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.4424e-04 - rmse: 0.0104 - val_loss: 2.3623e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 554/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4985e-04 - rmse: 0.0107\n",
      "Epoch 554: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6953e-04 - rmse: 0.0116 - val_loss: 2.3254e-04 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 555/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3236e-04 - rmse: 0.0099\n",
      "Epoch 555: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.6295e-04 - rmse: 0.0113 - val_loss: 2.7431e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 556/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5234e-04 - rmse: 0.0108\n",
      "Epoch 556: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.9937e-04 - rmse: 0.0128 - val_loss: 2.6930e-04 - val_rmse: 0.0116 - lr: 1.0000e-04\n",
      "Epoch 557/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0970e-04 - rmse: 0.0132\n",
      "Epoch 557: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.5486e-04 - rmse: 0.0110 - val_loss: 2.5353e-04 - val_rmse: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 558/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7704e-04 - rmse: 0.0119\n",
      "Epoch 558: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.4340e-04 - rmse: 0.0104 - val_loss: 2.3284e-04 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 559/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4087e-04 - rmse: 0.0103\n",
      "Epoch 559: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.4565e-04 - rmse: 0.0105 - val_loss: 2.1759e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 560/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0436e-04 - rmse: 0.0083\n",
      "Epoch 560: val_loss improved from 0.00020 to 0.00020, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.1287e-04 - rmse: 0.0088 - val_loss: 1.9922e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 561/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0131e-04 - rmse: 0.0082\n",
      "Epoch 561: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1342e-04 - rmse: 0.0089 - val_loss: 2.0332e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 562/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1301e-04 - rmse: 0.0088\n",
      "Epoch 562: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1011e-04 - rmse: 0.0087 - val_loss: 2.1884e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 563/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2401e-04 - rmse: 0.0095\n",
      "Epoch 563: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1130e-04 - rmse: 0.0088 - val_loss: 2.0478e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 564/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9133e-04 - rmse: 0.0075\n",
      "Epoch 564: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0972e-04 - rmse: 0.0087 - val_loss: 2.0869e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 565/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0821e-04 - rmse: 0.0086\n",
      "Epoch 565: val_loss improved from 0.00020 to 0.00020, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.0378e-04 - rmse: 0.0083 - val_loss: 1.9643e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 566/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1540e-04 - rmse: 0.0090\n",
      "Epoch 566: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1091e-04 - rmse: 0.0087 - val_loss: 2.0658e-04 - val_rmse: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 567/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1446e-04 - rmse: 0.0089\n",
      "Epoch 567: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.0783e-04 - rmse: 0.0086 - val_loss: 2.1212e-04 - val_rmse: 0.0088 - lr: 1.0000e-04\n",
      "Epoch 568/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2548e-04 - rmse: 0.0095\n",
      "Epoch 568: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1319e-04 - rmse: 0.0089 - val_loss: 2.1033e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 569/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0861e-04 - rmse: 0.0086\n",
      "Epoch 569: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1486e-04 - rmse: 0.0090 - val_loss: 2.0917e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 570/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2993e-04 - rmse: 0.0098\n",
      "Epoch 570: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.1474e-04 - rmse: 0.0090 - val_loss: 2.1712e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 571/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0647e-04 - rmse: 0.0085\n",
      "Epoch 571: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0501e-04 - rmse: 0.0084 - val_loss: 2.0529e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 572/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1215e-04 - rmse: 0.0088\n",
      "Epoch 572: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0816e-04 - rmse: 0.0086 - val_loss: 2.0000e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 573/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9559e-04 - rmse: 0.0078\n",
      "Epoch 573: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.9917e-04 - rmse: 0.0081 - val_loss: 2.1393e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 574/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1511e-04 - rmse: 0.0090\n",
      "Epoch 574: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0815e-04 - rmse: 0.0086 - val_loss: 1.9725e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 575/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0140e-04 - rmse: 0.0082\n",
      "Epoch 575: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9823e-04 - rmse: 0.0080 - val_loss: 2.0190e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 576/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9902e-04 - rmse: 0.0081\n",
      "Epoch 576: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.9705e-04 - rmse: 0.0079 - val_loss: 2.0989e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 577/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1749e-04 - rmse: 0.0091\n",
      "Epoch 577: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.0682e-04 - rmse: 0.0085 - val_loss: 2.2226e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 578/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0073e-04 - rmse: 0.0082\n",
      "Epoch 578: val_loss improved from 0.00020 to 0.00020, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.2336e-04 - rmse: 0.0095 - val_loss: 1.9509e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 579/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1889e-04 - rmse: 0.0092\n",
      "Epoch 579: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.1550e-04 - rmse: 0.0090 - val_loss: 2.4369e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 580/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4186e-04 - rmse: 0.0104\n",
      "Epoch 580: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.3064e-04 - rmse: 0.0098 - val_loss: 2.6067e-04 - val_rmse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 581/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5139e-04 - rmse: 0.0108\n",
      "Epoch 581: val_loss did not improve from 0.00020\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.2572e-04 - rmse: 0.0096 - val_loss: 2.1248e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 582/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1397e-04 - rmse: 0.0089\n",
      "Epoch 582: val_loss improved from 0.00020 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 2.0342e-04 - rmse: 0.0083 - val_loss: 1.9017e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 583/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7967e-04 - rmse: 0.0068\n",
      "Epoch 583: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9383e-04 - rmse: 0.0077 - val_loss: 1.9454e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 584/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9850e-04 - rmse: 0.0080\n",
      "Epoch 584: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.9357e-04 - rmse: 0.0077 - val_loss: 1.9911e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 585/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9435e-04 - rmse: 0.0078\n",
      "Epoch 585: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9559e-04 - rmse: 0.0079 - val_loss: 2.0058e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 586/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0504e-04 - rmse: 0.0084\n",
      "Epoch 586: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9924e-04 - rmse: 0.0081 - val_loss: 1.9701e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 587/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9014e-04 - rmse: 0.0075\n",
      "Epoch 587: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0074e-04 - rmse: 0.0082 - val_loss: 1.9673e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 588/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9141e-04 - rmse: 0.0076\n",
      "Epoch 588: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9169e-04 - rmse: 0.0076 - val_loss: 1.9348e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 589/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8638e-04 - rmse: 0.0073\n",
      "Epoch 589: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0319e-04 - rmse: 0.0083 - val_loss: 2.0822e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 590/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8924e-04 - rmse: 0.0075\n",
      "Epoch 590: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.1220e-04 - rmse: 0.0089 - val_loss: 1.9853e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 591/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0822e-04 - rmse: 0.0086\n",
      "Epoch 591: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0131e-04 - rmse: 0.0082 - val_loss: 2.2057e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 592/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1773e-04 - rmse: 0.0092\n",
      "Epoch 592: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0768e-04 - rmse: 0.0086 - val_loss: 2.1384e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 593/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1793e-04 - rmse: 0.0092\n",
      "Epoch 593: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.4433e-04 - rmse: 0.0105 - val_loss: 2.2462e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 594/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1768e-04 - rmse: 0.0092\n",
      "Epoch 594: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7494e-04 - rmse: 0.0119 - val_loss: 2.8995e-04 - val_rmse: 0.0125 - lr: 1.0000e-04\n",
      "Epoch 595/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6757e-04 - rmse: 0.0116\n",
      "Epoch 595: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7093e-04 - rmse: 0.0117 - val_loss: 2.9973e-04 - val_rmse: 0.0129 - lr: 1.0000e-04\n",
      "Epoch 596/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0360e-04 - rmse: 0.0130\n",
      "Epoch 596: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.8401e-04 - rmse: 0.0123 - val_loss: 4.0452e-04 - val_rmse: 0.0165 - lr: 1.0000e-04\n",
      "Epoch 597/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.7452e-04 - rmse: 0.0155\n",
      "Epoch 597: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.2146e-04 - rmse: 0.0137 - val_loss: 2.4823e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 598/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5110e-04 - rmse: 0.0109\n",
      "Epoch 598: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.6379e-04 - rmse: 0.0114 - val_loss: 2.2467e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 599/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1652e-04 - rmse: 0.0091\n",
      "Epoch 599: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2564e-04 - rmse: 0.0096 - val_loss: 2.0328e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 600/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2140e-04 - rmse: 0.0094\n",
      "Epoch 600: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1223e-04 - rmse: 0.0089 - val_loss: 2.1540e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 601/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1283e-04 - rmse: 0.0089\n",
      "Epoch 601: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.1124e-04 - rmse: 0.0088 - val_loss: 2.1590e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 602/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1601e-04 - rmse: 0.0091\n",
      "Epoch 602: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0667e-04 - rmse: 0.0086 - val_loss: 2.2670e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 603/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3131e-04 - rmse: 0.0099\n",
      "Epoch 603: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2873e-04 - rmse: 0.0098 - val_loss: 2.4653e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 604/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3180e-04 - rmse: 0.0099\n",
      "Epoch 604: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.3288e-04 - rmse: 0.0100 - val_loss: 2.7782e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 605/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5466e-04 - rmse: 0.0110\n",
      "Epoch 605: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4738e-04 - rmse: 0.0107 - val_loss: 2.0021e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 606/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8460e-04 - rmse: 0.0072\n",
      "Epoch 606: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.1334e-04 - rmse: 0.0090 - val_loss: 2.1750e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 607/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1634e-04 - rmse: 0.0091\n",
      "Epoch 607: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2428e-04 - rmse: 0.0096 - val_loss: 2.2767e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 608/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2782e-04 - rmse: 0.0097\n",
      "Epoch 608: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2713e-04 - rmse: 0.0097 - val_loss: 3.4763e-04 - val_rmse: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 609/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3865e-04 - rmse: 0.0143\n",
      "Epoch 609: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.9336e-04 - rmse: 0.0127 - val_loss: 3.2763e-04 - val_rmse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 610/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.4069e-04 - rmse: 0.0144\n",
      "Epoch 610: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.0168e-04 - rmse: 0.0130 - val_loss: 2.7292e-04 - val_rmse: 0.0118 - lr: 1.0000e-04\n",
      "Epoch 611/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.8929e-04 - rmse: 0.0125\n",
      "Epoch 611: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7168e-04 - rmse: 0.0118 - val_loss: 2.2999e-04 - val_rmse: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 612/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2329e-04 - rmse: 0.0095\n",
      "Epoch 612: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5425e-04 - rmse: 0.0110 - val_loss: 2.5525e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 613/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5805e-04 - rmse: 0.0112\n",
      "Epoch 613: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4491e-04 - rmse: 0.0106 - val_loss: 3.2733e-04 - val_rmse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 614/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0695e-04 - rmse: 0.0132\n",
      "Epoch 614: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.6252e-04 - rmse: 0.0114 - val_loss: 2.7667e-04 - val_rmse: 0.0120 - lr: 1.0000e-04\n",
      "Epoch 615/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.9182e-04 - rmse: 0.0126\n",
      "Epoch 615: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5131e-04 - rmse: 0.0109 - val_loss: 2.1190e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 616/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1995e-04 - rmse: 0.0093\n",
      "Epoch 616: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2698e-04 - rmse: 0.0097 - val_loss: 2.2493e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 617/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2978e-04 - rmse: 0.0099\n",
      "Epoch 617: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1452e-04 - rmse: 0.0091 - val_loss: 1.9278e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 618/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8446e-04 - rmse: 0.0072\n",
      "Epoch 618: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0731e-04 - rmse: 0.0087 - val_loss: 2.2095e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 619/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0651e-04 - rmse: 0.0086\n",
      "Epoch 619: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9869e-04 - rmse: 0.0081 - val_loss: 2.1969e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 620/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3239e-04 - rmse: 0.0100\n",
      "Epoch 620: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1376e-04 - rmse: 0.0090 - val_loss: 2.0058e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 621/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8902e-04 - rmse: 0.0075\n",
      "Epoch 621: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.9800e-04 - rmse: 0.0081 - val_loss: 2.2031e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 622/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3938e-04 - rmse: 0.0103\n",
      "Epoch 622: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.0976e-04 - rmse: 0.0088 - val_loss: 2.0087e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 623/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0443e-04 - rmse: 0.0085\n",
      "Epoch 623: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.0167e-04 - rmse: 0.0083 - val_loss: 1.8966e-04 - val_rmse: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 624/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9567e-04 - rmse: 0.0080\n",
      "Epoch 624: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9849e-04 - rmse: 0.0081 - val_loss: 2.0678e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 625/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0503e-04 - rmse: 0.0085\n",
      "Epoch 625: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0671e-04 - rmse: 0.0086 - val_loss: 2.1634e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 626/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0940e-04 - rmse: 0.0088\n",
      "Epoch 626: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1246e-04 - rmse: 0.0090 - val_loss: 2.3776e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 627/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3427e-04 - rmse: 0.0101\n",
      "Epoch 627: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2226e-04 - rmse: 0.0095 - val_loss: 2.2822e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 628/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3421e-04 - rmse: 0.0101\n",
      "Epoch 628: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0783e-04 - rmse: 0.0087 - val_loss: 1.9159e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 629/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8824e-04 - rmse: 0.0075\n",
      "Epoch 629: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9501e-04 - rmse: 0.0079 - val_loss: 1.9696e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 630/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9740e-04 - rmse: 0.0081\n",
      "Epoch 630: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 2.0180e-04 - rmse: 0.0084 - val_loss: 1.8862e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 631/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9218e-04 - rmse: 0.0078\n",
      "Epoch 631: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0182e-04 - rmse: 0.0084 - val_loss: 2.1696e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 632/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1045e-04 - rmse: 0.0089\n",
      "Epoch 632: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9462e-04 - rmse: 0.0079 - val_loss: 1.9865e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 633/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1083e-04 - rmse: 0.0089\n",
      "Epoch 633: val_loss improved from 0.00019 to 0.00019, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.9622e-04 - rmse: 0.0080 - val_loss: 1.8699e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 634/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7478e-04 - rmse: 0.0066\n",
      "Epoch 634: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9335e-04 - rmse: 0.0078 - val_loss: 1.9816e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 635/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0756e-04 - rmse: 0.0087\n",
      "Epoch 635: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9782e-04 - rmse: 0.0081 - val_loss: 2.0953e-04 - val_rmse: 0.0088 - lr: 1.0000e-04\n",
      "Epoch 636/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1591e-04 - rmse: 0.0092\n",
      "Epoch 636: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9958e-04 - rmse: 0.0082 - val_loss: 1.9790e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 637/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1353e-04 - rmse: 0.0090\n",
      "Epoch 637: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9297e-04 - rmse: 0.0078 - val_loss: 1.8992e-04 - val_rmse: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 638/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8445e-04 - rmse: 0.0073\n",
      "Epoch 638: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9561e-04 - rmse: 0.0080 - val_loss: 1.8742e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 639/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0149e-04 - rmse: 0.0084\n",
      "Epoch 639: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0384e-04 - rmse: 0.0085 - val_loss: 1.9058e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 640/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9979e-04 - rmse: 0.0083\n",
      "Epoch 640: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0237e-04 - rmse: 0.0084 - val_loss: 1.9625e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 641/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9100e-04 - rmse: 0.0077\n",
      "Epoch 641: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0203e-04 - rmse: 0.0084 - val_loss: 2.2098e-04 - val_rmse: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 642/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3931e-04 - rmse: 0.0104\n",
      "Epoch 642: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.2169e-04 - rmse: 0.0095 - val_loss: 2.2279e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 643/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2269e-04 - rmse: 0.0095\n",
      "Epoch 643: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1395e-04 - rmse: 0.0091 - val_loss: 2.0428e-04 - val_rmse: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 644/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9526e-04 - rmse: 0.0080\n",
      "Epoch 644: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0434e-04 - rmse: 0.0085 - val_loss: 2.4091e-04 - val_rmse: 0.0105 - lr: 1.0000e-04\n",
      "Epoch 645/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4836e-04 - rmse: 0.0108\n",
      "Epoch 645: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1335e-04 - rmse: 0.0091 - val_loss: 2.5168e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 646/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2677e-04 - rmse: 0.0098\n",
      "Epoch 646: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.2431e-04 - rmse: 0.0096 - val_loss: 1.9844e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 647/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9046e-04 - rmse: 0.0077\n",
      "Epoch 647: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1251e-04 - rmse: 0.0090 - val_loss: 1.9502e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 648/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8710e-04 - rmse: 0.0075\n",
      "Epoch 648: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2188e-04 - rmse: 0.0095 - val_loss: 2.0495e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 649/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0665e-04 - rmse: 0.0087\n",
      "Epoch 649: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3299e-04 - rmse: 0.0101 - val_loss: 2.2712e-04 - val_rmse: 0.0098 - lr: 1.0000e-04\n",
      "Epoch 650/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3307e-04 - rmse: 0.0101\n",
      "Epoch 650: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.0118e-04 - rmse: 0.0084 - val_loss: 2.3691e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 651/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4182e-04 - rmse: 0.0105\n",
      "Epoch 651: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1781e-04 - rmse: 0.0093 - val_loss: 2.0277e-04 - val_rmse: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 652/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0917e-04 - rmse: 0.0088\n",
      "Epoch 652: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9890e-04 - rmse: 0.0082 - val_loss: 1.8765e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 653/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7896e-04 - rmse: 0.0069\n",
      "Epoch 653: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0152e-04 - rmse: 0.0084 - val_loss: 1.8998e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 654/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8859e-04 - rmse: 0.0076\n",
      "Epoch 654: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9376e-04 - rmse: 0.0079 - val_loss: 2.0421e-04 - val_rmse: 0.0086 - lr: 1.0000e-04\n",
      "Epoch 655/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9728e-04 - rmse: 0.0081\n",
      "Epoch 655: val_loss did not improve from 0.00019\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9959e-04 - rmse: 0.0083 - val_loss: 2.1097e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 656/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0423e-04 - rmse: 0.0086\n",
      "Epoch 656: val_loss improved from 0.00019 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 1.9711e-04 - rmse: 0.0081 - val_loss: 1.8140e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 657/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8145e-04 - rmse: 0.0071\n",
      "Epoch 657: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9536e-04 - rmse: 0.0080 - val_loss: 1.8611e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 658/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8915e-04 - rmse: 0.0076\n",
      "Epoch 658: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0225e-04 - rmse: 0.0084 - val_loss: 1.8394e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 659/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7663e-04 - rmse: 0.0068\n",
      "Epoch 659: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8340e-04 - rmse: 0.0072 - val_loss: 1.9705e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 660/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8382e-04 - rmse: 0.0073\n",
      "Epoch 660: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.8808e-04 - rmse: 0.0076 - val_loss: 1.9561e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 661/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0933e-04 - rmse: 0.0089\n",
      "Epoch 661: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8699e-04 - rmse: 0.0075 - val_loss: 1.9374e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 662/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0523e-04 - rmse: 0.0086\n",
      "Epoch 662: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9091e-04 - rmse: 0.0078 - val_loss: 1.8346e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 663/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8821e-04 - rmse: 0.0076\n",
      "Epoch 663: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9255e-04 - rmse: 0.0079 - val_loss: 1.8351e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 664/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7491e-04 - rmse: 0.0066\n",
      "Epoch 664: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9381e-04 - rmse: 0.0079 - val_loss: 1.9376e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 665/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9422e-04 - rmse: 0.0080\n",
      "Epoch 665: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9992e-04 - rmse: 0.0083 - val_loss: 2.1834e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 666/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0106e-04 - rmse: 0.0084\n",
      "Epoch 666: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1053e-04 - rmse: 0.0089 - val_loss: 2.0361e-04 - val_rmse: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 667/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9435e-04 - rmse: 0.0080\n",
      "Epoch 667: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.0661e-04 - rmse: 0.0087 - val_loss: 1.9570e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 668/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0223e-04 - rmse: 0.0085\n",
      "Epoch 668: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0972e-04 - rmse: 0.0089 - val_loss: 2.3646e-04 - val_rmse: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 669/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1791e-04 - rmse: 0.0093\n",
      "Epoch 669: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0410e-04 - rmse: 0.0086 - val_loss: 2.0227e-04 - val_rmse: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 670/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0853e-04 - rmse: 0.0088\n",
      "Epoch 670: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9299e-04 - rmse: 0.0079 - val_loss: 1.9930e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 671/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0022e-04 - rmse: 0.0084\n",
      "Epoch 671: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1272e-04 - rmse: 0.0091 - val_loss: 1.9148e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 672/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9885e-04 - rmse: 0.0083\n",
      "Epoch 672: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9950e-04 - rmse: 0.0083 - val_loss: 1.9826e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 673/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0257e-04 - rmse: 0.0085\n",
      "Epoch 673: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9830e-04 - rmse: 0.0082 - val_loss: 2.2198e-04 - val_rmse: 0.0096 - lr: 1.0000e-04\n",
      "Epoch 674/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1324e-04 - rmse: 0.0091\n",
      "Epoch 674: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.0887e-04 - rmse: 0.0089 - val_loss: 2.0539e-04 - val_rmse: 0.0087 - lr: 1.0000e-04\n",
      "Epoch 675/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2930e-04 - rmse: 0.0100\n",
      "Epoch 675: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1379e-04 - rmse: 0.0091 - val_loss: 2.1545e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 676/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9526e-04 - rmse: 0.0081\n",
      "Epoch 676: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 2.0432e-04 - rmse: 0.0086 - val_loss: 1.8017e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 677/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7081e-04 - rmse: 0.0064\n",
      "Epoch 677: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.9055e-04 - rmse: 0.0078 - val_loss: 2.0987e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 678/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0909e-04 - rmse: 0.0089\n",
      "Epoch 678: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9464e-04 - rmse: 0.0080 - val_loss: 1.9934e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 679/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9816e-04 - rmse: 0.0082\n",
      "Epoch 679: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8998e-04 - rmse: 0.0077 - val_loss: 1.9605e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 680/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1465e-04 - rmse: 0.0092\n",
      "Epoch 680: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.0364e-04 - rmse: 0.0086 - val_loss: 2.1253e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 681/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0974e-04 - rmse: 0.0089\n",
      "Epoch 681: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.0017e-04 - rmse: 0.0084 - val_loss: 2.3714e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 682/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5412e-04 - rmse: 0.0111\n",
      "Epoch 682: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0529e-04 - rmse: 0.0087 - val_loss: 1.9549e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 683/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0121e-04 - rmse: 0.0084\n",
      "Epoch 683: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8513e-04 - rmse: 0.0074 - val_loss: 1.9112e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 684/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9554e-04 - rmse: 0.0081\n",
      "Epoch 684: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9191e-04 - rmse: 0.0079 - val_loss: 1.8375e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 685/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7407e-04 - rmse: 0.0066\n",
      "Epoch 685: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8915e-04 - rmse: 0.0077 - val_loss: 1.9002e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 686/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8610e-04 - rmse: 0.0075\n",
      "Epoch 686: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9238e-04 - rmse: 0.0079 - val_loss: 2.0988e-04 - val_rmse: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 687/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9540e-04 - rmse: 0.0081\n",
      "Epoch 687: val_loss did not improve from 0.00018\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9085e-04 - rmse: 0.0078 - val_loss: 1.8555e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 688/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8511e-04 - rmse: 0.0074\n",
      "Epoch 688: val_loss improved from 0.00018 to 0.00018, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.7938e-04 - rmse: 0.0070 - val_loss: 1.7956e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 689/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6789e-04 - rmse: 0.0062\n",
      "Epoch 689: val_loss improved from 0.00018 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.7845e-04 - rmse: 0.0070 - val_loss: 1.7213e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 690/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7401e-04 - rmse: 0.0067\n",
      "Epoch 690: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7407e-04 - rmse: 0.0067 - val_loss: 1.7664e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 691/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7326e-04 - rmse: 0.0066\n",
      "Epoch 691: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8468e-04 - rmse: 0.0074 - val_loss: 1.8088e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 692/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8058e-04 - rmse: 0.0071\n",
      "Epoch 692: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8624e-04 - rmse: 0.0075 - val_loss: 1.7801e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 693/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7152e-04 - rmse: 0.0065\n",
      "Epoch 693: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.8271e-04 - rmse: 0.0073 - val_loss: 1.7938e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 694/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9000e-04 - rmse: 0.0078\n",
      "Epoch 694: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8154e-04 - rmse: 0.0072 - val_loss: 1.8540e-04 - val_rmse: 0.0075 - lr: 1.0000e-04\n",
      "Epoch 695/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8128e-04 - rmse: 0.0072\n",
      "Epoch 695: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8819e-04 - rmse: 0.0077 - val_loss: 1.7330e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 696/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6840e-04 - rmse: 0.0062\n",
      "Epoch 696: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8583e-04 - rmse: 0.0075 - val_loss: 1.9576e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 697/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9242e-04 - rmse: 0.0079\n",
      "Epoch 697: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9111e-04 - rmse: 0.0079 - val_loss: 1.8688e-04 - val_rmse: 0.0076 - lr: 1.0000e-04\n",
      "Epoch 698/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7456e-04 - rmse: 0.0067\n",
      "Epoch 698: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7985e-04 - rmse: 0.0071 - val_loss: 1.7805e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 699/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9078e-04 - rmse: 0.0078\n",
      "Epoch 699: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9080e-04 - rmse: 0.0078 - val_loss: 1.7895e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 700/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7499e-04 - rmse: 0.0068\n",
      "Epoch 700: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7414e-04 - rmse: 0.0067 - val_loss: 1.7534e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 701/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6827e-04 - rmse: 0.0062\n",
      "Epoch 701: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7453e-04 - rmse: 0.0067 - val_loss: 1.7474e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 702/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7158e-04 - rmse: 0.0065\n",
      "Epoch 702: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7740e-04 - rmse: 0.0069 - val_loss: 1.7858e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 703/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8013e-04 - rmse: 0.0071\n",
      "Epoch 703: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8135e-04 - rmse: 0.0072 - val_loss: 1.8117e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 704/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6969e-04 - rmse: 0.0064\n",
      "Epoch 704: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7101e-04 - rmse: 0.0065 - val_loss: 1.7734e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 705/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8852e-04 - rmse: 0.0077\n",
      "Epoch 705: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7846e-04 - rmse: 0.0070 - val_loss: 1.7523e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 706/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7188e-04 - rmse: 0.0065\n",
      "Epoch 706: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7601e-04 - rmse: 0.0069 - val_loss: 1.8087e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 707/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7211e-04 - rmse: 0.0066\n",
      "Epoch 707: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7465e-04 - rmse: 0.0068 - val_loss: 1.8116e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 708/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8068e-04 - rmse: 0.0072\n",
      "Epoch 708: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8239e-04 - rmse: 0.0073 - val_loss: 1.8059e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 709/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7836e-04 - rmse: 0.0070\n",
      "Epoch 709: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7897e-04 - rmse: 0.0071 - val_loss: 1.8237e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 710/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9516e-04 - rmse: 0.0081\n",
      "Epoch 710: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8952e-04 - rmse: 0.0078 - val_loss: 1.7879e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 711/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8589e-04 - rmse: 0.0076\n",
      "Epoch 711: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1890e-04 - rmse: 0.0095 - val_loss: 1.7989e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 712/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9391e-04 - rmse: 0.0081\n",
      "Epoch 712: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2516e-04 - rmse: 0.0098 - val_loss: 1.7874e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 713/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8412e-04 - rmse: 0.0074\n",
      "Epoch 713: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4127e-04 - rmse: 0.0106 - val_loss: 1.8136e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 714/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7017e-04 - rmse: 0.0064\n",
      "Epoch 714: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4893e-04 - rmse: 0.0110 - val_loss: 2.3005e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 715/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1859e-04 - rmse: 0.0095\n",
      "Epoch 715: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3154e-04 - rmse: 0.0101 - val_loss: 2.5123e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 716/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4211e-04 - rmse: 0.0106\n",
      "Epoch 716: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.4724e-04 - rmse: 0.0109 - val_loss: 5.2134e-04 - val_rmse: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 717/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.0592e-04 - rmse: 0.0194\n",
      "Epoch 717: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.9360e-04 - rmse: 0.0163 - val_loss: 9.0106e-04 - val_rmse: 0.0278 - lr: 1.0000e-04\n",
      "Epoch 718/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.6781e-04 - rmse: 0.0253\n",
      "Epoch 718: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.3212e-04 - rmse: 0.0201 - val_loss: 9.9120e-04 - val_rmse: 0.0294 - lr: 1.0000e-04\n",
      "Epoch 719/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9.3622e-04 - rmse: 0.0284\n",
      "Epoch 719: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 7.0340e-04 - rmse: 0.0240 - val_loss: 4.9226e-04 - val_rmse: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 720/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.8074e-04 - rmse: 0.0159\n",
      "Epoch 720: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 6.7749e-04 - rmse: 0.0234 - val_loss: 5.3802e-04 - val_rmse: 0.0202 - lr: 1.0000e-04\n",
      "Epoch 721/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5.3654e-04 - rmse: 0.0202\n",
      "Epoch 721: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6740e-04 - rmse: 0.0184 - val_loss: 3.4874e-04 - val_rmse: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 722/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.5681e-04 - rmse: 0.0151\n",
      "Epoch 722: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.3286e-04 - rmse: 0.0174 - val_loss: 7.7946e-04 - val_rmse: 0.0255 - lr: 1.0000e-04\n",
      "Epoch 723/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7.6488e-04 - rmse: 0.0252\n",
      "Epoch 723: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 5.3941e-04 - rmse: 0.0203 - val_loss: 5.0488e-04 - val_rmse: 0.0194 - lr: 1.0000e-04\n",
      "Epoch 724/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4.6156e-04 - rmse: 0.0183\n",
      "Epoch 724: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.7721e-04 - rmse: 0.0158 - val_loss: 1.9459e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 725/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9785e-04 - rmse: 0.0083\n",
      "Epoch 725: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.6489e-04 - rmse: 0.0117 - val_loss: 2.9817e-04 - val_rmse: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 726/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.7094e-04 - rmse: 0.0119\n",
      "Epoch 726: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.3204e-04 - rmse: 0.0102 - val_loss: 2.4142e-04 - val_rmse: 0.0106 - lr: 1.0000e-04\n",
      "Epoch 727/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2469e-04 - rmse: 0.0098\n",
      "Epoch 727: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.5358e-04 - rmse: 0.0112 - val_loss: 2.4201e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 728/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2647e-04 - rmse: 0.0099\n",
      "Epoch 728: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4219e-04 - rmse: 0.0107 - val_loss: 2.9964e-04 - val_rmse: 0.0131 - lr: 1.0000e-04\n",
      "Epoch 729/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0725e-04 - rmse: 0.0134\n",
      "Epoch 729: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.7552e-04 - rmse: 0.0121 - val_loss: 2.7924e-04 - val_rmse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 730/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5951e-04 - rmse: 0.0115\n",
      "Epoch 730: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 2.8075e-04 - rmse: 0.0124 - val_loss: 1.8088e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 731/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8619e-04 - rmse: 0.0076\n",
      "Epoch 731: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9764e-04 - rmse: 0.0083 - val_loss: 2.4384e-04 - val_rmse: 0.0108 - lr: 1.0000e-04\n",
      "Epoch 732/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4632e-04 - rmse: 0.0109\n",
      "Epoch 732: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2523e-04 - rmse: 0.0099 - val_loss: 2.3220e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 733/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2185e-04 - rmse: 0.0097\n",
      "Epoch 733: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1396e-04 - rmse: 0.0093 - val_loss: 1.9667e-04 - val_rmse: 0.0083 - lr: 1.0000e-04\n",
      "Epoch 734/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0197e-04 - rmse: 0.0086\n",
      "Epoch 734: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.0531e-04 - rmse: 0.0088 - val_loss: 2.1634e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 735/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0738e-04 - rmse: 0.0089\n",
      "Epoch 735: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0456e-04 - rmse: 0.0088 - val_loss: 2.1117e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 736/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1041e-04 - rmse: 0.0091\n",
      "Epoch 736: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.0456e-04 - rmse: 0.0088 - val_loss: 1.9469e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 737/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8725e-04 - rmse: 0.0077\n",
      "Epoch 737: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2370e-04 - rmse: 0.0098 - val_loss: 2.2733e-04 - val_rmse: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 738/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2855e-04 - rmse: 0.0100\n",
      "Epoch 738: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.1111e-04 - rmse: 0.0091 - val_loss: 2.3030e-04 - val_rmse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 739/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.4135e-04 - rmse: 0.0107\n",
      "Epoch 739: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.2748e-04 - rmse: 0.0100 - val_loss: 1.7790e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 740/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6702e-04 - rmse: 0.0063\n",
      "Epoch 740: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9199e-04 - rmse: 0.0080 - val_loss: 1.8237e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 741/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8634e-04 - rmse: 0.0077\n",
      "Epoch 741: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9161e-04 - rmse: 0.0080 - val_loss: 1.9520e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 742/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8202e-04 - rmse: 0.0074\n",
      "Epoch 742: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7693e-04 - rmse: 0.0070 - val_loss: 1.8676e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 743/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8623e-04 - rmse: 0.0077\n",
      "Epoch 743: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8609e-04 - rmse: 0.0076 - val_loss: 1.7324e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 744/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6401e-04 - rmse: 0.0060\n",
      "Epoch 744: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7130e-04 - rmse: 0.0066 - val_loss: 1.7417e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 745/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7254e-04 - rmse: 0.0067\n",
      "Epoch 745: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7730e-04 - rmse: 0.0071 - val_loss: 1.8144e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 746/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7792e-04 - rmse: 0.0071\n",
      "Epoch 746: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 1.7726e-04 - rmse: 0.0071 - val_loss: 1.6793e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 747/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6206e-04 - rmse: 0.0059\n",
      "Epoch 747: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6920e-04 - rmse: 0.0065 - val_loss: 1.7537e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 748/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7177e-04 - rmse: 0.0067\n",
      "Epoch 748: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6998e-04 - rmse: 0.0065 - val_loss: 1.7465e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 749/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7233e-04 - rmse: 0.0067\n",
      "Epoch 749: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6748e-04 - rmse: 0.0063 - val_loss: 1.7219e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 750/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7848e-04 - rmse: 0.0071\n",
      "Epoch 750: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7403e-04 - rmse: 0.0068 - val_loss: 1.6899e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 751/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5427e-04 - rmse: 0.0052\n",
      "Epoch 751: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6180e-04 - rmse: 0.0059 - val_loss: 1.7288e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 752/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8213e-04 - rmse: 0.0074\n",
      "Epoch 752: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7679e-04 - rmse: 0.0070 - val_loss: 1.6971e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 753/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6555e-04 - rmse: 0.0062\n",
      "Epoch 753: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.6846e-04 - rmse: 0.0064 - val_loss: 1.7070e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 754/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7287e-04 - rmse: 0.0068\n",
      "Epoch 754: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6733e-04 - rmse: 0.0063 - val_loss: 1.7003e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 755/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6211e-04 - rmse: 0.0059\n",
      "Epoch 755: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7535e-04 - rmse: 0.0069 - val_loss: 1.7431e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 756/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6819e-04 - rmse: 0.0064\n",
      "Epoch 756: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6764e-04 - rmse: 0.0064 - val_loss: 1.7053e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 757/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7915e-04 - rmse: 0.0072\n",
      "Epoch 757: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.7076e-04 - rmse: 0.0066 - val_loss: 1.7736e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 758/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7194e-04 - rmse: 0.0067\n",
      "Epoch 758: val_loss improved from 0.00017 to 0.00017, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.6361e-04 - rmse: 0.0060 - val_loss: 1.6554e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 759/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7856e-04 - rmse: 0.0072\n",
      "Epoch 759: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7023e-04 - rmse: 0.0066 - val_loss: 1.6719e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 760/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5847e-04 - rmse: 0.0056\n",
      "Epoch 760: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6485e-04 - rmse: 0.0062 - val_loss: 1.6886e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 761/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7653e-04 - rmse: 0.0070\n",
      "Epoch 761: val_loss did not improve from 0.00017\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6491e-04 - rmse: 0.0062 - val_loss: 1.7063e-04 - val_rmse: 0.0066 - lr: 1.0000e-04\n",
      "Epoch 762/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7658e-04 - rmse: 0.0070\n",
      "Epoch 762: val_loss improved from 0.00017 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 1.7111e-04 - rmse: 0.0066 - val_loss: 1.6423e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 763/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6525e-04 - rmse: 0.0062\n",
      "Epoch 763: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.7415e-04 - rmse: 0.0069 - val_loss: 1.7237e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 764/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6429e-04 - rmse: 0.0061\n",
      "Epoch 764: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7429e-04 - rmse: 0.0069 - val_loss: 1.7910e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 765/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9651e-04 - rmse: 0.0083\n",
      "Epoch 765: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.8910e-04 - rmse: 0.0079 - val_loss: 1.9122e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 766/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7338e-04 - rmse: 0.0068\n",
      "Epoch 766: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.7582e-04 - rmse: 0.0070 - val_loss: 1.9329e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 767/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9721e-04 - rmse: 0.0084\n",
      "Epoch 767: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.8588e-04 - rmse: 0.0077 - val_loss: 1.6508e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7393e-04 - rmse: 0.0069\n",
      "Epoch 768: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7751e-04 - rmse: 0.0071 - val_loss: 2.0829e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 769/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9975e-04 - rmse: 0.0085\n",
      "Epoch 769: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9226e-04 - rmse: 0.0081 - val_loss: 1.9676e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 770/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9682e-04 - rmse: 0.0084\n",
      "Epoch 770: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9374e-04 - rmse: 0.0082 - val_loss: 1.7356e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 771/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7069e-04 - rmse: 0.0066\n",
      "Epoch 771: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7641e-04 - rmse: 0.0071 - val_loss: 2.1979e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 772/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2226e-04 - rmse: 0.0098\n",
      "Epoch 772: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0302e-04 - rmse: 0.0087 - val_loss: 1.6855e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 773/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6287e-04 - rmse: 0.0060\n",
      "Epoch 773: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9108e-04 - rmse: 0.0080 - val_loss: 1.9354e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 774/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0628e-04 - rmse: 0.0089\n",
      "Epoch 774: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0024e-04 - rmse: 0.0086 - val_loss: 2.1215e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 775/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1812e-04 - rmse: 0.0096\n",
      "Epoch 775: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0719e-04 - rmse: 0.0090 - val_loss: 1.8800e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 776/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8119e-04 - rmse: 0.0074\n",
      "Epoch 776: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0209e-04 - rmse: 0.0087 - val_loss: 2.8790e-04 - val_rmse: 0.0127 - lr: 1.0000e-04\n",
      "Epoch 777/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.5555e-04 - rmse: 0.0114\n",
      "Epoch 777: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.5297e-04 - rmse: 0.0113 - val_loss: 2.3393e-04 - val_rmse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 778/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6919e-04 - rmse: 0.0120\n",
      "Epoch 778: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6991e-04 - rmse: 0.0120 - val_loss: 2.4688e-04 - val_rmse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 779/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2551e-04 - rmse: 0.0100\n",
      "Epoch 779: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.8519e-04 - rmse: 0.0126 - val_loss: 3.4221e-04 - val_rmse: 0.0147 - lr: 1.0000e-04\n",
      "Epoch 780/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.0108e-04 - rmse: 0.0132\n",
      "Epoch 780: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.9438e-04 - rmse: 0.0130 - val_loss: 2.8502e-04 - val_rmse: 0.0126 - lr: 1.0000e-04\n",
      "Epoch 781/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3.3023e-04 - rmse: 0.0143\n",
      "Epoch 781: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6746e-04 - rmse: 0.0119 - val_loss: 2.3126e-04 - val_rmse: 0.0102 - lr: 1.0000e-04\n",
      "Epoch 782/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0425e-04 - rmse: 0.0088\n",
      "Epoch 782: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.2045e-04 - rmse: 0.0097 - val_loss: 2.2050e-04 - val_rmse: 0.0097 - lr: 1.0000e-04\n",
      "Epoch 783/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2980e-04 - rmse: 0.0102\n",
      "Epoch 783: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.0052e-04 - rmse: 0.0086 - val_loss: 2.0332e-04 - val_rmse: 0.0088 - lr: 1.0000e-04\n",
      "Epoch 784/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0096e-04 - rmse: 0.0087\n",
      "Epoch 784: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9403e-04 - rmse: 0.0082 - val_loss: 2.1400e-04 - val_rmse: 0.0094 - lr: 1.0000e-04\n",
      "Epoch 785/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0791e-04 - rmse: 0.0090\n",
      "Epoch 785: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 2.0074e-04 - rmse: 0.0086 - val_loss: 1.8708e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 786/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9852e-04 - rmse: 0.0085\n",
      "Epoch 786: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8645e-04 - rmse: 0.0078 - val_loss: 1.6670e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 787/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7763e-04 - rmse: 0.0072\n",
      "Epoch 787: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8436e-04 - rmse: 0.0076 - val_loss: 1.8519e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 788/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8630e-04 - rmse: 0.0078\n",
      "Epoch 788: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8279e-04 - rmse: 0.0075 - val_loss: 1.6695e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 789/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8011e-04 - rmse: 0.0074\n",
      "Epoch 789: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7758e-04 - rmse: 0.0072 - val_loss: 1.9006e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 790/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6739e-04 - rmse: 0.0064\n",
      "Epoch 790: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7278e-04 - rmse: 0.0068 - val_loss: 1.7166e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 791/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7124e-04 - rmse: 0.0067\n",
      "Epoch 791: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6865e-04 - rmse: 0.0065 - val_loss: 1.8761e-04 - val_rmse: 0.0079 - lr: 1.0000e-04\n",
      "Epoch 792/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9195e-04 - rmse: 0.0081\n",
      "Epoch 792: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7719e-04 - rmse: 0.0072 - val_loss: 1.8966e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 793/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9561e-04 - rmse: 0.0084\n",
      "Epoch 793: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.8582e-04 - rmse: 0.0077 - val_loss: 1.8043e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 794/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7489e-04 - rmse: 0.0070\n",
      "Epoch 794: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8279e-04 - rmse: 0.0076 - val_loss: 1.6486e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 795/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6168e-04 - rmse: 0.0060\n",
      "Epoch 795: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7112e-04 - rmse: 0.0067 - val_loss: 1.7855e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 796/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7302e-04 - rmse: 0.0069\n",
      "Epoch 796: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7591e-04 - rmse: 0.0071 - val_loss: 1.9660e-04 - val_rmse: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 797/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0946e-04 - rmse: 0.0092\n",
      "Epoch 797: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.8495e-04 - rmse: 0.0077 - val_loss: 1.8634e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 798/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8410e-04 - rmse: 0.0076\n",
      "Epoch 798: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7197e-04 - rmse: 0.0068 - val_loss: 1.8061e-04 - val_rmse: 0.0074 - lr: 1.0000e-04\n",
      "Epoch 799/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7935e-04 - rmse: 0.0073\n",
      "Epoch 799: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.7546e-04 - rmse: 0.0071 - val_loss: 1.6274e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 800/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6001e-04 - rmse: 0.0059\n",
      "Epoch 800: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6927e-04 - rmse: 0.0066 - val_loss: 1.7044e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 801/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6481e-04 - rmse: 0.0063\n",
      "Epoch 801: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6945e-04 - rmse: 0.0066 - val_loss: 1.7529e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 802/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7421e-04 - rmse: 0.0070\n",
      "Epoch 802: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6896e-04 - rmse: 0.0066 - val_loss: 1.7467e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 803/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6891e-04 - rmse: 0.0066\n",
      "Epoch 803: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7686e-04 - rmse: 0.0072 - val_loss: 1.7095e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 804/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6947e-04 - rmse: 0.0066\n",
      "Epoch 804: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6713e-04 - rmse: 0.0065 - val_loss: 1.7049e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 805/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6874e-04 - rmse: 0.0066\n",
      "Epoch 805: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6893e-04 - rmse: 0.0066 - val_loss: 1.7580e-04 - val_rmse: 0.0071 - lr: 1.0000e-04\n",
      "Epoch 806/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6911e-04 - rmse: 0.0066\n",
      "Epoch 806: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7139e-04 - rmse: 0.0068 - val_loss: 1.6597e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 807/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6152e-04 - rmse: 0.0060\n",
      "Epoch 807: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6327e-04 - rmse: 0.0062 - val_loss: 1.8982e-04 - val_rmse: 0.0080 - lr: 1.0000e-04\n",
      "Epoch 808/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9408e-04 - rmse: 0.0083\n",
      "Epoch 808: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8060e-04 - rmse: 0.0074 - val_loss: 1.6769e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 809/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6129e-04 - rmse: 0.0060\n",
      "Epoch 809: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.7498e-04 - rmse: 0.0071 - val_loss: 1.7827e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 810/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7699e-04 - rmse: 0.0072\n",
      "Epoch 810: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.6961e-04 - rmse: 0.0067 - val_loss: 1.7357e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 811/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7069e-04 - rmse: 0.0067\n",
      "Epoch 811: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6186e-04 - rmse: 0.0061 - val_loss: 1.6637e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 812/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7510e-04 - rmse: 0.0071\n",
      "Epoch 812: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.6459e-04 - rmse: 0.0063 - val_loss: 1.6146e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 813/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5553e-04 - rmse: 0.0055\n",
      "Epoch 813: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6389e-04 - rmse: 0.0062 - val_loss: 1.6945e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 814/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5654e-04 - rmse: 0.0056\n",
      "Epoch 814: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.5842e-04 - rmse: 0.0058 - val_loss: 1.5922e-04 - val_rmse: 0.0058 - lr: 1.0000e-04\n",
      "Epoch 815/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6811e-04 - rmse: 0.0066\n",
      "Epoch 815: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6612e-04 - rmse: 0.0064 - val_loss: 1.6691e-04 - val_rmse: 0.0065 - lr: 1.0000e-04\n",
      "Epoch 816/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6928e-04 - rmse: 0.0067\n",
      "Epoch 816: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6827e-04 - rmse: 0.0066 - val_loss: 1.7111e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 817/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6047e-04 - rmse: 0.0060\n",
      "Epoch 817: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.6974e-04 - rmse: 0.0067 - val_loss: 1.6990e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 818/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7961e-04 - rmse: 0.0074\n",
      "Epoch 818: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7091e-04 - rmse: 0.0068 - val_loss: 1.6606e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 819/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6548e-04 - rmse: 0.0064\n",
      "Epoch 819: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6437e-04 - rmse: 0.0063 - val_loss: 1.6307e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 820/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6656e-04 - rmse: 0.0065\n",
      "Epoch 820: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6250e-04 - rmse: 0.0061 - val_loss: 1.6262e-04 - val_rmse: 0.0062 - lr: 1.0000e-04\n",
      "Epoch 821/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5830e-04 - rmse: 0.0058\n",
      "Epoch 821: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6102e-04 - rmse: 0.0060 - val_loss: 1.7209e-04 - val_rmse: 0.0069 - lr: 1.0000e-04\n",
      "Epoch 822/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7791e-04 - rmse: 0.0073\n",
      "Epoch 822: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6685e-04 - rmse: 0.0065 - val_loss: 1.6953e-04 - val_rmse: 0.0067 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7252e-04 - rmse: 0.0069\n",
      "Epoch 823: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8721e-04 - rmse: 0.0079 - val_loss: 1.6223e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 824/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5564e-04 - rmse: 0.0056\n",
      "Epoch 824: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6295e-04 - rmse: 0.0062 - val_loss: 1.8961e-04 - val_rmse: 0.0081 - lr: 1.0000e-04\n",
      "Epoch 825/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7774e-04 - rmse: 0.0073\n",
      "Epoch 825: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7457e-04 - rmse: 0.0071 - val_loss: 1.7782e-04 - val_rmse: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 826/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8964e-04 - rmse: 0.0081\n",
      "Epoch 826: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7178e-04 - rmse: 0.0069 - val_loss: 1.7088e-04 - val_rmse: 0.0068 - lr: 1.0000e-04\n",
      "Epoch 827/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6065e-04 - rmse: 0.0060\n",
      "Epoch 827: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6264e-04 - rmse: 0.0062 - val_loss: 1.5952e-04 - val_rmse: 0.0059 - lr: 1.0000e-04\n",
      "Epoch 828/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5245e-04 - rmse: 0.0053\n",
      "Epoch 828: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5784e-04 - rmse: 0.0058 - val_loss: 1.6178e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 829/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5786e-04 - rmse: 0.0058\n",
      "Epoch 829: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5945e-04 - rmse: 0.0059 - val_loss: 1.6513e-04 - val_rmse: 0.0064 - lr: 1.0000e-04\n",
      "Epoch 830/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7147e-04 - rmse: 0.0069\n",
      "Epoch 830: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.6405e-04 - rmse: 0.0063 - val_loss: 1.6468e-04 - val_rmse: 0.0063 - lr: 1.0000e-04\n",
      "Epoch 831/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6179e-04 - rmse: 0.0061\n",
      "Epoch 831: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.6387e-04 - rmse: 0.0063 - val_loss: 1.5986e-04 - val_rmse: 0.0060 - lr: 1.0000e-04\n",
      "Epoch 832/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7179e-04 - rmse: 0.0069\n",
      "Epoch 832: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6190e-04 - rmse: 0.0061 - val_loss: 1.7566e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 833/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7155e-04 - rmse: 0.0069\n",
      "Epoch 833: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6626e-04 - rmse: 0.0065 - val_loss: 1.7554e-04 - val_rmse: 0.0072 - lr: 1.0000e-04\n",
      "Epoch 834/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8212e-04 - rmse: 0.0076\n",
      "Epoch 834: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.7268e-04 - rmse: 0.0070 - val_loss: 1.8347e-04 - val_rmse: 0.0077 - lr: 1.0000e-04\n",
      "Epoch 835/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8825e-04 - rmse: 0.0080\n",
      "Epoch 835: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8113e-04 - rmse: 0.0075 - val_loss: 1.8554e-04 - val_rmse: 0.0078 - lr: 1.0000e-04\n",
      "Epoch 836/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.9377e-04 - rmse: 0.0083\n",
      "Epoch 836: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.8936e-04 - rmse: 0.0081 - val_loss: 1.9222e-04 - val_rmse: 0.0082 - lr: 1.0000e-04\n",
      "Epoch 837/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8057e-04 - rmse: 0.0075\n",
      "Epoch 837: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9977e-04 - rmse: 0.0087 - val_loss: 2.5020e-04 - val_rmse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 838/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.6792e-04 - rmse: 0.0120\n",
      "Epoch 838: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.6788e-04 - rmse: 0.0120 - val_loss: 2.4789e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 839/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2725e-04 - rmse: 0.0102\n",
      "Epoch 839: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.5258e-04 - rmse: 0.0113 - val_loss: 1.7289e-04 - val_rmse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 840/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7578e-04 - rmse: 0.0072\n",
      "Epoch 840: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.1379e-04 - rmse: 0.0095 - val_loss: 2.4791e-04 - val_rmse: 0.0111 - lr: 1.0000e-04\n",
      "Epoch 841/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.3907e-04 - rmse: 0.0107\n",
      "Epoch 841: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.2098e-04 - rmse: 0.0098 - val_loss: 2.3833e-04 - val_rmse: 0.0107 - lr: 1.0000e-04\n",
      "Epoch 842/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1106e-04 - rmse: 0.0093\n",
      "Epoch 842: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.9762e-04 - rmse: 0.0086 - val_loss: 2.0529e-04 - val_rmse: 0.0090 - lr: 1.0000e-04\n",
      "Epoch 843/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.2686e-04 - rmse: 0.0101\n",
      "Epoch 843: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.9898e-04 - rmse: 0.0087 - val_loss: 2.0936e-04 - val_rmse: 0.0092 - lr: 1.0000e-04\n",
      "Epoch 844/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0899e-04 - rmse: 0.0092\n",
      "Epoch 844: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.9520e-04 - rmse: 0.0084 - val_loss: 1.6152e-04 - val_rmse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 845/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6449e-04 - rmse: 0.0064\n",
      "Epoch 845: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.8057e-04 - rmse: 0.0075 - val_loss: 2.0962e-04 - val_rmse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 846/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.1310e-04 - rmse: 0.0094\n",
      "Epoch 846: val_loss did not improve from 0.00016\n",
      "\n",
      "Epoch 846: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.9105e-04 - rmse: 0.0082 - val_loss: 2.0742e-04 - val_rmse: 0.0091 - lr: 1.0000e-04\n",
      "Epoch 847/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2.0070e-04 - rmse: 0.0088\n",
      "Epoch 847: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.8181e-04 - rmse: 0.0076 - val_loss: 1.6981e-04 - val_rmse: 0.0068 - lr: 5.0000e-05\n",
      "Epoch 848/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.8103e-04 - rmse: 0.0076\n",
      "Epoch 848: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.7653e-04 - rmse: 0.0073 - val_loss: 1.6557e-04 - val_rmse: 0.0065 - lr: 5.0000e-05\n",
      "Epoch 849/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6310e-04 - rmse: 0.0063\n",
      "Epoch 849: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.6668e-04 - rmse: 0.0065 - val_loss: 1.5704e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 850/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6025e-04 - rmse: 0.0060\n",
      "Epoch 850: val_loss did not improve from 0.00016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 29ms/step - loss: 1.6513e-04 - rmse: 0.0064 - val_loss: 1.5888e-04 - val_rmse: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 851/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6094e-04 - rmse: 0.0061\n",
      "Epoch 851: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.6156e-04 - rmse: 0.0061 - val_loss: 1.7302e-04 - val_rmse: 0.0070 - lr: 5.0000e-05\n",
      "Epoch 852/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7034e-04 - rmse: 0.0068\n",
      "Epoch 852: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5971e-04 - rmse: 0.0060 - val_loss: 1.5981e-04 - val_rmse: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 853/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6112e-04 - rmse: 0.0061\n",
      "Epoch 853: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5811e-04 - rmse: 0.0059 - val_loss: 1.6075e-04 - val_rmse: 0.0061 - lr: 5.0000e-05\n",
      "Epoch 854/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6281e-04 - rmse: 0.0063\n",
      "Epoch 854: val_loss improved from 0.00016 to 0.00016, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.5577e-04 - rmse: 0.0057 - val_loss: 1.5519e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 855/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6366e-04 - rmse: 0.0063\n",
      "Epoch 855: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5800e-04 - rmse: 0.0059 - val_loss: 1.5618e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 856/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5263e-04 - rmse: 0.0054\n",
      "Epoch 856: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5619e-04 - rmse: 0.0057 - val_loss: 1.5715e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 857/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5619e-04 - rmse: 0.0057\n",
      "Epoch 857: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5202e-04 - rmse: 0.0053 - val_loss: 1.5698e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 858/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7533e-04 - rmse: 0.0072\n",
      "Epoch 858: val_loss did not improve from 0.00016\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5818e-04 - rmse: 0.0059 - val_loss: 1.5584e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 859/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5853e-04 - rmse: 0.0059\n",
      "Epoch 859: val_loss improved from 0.00016 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.5480e-04 - rmse: 0.0056 - val_loss: 1.5409e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 860/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6168e-04 - rmse: 0.0062\n",
      "Epoch 860: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5405e-04 - rmse: 0.0055 - val_loss: 1.5720e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 861/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5605e-04 - rmse: 0.0057\n",
      "Epoch 861: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5503e-04 - rmse: 0.0056 - val_loss: 1.5423e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 862/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4704e-04 - rmse: 0.0048\n",
      "Epoch 862: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5341e-04 - rmse: 0.0055 - val_loss: 1.5646e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 863/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5725e-04 - rmse: 0.0058\n",
      "Epoch 863: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5283e-04 - rmse: 0.0054 - val_loss: 1.5487e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 864/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5783e-04 - rmse: 0.0059\n",
      "Epoch 864: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5357e-04 - rmse: 0.0055 - val_loss: 1.5638e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 865/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5728e-04 - rmse: 0.0058\n",
      "Epoch 865: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5522e-04 - rmse: 0.0056 - val_loss: 1.5551e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 866/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4094e-04 - rmse: 0.0042\n",
      "Epoch 866: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5472e-04 - rmse: 0.0056 - val_loss: 1.5712e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 867/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4985e-04 - rmse: 0.0051\n",
      "Epoch 867: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5192e-04 - rmse: 0.0053 - val_loss: 1.5561e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 868/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5084e-04 - rmse: 0.0052\n",
      "Epoch 868: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5417e-04 - rmse: 0.0055 - val_loss: 1.5800e-04 - val_rmse: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 869/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5121e-04 - rmse: 0.0053\n",
      "Epoch 869: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.5534e-04 - rmse: 0.0056 - val_loss: 1.5329e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 870/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5260e-04 - rmse: 0.0054\n",
      "Epoch 870: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5360e-04 - rmse: 0.0055 - val_loss: 1.5757e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 871/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5291e-04 - rmse: 0.0054\n",
      "Epoch 871: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5174e-04 - rmse: 0.0053 - val_loss: 1.5388e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 872/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6162e-04 - rmse: 0.0062\n",
      "Epoch 872: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5619e-04 - rmse: 0.0057 - val_loss: 1.5594e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 873/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5133e-04 - rmse: 0.0053\n",
      "Epoch 873: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5454e-04 - rmse: 0.0056 - val_loss: 1.5381e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 874/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5261e-04 - rmse: 0.0054\n",
      "Epoch 874: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5750e-04 - rmse: 0.0058 - val_loss: 1.5432e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 875/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5055e-04 - rmse: 0.0052\n",
      "Epoch 875: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.4997e-04 - rmse: 0.0052 - val_loss: 1.5622e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 876/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4706e-04 - rmse: 0.0049\n",
      "Epoch 876: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5402e-04 - rmse: 0.0055 - val_loss: 1.5496e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 877/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4949e-04 - rmse: 0.0051\n",
      "Epoch 877: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5571e-04 - rmse: 0.0057 - val_loss: 1.5449e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 878/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4005e-04 - rmse: 0.0041\n",
      "Epoch 878: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5196e-04 - rmse: 0.0054 - val_loss: 1.5418e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 879/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5056e-04 - rmse: 0.0052\n",
      "Epoch 879: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5035e-04 - rmse: 0.0052 - val_loss: 1.5393e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 880/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5010e-04 - rmse: 0.0052\n",
      "Epoch 880: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5413e-04 - rmse: 0.0056 - val_loss: 1.5710e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 881/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5246e-04 - rmse: 0.0054\n",
      "Epoch 881: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5271e-04 - rmse: 0.0054 - val_loss: 1.5395e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 882/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5728e-04 - rmse: 0.0058\n",
      "Epoch 882: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5599e-04 - rmse: 0.0057 - val_loss: 1.5576e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 883/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5309e-04 - rmse: 0.0055\n",
      "Epoch 883: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1.5355e-04 - rmse: 0.0055 - val_loss: 1.5274e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 884/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5970e-04 - rmse: 0.0060\n",
      "Epoch 884: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5273e-04 - rmse: 0.0054 - val_loss: 1.5621e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 885/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4793e-04 - rmse: 0.0050\n",
      "Epoch 885: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5397e-04 - rmse: 0.0055 - val_loss: 1.5668e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 886/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5613e-04 - rmse: 0.0057\n",
      "Epoch 886: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5686e-04 - rmse: 0.0058 - val_loss: 1.5461e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 887/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4781e-04 - rmse: 0.0050\n",
      "Epoch 887: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4801e-04 - rmse: 0.0050 - val_loss: 1.5409e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 888/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4985e-04 - rmse: 0.0052\n",
      "Epoch 888: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5486e-04 - rmse: 0.0056 - val_loss: 1.5500e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 889/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5938e-04 - rmse: 0.0060\n",
      "Epoch 889: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5239e-04 - rmse: 0.0054 - val_loss: 1.5891e-04 - val_rmse: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 890/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6834e-04 - rmse: 0.0067\n",
      "Epoch 890: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5637e-04 - rmse: 0.0058 - val_loss: 1.5580e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 891/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5011e-04 - rmse: 0.0052\n",
      "Epoch 891: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5255e-04 - rmse: 0.0054 - val_loss: 1.5578e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 892/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5589e-04 - rmse: 0.0057\n",
      "Epoch 892: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5598e-04 - rmse: 0.0057 - val_loss: 1.5911e-04 - val_rmse: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 893/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5381e-04 - rmse: 0.0055\n",
      "Epoch 893: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5458e-04 - rmse: 0.0056 - val_loss: 1.5709e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 894/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5794e-04 - rmse: 0.0059\n",
      "Epoch 894: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 1.5897e-04 - rmse: 0.0060 - val_loss: 1.5238e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 895/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4559e-04 - rmse: 0.0048\n",
      "Epoch 895: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4917e-04 - rmse: 0.0051 - val_loss: 1.5621e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 896/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5471e-04 - rmse: 0.0056\n",
      "Epoch 896: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5322e-04 - rmse: 0.0055 - val_loss: 1.5646e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 897/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5040e-04 - rmse: 0.0052\n",
      "Epoch 897: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5049e-04 - rmse: 0.0052 - val_loss: 1.5458e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 898/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.7315e-04 - rmse: 0.0071\n",
      "Epoch 898: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6143e-04 - rmse: 0.0062 - val_loss: 1.5572e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 899/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5111e-04 - rmse: 0.0053\n",
      "Epoch 899: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5063e-04 - rmse: 0.0053 - val_loss: 1.5766e-04 - val_rmse: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 900/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6272e-04 - rmse: 0.0063\n",
      "Epoch 900: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5590e-04 - rmse: 0.0057 - val_loss: 1.6030e-04 - val_rmse: 0.0061 - lr: 5.0000e-05\n",
      "Epoch 901/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6711e-04 - rmse: 0.0066\n",
      "Epoch 901: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5653e-04 - rmse: 0.0058 - val_loss: 1.5519e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 902/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4579e-04 - rmse: 0.0048\n",
      "Epoch 902: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5534e-04 - rmse: 0.0057 - val_loss: 1.5994e-04 - val_rmse: 0.0061 - lr: 5.0000e-05\n",
      "Epoch 903/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4970e-04 - rmse: 0.0052\n",
      "Epoch 903: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5381e-04 - rmse: 0.0056 - val_loss: 1.5472e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 904/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5532e-04 - rmse: 0.0057\n",
      "Epoch 904: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5209e-04 - rmse: 0.0054 - val_loss: 1.5743e-04 - val_rmse: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 905/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5603e-04 - rmse: 0.0058\n",
      "Epoch 905: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5559e-04 - rmse: 0.0057 - val_loss: 1.5343e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 906/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4253e-04 - rmse: 0.0044\n",
      "Epoch 906: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5091e-04 - rmse: 0.0053 - val_loss: 1.5506e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 907/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5294e-04 - rmse: 0.0055\n",
      "Epoch 907: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5008e-04 - rmse: 0.0052 - val_loss: 1.5386e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 908/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6113e-04 - rmse: 0.0062\n",
      "Epoch 908: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.5507e-04 - rmse: 0.0057 - val_loss: 1.5294e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 909/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5584e-04 - rmse: 0.0058\n",
      "Epoch 909: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5368e-04 - rmse: 0.0056 - val_loss: 1.5258e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 910/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4203e-04 - rmse: 0.0044\n",
      "Epoch 910: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 1.4987e-04 - rmse: 0.0052 - val_loss: 1.5171e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 911/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4338e-04 - rmse: 0.0045\n",
      "Epoch 911: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5154e-04 - rmse: 0.0054 - val_loss: 1.5277e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 912/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4761e-04 - rmse: 0.0050\n",
      "Epoch 912: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5113e-04 - rmse: 0.0053 - val_loss: 1.5175e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 913/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4561e-04 - rmse: 0.0048\n",
      "Epoch 913: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4990e-04 - rmse: 0.0052 - val_loss: 1.5265e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 914/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5740e-04 - rmse: 0.0059\n",
      "Epoch 914: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5376e-04 - rmse: 0.0056 - val_loss: 1.5207e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 915/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5355e-04 - rmse: 0.0056\n",
      "Epoch 915: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5330e-04 - rmse: 0.0055 - val_loss: 1.5351e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 916/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5057e-04 - rmse: 0.0053\n",
      "Epoch 916: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5070e-04 - rmse: 0.0053 - val_loss: 1.5373e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 917/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6150e-04 - rmse: 0.0062\n",
      "Epoch 917: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.5312e-04 - rmse: 0.0055 - val_loss: 1.5155e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 918/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4804e-04 - rmse: 0.0050\n",
      "Epoch 918: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4957e-04 - rmse: 0.0052 - val_loss: 1.5208e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 919/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6016e-04 - rmse: 0.0061\n",
      "Epoch 919: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5355e-04 - rmse: 0.0056 - val_loss: 1.5823e-04 - val_rmse: 0.0060 - lr: 5.0000e-05\n",
      "Epoch 920/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5898e-04 - rmse: 0.0060\n",
      "Epoch 920: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5528e-04 - rmse: 0.0057 - val_loss: 1.5759e-04 - val_rmse: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 921/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5480e-04 - rmse: 0.0057\n",
      "Epoch 921: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5344e-04 - rmse: 0.0056 - val_loss: 1.5604e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 922/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5256e-04 - rmse: 0.0055\n",
      "Epoch 922: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5665e-04 - rmse: 0.0058 - val_loss: 1.5578e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 923/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4942e-04 - rmse: 0.0052\n",
      "Epoch 923: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5341e-04 - rmse: 0.0056 - val_loss: 1.6353e-04 - val_rmse: 0.0064 - lr: 5.0000e-05\n",
      "Epoch 924/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6106e-04 - rmse: 0.0062\n",
      "Epoch 924: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5956e-04 - rmse: 0.0061 - val_loss: 1.5203e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 925/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5008e-04 - rmse: 0.0053\n",
      "Epoch 925: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5363e-04 - rmse: 0.0056 - val_loss: 1.5414e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 926/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4936e-04 - rmse: 0.0052\n",
      "Epoch 926: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.5083e-04 - rmse: 0.0053 - val_loss: 1.5112e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 927/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5332e-04 - rmse: 0.0056\n",
      "Epoch 927: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5311e-04 - rmse: 0.0055 - val_loss: 1.5144e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 928/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4652e-04 - rmse: 0.0049\n",
      "Epoch 928: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4899e-04 - rmse: 0.0052 - val_loss: 1.5121e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 929/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5382e-04 - rmse: 0.0056\n",
      "Epoch 929: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5099e-04 - rmse: 0.0053 - val_loss: 1.5297e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 930/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5748e-04 - rmse: 0.0059\n",
      "Epoch 930: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5682e-04 - rmse: 0.0059 - val_loss: 1.5400e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 931/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4882e-04 - rmse: 0.0051\n",
      "Epoch 931: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5012e-04 - rmse: 0.0053 - val_loss: 1.5610e-04 - val_rmse: 0.0058 - lr: 5.0000e-05\n",
      "Epoch 932/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5234e-04 - rmse: 0.0055\n",
      "Epoch 932: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5241e-04 - rmse: 0.0055 - val_loss: 1.6061e-04 - val_rmse: 0.0062 - lr: 5.0000e-05\n",
      "Epoch 933/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5400e-04 - rmse: 0.0056\n",
      "Epoch 933: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5418e-04 - rmse: 0.0056 - val_loss: 1.5515e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 934/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5009e-04 - rmse: 0.0053\n",
      "Epoch 934: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5296e-04 - rmse: 0.0055 - val_loss: 1.5757e-04 - val_rmse: 0.0059 - lr: 5.0000e-05\n",
      "Epoch 935/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5100e-04 - rmse: 0.0054\n",
      "Epoch 935: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5693e-04 - rmse: 0.0059 - val_loss: 1.5128e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 936/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4896e-04 - rmse: 0.0052\n",
      "Epoch 936: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5346e-04 - rmse: 0.0056 - val_loss: 1.5273e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 937/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4538e-04 - rmse: 0.0048\n",
      "Epoch 937: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5337e-04 - rmse: 0.0056 - val_loss: 1.5531e-04 - val_rmse: 0.0057 - lr: 5.0000e-05\n",
      "Epoch 938/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5369e-04 - rmse: 0.0056\n",
      "Epoch 938: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5465e-04 - rmse: 0.0057 - val_loss: 1.5355e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 939/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5090e-04 - rmse: 0.0054\n",
      "Epoch 939: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5222e-04 - rmse: 0.0055 - val_loss: 1.5374e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 940/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5691e-04 - rmse: 0.0059\n",
      "Epoch 940: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 1.4961e-04 - rmse: 0.0052 - val_loss: 1.4987e-04 - val_rmse: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 941/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5135e-04 - rmse: 0.0054\n",
      "Epoch 941: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5069e-04 - rmse: 0.0053 - val_loss: 1.5041e-04 - val_rmse: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 942/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4187e-04 - rmse: 0.0044\n",
      "Epoch 942: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4548e-04 - rmse: 0.0048 - val_loss: 1.5044e-04 - val_rmse: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 943/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5238e-04 - rmse: 0.0055\n",
      "Epoch 943: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5089e-04 - rmse: 0.0054 - val_loss: 1.5323e-04 - val_rmse: 0.0056 - lr: 5.0000e-05\n",
      "Epoch 944/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5184e-04 - rmse: 0.0054\n",
      "Epoch 944: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5124e-04 - rmse: 0.0054 - val_loss: 1.5007e-04 - val_rmse: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 945/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4396e-04 - rmse: 0.0047\n",
      "Epoch 945: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4898e-04 - rmse: 0.0052 - val_loss: 1.5193e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 946/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4944e-04 - rmse: 0.0052\n",
      "Epoch 946: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4859e-04 - rmse: 0.0051 - val_loss: 1.5044e-04 - val_rmse: 0.0053 - lr: 5.0000e-05\n",
      "Epoch 947/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5393e-04 - rmse: 0.0056\n",
      "Epoch 947: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5121e-04 - rmse: 0.0054 - val_loss: 1.5211e-04 - val_rmse: 0.0055 - lr: 5.0000e-05\n",
      "Epoch 948/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4647e-04 - rmse: 0.0049\n",
      "Epoch 948: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4963e-04 - rmse: 0.0052 - val_loss: 1.5077e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 949/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4995e-04 - rmse: 0.0053\n",
      "Epoch 949: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 949: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5190e-04 - rmse: 0.0055 - val_loss: 1.5086e-04 - val_rmse: 0.0054 - lr: 5.0000e-05\n",
      "Epoch 950/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4383e-04 - rmse: 0.0047\n",
      "Epoch 950: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4623e-04 - rmse: 0.0049 - val_loss: 1.5149e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 951/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5809e-04 - rmse: 0.0060\n",
      "Epoch 951: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5182e-04 - rmse: 0.0055 - val_loss: 1.5035e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 952/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4762e-04 - rmse: 0.0051\n",
      "Epoch 952: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4780e-04 - rmse: 0.0051 - val_loss: 1.4991e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 953/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4885e-04 - rmse: 0.0052\n",
      "Epoch 953: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4959e-04 - rmse: 0.0053 - val_loss: 1.5025e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 954/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4435e-04 - rmse: 0.0047\n",
      "Epoch 954: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.5064e-04 - rmse: 0.0054 - val_loss: 1.4971e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 955/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4482e-04 - rmse: 0.0048\n",
      "Epoch 955: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4735e-04 - rmse: 0.0050 - val_loss: 1.4984e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 956/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4782e-04 - rmse: 0.0051\n",
      "Epoch 956: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4660e-04 - rmse: 0.0050 - val_loss: 1.5042e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 957/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4564e-04 - rmse: 0.0049\n",
      "Epoch 957: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4865e-04 - rmse: 0.0052 - val_loss: 1.5079e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 958/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4666e-04 - rmse: 0.0050\n",
      "Epoch 958: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 1.5108e-04 - rmse: 0.0054 - val_loss: 1.4939e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 959/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4356e-04 - rmse: 0.0046\n",
      "Epoch 959: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4430e-04 - rmse: 0.0047 - val_loss: 1.4980e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 960/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5476e-04 - rmse: 0.0057\n",
      "Epoch 960: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4878e-04 - rmse: 0.0052 - val_loss: 1.5047e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 961/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4615e-04 - rmse: 0.0049\n",
      "Epoch 961: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 1.4788e-04 - rmse: 0.0051 - val_loss: 1.4927e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 962/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5004e-04 - rmse: 0.0053\n",
      "Epoch 962: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 1.4938e-04 - rmse: 0.0052 - val_loss: 1.4920e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 963/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4656e-04 - rmse: 0.0050\n",
      "Epoch 963: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5021e-04 - rmse: 0.0053 - val_loss: 1.5170e-04 - val_rmse: 0.0055 - lr: 2.5000e-05\n",
      "Epoch 964/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4294e-04 - rmse: 0.0046\n",
      "Epoch 964: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4629e-04 - rmse: 0.0049 - val_loss: 1.4970e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 965/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5505e-04 - rmse: 0.0058\n",
      "Epoch 965: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.5075e-04 - rmse: 0.0054 - val_loss: 1.4932e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 966/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3763e-04 - rmse: 0.0040\n",
      "Epoch 966: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4746e-04 - rmse: 0.0051 - val_loss: 1.5168e-04 - val_rmse: 0.0055 - lr: 2.5000e-05\n",
      "Epoch 967/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5258e-04 - rmse: 0.0055\n",
      "Epoch 967: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4549e-04 - rmse: 0.0049 - val_loss: 1.5045e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 968/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4604e-04 - rmse: 0.0049\n",
      "Epoch 968: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5133e-04 - rmse: 0.0054 - val_loss: 1.5086e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 969/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4374e-04 - rmse: 0.0047\n",
      "Epoch 969: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4785e-04 - rmse: 0.0051 - val_loss: 1.5071e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 970/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5615e-04 - rmse: 0.0059\n",
      "Epoch 970: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4864e-04 - rmse: 0.0052 - val_loss: 1.4956e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 971/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4685e-04 - rmse: 0.0050\n",
      "Epoch 971: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4980e-04 - rmse: 0.0053 - val_loss: 1.5022e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 972/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4678e-04 - rmse: 0.0050\n",
      "Epoch 972: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4831e-04 - rmse: 0.0051 - val_loss: 1.5087e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 973/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4279e-04 - rmse: 0.0046\n",
      "Epoch 973: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4784e-04 - rmse: 0.0051 - val_loss: 1.4948e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 974/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5204e-04 - rmse: 0.0055\n",
      "Epoch 974: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5126e-04 - rmse: 0.0054 - val_loss: 1.5082e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 975/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4714e-04 - rmse: 0.0050\n",
      "Epoch 975: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4392e-04 - rmse: 0.0047 - val_loss: 1.5033e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 976/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4845e-04 - rmse: 0.0052\n",
      "Epoch 976: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5343e-04 - rmse: 0.0056 - val_loss: 1.5285e-04 - val_rmse: 0.0056 - lr: 2.5000e-05\n",
      "Epoch 977/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5156e-04 - rmse: 0.0055\n",
      "Epoch 977: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5290e-04 - rmse: 0.0056 - val_loss: 1.5220e-04 - val_rmse: 0.0055 - lr: 2.5000e-05\n",
      "Epoch 978/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4858e-04 - rmse: 0.0052\n",
      "Epoch 978: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 1.5154e-04 - rmse: 0.0055 - val_loss: 1.4905e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 979/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4940e-04 - rmse: 0.0053\n",
      "Epoch 979: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4947e-04 - rmse: 0.0053 - val_loss: 1.4996e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 980/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4505e-04 - rmse: 0.0048\n",
      "Epoch 980: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4742e-04 - rmse: 0.0051 - val_loss: 1.5165e-04 - val_rmse: 0.0055 - lr: 2.5000e-05\n",
      "Epoch 981/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4643e-04 - rmse: 0.0050\n",
      "Epoch 981: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4775e-04 - rmse: 0.0051 - val_loss: 1.4940e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 982/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5514e-04 - rmse: 0.0058\n",
      "Epoch 982: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5254e-04 - rmse: 0.0055 - val_loss: 1.4935e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 983/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4560e-04 - rmse: 0.0049\n",
      "Epoch 983: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4403e-04 - rmse: 0.0047 - val_loss: 1.5352e-04 - val_rmse: 0.0056 - lr: 2.5000e-05\n",
      "Epoch 984/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4731e-04 - rmse: 0.0051\n",
      "Epoch 984: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5176e-04 - rmse: 0.0055 - val_loss: 1.5025e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 985/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5069e-04 - rmse: 0.0054\n",
      "Epoch 985: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4902e-04 - rmse: 0.0052 - val_loss: 1.4910e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 986/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4435e-04 - rmse: 0.0048\n",
      "Epoch 986: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4716e-04 - rmse: 0.0050 - val_loss: 1.5040e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 987/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4628e-04 - rmse: 0.0050\n",
      "Epoch 987: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.4722e-04 - rmse: 0.0051 - val_loss: 1.4899e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 988/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5304e-04 - rmse: 0.0056\n",
      "Epoch 988: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4854e-04 - rmse: 0.0052 - val_loss: 1.4911e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 989/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4797e-04 - rmse: 0.0051\n",
      "Epoch 989: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4582e-04 - rmse: 0.0049 - val_loss: 1.4963e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 990/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5676e-04 - rmse: 0.0059\n",
      "Epoch 990: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 1.5095e-04 - rmse: 0.0054 - val_loss: 1.4887e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 991/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4478e-04 - rmse: 0.0048\n",
      "Epoch 991: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4822e-04 - rmse: 0.0052 - val_loss: 1.4934e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 992/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4649e-04 - rmse: 0.0050\n",
      "Epoch 992: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4715e-04 - rmse: 0.0050 - val_loss: 1.4959e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 993/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4583e-04 - rmse: 0.0049\n",
      "Epoch 993: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 1.4867e-04 - rmse: 0.0052 - val_loss: 1.4874e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 994/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4161e-04 - rmse: 0.0045\n",
      "Epoch 994: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4657e-04 - rmse: 0.0050 - val_loss: 1.5010e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 995/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4795e-04 - rmse: 0.0051\n",
      "Epoch 995: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4684e-04 - rmse: 0.0050 - val_loss: 1.4909e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 996/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4766e-04 - rmse: 0.0051\n",
      "Epoch 996: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4835e-04 - rmse: 0.0052 - val_loss: 1.4990e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 997/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4645e-04 - rmse: 0.0050\n",
      "Epoch 997: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4525e-04 - rmse: 0.0049 - val_loss: 1.4993e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 998/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.6005e-04 - rmse: 0.0062\n",
      "Epoch 998: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 1.4850e-04 - rmse: 0.0052 - val_loss: 1.4802e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 999/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4642e-04 - rmse: 0.0050\n",
      "Epoch 999: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4868e-04 - rmse: 0.0052 - val_loss: 1.4911e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1000/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5670e-04 - rmse: 0.0059\n",
      "Epoch 1000: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4814e-04 - rmse: 0.0052 - val_loss: 1.4953e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1001/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4469e-04 - rmse: 0.0048\n",
      "Epoch 1001: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4606e-04 - rmse: 0.0049 - val_loss: 1.4897e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1002/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5343e-04 - rmse: 0.0056\n",
      "Epoch 1002: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4750e-04 - rmse: 0.0051 - val_loss: 1.4854e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1003/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4765e-04 - rmse: 0.0051\n",
      "Epoch 1003: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4729e-04 - rmse: 0.0051 - val_loss: 1.4879e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1004/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4983e-04 - rmse: 0.0053\n",
      "Epoch 1004: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4791e-04 - rmse: 0.0051 - val_loss: 1.4858e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1005/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4523e-04 - rmse: 0.0049\n",
      "Epoch 1005: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4496e-04 - rmse: 0.0048 - val_loss: 1.4865e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1006/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5936e-04 - rmse: 0.0061\n",
      "Epoch 1006: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4644e-04 - rmse: 0.0050 - val_loss: 1.4845e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1007/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4389e-04 - rmse: 0.0047\n",
      "Epoch 1007: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4784e-04 - rmse: 0.0051 - val_loss: 1.4978e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1008/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4704e-04 - rmse: 0.0051\n",
      "Epoch 1008: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5062e-04 - rmse: 0.0054 - val_loss: 1.4845e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1009/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4907e-04 - rmse: 0.0052\n",
      "Epoch 1009: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4668e-04 - rmse: 0.0050 - val_loss: 1.4813e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1010/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4617e-04 - rmse: 0.0050\n",
      "Epoch 1010: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4444e-04 - rmse: 0.0048 - val_loss: 1.4889e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1011/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4791e-04 - rmse: 0.0051\n",
      "Epoch 1011: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5031e-04 - rmse: 0.0054 - val_loss: 1.4847e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1012/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4784e-04 - rmse: 0.0051\n",
      "Epoch 1012: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4588e-04 - rmse: 0.0049 - val_loss: 1.4861e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1013/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4421e-04 - rmse: 0.0048\n",
      "Epoch 1013: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4667e-04 - rmse: 0.0050 - val_loss: 1.4897e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1014/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4888e-04 - rmse: 0.0052\n",
      "Epoch 1014: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 1.4479e-04 - rmse: 0.0048 - val_loss: 1.4774e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1015/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5292e-04 - rmse: 0.0056\n",
      "Epoch 1015: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5013e-04 - rmse: 0.0054 - val_loss: 1.4978e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1016/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5070e-04 - rmse: 0.0054\n",
      "Epoch 1016: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4704e-04 - rmse: 0.0051 - val_loss: 1.4876e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1017/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4645e-04 - rmse: 0.0050\n",
      "Epoch 1017: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4659e-04 - rmse: 0.0050 - val_loss: 1.4809e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1018/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5135e-04 - rmse: 0.0055\n",
      "Epoch 1018: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.5255e-04 - rmse: 0.0056 - val_loss: 1.4890e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1019/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4012e-04 - rmse: 0.0043\n",
      "Epoch 1019: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4100e-04 - rmse: 0.0044 - val_loss: 1.4878e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1020/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5593e-04 - rmse: 0.0059\n",
      "Epoch 1020: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4905e-04 - rmse: 0.0053 - val_loss: 1.4823e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1021/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5375e-04 - rmse: 0.0057\n",
      "Epoch 1021: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4644e-04 - rmse: 0.0050 - val_loss: 1.4928e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1022/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4738e-04 - rmse: 0.0051\n",
      "Epoch 1022: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.4755e-04 - rmse: 0.0051 - val_loss: 1.4773e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1023/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4637e-04 - rmse: 0.0050\n",
      "Epoch 1023: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4895e-04 - rmse: 0.0052 - val_loss: 1.4865e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1024/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4574e-04 - rmse: 0.0049\n",
      "Epoch 1024: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4437e-04 - rmse: 0.0048 - val_loss: 1.4808e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1025/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5478e-04 - rmse: 0.0058\n",
      "Epoch 1025: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4634e-04 - rmse: 0.0050 - val_loss: 1.4777e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1026/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4793e-04 - rmse: 0.0052\n",
      "Epoch 1026: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4821e-04 - rmse: 0.0052 - val_loss: 1.4875e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1027/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4360e-04 - rmse: 0.0047\n",
      "Epoch 1027: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.5070e-04 - rmse: 0.0054 - val_loss: 1.4794e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1028/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4116e-04 - rmse: 0.0045\n",
      "Epoch 1028: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4178e-04 - rmse: 0.0045 - val_loss: 1.4836e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1029/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5021e-04 - rmse: 0.0054\n",
      "Epoch 1029: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4730e-04 - rmse: 0.0051 - val_loss: 1.4923e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1030/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4048e-04 - rmse: 0.0044\n",
      "Epoch 1030: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 1.4352e-04 - rmse: 0.0047 - val_loss: 1.4748e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1031/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4962e-04 - rmse: 0.0053\n",
      "Epoch 1031: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5253e-04 - rmse: 0.0056 - val_loss: 1.4958e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1032/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4854e-04 - rmse: 0.0052\n",
      "Epoch 1032: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4401e-04 - rmse: 0.0048 - val_loss: 1.5082e-04 - val_rmse: 0.0054 - lr: 2.5000e-05\n",
      "Epoch 1033/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4182e-04 - rmse: 0.0045\n",
      "Epoch 1033: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4722e-04 - rmse: 0.0051 - val_loss: 1.4899e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1034/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4813e-04 - rmse: 0.0052\n",
      "Epoch 1034: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4614e-04 - rmse: 0.0050 - val_loss: 1.4969e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1035/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4788e-04 - rmse: 0.0052\n",
      "Epoch 1035: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4794e-04 - rmse: 0.0052 - val_loss: 1.4748e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1036/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4225e-04 - rmse: 0.0046\n",
      "Epoch 1036: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4611e-04 - rmse: 0.0050 - val_loss: 1.4766e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1037/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5144e-04 - rmse: 0.0055\n",
      "Epoch 1037: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4649e-04 - rmse: 0.0050 - val_loss: 1.4886e-04 - val_rmse: 0.0053 - lr: 2.5000e-05\n",
      "Epoch 1038/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4674e-04 - rmse: 0.0050\n",
      "Epoch 1038: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4641e-04 - rmse: 0.0050 - val_loss: 1.4764e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1039/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4704e-04 - rmse: 0.0051\n",
      "Epoch 1039: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4519e-04 - rmse: 0.0049 - val_loss: 1.4774e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1040/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5234e-04 - rmse: 0.0056\n",
      "Epoch 1040: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4702e-04 - rmse: 0.0051 - val_loss: 1.4764e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1041/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4896e-04 - rmse: 0.0053\n",
      "Epoch 1041: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4624e-04 - rmse: 0.0050 - val_loss: 1.4760e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1042/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4461e-04 - rmse: 0.0048\n",
      "Epoch 1042: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.4565e-04 - rmse: 0.0049 - val_loss: 1.4809e-04 - val_rmse: 0.0052 - lr: 2.5000e-05\n",
      "Epoch 1043/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4938e-04 - rmse: 0.0053\n",
      "Epoch 1043: val_loss improved from 0.00015 to 0.00015, saving model to D:\\TrainedModels\\20230102\\Case1520230102unsteady_AeroCNN1_Case15_val_0.2_test0.1_200kernels_5FClayers_256units_checkpoint.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 1.4524e-04 - rmse: 0.0049 - val_loss: 1.4712e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1044/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4630e-04 - rmse: 0.0050\n",
      "Epoch 1044: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4651e-04 - rmse: 0.0050 - val_loss: 1.4755e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1045/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.5650e-04 - rmse: 0.0059\n",
      "Epoch 1045: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4685e-04 - rmse: 0.0051 - val_loss: 1.4756e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1046/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4067e-04 - rmse: 0.0044\n",
      "Epoch 1046: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.4731e-04 - rmse: 0.0051 - val_loss: 1.4751e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1047/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4459e-04 - rmse: 0.0048\n",
      "Epoch 1047: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4375e-04 - rmse: 0.0048 - val_loss: 1.4745e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1048/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.3920e-04 - rmse: 0.0042\n",
      "Epoch 1048: val_loss did not improve from 0.00015\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.4610e-04 - rmse: 0.0050 - val_loss: 1.4755e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1049/10000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.4711e-04 - rmse: 0.0051Restoring model weights from the end of the best epoch: 849.\n",
      "\n",
      "Epoch 1049: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 1049: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.4665e-04 - rmse: 0.0050 - val_loss: 1.4751e-04 - val_rmse: 0.0051 - lr: 2.5000e-05\n",
      "Epoch 1049: early stopping\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "history = model.fit([x_time_train, x_coord_train], y_train, batch_size=batch_size,\n",
    "                    validation_data=[[x_time_val, x_coord_val], y_val],\n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN, validation_steps=VALIDATION_STEPS,\n",
    "                    epochs=10000, shuffle=True, callbacks=[es, ckpt, rp])\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:01:52.896947\n"
     ]
    }
   ],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fbce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_dir = \"D:\\\\VAWT_data\\\\flap_unsteady\\\\result\\\\\"+\"20230102_AeroCNN1_Case13_WithParameters\\\\test\"+str(test_rate)+\"_val\"+str(val_rate)+\"_\"+str(n_kernels)+\"kernels_\"+str(n_layers)+\"layers_\"+ str(n_units) +\"units_CmPrediction\"\n",
    "if not os.path.exists(storage_dir):\n",
    "    os.makedirs(storage_dir)\n",
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2, label='Training loss')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation loss')\n",
    "plt.title('Training loss (mean squared error)\\nAeroCNN-I, optimal settings, $C_m$ prediction', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"TrainingLoss_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAE2CAYAAACA+DK5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7jElEQVR4nO3dd5xU1dnA8d8zM9uXhQWWJuBKExEVFBV711hRrEmMwfhGTWKM0cQkxiiWFGNLXmvMm2g0JpiiiWIXFXsBAQtFUHrdhS1s35l53j/OHZgdZndn6+zOPN/PZz67c+659z5nyjNnzr1zj6gqxhhjUpsv2QEYY4zpepbsjTEmDViyN8aYNGDJ3hhj0oAle2OMSQOW7I0xJg302mQvIjNFRKNum0Rktojs20X7O0hEZiZY9xEvppfjLMsRke3e8hmdHWdHiEieiNwiIstEpFZENovIXBG5JNmxdSYRuUJEWjznWERmxLy+om/Xd1esySQi47z3Wb+Y8shjk99NcRzt7W9iF+9nkNfe4pjyHvE4dFSvTfaeCuAQ73YVMA54WUT6d8G+DgJubEP9KuAYERkcU35a54XU6f4NXArcC5wCXAl86v2fro5l52sscns4qRF1n3G413y/mPJncY9DTXcH1MUG4dpbHFOeEo9DINkBdFBQVd/z/n9PRFYB7wJfAf6WtKicZUAf4Fxc8oy4AHga+FoygmqOiIwFTgLOU9V/Ri16QkQkSWHFJSI5qlrbTbv7UFWrEq3cXGwdibmb29sqVS0BSpIdR7L1tseht/fsYy3y/o6IFIiI3/sKtkZE6kXkMxHZJdGKyHki8olXZ62I/FJEAt6yGcA93v+Rr/KvJxDPE7jkHtlHH1wveVa8yiIyTUTmiUidNyz1WxHJiFo+XkRmefHVeG25SkR8UXUiX3mPFpF/ikiViHwpIt9tJdZ+3t9NsQs05mfWInKkiCzy4pwvIoeKSGn0MJeIrBKRO2LWa/K11xs2utcbNqoRkZUicp+IFMSspyJytYj8TkRKgE+88mzvMVrrPW+LROSUmHWzvH2Ui8g2EbkbyKCTtBBbc+UDReQvIrLVa/PrIjIlZpurROROEfmFiKwDKtsYU6L7uMPbxybvdfK4iPT1lh8NPONVX+m1Z5W3LPZ5LPbuXyAiD4tIpYisE5ELveXXisgGESkRkdtiXq+tvqYTbHOG157I+3yDiDwlIplRdUZ6+9rm7etFEdkz0ga85wh4TXa+z9vzOJwnIn8QkQrvcbgptj0icq6ILBc3XPqaiEyWmKFdETlD3PurWkTKROR9ETmqLY9LE6raK2/ATKA0pmxPQHG900jZL4FG4Hpcz/Uhr85Xo+qc6JX9Bfet4FqgHnjQW14E3OHVmerdJrQQ2yPAPGAvIAyM9MovAjYABd62ZkStcx4QAu734vkOUA7cEVXnOOAm4HTgaNzQVQXws6g6R3vbXu61+QTgz17ZQS3EXIAbeprv7T+7mXrDgGrgNdyQ1KXAStxX2ZlR9VZFx+6VzfDiyI96XB8AzgGOAi4ElgAvxqynwEbch+dXgFO88tnAFu+xOhH4PyAITIpa926gDrgGOBl4EliH9xnWwuMRibUv7htw9E0SiK258rdwH6gXe8/jG8B2YEzMY7cReAU4A5jexvdGovtYD8z16lyKe739M+r1cI3XjrNwr/nJzTyPxd791cCvcK+5v+Nez3cC//Ieg5979S5o52t6YgttvsF7zL4JHIl7Pz0C5HjL+wNrgAXestO8x2ktkANk4b5tK/Bddr7P2/M4rPLafQLwG3bNSVO8xyby2vgh8DlROQEYDTQAt+OGEk8BfgGc1e6c2dVJuatueMmenW/A0cDL3pOZFfUEVwM3xqz7HLAs6v57wGsxda71npDh3v0raCVBRK37CDDP+38R8OOo/f4OyI95YgX3Rnk4ZjvfAmqBAXH2IV67rwO+jPPGuDmqLAP3dfM3rcT9VVzCV++F9gbwbZomt98CW4HcqLKve+u0KdnH2X8AOMyrMzKqXIEFMXWP88qPiil/g50Ja4D3+P0karkPWNracxkVa7zb0S3F1kLMX4mNGcjznps/xDx2G2nmA7eVuNuyj23Rz4X3PIaBvbz7p3nbKm7peWRnkns4qk4BrpO1HPBHlX8APNFM7K29pltK9rOBO1tYfov3uu0fVVaI+2D5nnd/Yuzz287H4dGYeguBWVH3/4k7Fhb9vrqWpjnhHGBrW5//lm69fRhnAO4F1QisACbjekH13vKJQC7uwY32BDBO3NF3P7B/M3V8uAMwHTELuEDcQePjiT+EMw4YCfxDRAKRG/AqkO21IzJscZOIrMB982jEfXPZw6sf7aXIP6oaedMNbylQVf07sDvuQ2aWF9dDND3+cRDwsqpGH5R6sqXttkREviEiC0SkCteet7xF42KqPhtz/3hc7/XtmMdsDq7nBLAP7vH7b2QlVQ1H30/AkcCBMbf5rcTWXPlBQImqzo2KpxqXqA6PqTtHVevaEGd79vGyNj0e8SQu4R7Yjv2Ce+wj+6zEfcDMVdVQVJ0VwG6RO218TbdkITDDGzLaV2SX40zH4zqDlVGvle2453IKneulmPuLafreOxB4Rr2s7nk6Zp1PgL7ecNyJIpLX0aB6e7KvwD1wU4HLgEzgb1HjY0O9v5tj1ovcLwQG4nq+zdXp6Jk9s3AfJtcB63XnAeVoA72/z7Hzw6sRNzwCO49B3Ab8CJeAT8G1/VZvWXbMNstj7jfEqbMLVd2qqg+r6kXefh/GfVjt51UZghs6iV6nFveNoE1E5CzgUdxB9XNxz+NZ3uLYWGOfn4FeLI0xt5nsfLyGeH+3xKwbe78lC1R1XsxteyuxNVc+tJm6m9n1ddbcNlvTln009zwOpX3KY+43NFMW/dy25TXdkluB+3BDMIuAtSLyg6jlA4Hz2fX1cgxRx/g6SXnM/dg2D2HXA7tN7qvqMmAaMAqXF0pF5G8iUtTeoFLhbJx53v/vi0gtLnmci+uZb/SWDcJ9hYuInA65zbs1enVopk67qepKEfkANy53ezPVIvu4FDcMFSuS9M8F7lHV30YWiMipHYmvJaraKO6A5sXAeNybaBMxj5WI5OCGpqLV4T58o8Umm3OB91V1x8HjFg5Aacz9bbgx5zNbaELkYPMgmj6Psc91R8XG1lz5xmb2PZhdX2fNbbM1bdlHc8/jRrpPp7ymvW9BNwA3iDuz7HLgdyKyTFVfwLX9adxwTqzYD++utgl3vCraLklcVZ8FnvUOmp+KGwK+h6iTPtqit/fsY/0V+Az4iXf/U9yBw3Nj6p0HfK6qJd5XzPnN1Anjep3gPp0Rkbb0NiLuxB3Rf7SZ5ctwias4Ti9ynqpGPqhycF918WLx084nPpaI9PHe7LHGen8jvcUPgRNEJDeqzvQ4663DHaCOdkLM/Sbt8Xw9gXDBDRkMAariPWZenU9wHzrTIit53/qm7bq5bvE+MEhEjoyKJxf3Rn6r2bW6bh8nSNMfBE3HfchEHr8G7297XvOJ6vTXtKoux31bqAcmeMVzgL2Bz+K8XpZ5dZprb2c/Dh8Cp8cMNZ3RXGVVrVDVvwFPsbM9bdbbe/ZNqKqKyK+Ax0XkOFWdIyK/A64XkSDuRTwd93Xxq1Gr3gi8KCIP44Zd9sH1AP6oquu8Oku9vz8QkVeByqgXSWtx/QP4RwvLwyJyDfCYuNMOn8e9wEbheq7neGPkLwPf88Y3twHfw51F0Bn2BJ4WkT8D7+A+JCfhzqBYyM5E8Ttvv7NF5C7c2Tk/wx0IjfYUcI+IXId7cU/HvdmivQzcJyI/xyWpU3AHXhPxMvAi7kd0t+E+5Au8mLNV9WequlVEHgJu8p7/z3AHnNvyi8cDvW+M0bao6pdt2AYAqvqiiLyN++3CT3HfNn+ES3jNfevbwTsN8DXgGFV9vRP2UYvrOd6OG7q5HXhKVRd7yyOv78tEZBZQo6qf0Lk65TUtIk/hOm0LcO06B5ff3vCq3IU72+tVEbkH17kajDsL7C3veNUab91vikgF0Oh1HDr7cbgN93qf5eWcvXCvS3AdTETkMtzxwhdwZ/CNxXVIm+swtq4zj/Z25404p1565X7caUwvRt2/CXeKVQPuYMnX46x3Pq4n2IDrlf4SCEQtF9yZKBu8J+T1FmJ7BO9snGaWNzkbJ6r8ZOBN3BlElbgke2skDtyL8ylv2WYvnm/T9IyAo4lz5gLwOvCvFmIqBG7GvQi34pL9UtwLs39M3aOBj3E9p4W4M2hKaXo2TgbuDbYJKAN+jxumio7VjzuldYvXpn8DB3t1TovalgJXxIk5y3tuV3jP2ybcm+PUmDr3447vlOG+Bl9Nx87G+b8EYmuuvAj3hi3DJZa5wIExdVYRcyaTV36Kt91mT/tt4z7uxL2PNnuvub8D/WLqXYM7UywIrIp5bGLPQjmttXYQ896gA6/pmO3+GNeZq8ANy7wPTIupMwx3DGoz7rW7CjcasHdUna/j8kdD9Gukg49DkzZ7ZefhXrd1uI7U8d66Z3rLD8Ed4N/g1VmJey9mtfTct3QTb8PGdIiIlAL3qurMZMeSqkTkJuBIVT2mE7a1Cvfh/6MOB2Y6TNwP0B4DRqnqytbqt0dKDeMYk+IOxX1bMr2ciDyAG8Iqw52tdz3wbFclerBkb0yvoaqxB7hN7zUAN7w4ADds+gTuh1VdxoZxjDEmDaTaqZfGGGPisGRvjDFpwJK9McakAUv2xhiTBizZm6QQN9nED0XkA2+Sh1pvooYfStSEE72JiEyUnRNeRMoeEZF5za+1yzbOkzhzE7d1O8bEslMvTbcTkULcxByjcb9ovcFbdDJusof1tHB5iV7mFtylChJ1Hu4KjY90cDvGNGHJ3nQr7+JPT+J+uj5VVZdGLX5BRB6j6RVKuzM2P26ijYZWKydIVb/oSdsx6cuGcUx3+ybuWieXxyR6ANRdhbBDvyKMDHmIyJkislTcXLlviciEFup9hrsGycHessNFZK64uUq3isgfxc0hHL3+d8XNnVotIs8Q5zrw8YZfxM3h+5q4eV8rxM0RO1lEHgHOBo6SnXOgzmxhO83OmxzTvhNE5GMvzrdEJPaCdCYNWLI33e1qYImqtmW2qPbYHXdpgVtwc4v2xV3ZNPYytcW4i2/9GnehsZUichjukribcFdPvMpb9nBkJRGZhpssYzbuip6f4Ob6bZE3nj8HN4fCN3EX4HsTN3vTLbirWi7AXQjrENy8uvG2cyLuV5cf4S7ZfA/u6pb3xlQdibua5S9xV3odhJsRLXYmJ5PibBjHdBsR2R13+ejru2F3A3FXPXzH2/d84AvclQofjKo3ADheVRdGxfl34B1VPT+qbD0wR0QmquqnuEs/v6Cq3/GqvChuFqH/aSWuX+MmgTlJd/58/YWo/WwDfBp/RrNoN+OuvPrNyDa8/P1rEblVd16auz9wmLprvEeu5/8U7pLWu3yzMqnLevamO+3j/f20G/a1JZLoAVR1Ne565wfF1Fsfk+hzcT3q2PmA38L1xg/wxvYns+tcti3OxStuHtGDgb9oB65TIm2bN3lVJNF7Iteqb3E+YpN6LNmb7tTX+9ve+VXbIt48s1vYdVw9NpZC3HX276fpXKX1uGv0j8BdLz4QZx+tzW1biJsXoaPT/rVl3uTymDrdMfuU6YFsGMd0p0gyHNZaRRH5g/fvWNz8t9fhxpun45LtqfEO8EaJNw/rINxsVdFie9jlXtlM3ETPsTbgJocOxtlHa3PbluEmvmnvhN4RpXThvMkmNVnP3nSnd3EzEl0cb6GIHB51dxJulqXjcAdY7wE+UdWpuOGLePPeRhskIodGbXskbujjg5ZWUtVq4D1gT40/H/AGdfMWL2TXuWxbjMnb9vvARS0cIG2glV63Jj5vsjE7WM/edBtVrRKRnwAPiMh/cTPzlOB+XHUubg7Zw7yDiGOA41RVRUSB91T1eW9TPlrvvZbi5vT9Be5D42bcN4tHEgj1WtzB2DDwL9w0dyNxk3b/XFU/B34FPOlNQvEUbi7TrySw7Z/iflD2vLj5catxY+zzVHU27qDpNBE5Ezc95gZV3RBnO4nMm2zMDtazN91KVR/ETaLeH5d4n8WdMrga+KFXbU9ghapWeff3w02CTtT9j1vZ1WrcvKQzccmwEncGTF0CMb4FHIkbLnoMeAb3AbAWb1xcVZ8Cvg+cDvwHd8D2kgS2/QZwApCLm//0CdwHRSRB3w+8hDuN80PcvL3xtvMScAEwxYvvKtycsle0FoNJTzZ5ielxROSrwFGqerl3/2Hgv6r6H+/+BmBc1IdB7PqP4CanntI9ERvT81nP3vRE++HGxCMmR+6LyBCgurlEb4yJz3r2JuVYz96YXVmyN8aYNGDDOMYYkwZ67KmXAwcO1OLi4mSHYYwxvcr8+fNLVbUotrzHJvvi4mLmzbOJeYwxpi1EZHW8chvGMcaYNGDJ3hhj0oAle2OMSQOW7I0xJg1YsjfGmDRgyd4YY9KAJXtjjEkDKZfsr35iIWc/8A7rymqSHYoxxvQYPfZHVe31yfoKlm+poro+lOxQjDGmx0i5nn3A7wOUxqAle2OMiUi5ZP+/269iedZF+Cri/mLYGGPSUsolez9hMiQEdRXJDsUYY3qMlEv2Nb58AMK15ckNxBhjepCUS/Z1vjwApL4yyZEYY0zPkXLJvtbvevY+S/bGGLNDyiX7On8fwHr2xhgTLeWSff2Onr0doDXGmIiUS/YNAdez9zdsT3IkxhjTc6Rcsq/xevZbS7ckORJjjOk5Ui7Zv7mmHoCysq1JjsQYY3qOlEv228kFoAC7EJoxxkSkXLKv0WwAcqQ+yZEYY0zPkXLJvo5MALJpSHIkxhjTc6Rcsr9u2v6AJXtjjImWcsn+iAkjADeMEwyFkxyNMcb0DCmX7CXDHaDNoYHaRrumvTHGQAome7xkn009DUHr2RtjDKRisvdnEMRHpoSor7czcowxBlIx2YtQTxYAjfV2rr0xxkAqJnugXrxkX1ed5EiMMaZnSMlk3+Al+6Ale2OMAVI22btf0QZtGMcYY4AEk72ITBCROSJSIyIbRORmEfEnuhMR8YnIfBFRETmt/eEmpsHnevYhS/bGGANAoLUKIlIIvAIsBqYBo4E7cR8U1ye4n/8BdmtnjG0W9JJ9uMGGcYwxBhLr2V8O5ADTVfVlVX0QuAm4WkQKWlvZ+7D4JfDzDkXaBkGfG8axnr0xxjiJJPuTgRdVNXpS11m4D4CjElj/FuBtYE7bw2ufoD8HgHCDJXtjjIHEkv14YGl0gaquAWq8Zc0SkX2Bi4EftTfA9gj73JUvQ0G7GJoxxkBiyb4QKI9TXuYta8k9wH2quqKNcXWI+jMACAftF7TGGAMJHKD1aJwyaabcLRS5ANgTOD3RYETkUuBSgJEjRya62q58Ltmr9eyNMQZIrGdfBvSLU96X+D1+RCQDuB24DfCJSD8gcjA3T0T6xFtPVR9S1SmqOqWoqCiB0JoRcMM4YUv2xhgDJJbslxIzNi8iI4A8Ysbyo+QBw4G7cB8WZcAib9ksYEF7gk2Y30v2jZbsjTEGEhvGeR74sYj0UdXtXtn5QC0wt5l1qoBjYsqGAH8HrgNebUesifPG7AlZsjfGGEgs2T8IXAk8KSK3AaOAmcBd0adjisgKYK6qXqKqQeD16I2ISLH37yeq+n7HQ2+eeD17tWRvjDFAAsleVctE5DjgXuAZ3Dj93biEH7uthC+h0JV8Aa9nb2P2xhgDJHg2jqouBo5tpU5xK8tX4c7g6XK+gLtcgg3jGGOMk5JXvfRneAdoLdkbYwyQosk+I9NdG8fOszfGGCdFk31kGKcxuYEYY0wPkZrJPssle+vZG2OMk5LJPssbxpGwJXtjjIEUTfaZWS7Z+8I2jGOMMZCiyd7vnXrp12CSIzHGmJ4hJZO9eKdeBizZG2MMkKLJPuD17APYMI4xxkCKJnuf9eyNMaaJlEz2/h09+yCqzc6vYowxaSMlk32kZ59JkLDlemOMSc1kH5m8JIMgwXA4ycEYY0zypWiyd5c4ziBIyLr2xhiTqsne69lLkMaQJXtjjEnNZO9zPftM69kbYwyQqsneG8YJELIxe2OMIVWTvc9NwBUgRNCGcYwxJvWTvQ3jGGNMqib7JsM4luyNMSY1k32kZy9hQqFQkoMxxpjkS81kL0LIa1pjo10MzRhjUjPZA0Fc7z5s89AaY0zqJvuQ+N3foCV7Y4xJ3WSPl+wbbR5aY4xJ3WQvNoxjjDERKZvsw17PPmzDOMYYk7rJ3nr2xhizU8om+/COA7Q2Zm+MMSmc7CM9e5uH1hhjEkr2IjJBROaISI2IbBCRm0W8rnPz6+wtIi949etFZI2I/J+IDO2c0FsWGcZRG7M3xhjvl0ctEJFC4BVgMTANGA3cifuguL6FVfsCK4FHgQ3AHsCNwAEicqCqdmmXOzKMYz17Y4xJINkDlwM5wHRVrQReFpECYKaI/NYr24WqvgO8E1X0uoisA14C9gU+6ljoLdPIMI6N2RtjTELDOCcDL8Yk9Vm4D4Cj2ri/rd7fzDau12aRMXu1s3GMMSahZD8eWBpdoKprgBpvWYtExCcimSKyJ/Ab4EPgg3bE2ibqc8M4GrZhHGOMSSTZFwLlccrLvGWteQ6ox31g9AdOU9W4cwWKyKUiMk9E5pWUlCSw6ebt6NnbMI4xxiR86mW8GUCkmfJY3wemAt8A8oHnRSQ77k5UH1LVKao6paioKMHQ4gv7bBjHGGMiEjlAWwb0i1Pel/g9/iZUdbn37/si8ibuDJ2vAX9OLMR2ivTsbRjHGGMS6tkvJWZsXkRGAHnEjOW3RlVXA9uAUW1Zrz0iPXvs1EtjjEko2T8PnCQifaLKzgdqgblt2Zl3kHYArnffpdSGcYwxZodEhnEeBK4EnhSR23C98pnAXdGnY4rICmCuql7i3b8DCALv44Z79gKuBb7AnbrZtWwYxxhjdmg12atqmYgcB9wLPINL3HfjEn7stqIvoTAPd3D2UiAbWAP8G/i1qlZ3NPDWqD8DALGevTHGJNSzR1UXA8e2Uqc45v4suqMH3wwVO8/eGGMiUvaql/hczx7r2RtjTAone7/3pcV69sYYk8LJ3jsbRyzZG2NM6iZ79YZxbMzeGGNSONmLN4zjC9uYvTHGpGyy10AOAMNrFoMmcgkfY4xJXSmb7MOBXAAmVL0Hq95McjTGGJNcKZvsNSNnx/+VX7xHKGy9e2NM+krZZC++nb8Xe+C1Lzjyt69RHwwlMSJjjEmelE32AXYm9j5Sw/ryWpZu3J7EiIwxJnlSONnvPOXyu4GnGS9rEHH356/exuqtXX55HmOM6TFSNtnX9W16yfz7Mn6PT4S122o4+4F3Oer213csm7+6jHtfXU64mXH99eW1PPL2SuoabRjIGNM7JXQhtN6oathhPBI8kRmBlwAY7dtI8M/jeb5hXy72j2VxuBi2jmf2yjBX/OtzAHYfkMfp+w0D4B/z1jK8MIdDRw9k2r1vUVrVwLbqBq4+cc9kNckYY9otZZP99voQtwUv4Bz/G+RLHQCBUA2n+9/jdP97rtI9t3AacEJWgGqyqX91LKyZRGnOHrzwaiVvhyey7DdnUVrlJi1fsLY8OY0xxpgOStlk3yc7QC3ZnFj/W7KlgQN8nzNcSqnVTPaQTYzxrWcQ5QyScrKkkSyqoGIBzF/AQODPmVCpOfCP/3Chv5CPwmPxSccmQTfGmGRJ2WR/yKgBfGPq7jz2HqDwZWhYMzWVfGrJp5Yxvg2MlXWMlfVM8n3BBN9qWPwfbvWuljxn2+lQew/kFHZXM4wxplOI9tBLCUyZMkXnzZvXoW18WVLFsXe2aZrcJkbIZo71LWSa/232960AoNJfSPbBM8ic/DUoGteh+IwxprOJyHxVnRJbnrJn4wBkZ/hbr9SCtTqYv4ROYnrDzZxRfwsfhsdRECoj85274a/TIWRX1DTG9A4pnewDPum0bX2sozmv4QZuaPymK6hYC7Ov6rTtG2NMV0rpZD8gP4vRRXmdtj3Fx6Ohkzi7/kZqNRMWPAaLkjbNrjHGJCylk73fJ7x41ZG8ee0xcZf/7dsHM+PQ4iZlVx47hlmXTmX6/rsBcOo+Q3dZb77uyY1B18MPPfNDKF3euYEbY0wnS+kDtNFeXbqZZxZt5NfT92FrdQPD+mYjIpRW1TPl1lcA+PFJe/K9Y8bsWCccVnw+4cq/L+DpRRtitqj8PuM+pvnfoXHwfmRc+urOeW+NMSZJmjtAmzbJvjVbKuso6pOFyK7j/D9/6hMef3/NLuX51PBC1k8ZLqWUFOxN0beegH4juiNcY4yJKy3PxmmLQQXZcRM9wJXHjeWg4v7sObjPjrKC7ABV5PLTxm8DUFT5GXrvgd0SqzHGtJWNOyRgcEE2/7j8ELbXNXL9fz7l3ANGMHVUf8b8/HneCu/DmnARI30lSLAWasvsR1fGmB7HevZt0Cc7g99fMJnDxw4k4Pdx4+kTADinYebOSpsXJyc4Y4xpgSX7DoicybOFQh4PHgfAgtn3JzEiY4yJz5J9B4gIfbLcSNjDoZMIqTC5dDbhT59KcmTGGNOUJfsOevbKI5h5+gRu/fY5/Cr4dQDCb9yR5KiMMaaphJK9iEwQkTkiUiMiG0TkZhFp8cIzInKgiDwsIiu89ZaJyI0ikt05ofcMIwfkMuOwPZg6agCzQu7HW+EtyyBss1oZY3qOVpO9iBQCrwAKTANuBq4Bbmpl1fOB0cBtwCnAfcDVwOMdiLdHO2LvPdig/cmkkcZXbk12OMYYs0MiPfvLgRxguqq+rKoP4hL91SJS0MJ6t6nqkar6R1V9XVX/F/gxMF1Edu946D3P3edP4iXfEQBkvHMX28u3JjkiY4xxEkn2JwMvqmplVNks3AfAUc2tpKolcYoXeH8HJRxhL5KT6admyvd23P/7E39NYjTGGLNTIsl+PLA0ukBV1wA13rK2OBQIA8vauF6vcfoh+3BH47kA5K1t/8QpxhjTmRJJ9oVAeZzyMm9ZQkRkCPBz4LGYbwkpZWjfbN4I7wvAsYFF0EOvPWSMSS+JnnoZL2NJM+W7VhTJBP4BVAE/bKHepSIyT0TmlZTEGwXq+QJ+H9d/+2uUagFDKeWpl15JdkjGGJNQsi8D+sUp70v8Hn8T4q4u9iiwN3CKqpY1V1dVH1LVKao6paioKIHQeqaDRg3k9fAkAJa98a/kBmOMMSSW7JcSMzYvIiOAPGLG8ptxN+6UzWmqmkj9lLB5sDt2fYx/IbM/jr0WvjHGdK9Ekv3zwEki0ieq7HygFmjxCKSI/Az4PnChqr7V7ih7oRkXfQuAg31Lef+J25IcjTEm3SWS7B8E6oEnReR4EbkUmAncFX2g1ful7J+i7n8N+BVuCGe9iEyNuvXeMZoE5RX0Z50OBGC6/y3qg/aLWmNM8rSa7L0x9uMAP/AM7gdVdwM3xlQNeHUiTvT+zgDejbmd2pGge4uLG64FYIKsZuWaXWe6MsaY7pLQ5CWquhg4tpU6xTH3Z+ASfdo6/NDDWfjhaCb5vqB+/acwao9kh2SMSVN21csudMNpE6jOHQ7A/I8/SXI0xph0Zsm+C4kIS+r6A5C98YMkR2OMSWeW7LvYXsdeCMDhvk9R+zWtMSZJLNl3scMOO5o6MhnpK+HjFauTHY4xJk1Zsu9q/gBbcscAsHHJe0kOxhiTrizZd4Pt/fcBYN2nb7C9rjHJ0Rhj0pEl+24wYC936YTRtZ9y3J122WNjTPezZN8Nhkx0yf4A33JKttcmORpjTDqyZN8d+g5nvQ6gQGoYJ+uSHY0xJg1Zsu8m88PjAJji+zzJkRhj0pEl+27ySdhdKmGMrE9yJMaYdGTJvptMO3oqAMOlNMmRGGPSkSX7bjJ+wiQAJvpWomG73LExpntZsu8mgWH7sk4HMlS20bjq3WSHY4xJM5bsu4sIc0P7AbBs4dtJDsYYk24s2Xej9d7MVWtXLk9yJMaYdGPJvhudfPiBAPSttwnIjTHdy5J9Nxo2dpL727AyuYEYY9KOJftuVDhyIgAjdBNVtfVJjsYYk04s2XcjX2YOFdKHgITZsMEum2CM6T6W7LvZ9oA7SLtuzZdJjsQYk04s2XezUN5gAB59+X1CYZum0BjTPSzZdzPtMwSAwVLOko2VSY7GGJMuLNl3s2Cu69kPpoyg9eyNMd3Ekn03y+6/GwBDZBsVtTZFoTGme1iy72bDdx8LuGRfacneGNNNLNl3t4JhAAyXEuvZG2O6jSX77jZwHGF87CGbqKquSnY0xpg0Ycm+u2Xmsj17GBkSQirWJDsaY0yasGSfBHU57owcX9WmJEdijEkXCSV7EZkgInNEpEZENojIzSLib2WdTBG5XUTeFJFaEbHzDD2Nee5c+8zqjUmOxBiTLlpN9iJSCLwCKDANuBm4BriplVVzgf8BaoB3OhZmihniLog2suy9JAdijEkXifTsLwdygOmq+rKqPohL9FeLSEFzK6lqOdBfVU8CnuqMYFPFgH2+AsCI+hU0BMNJjsYYkw4SSfYnAy+qavRv+2fhPgCOamlFVbWhmzhyhu1FGKGYjSzfVJbscIwxaSCRZD8eWBpdoKprcMMz47siqJSXkUOlv5CAhNmywc7IMcZ0vUSSfSFQHqe8zFvWaUTkUhGZJyLzSkpKOnPTPc72zEEANGxbm+RIjDHpINFTL+MNx0gz5e2mqg+p6hRVnVJUVNSZm+5xtueOBCCjdHGSIzHGpINEkn0Z0C9OeV/i9/hNAqoG7APAsE2vJTkSY0w6SCTZLyVmbF5ERgB5xIzlm8QNHFYMwPiq9+Cjx5IbjDEm5SWS7J8HThKRPlFl5wO1wNwuiSoNDB02csf/Va/8JomRGGPSQSLJ/kGgHnhSRI4XkUuBmcBd0adjisgKEflT9IoicrKInANM8u6f491276wG9FY5/Ybs+H+9XQ/NGNPFAq1VUNUyETkOuBd4BjdOfzcu4cduK/YSCg8A0Yn9n97fi4FH2hxtKiks3vHvnr51hENhfH67VJExpmu0muwBVHUxcGwrdYoTKTOejOwmd6vKN1MwYGiSgjHGpDrrSibR3Y1n7/i/ZvPKJEZijEl1luyTaPw+U3b8X1dqyd4Y03Us2SfRV867jAYyAAhttWRvjOk6luyTSHx+Xhj6XQAaSlclNxhjTEqzZJ9kBUNHu3/KVyU1DmNMarNkn2TDit2Pk/NqNiQ5EmNMKrNkn2TFY/YCYHB4C5W19UmOxhiTqizZJ1lmbgEVUkCWNLJ8mV0B0xjTNSzZ9wCleeMAqFz4NBvKa5McjTEmFVmy7wG2jzgagGNW3cUDd1zHurKa5AZkjEk5lux7gD32GL3j/1sCf2bZepuX1hjTuSzZ9wB9d9uzyf2qzV8kKRJjTKqyZN8TDNsfhuyz427VF+/SGAonMSBjTKqxZN8TiMBlb1Jf5BL+1zf8ikt+8Rv+9Nw7fPv+55m3aluSAzTG9Hai2qlzhneaKVOm6Lx585IdRvfauAj+cGSTohrNYmL9nygqyOHWM/fhhAmDdywLhsI88s4qjhpXxNjBfWK3ZoxJQyIyX1WnxJZbz74nGbof/939+iZFuVLPkqyLGbx9Md9+9ENWrF5DqMGdnjnrw7Xc+uwSTrj7jWREa4zpRaxn38PUNYb4/Z/+woUbb2U32dpkWb0GyJIgAL9onMHs0FTKKNixfMahxcw8Y+9ujdcY07M017O3ZN+ThYK8+8LjHPLhlS1WezZ0EGt0MJu1kOAB3+L60/dlfXkt2+uCTBrRr3tiNcb0CM0l+4SmJTRJ4g9wyKnf5Psfb2e/6reY6lvCRN+qXaqd6v9g552PH2XZwuHMDe/H86GDGLP/Mdx+7n4ArCqtZvmWKqaO6k+f7IxuaoQxpiewnn0voKq8sbyUicMKWFdWyw0PPs65MocLA3NaXXdtuIhG/HyuI1ilg9ldNhMIBJh88iXM/bKC/pPO4Og9ixCRJuuVVtVT1xhieGFuVzXLGNMFbBgnBS3eUMm81ds4Z3wWufmF8M49rNlWRcHCP9JPqhPezjbN58rG7zN6vyO4+oyDyAr4GP+LFwD47KaTyMuyL4DG9BaW7NNIXWOI4++aS7hsLef1XcyZMpfiuiWtr6cZVJDHOi3iw/B4ngodxuH7juPIjCUcedZl4Avs8g3ApJgtS+HDP8Kxv4CcfsmOxrSDJfs0VB8Mken3ISLUNzbyzkcfc98LC8jvV8TvTh3K+jcfZe/VjyW8vRLty2yO4Mt9fshFR+zJ8C/+xsa3HmfO+Jv55ilHkhmwM3l7vZl93d+jr4Ojf5LcWEy7WLI3ANQ2hBCB7Aw/4L4FbCir5t5XVxD45G98x/80hVLVpmGgiG82/ITNmbvzxytOZ8TAgtZXMD1PJNkDTP8j7Hte8mIx7WLJ3rQoHFbe+WIrB+5RyLkPvsuSdVtpxM8vJtXy2RerOa7uxaZn/bRgi/Zjgw5gQ9ER9Bk2Dh17AgeM24PqhhCFeZlk+H2RnULtNsgb2IUtMwkLNsCtRU3LZlYkJxbTbpbsTcJCYeW2F5ZyxNiBHDF255u/MRhiyZrNfPbWfxlSu4LaylI2V9RyceDFhLa7LDycIH6qySU0bH8O2fQ4ANukH+Grl9F/3Rwa3vxfss5+ABkwqkvaZlpQuRHuGt+0zJJ9r2PJ3nSpu17+nNdffYFy8rlqt2VML32wTeuvCA9jjG/npOvvD/kaI/aczNBJJ1FRUU5Oho93lm9m9/EHMGpIYWeHn1x1leDzQ2ZecuPY9Ak8eHjTMkv2vY4le9Ol6oMhLvrTBxw8agBXnzAOVFm5tYZFH73HiKpP2Lbgv4TxsVH7MyPwUof2dUfwfI4461IGayn9++SROXQC6+qyKMgOMKggu/0bDgUBBX83/uAs2AB3jIHcgXDlR1BXAStegdHHueTfnbF88Ro8dmaTom0/LqF/Xmbbt7VlKdSUQvHhrdc1ncqSvUmq2oYQAb+48fpgA/Xl68nMK6RRMpnz4NVMKXuWIqns0D6WhEdQRxYZg8bC1O/Sr28Btc9ex9jyt3fUebfgK4ybcT9VtQ0U9O1PYX4WbFnKZgaQ989zyS9ZwLZ+E5k38hKOPv0iAn89gzB+AjOedpeiDoehtgzyBjQbx0efr+L1T1Zz2WmHtfobhcblr5Px+DQANlzyEUPn/gRZ8TIAOvJQ5OLn3H67gX78T+TJ/2lStip/MuGzHmLU6HGJb2jDAnjoaABKLppL0ahJ7Yqnsq6R9WW17DXUDva3RYeSvYhMAO4BDgHKgf8DblLVUCvr9QV+B5yJu8LmbOBKVd3awmqAJfu0pAreaaIVW9bR58vn2PbJS2xozCMzO4/3Gvbgwm33EgqHKZDkTsz+Qd7R5E35Kn2GT2DY8D0ISgaBms1seeQbDKtcBMCvc3/MNT/4MZlZWYQbG/AFMiibdRnZq18ncMlzZBSNYfldX2Fs5bvN7mfl1F9SPPUMqhc+SXi3gygongwZOQQrt9Dwr2/TWLGZVQOPYuyJl5E72DvOUV8Fn/6LcP5QwrkDkAFj8H/wB5gwDQaNj7ufhmCY5x78CWeWPsTc8H4c5VvUNI4p17N8exaHn/1dcjOb+QBThdLlcN+BO4pe73c2R1/15zY8sp5wmBW/PYIxdZ+yKm9fir/zJOQXtb6eaX+yF5FC4DNgMXAbMBq4E7hbVa9vZd0XgD2BHwFhb/3NqnpEawFbsjfNUVW2rPmcLVu3UsxGqirLKfnkZQJblzKBlckOL6ne9k3hsHDz75vS3DEs2vsn7L5yFh/UDKFo8mkU59bzx3fW89OqX9NfqnhkwA+ZsfXuuOsvCY/Ed/JtDNlrKg1hIa9mPTmDR/Px7PvZb9HNze63JmcI5VJIWd+9GHjoN8goXULjqvfIP/2X5PbfjcZgiAUv/oXsii+ZeN4NVL/5AAVv3tRkG2v2v5aRJ14B2X2b2YuBjiX7nwHXAruraqVXdi0wExgSKYuz3iHAO8BRqvqGV3YQ8D5wgqq+0tJ+LdmbjqquqaW6vp5++flkZgRAFS1fzfIlCxnWvx+VJWvZNv/fFARCNB52Dbl1mxnaL5fG8g2E5t5Bdt0WZudNZ5+8csrLtrFn4xKyqafKV0B+uPkhp1dDk5icW0Jh/fqE4qyRPPyEyNI6AKokH/qNIL+s9V89d7YQPrb/4Av63r830ljToW0tyZjAXo2LOymynT7IPpSMrDwyMgL4Gqvxh2rZSj8a1Ud+BqBhlm9tZPcCH9k16ykL5VAUqCUjt4Ct2btDVj6+YC396tZTUL2KLK1jccERFFcvojZzABV5xZSE+zAsz8fq8gby83PpkxVgU0UdA3PcN88+BX0pLask2FBLn7792VRSypg9RhEMQ8Av1AfD5GQGUFUq6kLUBiFHGtlcUcuwftlk+ODzTRXk+0MMHz6crKwcQMFLxwXFkxg96ciWHoZmdSTZvwFsUNULospGAquBM1T1mWbWuxm4VFWHxJR/CTylqte0tF9L9qZHqi2HzHyoLoHMPCoafWxb/QnrKxrZbdhQMvsOYVhhPhJqpGHJszRu/pyaARMpDeexecEL7D50EPn1m1heLkh9BTrsAA449Vtk1pawNZRDYeXn+IftB4FMQms+4POFb6Pla8gdMg7/qrkEakuoDhTS2G8P+kw+m0HB9Wwq2Ubmp7NorCmnVjOQviPIKT6ATdUwqGEt2Rs/ZE7W8Rxc8xqj6pom3w3an1rNotJXwLC+OQw++Fw49ArYvgmqtlC/9EXqGxrI7DOQ4Ny7yK/flNDD1PiN2UjxYdTcMZGC2qYferWaSY40tLqNRVlTmDAAMjakXx54d+hFHHLZPe1atyPJfgtwv6rOjCmvBmaq6u3NrPcPYJCqHh1T/iyAqp7a0n4t2RvTBbzjItHCYcXnS/wgsAYbWFcZpL4xSL6/ga2lpRQP6kteTg5kFYAv6rIZqhAOoT4/UlfuyvxZBPGzvUEpX7WQ2urtDNl9Tyq3V5IdELas/5KBw0YzdI+93LWY6qsgWE/156+zcmMJG8uq8ddtw5+VB+EQ+Y0lLK0poG9eDn21kspQJmV1Sm5eHhVlpSytG8jUsUPIqviCTL+QrbWQkUNGRgbUb6d2ezkbQwX0zYTCHD/BYJDKqiokM4/q2lpyfCFC6trSJyNEaZ2P3IBSVu8nO0PICddQW1dH37xsfD4h0+8jklfDqvg0zLaqWrKzMtlY5R7r/OxMttYEUXxMLAzhl/DOx0x8+MedwEGnfqtdT3FHrmdfiDsoG6vMW9ae9ewXM8YkQ5wze9qS6AEkkMmI/jtPxxwysIVfQIuAP4AA5OxMFwGgMBMKJ07dUdbfGwMYskfMbGtZ+ZCVT97ks5k4GSbG2c0BbWpBekr0ylXxuv/STHm71xORS0VknojMKykpSTA0Y4wxrUkk2ZcB/eKU9yV+z7219fo1t56qPqSqU1R1SlGRnWZljDGdJZFkvxRocnKuiIwA8rxlCa/nGd/KesYYYzpZIsn+eeAkEekTVXY+UAvMbWW9ISKy4/fSIjIFN17/fDtiNcYY006JJPsHgXrgSRE5XkQuxZ1jf1f0OfYiskJE/hS5r6rvAi8Cj4rIdBE5E3gceKu1c+yNMcZ0rlaTvaqWAccBfuAZ4CbgbuDGmKoBr060C3C9/z8DjwLzgbM6FrIxxpi2SmgmaVVdDBzbSp3iOGXlwMXezRhjTJLYpKHGGJMGeuwljkWkBHdJhvYYCJR2Yjg9lbUztaRLOyF92pqMdu6uqrucu95jk31HiMi8eD8XTjXWztSSLu2E9GlrT2qnDeMYY0wasGRvjDFpIFWT/UPJDqCbWDtTS7q0E9KnrT2mnSk5Zm+MMaapVO3ZG2OMiZIyyV5EJojIHBGpEZENInKziMT+orfHEpFzReRpEVkvIlUiMl9EvhpTR0TkOhFZKyK1IvKGiEyKs61e81iIyG5ee1VE8qPKe31bRSQgIj8VkeUiUi8i60Tk7pg6qdDOC0TkI+95XC8ij4rIsJg6vaqdIjJGRP4gIotEJCQir8ep02ltSnRbHaKqvf6GmyhlA/AKcAJwOVAN3Jrs2NrQhneBvwHn4X6tfAfuuv/fj6rzM9wF6K4Ajgeew53DO6S3PhZemzd5bc1PpbYCj3nxXQYcBVwI/CqmTq9uJ3CG99zdi7usyoXAKuAjwNdb2wlMA9YC/wSWAK/HqdNpbUpkWx1uU7JfLJ30xPwMd/38gqiya4Ga6LKefAMGxin7G7DS+z8bqABuiFqeB5REv3B602MBHAFsA35EVLJPhbYCXwEagQkt1EmFds4C5seURT4A9uqt7aTpB9W/YpN9Z7Yp0W119JYqwzgnAy9q1FU4cS/CHFyPqsdT1Xi/slsADPL+PxQoAP4RtU417uJ0J0et0yseC+9r7D3Azez6C8NUaOu3gFfVXVeqOanQzgxcoopW7v2NzHfY69qpquFWqnRmmxLdVoekSrLfZUIUVV2D+/SMN4FKb3EoEEkW44EQsDymzhKatrG3PBaX43o098VZlgptPRj4XETuFZFKb7z2yZix7FRo55+BI0TkIhEpEJFxwK3Aa1EfdKnQzlid2aZEt9UhqZLs2zspeo8lIsfhxg0jybAQqFLVUEzVMiBXRDKj6pXH2WSPeSxEZABwC3C1qjbGqZIKbR0CzAAm4S71fTFuXuynRHbM+t3r26mqz+La+RCuh78Md6nz6VHVen074+jMNiW6rQ5J6BLHvUR7J0XvcUSkGDde/19VfSRqUXNtjF3W0x+LXwLvq+pzLdTp7W0V7zZNVbcCiMhG3PwOxwJzvHq9up0icgxugqPf42agG4yb3OgpETk+KoH16nY2ozPblOi22i1Vkn17J0XvcUSkP+5NswZ3ZkNEGdBHRPwxPYB+QE1UD7lHPxYisjduPPtIEennFed6f/uKSIjUaGsZ8GUk0XveAhqACbhknwrtvBN4WlV/EikQkYW4oYtpwJOkRjtjdWabEt1Wh6TKME57J0XvUUQkF5gNZAKnegdpIpbivh6PiVktdkywpz8WY3EH9d7FvcjL2DlUtQ530DYV2rqkmXIBIgf/UqGd44GF0QWqugx3GuForygV2hmrM9uU6LY6JFWSfXsnRe8xRCSAO6d3LHCyqm6JqfIOUAmcG7VOLnA6TSdw7+mPxVvAMTG327xlpwC3kxptnQ3sKyIDo8qOxH3QLfLup0I7VwP7RxeIyF64s01WeUWp0M5YndmmRLfVMd157mpX3XAHODYCL+N+kHApUEUP+NFJG9rwEG5s7kpgaswtS3ees1sDfA/3A5ZncactDu7NjwXuAN+O8+xToa24U+nW4L7BnA58DfcjnZdj6vX2dv4A903lTi+2r+MO0q4E8nprO3FDi+d4t3eBz6Lu53Z2mxLZVofblOwXSyc+OROAV3GfmBtxZ3v4kx1XG+Jf5SW8eLdir44AP8cNd9QCbwKTe/tjQfxk3+vbivta/hzuF5NlwCNAYUydXt1OL/7vAB977VwPPAGM6s3tBIq78/2Y6LY6crOrXhpjTBpIlTF7Y4wxLbBkb4wxacCSvTHGpAFL9sYYkwYs2RtjTBqwZG+MMWnAkr1JaSIyU9yUh/FuF7a+hU6PR0Xkiu7erzGpciE0Y1pSgZs5KtaK7g7EmGSxZG/SQVBV30t2EMYkkw3jmLQmIsXe0MrXROQxEdkuIltE5MY4dY8VkfdFpE5ENovI/SKSH1NngIj8QUQ2evWWichVMZvyi8ivRKTE29d9IpLVle00xnr2Ji14VxVtQlWDUXdvx12p8hzc1SlvFJFSVb3PW38C8ALuglZnAyOA3wCj8IaIRCQHeB03b/BNuMvTjmHXS9deg7tWyoXAvsCvcVeP/G3HW2pMfHZtHJPSRGQmsEsv3bOH93cl7mqUJ0at90fcJZdHqGpYRGbhphUcr94EEyJyHu6iX4eq6rsichnwALC/qi5sJh4F3lTVI6PK/gMMUdWp7W6oMa2wYRyTDiqAA+PcNkTVeSpmnSeBYcBw7/5BwFPadCahfwNB4HDv/rHAguYSfZSXYu4vjtqPMV3ChnFMOgiq6rx4C3bO/U3sZDGR+0Nx16UfCmyOrqCqIRHZCvT3igbgLmHbmvKY+w1AdgLrGdNu1rM3xhnUzP2NUX+b1BERPy7Bb/OKtuI+FIzpcSzZG+OcFXN/Oi7Br/Puvw+c5SX46DoB3FSL4CYRnywi+3ZloMa0hw3jmHQQEJF4Bz/XRv2/t4j8ATcOfyRwCfADVY1MDn4rsAD4j4g8gBtjvw14UVXf9eo8iptW7iXvwPAy3EHgcar6005ukzFtYsnepIO+uHlEY/0C+Kv3/7XAabhkX4ebOu7eSEVV/UxETgZ+hTt4Wwn83VsvUqdORI7FnZJ5M24e2lXA/Z3bHGPazk69NGlNRIpxp16erqqzkxyOMV3GxuyNMSYNWLI3xpg0YMM4xhiTBqxnb4wxacCSvTHGpAFL9sYYkwYs2RtjTBqwZG+MMWnAkr0xxqSB/wcf50+7Oqo+QwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.plot(hist['val_rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error, optimal settings\\n$C_m$ prediction', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2, label='Training RMSE')\n",
    "plt.plot(hist['val_loss'], lw=2, label='Validation RMSE')\n",
    "plt.title('Root Mean Squared Error\\nAeroCNN-I, optimal settings\\n$C_m$ prediction', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "saveName = \"RMSE_test\"+str(test_rate) + \".jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c76ae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 8ms/step - loss: 1.5596e-04 - rmse: 0.0057\n"
     ]
    }
   ],
   "source": [
    "train_results = model.evaluate([x_time_train, x_coord_train], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b1d836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5704e-04 - rmse: 0.0058\n"
     ]
    }
   ],
   "source": [
    "val_results = model.evaluate([x_time_val, x_coord_val], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abc70d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 1.5514e-04 - rmse: 0.0056\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate([x_time_test, x_coord_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "745feda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "decoded_train_ = model.predict([x_time_train, x_coord_train])\n",
    "decoded_val_ = model.predict([x_time_val, x_coord_val])\n",
    "decoded_test_ = model.predict([x_time_test, x_coord_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51faee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_index(y_total, y_partial):\n",
    "    return np.unique(np.where(np.isin(y_total, y_partial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e8e16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_absolute(y_pred, y_true):\n",
    "    return np.abs(y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aee7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize \n",
    "def denormalize(y):\n",
    "    return y*(np.max(cm)-np.min(cm))+np.min(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "946bb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_error(y_pred, y_real):\n",
    "    return np.sqrt(np.sum((y_pred - y_real)**2) / np.sum(y_real**2))\n",
    "\n",
    "def mape(y_pred, y_real):\n",
    "    return 100/len(y_real) * np.sum(np.abs((y_real-y_pred)/y_real))\n",
    "\n",
    "def smape(y_pred, y_real):\n",
    "    return 100*np.sum(np.abs(y_pred-y_real))/np.sum(y_real + y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb958632",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = define_index(y, y_train)\n",
    "index_val = define_index(y, y_val)\n",
    "index_test = define_index(y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012284900653642003\n",
      "0.4967495731959914\n"
     ]
    }
   ],
   "source": [
    "l2_error_train = l2_error(decoded_train_, y_train)\n",
    "mape_train = smape(decoded_train_, y_train)\n",
    "print(l2_error_train)\n",
    "print(mape_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c63ffb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012260955203812802\n",
      "0.48135712914146367\n"
     ]
    }
   ],
   "source": [
    "l2_error_val = l2_error(decoded_val_, y_val)\n",
    "mape_val= smape(decoded_val_, y_val)\n",
    "print(l2_error_val)\n",
    "print(mape_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3770434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012316242180031516\n",
      "0.5085792850960973\n"
     ]
    }
   ],
   "source": [
    "l2_error_test = l2_error(decoded_test_, y_test)\n",
    "mape_test= smape(decoded_test_, y_test)\n",
    "print(l2_error_test)\n",
    "print(mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "945ad132",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = denormalize(y_train)\n",
    "y_val = denormalize(y_val)\n",
    "y_test = denormalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93ca4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = denormalize(decoded_train_)\n",
    "decoded_val = denormalize(decoded_val_)\n",
    "decoded_test = denormalize(decoded_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55d01da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"D:\\\\TrainedModels\\\\20230102\"\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "os.chdir(model_directory)\n",
    "model_name = \"20221230unsteady_AeroCNN1_Case15_val_\"+str(val_rate)+\"_test\"+str(test_rate)+ \"_\" + str(n_kernels)+\"kernels_\" + str(n_layers) +\"layers_\"+str(n_units)+\"units_CmPrediction.h5\"\n",
    "model.save(model_name, overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = error_absolute(decoded_train, y_train)\n",
    "error_val_abs = error_absolute(decoded_val, y_val)\n",
    "error_test_abs = error_absolute(decoded_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e21d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(x_time_train)):\n",
    "    l2_error_train_data = l2_error(decoded_train[i], y_train[i])\n",
    "    l2_error_train_list.append(l2_error_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "053a1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val_list = []\n",
    "for i in range(0, len(x_time_val)):\n",
    "    l2_error_val_data = l2_error(decoded_val[i], y_val[i])\n",
    "    l2_error_val_list.append(l2_error_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(x_time_test)):\n",
    "    l2_error_test_data = l2_error(decoded_test[i], y_test[i])\n",
    "    l2_error_test_list.append(l2_error_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e5afbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_train_list = []\n",
    "for i in range(0, len(x_time_train)):\n",
    "    mape_train_data = smape(decoded_train[i], y_train[i])\n",
    "    mape_train_list.append(mape_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fa71fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_val_list = []\n",
    "for i in range(0, len(x_time_val)):\n",
    "    mape_val_data = smape(decoded_val[i], y_val[i])\n",
    "    mape_val_list.append(mape_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2f0fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_test_list = []\n",
    "for i in range(0, len(x_time_test)):\n",
    "    mape_test_data = smape(decoded_test[i], y_test[i])\n",
    "    mape_test_list.append(mape_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7f75a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_plot(y_pred, y_real, dataset=\"train\"):\n",
    "    dictionary_name = {\"train\":\"training\", \"val\":\"validation\", \"test\":\"test\"}\n",
    "    dictionary_data = {\"train\":l2_error_train_list, \"val\":l2_error_val_list, \"test\":l2_error_test_list}\n",
    "    dictionary_error = {\"train\":l2_error_train, \"val\":l2_error_val, \"test\":l2_error_test}\n",
    "    plot_title = '$L_2$ error norm distribution - MLP, unsteady, '+ dictionary_name.get(dataset) +'.\\nValidation rate {0}, test rate {1}, {2} layers, {3} units ($C_m$)'.format(\n",
    "        val_rate, test_rate, n_layers, n_units)\n",
    "    plt.plot(np.linspace(1,y_real.shape[0],y_real.shape[0]),\n",
    "             dictionary_error.get(dataset)*np.ones(y_real.shape[0],), 'k', lw=2.5)\n",
    "    plt.scatter(np.linspace(1, y_real.shape[0], y_real.shape[0]), dictionary_data.get(dataset), c='b')\n",
    "    plt.xlabel('Index', fontsize=15)\n",
    "    plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "    plt.yscale('log')\n",
    "    plt.title(plot_title, fontsize=15)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd795141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_plot(decoded_train, y_train, dataset=\"train\")\n",
    "saveName = \"trainingErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d10cf447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_plot(decoded_val, y_val, dataset=\"val\")\n",
    "saveName = \"validationErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_plot(decoded_test, y_test, dataset=\"test\")\n",
    "saveName = \"testErrorDistribution.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8978795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict([x_time, x_coord])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "714cd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tTrain = x_time[index_train] + 10\n",
    "tVal = x_time[index_val] + 10\n",
    "tTest = x_time[index_test] + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58d8635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.000313], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4a78a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012282986695125005\n"
     ]
    }
   ],
   "source": [
    "print(l2_error(predicted, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1d9be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each set of data in sorted order\n",
    "iTrain=[]\n",
    "iVal=[]\n",
    "iTest=[]\n",
    "for i, index in enumerate(index_train):\n",
    "    iTrain.append(y[index])\n",
    "for k , index in enumerate(index_val):\n",
    "    iVal.append(y[index])\n",
    "for j, index in enumerate(index_test):\n",
    "    iTest.append(y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ab1b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iTrain = np.array(iTrain)\n",
    "iVal = np.array(iVal)\n",
    "iTest = np.array(iTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f119a7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.   ],\n",
       "       [10.001],\n",
       "       [10.002],\n",
       "       [10.003],\n",
       "       [10.004],\n",
       "       [10.005],\n",
       "       [10.006],\n",
       "       [10.007],\n",
       "       [10.008],\n",
       "       [10.009],\n",
       "       [10.01 ],\n",
       "       [10.011],\n",
       "       [10.012],\n",
       "       [10.013],\n",
       "       [10.014],\n",
       "       [10.015],\n",
       "       [10.016],\n",
       "       [10.017],\n",
       "       [10.018],\n",
       "       [10.019],\n",
       "       [10.02 ],\n",
       "       [10.021],\n",
       "       [10.022],\n",
       "       [10.023],\n",
       "       [10.024],\n",
       "       [10.025],\n",
       "       [10.026],\n",
       "       [10.027],\n",
       "       [10.028],\n",
       "       [10.029],\n",
       "       [10.03 ],\n",
       "       [10.031],\n",
       "       [10.032],\n",
       "       [10.033],\n",
       "       [10.034],\n",
       "       [10.035],\n",
       "       [10.036],\n",
       "       [10.037],\n",
       "       [10.038],\n",
       "       [10.039],\n",
       "       [10.04 ],\n",
       "       [10.041],\n",
       "       [10.042],\n",
       "       [10.043],\n",
       "       [10.044],\n",
       "       [10.045],\n",
       "       [10.046],\n",
       "       [10.047],\n",
       "       [10.048],\n",
       "       [10.049],\n",
       "       [10.05 ],\n",
       "       [10.051],\n",
       "       [10.052],\n",
       "       [10.053],\n",
       "       [10.054],\n",
       "       [10.055],\n",
       "       [10.056],\n",
       "       [10.057],\n",
       "       [10.058],\n",
       "       [10.059],\n",
       "       [10.06 ],\n",
       "       [10.061],\n",
       "       [10.062],\n",
       "       [10.063],\n",
       "       [10.064],\n",
       "       [10.065],\n",
       "       [10.066],\n",
       "       [10.067],\n",
       "       [10.068],\n",
       "       [10.069],\n",
       "       [10.07 ],\n",
       "       [10.071],\n",
       "       [10.072],\n",
       "       [10.073],\n",
       "       [10.074],\n",
       "       [10.075],\n",
       "       [10.076],\n",
       "       [10.077],\n",
       "       [10.078],\n",
       "       [10.079],\n",
       "       [10.08 ],\n",
       "       [10.081],\n",
       "       [10.082],\n",
       "       [10.083],\n",
       "       [10.084],\n",
       "       [10.085],\n",
       "       [10.086],\n",
       "       [10.087],\n",
       "       [10.088],\n",
       "       [10.089],\n",
       "       [10.09 ],\n",
       "       [10.091],\n",
       "       [10.092],\n",
       "       [10.093],\n",
       "       [10.094],\n",
       "       [10.095],\n",
       "       [10.096],\n",
       "       [10.097],\n",
       "       [10.098],\n",
       "       [10.099],\n",
       "       [10.1  ],\n",
       "       [10.101],\n",
       "       [10.102],\n",
       "       [10.103],\n",
       "       [10.104],\n",
       "       [10.105],\n",
       "       [10.106],\n",
       "       [10.107],\n",
       "       [10.108],\n",
       "       [10.109],\n",
       "       [10.11 ],\n",
       "       [10.111],\n",
       "       [10.112],\n",
       "       [10.113],\n",
       "       [10.114],\n",
       "       [10.115],\n",
       "       [10.116],\n",
       "       [10.117],\n",
       "       [10.118],\n",
       "       [10.119],\n",
       "       [10.12 ],\n",
       "       [10.121],\n",
       "       [10.122],\n",
       "       [10.123],\n",
       "       [10.124],\n",
       "       [10.125],\n",
       "       [10.126],\n",
       "       [10.127],\n",
       "       [10.128],\n",
       "       [10.129],\n",
       "       [10.13 ],\n",
       "       [10.131],\n",
       "       [10.132],\n",
       "       [10.133],\n",
       "       [10.134],\n",
       "       [10.135],\n",
       "       [10.136],\n",
       "       [10.137],\n",
       "       [10.138],\n",
       "       [10.139],\n",
       "       [10.14 ],\n",
       "       [10.141],\n",
       "       [10.142],\n",
       "       [10.143],\n",
       "       [10.144],\n",
       "       [10.145],\n",
       "       [10.146],\n",
       "       [10.147],\n",
       "       [10.148],\n",
       "       [10.149],\n",
       "       [10.15 ],\n",
       "       [10.151],\n",
       "       [10.152],\n",
       "       [10.153],\n",
       "       [10.154],\n",
       "       [10.155],\n",
       "       [10.156],\n",
       "       [10.157],\n",
       "       [10.158],\n",
       "       [10.159],\n",
       "       [10.16 ],\n",
       "       [10.161],\n",
       "       [10.162],\n",
       "       [10.163],\n",
       "       [10.164],\n",
       "       [10.165],\n",
       "       [10.166],\n",
       "       [10.167],\n",
       "       [10.168],\n",
       "       [10.169],\n",
       "       [10.17 ],\n",
       "       [10.171],\n",
       "       [10.172],\n",
       "       [10.173],\n",
       "       [10.174],\n",
       "       [10.175],\n",
       "       [10.176],\n",
       "       [10.177],\n",
       "       [10.178],\n",
       "       [10.179],\n",
       "       [10.18 ],\n",
       "       [10.181],\n",
       "       [10.182],\n",
       "       [10.183],\n",
       "       [10.184],\n",
       "       [10.185],\n",
       "       [10.186],\n",
       "       [10.187],\n",
       "       [10.188],\n",
       "       [10.189],\n",
       "       [10.19 ],\n",
       "       [10.191],\n",
       "       [10.192],\n",
       "       [10.193],\n",
       "       [10.194],\n",
       "       [10.195],\n",
       "       [10.196],\n",
       "       [10.197],\n",
       "       [10.198],\n",
       "       [10.199],\n",
       "       [10.2  ],\n",
       "       [10.201],\n",
       "       [10.202],\n",
       "       [10.203],\n",
       "       [10.204],\n",
       "       [10.205],\n",
       "       [10.206],\n",
       "       [10.207],\n",
       "       [10.208],\n",
       "       [10.209],\n",
       "       [10.21 ],\n",
       "       [10.211],\n",
       "       [10.212],\n",
       "       [10.213],\n",
       "       [10.214],\n",
       "       [10.215],\n",
       "       [10.216],\n",
       "       [10.217],\n",
       "       [10.218],\n",
       "       [10.219],\n",
       "       [10.22 ],\n",
       "       [10.221],\n",
       "       [10.222],\n",
       "       [10.223],\n",
       "       [10.224],\n",
       "       [10.225],\n",
       "       [10.226],\n",
       "       [10.227],\n",
       "       [10.228],\n",
       "       [10.229],\n",
       "       [10.23 ],\n",
       "       [10.231],\n",
       "       [10.232],\n",
       "       [10.233],\n",
       "       [10.234],\n",
       "       [10.235],\n",
       "       [10.236],\n",
       "       [10.237],\n",
       "       [10.238],\n",
       "       [10.239],\n",
       "       [10.24 ],\n",
       "       [10.241],\n",
       "       [10.242],\n",
       "       [10.243],\n",
       "       [10.244],\n",
       "       [10.245],\n",
       "       [10.246],\n",
       "       [10.247],\n",
       "       [10.248],\n",
       "       [10.249],\n",
       "       [10.25 ],\n",
       "       [10.251],\n",
       "       [10.252],\n",
       "       [10.253],\n",
       "       [10.254],\n",
       "       [10.255],\n",
       "       [10.256],\n",
       "       [10.257],\n",
       "       [10.258],\n",
       "       [10.259],\n",
       "       [10.26 ],\n",
       "       [10.261],\n",
       "       [10.262],\n",
       "       [10.263],\n",
       "       [10.264],\n",
       "       [10.265],\n",
       "       [10.266],\n",
       "       [10.267],\n",
       "       [10.268],\n",
       "       [10.269],\n",
       "       [10.27 ],\n",
       "       [10.271],\n",
       "       [10.272],\n",
       "       [10.273],\n",
       "       [10.274],\n",
       "       [10.275],\n",
       "       [10.276],\n",
       "       [10.277],\n",
       "       [10.278],\n",
       "       [10.279],\n",
       "       [10.28 ],\n",
       "       [10.281],\n",
       "       [10.282],\n",
       "       [10.283],\n",
       "       [10.284],\n",
       "       [10.285],\n",
       "       [10.286],\n",
       "       [10.287],\n",
       "       [10.288],\n",
       "       [10.289],\n",
       "       [10.29 ],\n",
       "       [10.291],\n",
       "       [10.292],\n",
       "       [10.293],\n",
       "       [10.294],\n",
       "       [10.295],\n",
       "       [10.296],\n",
       "       [10.297],\n",
       "       [10.298],\n",
       "       [10.299],\n",
       "       [10.3  ],\n",
       "       [10.301],\n",
       "       [10.302],\n",
       "       [10.303],\n",
       "       [10.304],\n",
       "       [10.305],\n",
       "       [10.306],\n",
       "       [10.307],\n",
       "       [10.308],\n",
       "       [10.309],\n",
       "       [10.31 ],\n",
       "       [10.311],\n",
       "       [10.312],\n",
       "       [10.313],\n",
       "       [10.314],\n",
       "       [10.315],\n",
       "       [10.316],\n",
       "       [10.317],\n",
       "       [10.318],\n",
       "       [10.319],\n",
       "       [10.32 ],\n",
       "       [10.321],\n",
       "       [10.322],\n",
       "       [10.323],\n",
       "       [10.324],\n",
       "       [10.325],\n",
       "       [10.326],\n",
       "       [10.327],\n",
       "       [10.328],\n",
       "       [10.329],\n",
       "       [10.33 ],\n",
       "       [10.331],\n",
       "       [10.332],\n",
       "       [10.333],\n",
       "       [10.334],\n",
       "       [10.335],\n",
       "       [10.336],\n",
       "       [10.337],\n",
       "       [10.338],\n",
       "       [10.339],\n",
       "       [10.34 ],\n",
       "       [10.341],\n",
       "       [10.342],\n",
       "       [10.343],\n",
       "       [10.344],\n",
       "       [10.345],\n",
       "       [10.346],\n",
       "       [10.347],\n",
       "       [10.348],\n",
       "       [10.349],\n",
       "       [10.35 ],\n",
       "       [10.351],\n",
       "       [10.352],\n",
       "       [10.353],\n",
       "       [10.354],\n",
       "       [10.355],\n",
       "       [10.356],\n",
       "       [10.357],\n",
       "       [10.358],\n",
       "       [10.359],\n",
       "       [10.36 ],\n",
       "       [10.361],\n",
       "       [10.362],\n",
       "       [10.363],\n",
       "       [10.364],\n",
       "       [10.365],\n",
       "       [10.366],\n",
       "       [10.367],\n",
       "       [10.368],\n",
       "       [10.369],\n",
       "       [10.37 ],\n",
       "       [10.371],\n",
       "       [10.372],\n",
       "       [10.373],\n",
       "       [10.374],\n",
       "       [10.375],\n",
       "       [10.376],\n",
       "       [10.377],\n",
       "       [10.378],\n",
       "       [10.379],\n",
       "       [10.38 ],\n",
       "       [10.381],\n",
       "       [10.382],\n",
       "       [10.383],\n",
       "       [10.384],\n",
       "       [10.385],\n",
       "       [10.386],\n",
       "       [10.387],\n",
       "       [10.388],\n",
       "       [10.389],\n",
       "       [10.39 ],\n",
       "       [10.391],\n",
       "       [10.392],\n",
       "       [10.393],\n",
       "       [10.394],\n",
       "       [10.395],\n",
       "       [10.396],\n",
       "       [10.397],\n",
       "       [10.398],\n",
       "       [10.399],\n",
       "       [10.4  ],\n",
       "       [10.401],\n",
       "       [10.402],\n",
       "       [10.403],\n",
       "       [10.404],\n",
       "       [10.405],\n",
       "       [10.406],\n",
       "       [10.407],\n",
       "       [10.408],\n",
       "       [10.409],\n",
       "       [10.41 ],\n",
       "       [10.411],\n",
       "       [10.412],\n",
       "       [10.413],\n",
       "       [10.414],\n",
       "       [10.415],\n",
       "       [10.416],\n",
       "       [10.417],\n",
       "       [10.418],\n",
       "       [10.419],\n",
       "       [10.42 ],\n",
       "       [10.421],\n",
       "       [10.422],\n",
       "       [10.423],\n",
       "       [10.424],\n",
       "       [10.425],\n",
       "       [10.426],\n",
       "       [10.427],\n",
       "       [10.428],\n",
       "       [10.429],\n",
       "       [10.43 ],\n",
       "       [10.431],\n",
       "       [10.432],\n",
       "       [10.433],\n",
       "       [10.434],\n",
       "       [10.435],\n",
       "       [10.436],\n",
       "       [10.437],\n",
       "       [10.438],\n",
       "       [10.439],\n",
       "       [10.44 ],\n",
       "       [10.441],\n",
       "       [10.442],\n",
       "       [10.443],\n",
       "       [10.444],\n",
       "       [10.445],\n",
       "       [10.446],\n",
       "       [10.447],\n",
       "       [10.448],\n",
       "       [10.449],\n",
       "       [10.45 ],\n",
       "       [10.451],\n",
       "       [10.452],\n",
       "       [10.453],\n",
       "       [10.454],\n",
       "       [10.455],\n",
       "       [10.456],\n",
       "       [10.457],\n",
       "       [10.458],\n",
       "       [10.459],\n",
       "       [10.46 ],\n",
       "       [10.461],\n",
       "       [10.462],\n",
       "       [10.463],\n",
       "       [10.464],\n",
       "       [10.465],\n",
       "       [10.466],\n",
       "       [10.467],\n",
       "       [10.468],\n",
       "       [10.469],\n",
       "       [10.47 ],\n",
       "       [10.471],\n",
       "       [10.472],\n",
       "       [10.473],\n",
       "       [10.474],\n",
       "       [10.475],\n",
       "       [10.476],\n",
       "       [10.477],\n",
       "       [10.478],\n",
       "       [10.479],\n",
       "       [10.48 ],\n",
       "       [10.481],\n",
       "       [10.482],\n",
       "       [10.483],\n",
       "       [10.484],\n",
       "       [10.485],\n",
       "       [10.486],\n",
       "       [10.487],\n",
       "       [10.488],\n",
       "       [10.489],\n",
       "       [10.49 ],\n",
       "       [10.491],\n",
       "       [10.492],\n",
       "       [10.493],\n",
       "       [10.494],\n",
       "       [10.495],\n",
       "       [10.496],\n",
       "       [10.497],\n",
       "       [10.498],\n",
       "       [10.499],\n",
       "       [10.5  ],\n",
       "       [10.501],\n",
       "       [10.502],\n",
       "       [10.503],\n",
       "       [10.504],\n",
       "       [10.505],\n",
       "       [10.506],\n",
       "       [10.507],\n",
       "       [10.508],\n",
       "       [10.509],\n",
       "       [10.51 ],\n",
       "       [10.511],\n",
       "       [10.512],\n",
       "       [10.513],\n",
       "       [10.514],\n",
       "       [10.515],\n",
       "       [10.516],\n",
       "       [10.517],\n",
       "       [10.518],\n",
       "       [10.519],\n",
       "       [10.52 ],\n",
       "       [10.521],\n",
       "       [10.522],\n",
       "       [10.523],\n",
       "       [10.524],\n",
       "       [10.525],\n",
       "       [10.526],\n",
       "       [10.527],\n",
       "       [10.528],\n",
       "       [10.529],\n",
       "       [10.53 ],\n",
       "       [10.531],\n",
       "       [10.532],\n",
       "       [10.533],\n",
       "       [10.534],\n",
       "       [10.535],\n",
       "       [10.536],\n",
       "       [10.537],\n",
       "       [10.538],\n",
       "       [10.539],\n",
       "       [10.54 ],\n",
       "       [10.541],\n",
       "       [10.542],\n",
       "       [10.543],\n",
       "       [10.544],\n",
       "       [10.545],\n",
       "       [10.546],\n",
       "       [10.547],\n",
       "       [10.548],\n",
       "       [10.549],\n",
       "       [10.55 ],\n",
       "       [10.551],\n",
       "       [10.552],\n",
       "       [10.553],\n",
       "       [10.554],\n",
       "       [10.555],\n",
       "       [10.556],\n",
       "       [10.557],\n",
       "       [10.558],\n",
       "       [10.559],\n",
       "       [10.56 ],\n",
       "       [10.561],\n",
       "       [10.562],\n",
       "       [10.563],\n",
       "       [10.564],\n",
       "       [10.565],\n",
       "       [10.566],\n",
       "       [10.567],\n",
       "       [10.568],\n",
       "       [10.569],\n",
       "       [10.57 ],\n",
       "       [10.571],\n",
       "       [10.572],\n",
       "       [10.573],\n",
       "       [10.574],\n",
       "       [10.575],\n",
       "       [10.576],\n",
       "       [10.577],\n",
       "       [10.578],\n",
       "       [10.579],\n",
       "       [10.58 ],\n",
       "       [10.581],\n",
       "       [10.582],\n",
       "       [10.583],\n",
       "       [10.584],\n",
       "       [10.585],\n",
       "       [10.586],\n",
       "       [10.587],\n",
       "       [10.588],\n",
       "       [10.589],\n",
       "       [10.59 ],\n",
       "       [10.591],\n",
       "       [10.592],\n",
       "       [10.593],\n",
       "       [10.594],\n",
       "       [10.595],\n",
       "       [10.596],\n",
       "       [10.597],\n",
       "       [10.598],\n",
       "       [10.599],\n",
       "       [10.6  ],\n",
       "       [10.601],\n",
       "       [10.602],\n",
       "       [10.603],\n",
       "       [10.604],\n",
       "       [10.605],\n",
       "       [10.606],\n",
       "       [10.607],\n",
       "       [10.608],\n",
       "       [10.609],\n",
       "       [10.61 ],\n",
       "       [10.611],\n",
       "       [10.612],\n",
       "       [10.613],\n",
       "       [10.614],\n",
       "       [10.615],\n",
       "       [10.616],\n",
       "       [10.617],\n",
       "       [10.618],\n",
       "       [10.619],\n",
       "       [10.62 ],\n",
       "       [10.621],\n",
       "       [10.622],\n",
       "       [10.623],\n",
       "       [10.624],\n",
       "       [10.625],\n",
       "       [10.626],\n",
       "       [10.627],\n",
       "       [10.628],\n",
       "       [10.629],\n",
       "       [10.63 ],\n",
       "       [10.631],\n",
       "       [10.632],\n",
       "       [10.633],\n",
       "       [10.634],\n",
       "       [10.635],\n",
       "       [10.636],\n",
       "       [10.637],\n",
       "       [10.638],\n",
       "       [10.639],\n",
       "       [10.64 ],\n",
       "       [10.641],\n",
       "       [10.642],\n",
       "       [10.643],\n",
       "       [10.644],\n",
       "       [10.645],\n",
       "       [10.646],\n",
       "       [10.647],\n",
       "       [10.648],\n",
       "       [10.649],\n",
       "       [10.65 ],\n",
       "       [10.651],\n",
       "       [10.652],\n",
       "       [10.653],\n",
       "       [10.654],\n",
       "       [10.655],\n",
       "       [10.656],\n",
       "       [10.657],\n",
       "       [10.658],\n",
       "       [10.659],\n",
       "       [10.66 ],\n",
       "       [10.661],\n",
       "       [10.662],\n",
       "       [10.663],\n",
       "       [10.664],\n",
       "       [10.665],\n",
       "       [10.666],\n",
       "       [10.667],\n",
       "       [10.668],\n",
       "       [10.669],\n",
       "       [10.67 ],\n",
       "       [10.671],\n",
       "       [10.672],\n",
       "       [10.673],\n",
       "       [10.674],\n",
       "       [10.675],\n",
       "       [10.676],\n",
       "       [10.677],\n",
       "       [10.678],\n",
       "       [10.679],\n",
       "       [10.68 ],\n",
       "       [10.681],\n",
       "       [10.682],\n",
       "       [10.683],\n",
       "       [10.684],\n",
       "       [10.685],\n",
       "       [10.686],\n",
       "       [10.687],\n",
       "       [10.688],\n",
       "       [10.689],\n",
       "       [10.69 ],\n",
       "       [10.691],\n",
       "       [10.692],\n",
       "       [10.693],\n",
       "       [10.694],\n",
       "       [10.695],\n",
       "       [10.696],\n",
       "       [10.697],\n",
       "       [10.698],\n",
       "       [10.699],\n",
       "       [10.7  ],\n",
       "       [10.701],\n",
       "       [10.702],\n",
       "       [10.703],\n",
       "       [10.704],\n",
       "       [10.705],\n",
       "       [10.706],\n",
       "       [10.707],\n",
       "       [10.708],\n",
       "       [10.709],\n",
       "       [10.71 ],\n",
       "       [10.711],\n",
       "       [10.712],\n",
       "       [10.713],\n",
       "       [10.714],\n",
       "       [10.715],\n",
       "       [10.716],\n",
       "       [10.717],\n",
       "       [10.718],\n",
       "       [10.719],\n",
       "       [10.72 ],\n",
       "       [10.721],\n",
       "       [10.722],\n",
       "       [10.723],\n",
       "       [10.724],\n",
       "       [10.725],\n",
       "       [10.726],\n",
       "       [10.727],\n",
       "       [10.728],\n",
       "       [10.729],\n",
       "       [10.73 ],\n",
       "       [10.731],\n",
       "       [10.732],\n",
       "       [10.733],\n",
       "       [10.734],\n",
       "       [10.735],\n",
       "       [10.736],\n",
       "       [10.737],\n",
       "       [10.738],\n",
       "       [10.739],\n",
       "       [10.74 ],\n",
       "       [10.741],\n",
       "       [10.742],\n",
       "       [10.743],\n",
       "       [10.744],\n",
       "       [10.745],\n",
       "       [10.746],\n",
       "       [10.747],\n",
       "       [10.748],\n",
       "       [10.749],\n",
       "       [10.75 ],\n",
       "       [10.751],\n",
       "       [10.752],\n",
       "       [10.753],\n",
       "       [10.754],\n",
       "       [10.755],\n",
       "       [10.756],\n",
       "       [10.757],\n",
       "       [10.758],\n",
       "       [10.759],\n",
       "       [10.76 ],\n",
       "       [10.761],\n",
       "       [10.762],\n",
       "       [10.763],\n",
       "       [10.764],\n",
       "       [10.765],\n",
       "       [10.766],\n",
       "       [10.767],\n",
       "       [10.768],\n",
       "       [10.769],\n",
       "       [10.77 ],\n",
       "       [10.771],\n",
       "       [10.772],\n",
       "       [10.773],\n",
       "       [10.774],\n",
       "       [10.775],\n",
       "       [10.776],\n",
       "       [10.777],\n",
       "       [10.778],\n",
       "       [10.779],\n",
       "       [10.78 ],\n",
       "       [10.781],\n",
       "       [10.782],\n",
       "       [10.783],\n",
       "       [10.784],\n",
       "       [10.785],\n",
       "       [10.786],\n",
       "       [10.787],\n",
       "       [10.788],\n",
       "       [10.789],\n",
       "       [10.79 ],\n",
       "       [10.791],\n",
       "       [10.792],\n",
       "       [10.793],\n",
       "       [10.794],\n",
       "       [10.795],\n",
       "       [10.796],\n",
       "       [10.797],\n",
       "       [10.798],\n",
       "       [10.799],\n",
       "       [10.8  ],\n",
       "       [10.801],\n",
       "       [10.802],\n",
       "       [10.803],\n",
       "       [10.804],\n",
       "       [10.805],\n",
       "       [10.806],\n",
       "       [10.807],\n",
       "       [10.808],\n",
       "       [10.809],\n",
       "       [10.81 ],\n",
       "       [10.811],\n",
       "       [10.812],\n",
       "       [10.813],\n",
       "       [10.814],\n",
       "       [10.815],\n",
       "       [10.816],\n",
       "       [10.817],\n",
       "       [10.818],\n",
       "       [10.819],\n",
       "       [10.82 ],\n",
       "       [10.821],\n",
       "       [10.822],\n",
       "       [10.823],\n",
       "       [10.824],\n",
       "       [10.825],\n",
       "       [10.826],\n",
       "       [10.827],\n",
       "       [10.828],\n",
       "       [10.829],\n",
       "       [10.83 ],\n",
       "       [10.831],\n",
       "       [10.832],\n",
       "       [10.833],\n",
       "       [10.834],\n",
       "       [10.835],\n",
       "       [10.836],\n",
       "       [10.837],\n",
       "       [10.838],\n",
       "       [10.839],\n",
       "       [10.84 ],\n",
       "       [10.841],\n",
       "       [10.842],\n",
       "       [10.843],\n",
       "       [10.844],\n",
       "       [10.845],\n",
       "       [10.846],\n",
       "       [10.847],\n",
       "       [10.848],\n",
       "       [10.849],\n",
       "       [10.85 ],\n",
       "       [10.851],\n",
       "       [10.852],\n",
       "       [10.853],\n",
       "       [10.854],\n",
       "       [10.855],\n",
       "       [10.856],\n",
       "       [10.857],\n",
       "       [10.858],\n",
       "       [10.859],\n",
       "       [10.86 ],\n",
       "       [10.861],\n",
       "       [10.862],\n",
       "       [10.863],\n",
       "       [10.864],\n",
       "       [10.865],\n",
       "       [10.866],\n",
       "       [10.867],\n",
       "       [10.868],\n",
       "       [10.869],\n",
       "       [10.87 ],\n",
       "       [10.871],\n",
       "       [10.872],\n",
       "       [10.873],\n",
       "       [10.874],\n",
       "       [10.875],\n",
       "       [10.876],\n",
       "       [10.877],\n",
       "       [10.878],\n",
       "       [10.879],\n",
       "       [10.88 ],\n",
       "       [10.881],\n",
       "       [10.882],\n",
       "       [10.883],\n",
       "       [10.884],\n",
       "       [10.885],\n",
       "       [10.886],\n",
       "       [10.887],\n",
       "       [10.888],\n",
       "       [10.889],\n",
       "       [10.89 ],\n",
       "       [10.891],\n",
       "       [10.892],\n",
       "       [10.893],\n",
       "       [10.894],\n",
       "       [10.895],\n",
       "       [10.896],\n",
       "       [10.897],\n",
       "       [10.898],\n",
       "       [10.899],\n",
       "       [10.9  ],\n",
       "       [10.901],\n",
       "       [10.902],\n",
       "       [10.903],\n",
       "       [10.904],\n",
       "       [10.905],\n",
       "       [10.906],\n",
       "       [10.907],\n",
       "       [10.908],\n",
       "       [10.909],\n",
       "       [10.91 ],\n",
       "       [10.911],\n",
       "       [10.912],\n",
       "       [10.913],\n",
       "       [10.914],\n",
       "       [10.915],\n",
       "       [10.916],\n",
       "       [10.917],\n",
       "       [10.918],\n",
       "       [10.919],\n",
       "       [10.92 ],\n",
       "       [10.921],\n",
       "       [10.922],\n",
       "       [10.923],\n",
       "       [10.924],\n",
       "       [10.925],\n",
       "       [10.926],\n",
       "       [10.927],\n",
       "       [10.928],\n",
       "       [10.929],\n",
       "       [10.93 ],\n",
       "       [10.931],\n",
       "       [10.932],\n",
       "       [10.933],\n",
       "       [10.934],\n",
       "       [10.935],\n",
       "       [10.936],\n",
       "       [10.937],\n",
       "       [10.938],\n",
       "       [10.939],\n",
       "       [10.94 ],\n",
       "       [10.941],\n",
       "       [10.942],\n",
       "       [10.943],\n",
       "       [10.944],\n",
       "       [10.945],\n",
       "       [10.946],\n",
       "       [10.947],\n",
       "       [10.948],\n",
       "       [10.949],\n",
       "       [10.95 ],\n",
       "       [10.951],\n",
       "       [10.952],\n",
       "       [10.953],\n",
       "       [10.954],\n",
       "       [10.955],\n",
       "       [10.956],\n",
       "       [10.957],\n",
       "       [10.958],\n",
       "       [10.959],\n",
       "       [10.96 ],\n",
       "       [10.961],\n",
       "       [10.962],\n",
       "       [10.963],\n",
       "       [10.964],\n",
       "       [10.965],\n",
       "       [10.966],\n",
       "       [10.967],\n",
       "       [10.968],\n",
       "       [10.969],\n",
       "       [10.97 ],\n",
       "       [10.971],\n",
       "       [10.972],\n",
       "       [10.973],\n",
       "       [10.974],\n",
       "       [10.975],\n",
       "       [10.976],\n",
       "       [10.977],\n",
       "       [10.978],\n",
       "       [10.979],\n",
       "       [10.98 ],\n",
       "       [10.981],\n",
       "       [10.982],\n",
       "       [10.983],\n",
       "       [10.984],\n",
       "       [10.985],\n",
       "       [10.986],\n",
       "       [10.987],\n",
       "       [10.988],\n",
       "       [10.989],\n",
       "       [10.99 ],\n",
       "       [10.991],\n",
       "       [10.992],\n",
       "       [10.993],\n",
       "       [10.994],\n",
       "       [10.995],\n",
       "       [10.996],\n",
       "       [10.997],\n",
       "       [10.998],\n",
       "       [10.999]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "87c41222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cm_trainTestSplit_Plot(i, Cm, cm, tTrain, tVal, tTest, iTrain, iVal, iTest):\n",
    "    \n",
    "    title_0_Cm = 'Gurney flap not attached (NACA0018)\\n$C_m$ prediction, $L_2$ error=%.4f' % l2_error_Cm    \n",
    "    title_n_Cm = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_m$ prediction, $L_2$ error=%.4f'%(l2_error_Cm)\n",
    "    \n",
    "    if i==0:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    else:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    \n",
    "    # Cm graph plot\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm), 'k--', label='Predicted value')\n",
    "    plt.scatter(tTrain, denormalize(iTrain), color='b', label='Training set')\n",
    "    plt.scatter(tVal, denormalize(iVal), color='g', label='Validation set')\n",
    "    plt.scatter(tTest,denormalize(iTest), color='r', label='Test set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([-0.05, 0.22])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "893cf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf177275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error of Cm: 0.0123\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = [0.03]\n",
    "beta = [90]\n",
    "for i in range(0,1):\n",
    "    #Index from each dataset in sorted order\n",
    "    iTrain_ = []\n",
    "    iVal_ = []\n",
    "    iTest_ = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    t_train = []\n",
    "    t_val = []\n",
    "    t_test = []\n",
    "    \n",
    "    predictedValue = predicted[t_len*i:t_len*(i+1),:]\n",
    "    y_corres = y[t_len*i:t_len*(i+1),:]\n",
    "    \n",
    "    l2_error_Cm = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    print('L2 error of Cm: {0:0.4f}'.format(l2_error_Cm))\n",
    "    \n",
    "    cm_ = predictedValue#denormalize(predictedValue)\n",
    "    Cm = y_corres#denormalize(y_corres)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        iTrain_.append(predicted[index])\n",
    "    for jj, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        iVal_.append(predicted[index])    \n",
    "    for kk, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & (index_test>=i*t_len))]):\n",
    "        iTest_.append(predicted[index])\n",
    "        \n",
    "#     iTrain = denormalize(np.array(iTrain))\n",
    "#     iTest = denormalize(np.array(iTest))\n",
    "#     iVal = denormalize(np.array(iVal))\n",
    "    iTrain_ = np.array(iTrain_)\n",
    "    iVal_ = np.array(iVal_)\n",
    "    iTest_ = np.array(iTest_)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        t_train.append(t[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        t_val.append(t[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & ((index_test>=i*t_len)))]):\n",
    "        t_test.append(t[index])\n",
    "        \n",
    "    tTrain = np.array(t_train)\n",
    "    tVal = np.array(t_val)\n",
    "    tTest = np.array(t_test)\n",
    "        \n",
    "    Cm_trainTestSplit_Plot(i, Cm, cm_, tTrain, tVal, tTest, iTrain_, iVal_, iTest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7eb11de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cm_trainTestSplit_Plot2(i, Cm, cm, tTrain, tVal, tTest, iTrain, iVal, iTest):\n",
    "    \n",
    "    title_0_Cm = 'Gurney flap not attached (NACA0018)\\n$C_m$ prediction, $L_2$ error=%.4f' % l2_error_Cm    \n",
    "    title_n_Cm = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_m$ prediction, $L_2$ error=%.4f'%(l2_error_Cm)\n",
    "    \n",
    "    if i==0:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    else:\n",
    "        title_Cm = title_n_Cm\n",
    "        savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "    \n",
    "    # Cm graph plot\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm), 'r--', label='Predicted value')\n",
    "#     plt.scatter(tTrain, denormalize(iTrain), color='b', label='Training set')\n",
    "#     plt.scatter(tVal, denormalize(iVal), color='g', label='Validation set')\n",
    "#     plt.scatter(tTest,denormalize(iTest), color='r', label='Test set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper left')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b2cc294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error of Cm: 0.0123\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    #Index from each dataset\n",
    "    iTrain_ = []\n",
    "    iVal_ = []\n",
    "    iTest_ = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    t_train = []\n",
    "    t_val = []\n",
    "    t_test = []\n",
    "    \n",
    "    predictedValue = predicted[t_len*i:t_len*(i+1),:]\n",
    "    y_corres = y[t_len*i:t_len*(i+1),:]\n",
    "    \n",
    "    l2_error_Cm = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    print('L2 error of Cm: {0:0.4f}'.format(l2_error_Cm))\n",
    "    \n",
    "    cm_ = predictedValue#denormalize(predictedValue)\n",
    "    Cm = y_corres#denormalize(y_corres)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        iTrain_.append(predicted[index])\n",
    "    for jj, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        iVal_.append(predicted[index])    \n",
    "    for kk, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & (index_test>=i*t_len))]):\n",
    "        iTest_.append(predicted[index])\n",
    "        \n",
    "#     iTrain = denormalize(np.array(iTrain))\n",
    "#     iTest = denormalize(np.array(iTest))\n",
    "#     iVal = denormalize(np.array(iVal))\n",
    "    iTrain_ = np.array(iTrain_)\n",
    "    iVal_ = np.array(iVal_)\n",
    "    iTest_ = np.array(iTest_)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        t_train.append(t[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        t_val.append(t[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & ((index_test>=i*t_len)))]):\n",
    "        t_test.append(t[index])\n",
    "        \n",
    "    tTrain = np.array(t_train)\n",
    "    tVal = np.array(t_val)\n",
    "    tTest = np.array(t_test)\n",
    "        \n",
    "    Cm_trainTestSplit_Plot2(i, Cm, cm_, tTrain, tVal, tTest, iTrain_, iVal_, iTest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b420f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error of Cm: 0.0123\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,1):\n",
    "    #Index from each dataset\n",
    "    iTrain_ = []\n",
    "    iVal_ = []\n",
    "    iTest_ = []\n",
    "    \n",
    "    # Index from input data (alpha, in this case)\n",
    "    t_train = []\n",
    "    t_val = []\n",
    "    t_test = []\n",
    "    title_n_Cm = 'Gurney flap attached h=%.2f, '%(h[i]) + r'$\\beta$=%d'%(beta[i])+'\\n$C_m$ prediction, $L_2$ error=%.4f'%(l2_error_Cm)\n",
    "    \n",
    "    title_Cm = title_n_Cm\n",
    "    savename1 = \"CmComparison_h\"+str(h[i])+\"_beta\"+str(beta[i])+\".jpg\"\n",
    "\n",
    "    predictedValue = predicted[t_len*i:t_len*(i+1),:]\n",
    "    y_corres = y[t_len*i:t_len*(i+1),:]\n",
    "    \n",
    "    l2_error_Cm = np.sqrt(np.sum((predictedValue - y_corres)**2) / np.sum(y_corres**2))\n",
    "    \n",
    "    print('L2 error of Cm: {0:0.4f}'.format(l2_error_Cm))\n",
    "    \n",
    "    cm_ = predictedValue#denormalize(predictedValue)\n",
    "    Cm = y_corres#denormalize(y_corres)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        iTrain_.append(predicted[index])\n",
    "    for jj, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        iVal_.append(predicted[index])    \n",
    "    for kk, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & (index_test>=i*t_len))]):\n",
    "        iTest_.append(predicted[index])\n",
    "        \n",
    "#     iTrain = denormalize(np.array(iTrain))\n",
    "#     iTest = denormalize(np.array(iTest))\n",
    "#     iVal = denormalize(np.array(iVal))\n",
    "    iTrain_ = np.array(iTrain_)\n",
    "    iVal_ = np.array(iVal_)\n",
    "    iTest_ = np.array(iTest_)\n",
    "    \n",
    "    for ii, index in enumerate(index_train[np.where((index_train<(i+1)*t_len) & ((index_train>=i*t_len)))]):\n",
    "        t_train.append(t[index])\n",
    "    for kk, index in enumerate(index_val[np.where((index_val<(i+1)*t_len) & ((index_val>=i*t_len)))]):\n",
    "        t_val.append(t[index])\n",
    "    for jj, index in enumerate(index_test[np.where((index_test<(i+1)*t_len) & ((index_test>=i*t_len)))]):\n",
    "        t_test.append(t[index])\n",
    "        \n",
    "    tTrain = np.array(t_train)\n",
    "    tVal = np.array(t_val)\n",
    "    tTest = np.array(t_test)\n",
    "\n",
    "    # Cm graph plot\n",
    "    ## Training dataset\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm_), 'k--', label='Predicted value')\n",
    "    #plt.scatter(tTrain, iTrain, color='b', label='Training set')\n",
    "    #plt.scatter(tVal, iVal, color='g', label='Validation set')\n",
    "    plt.scatter(tTrain, denormalize(iTrain_), color='b', label='Training set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    #plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Validation dataset\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm_), 'k--', label='Predicted value')\n",
    "    plt.scatter(tVal, denormalize(iVal_), color='g', label='Validation set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    #plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    ## Test dataset\n",
    "    plt.plot(t, denormalize(Cm), 'k-', label='Ground truth')\n",
    "    plt.plot(t, denormalize(cm_), 'k--', label='Predicted value')\n",
    "    plt.scatter(tTest, denormalize(iTest_), color='r', label='Test set')\n",
    "    plt.xlabel('Rev.')\n",
    "    plt.ylabel('$C_m$')\n",
    "    plt.title(title_Cm, fontsize=15)        \n",
    "    plt.legend(loc='upper right')\n",
    "    #plt.ylim([0, 0.0042])\n",
    "    plt.grid()\n",
    "    #plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2f20d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(t, cm, 'k-', label='Ground truth')\n",
    "plt.plot(t, denormalize(predicted), 'r--', label='Predicted value')\n",
    "#     plt.scatter(tTrain, denormalize(iTrain), color='b', label='Training set')\n",
    "#     plt.scatter(tVal, denormalize(iVal), color='g', label='Validation set')\n",
    "#     plt.scatter(tTest,denormalize(iTest), color='r', label='Test set')\n",
    "plt.xlabel('Rev.')\n",
    "plt.ylabel('$C_m$')\n",
    "plt.title(title_Cm, fontsize=15)        \n",
    "plt.legend(loc='upper left')\n",
    "plt.xlim([10.46, 10.54])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.grid()\n",
    "plt.savefig(savename1, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83e3d3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.499])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb18ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "47c328a4527b1c811974d07e6cb5295efd3040c2b3e7cb17d9e712631aaeff5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
