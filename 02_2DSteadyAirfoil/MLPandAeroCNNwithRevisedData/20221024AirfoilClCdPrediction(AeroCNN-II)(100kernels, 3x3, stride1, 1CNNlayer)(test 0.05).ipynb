{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AeroCNN-II\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, r2_score\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "445ec134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bb435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mirrored_strategy = tf.distribute.MirroredStrategy([\"/GPU:0\",\"/GPU:1\", \"/GPU:2\"], cross_device_ops = tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernel=100\n",
    "l2Regularizer=1e-09\n",
    "kernel_size1 = 5\n",
    "kernel_size2 = 1\n",
    "#kernel_size3 = 5\n",
    "n_grid = 128\n",
    "strides = 1\n",
    "input_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d7f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.linspace(-10,20,16).reshape((16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f0eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.zeros((16*133,1))\n",
    "for i in range(0, 133):\n",
    "    aa[16*i:16*(i+1), :] = alpha[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e191fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = aa.reshape((133, 16, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ba4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\AeroCNN2Inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = \"D:\\\\rotatedInterpolation_pow2\\\\n_grid128\\\\velocityMagnitudeField\"\n",
    "origin_data = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\"\n",
    "origin_coord = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a9cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_orig = os.listdir(origin)\n",
    "folders = [file for file in folders_orig if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c16d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for j in range(0, alpha.shape[0]):\n",
    "        csv_file_name = origin + '\\\\airfoil' + str(i) + \"alpha\"+ str(int(alpha[j])) + \"_velocityMagnitudeInterpolated.csv\"\n",
    "        data = pd.read_csv(csv_file_name, header=None)\n",
    "        image_df = pd.concat([image_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa448a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_np = image_df.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6d479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_np.reshape((133, 16, n_grid+1, n_grid+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438d1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 1-image/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d6b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for alpha_ in alpha:\n",
    "        cl_name = origin_coord + \"\\\\airfoil\" + str(i) + \"\\\\\"+ str(int(alpha_)) + \"\\\\Cl_\" + str(i) + \"_\"+ str(int(alpha_)) +\".txt\"\n",
    "        data = pd.read_csv(cl_name, sep = \",\", header=None)\n",
    "        cl_df = pd.concat([cl_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa87b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for alpha_ in alpha:\n",
    "        cd_name = origin_coord + \"\\\\airfoil\" + str(i) + \"\\\\\"+ str(int(alpha_)) + \"\\\\Cd_\" + str(i) + \"_\"+ str(int(alpha_)) +\".txt\"\n",
    "        data = pd.read_csv(cd_name, sep = \",\", header=None)\n",
    "        cd_df = pd.concat([cd_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c4dc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = cl_df.iloc[:, :].values.reshape((-1,1))\n",
    "cl_nor = (cl-np.min(cl))/(np.max(cl)-np.min(cl))\n",
    "cd = cd_df.iloc[:, :].values.reshape((-1,1))\n",
    "cd_nor = (cd-np.min(cd))/(np.max(cd)-np.min(cd))\n",
    "\n",
    "y = np.hstack((cl, cd))\n",
    "y_nor = np.hstack((cl_nor, cd_nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31449c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nor = y_nor.reshape((133, 16, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb0bd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = origin_data + \"\\\\AirfoilIndexList.xlsx\"\n",
    "airfoilName_df = pd.read_excel(file_name)\n",
    "geometry_orig = airfoilName_df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb3458bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = np.zeros((133*16,1))\n",
    "geometry = geometry.astype(np.string_)\n",
    "for i in geometry_orig:\n",
    "    index_ = np.where(geometry_orig==i)\n",
    "    for j in range(0,16):\n",
    "        geometry[16*index_[0]+j,:] = np.asarray(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e31070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a65b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = geometry.reshape((133, 16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, aa_train, aa_test, geo_train, geo_test, y_train, y_test = train_test_split(image, aa, geometry, y_nor, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0290ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0]*x_train.shape[1], x_train.shape[2], x_train.shape[3], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0]*x_test.shape[1], x_test.shape[2], x_test.shape[3], 1))\n",
    "aa_train = aa_train.reshape((aa_train.shape[0]*aa_train.shape[1], aa_train.shape[2], aa_train.shape[3]))\n",
    "aa_test = aa_test.reshape((aa_test.shape[0]*aa_test.shape[1], aa_test.shape[2], aa_test.shape[3]))\n",
    "geo_train = geo_train.reshape((geo_train.shape[0]*geo_train.shape[1], geo_train.shape[2]))\n",
    "geo_test = geo_test.reshape((geo_test.shape[0]*geo_test.shape[1], geo_test.shape[2]))\n",
    "y_train = y_train.reshape((y_train.shape[0]*y_train.shape[1], y_train.shape[2], y_train.shape[3]))\n",
    "y_test = y_test.reshape((y_test.shape[0]*y_test.shape[1], y_test.shape[2], y_test.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6714e6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 129, 129, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "input_image = tf.keras.Input(shape=(n_grid+1, n_grid+1, 1))\n",
    "\n",
    "x_conv = tf.keras.layers.Conv2D(n_kernel, (kernel_size1, kernel_size1), strides=(strides, strides),\n",
    "                                activation='relu', padding='same',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                name='Conv2DLayer1')(input_image)\n",
    "x_ = tf.keras.layers.MaxPooling2D((2,2))(x_conv)\n",
    "x_conv = tf.keras.layers.Conv2D(1, (kernel_size2, kernel_size2), strides=(strides, strides),\n",
    "                                activation='relu', padding='same',\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                name='Conv2DLayer2')(x_)\n",
    "\n",
    "reshape1 = tf.keras.layers.Flatten()(x_conv)\n",
    "\n",
    "x_ = tf.keras.layers.Dense(units=200, activation='relu', name='firstHiddenLayer',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer))(reshape1)\n",
    "x_ = tf.keras.layers.Dense(units=100, activation='relu', name='secondHiddenLayer',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer))(x_)\n",
    "\n",
    "output_data = tf.keras.layers.Dense(units=2, activation='linear', name='outputLayer')(x_)\n",
    "output_image = tf.keras.layers.Reshape((2, 1))(output_data)\n",
    "# AeroCNN-II\n",
    "model = tf.keras.Model(input_image, output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 129, 129, 1)]     0         \n",
      "                                                                 \n",
      " Conv2DLayer1 (Conv2D)       (None, 129, 129, 100)     2600      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 100)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Conv2DLayer2 (Conv2D)       (None, 64, 64, 1)         101       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " firstHiddenLayer (Dense)    (None, 200)               819400    \n",
      "                                                                 \n",
      " secondHiddenLayer (Dense)   (None, 100)               20100     \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 2)                 202       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 2, 1)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 842,403\n",
      "Trainable params: 842,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93e266fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', patience=200,\n",
    "                   restore_best_weights=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'loss',factor = 0.5, patience = 25,\n",
    "                              min_lr = 1e-8, mode = 'min', verbose = 1)\n",
    "\n",
    "model_name = \"D:\\\\TrainedModels\\\\20221024\\\\\" + \"AeroCNN-II_ClCd_nGrid128_100kernel_2by2MaxPooling_1CNNlayer_testSize0.05(normalized).h5\"\n",
    "checkpoint_cb = ModelCheckpoint(model_name, save_best_only=True,\n",
    "                                monitor = 'loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "63/63 [==============================] - 3s 10ms/step - loss: 0.1723 - rmse: 0.4151 - lr: 0.0010\n",
      "Epoch 2/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1411 - rmse: 0.3757 - lr: 0.0010\n",
      "Epoch 3/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1176 - rmse: 0.3429 - lr: 0.0010\n",
      "Epoch 4/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0994 - rmse: 0.3153 - lr: 0.0010\n",
      "Epoch 5/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0853 - rmse: 0.2920 - lr: 0.0010\n",
      "Epoch 6/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0744 - rmse: 0.2728 - lr: 0.0010\n",
      "Epoch 7/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0663 - rmse: 0.2574 - lr: 0.0010\n",
      "Epoch 8/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0603 - rmse: 0.2456 - lr: 0.0010\n",
      "Epoch 9/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0560 - rmse: 0.2366 - lr: 0.0010\n",
      "Epoch 10/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0530 - rmse: 0.2302 - lr: 0.0010\n",
      "Epoch 11/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0510 - rmse: 0.2257 - lr: 0.0010\n",
      "Epoch 12/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0496 - rmse: 0.2228 - lr: 0.0010\n",
      "Epoch 13/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0488 - rmse: 0.2209 - lr: 0.0010\n",
      "Epoch 14/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0483 - rmse: 0.2197 - lr: 0.0010\n",
      "Epoch 15/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0480 - rmse: 0.2190 - lr: 0.0010\n",
      "Epoch 16/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0478 - rmse: 0.2186 - lr: 0.0010\n",
      "Epoch 17/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0477 - rmse: 0.2184 - lr: 0.0010\n",
      "Epoch 18/5000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0476 - rmse: 0.2183 - lr: 0.0010\n",
      "Epoch 19/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2182 - lr: 0.0010\n",
      "Epoch 20/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2182 - lr: 0.0010\n",
      "Epoch 21/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 22/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 23/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 24/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 25/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 26/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 27/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 28/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 29/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 30/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 31/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 32/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 33/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 34/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 35/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 36/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 37/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 38/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 39/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 40/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 41/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 42/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 0.0010\n",
      "Epoch 43/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0474 - rmse: 0.2177\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2182 - lr: 0.0010\n",
      "Epoch 44/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 45/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 46/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 47/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 48/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 49/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 50/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 51/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 52/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 53/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 54/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 55/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 56/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 57/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 58/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 59/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 60/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 61/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 62/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 63/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 64/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 65/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 66/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 67/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 68/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0477 - rmse: 0.2184\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 5.0000e-04\n",
      "Epoch 69/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 70/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 71/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 72/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 73/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 74/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 75/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 76/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 77/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 78/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 79/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 80/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 81/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 82/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 83/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 84/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 85/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 86/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 87/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 88/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 89/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 90/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 91/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 92/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 93/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0481 - rmse: 0.2194\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.5000e-04\n",
      "Epoch 94/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 95/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 96/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 97/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 98/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 99/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 100/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 101/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 102/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 103/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 104/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 105/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 106/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 107/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 108/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 109/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 110/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 111/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 112/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 113/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 114/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 115/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 116/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 117/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 118/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0477 - rmse: 0.2183\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2500e-04\n",
      "Epoch 119/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 120/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 121/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 122/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 123/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 124/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 125/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 126/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 127/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 128/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 129/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 130/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 131/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 132/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 133/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 134/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 135/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 136/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 137/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 138/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 139/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 141/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 142/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 143/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0480 - rmse: 0.2190\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.2500e-05\n",
      "Epoch 144/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 145/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 146/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 147/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 148/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 149/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 150/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 151/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 152/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 153/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 154/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 155/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 156/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 157/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 158/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 159/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 160/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 161/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 162/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 163/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 164/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 165/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 166/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 167/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 168/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0479 - rmse: 0.2188\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.1250e-05\n",
      "Epoch 169/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 170/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 171/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 172/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 173/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 174/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 175/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 176/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 177/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 178/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 179/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 180/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 181/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 182/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 183/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 184/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 185/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 186/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 187/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 188/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 189/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 190/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 191/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 192/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 193/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0476 - rmse: 0.2182\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5625e-05\n",
      "Epoch 194/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 195/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 196/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 197/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 198/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 199/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 200/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 201/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 202/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 203/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 204/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 205/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 206/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 207/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 208/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 209/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 210/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 211/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 212/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 213/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 214/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 215/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 216/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 217/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 218/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0471 - rmse: 0.2171\n",
      "Epoch 218: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 7.8125e-06\n",
      "Epoch 219/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 220/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 221/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 222/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 223/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 224/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 225/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 226/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 227/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 228/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 229/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 230/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 231/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 232/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 233/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 234/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 235/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 236/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 237/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 238/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 239/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 240/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 241/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 242/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 243/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0476 - rmse: 0.2182\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.9063e-06\n",
      "Epoch 244/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 245/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 246/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 247/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 248/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 249/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 250/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 251/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 252/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 253/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 254/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 255/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 256/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 257/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 258/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 259/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 260/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 261/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 262/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 263/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 264/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 265/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 266/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 267/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 268/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0476 - rmse: 0.2182\n",
      "Epoch 268: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.9531e-06\n",
      "Epoch 269/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 270/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 271/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 272/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 273/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 274/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 275/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 276/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 277/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 278/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 279/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 280/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 281/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 282/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 283/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 284/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 285/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 286/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 287/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 288/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 289/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 290/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 291/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 292/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 293/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0474 - rmse: 0.2176\n",
      "Epoch 293: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 9.7656e-07\n",
      "Epoch 294/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 295/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 296/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 297/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 298/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 299/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 300/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 301/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 302/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 303/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 304/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 305/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 306/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 307/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 308/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 309/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 310/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 311/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 312/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 313/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 314/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 315/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 316/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 317/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 318/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0476 - rmse: 0.2182\n",
      "Epoch 318: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 4.8828e-07\n",
      "Epoch 319/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 320/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 321/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 322/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 323/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 324/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 325/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 326/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 327/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 328/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 329/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 330/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 331/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 332/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 333/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 334/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 335/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 336/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 337/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 338/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 339/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 340/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 341/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 342/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 343/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0478 - rmse: 0.2187\n",
      "Epoch 343: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 2.4414e-07\n",
      "Epoch 344/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 345/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 346/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 347/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 348/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 349/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 350/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 351/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 352/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 353/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 354/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 355/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 356/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 357/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 358/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 359/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 360/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 361/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 362/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 363/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 364/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 365/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 366/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 367/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 368/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0473 - rmse: 0.2175\n",
      "Epoch 368: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.2207e-07\n",
      "Epoch 369/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 370/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 371/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 372/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 373/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 374/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 375/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 376/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 377/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 378/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 379/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 380/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 381/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 382/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 383/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 384/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 385/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 386/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 387/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 388/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 389/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 390/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 391/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 392/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 393/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0476 - rmse: 0.2182\n",
      "Epoch 393: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 6.1035e-08\n",
      "Epoch 394/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 395/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 396/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 397/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 398/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 399/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 400/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 401/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 402/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 403/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 404/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 405/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 406/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 407/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 408/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 409/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 410/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 411/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 412/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 413/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 414/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 415/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 416/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 417/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 418/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0479 - rmse: 0.2188\n",
      "Epoch 418: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 3.0518e-08\n",
      "Epoch 419/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 420/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 421/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 422/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 423/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 424/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 425/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 426/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 427/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 428/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 429/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 430/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 431/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 432/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 433/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 434/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 435/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 436/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 437/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 438/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 439/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 440/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 441/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 442/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 443/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0472 - rmse: 0.2173\n",
      "Epoch 443: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.5259e-08\n",
      "Epoch 444/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 445/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 446/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 447/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 448/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 449/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 450/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 451/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 452/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 453/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 454/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 455/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 456/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 457/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 458/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 459/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 460/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 461/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 462/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 463/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 464/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 465/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 466/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 467/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 468/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 469/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 470/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 471/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 472/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 473/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 474/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 475/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 476/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 477/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 478/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 479/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 480/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 481/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 482/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 483/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 484/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 485/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 486/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 487/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 488/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 489/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 490/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 491/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 492/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 493/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 494/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 495/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 496/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 497/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 498/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 499/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 500/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 501/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 502/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 503/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 504/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 505/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 506/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 507/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 508/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 509/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 510/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 511/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 512/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 513/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 514/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 515/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 516/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 517/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 518/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 519/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 520/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 521/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 522/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 523/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 524/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 525/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 526/5000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 527/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 528/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 529/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 530/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 531/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 532/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 533/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 534/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 535/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 536/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 537/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 538/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 539/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 540/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 541/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 542/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 543/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 544/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 545/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 546/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 547/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 548/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 549/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 550/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 551/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 552/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 553/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 554/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 555/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 556/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 557/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 558/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 559/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 560/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 561/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 562/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 563/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 564/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 565/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 566/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 567/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 568/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 569/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 570/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 571/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 572/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 573/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 574/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 575/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 576/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 577/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 578/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 579/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 580/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 581/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 582/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 583/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 584/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 585/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 586/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 587/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 588/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 589/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 590/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 591/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 592/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 593/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 594/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 595/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 596/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 597/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 598/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 599/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 600/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 601/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 602/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 603/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 604/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 605/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 606/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 607/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 608/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 609/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 610/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 611/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 612/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 613/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 614/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 615/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 616/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 617/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 618/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 620/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 621/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 622/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 623/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 624/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 625/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 626/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 627/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 628/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 629/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 630/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 631/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 632/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 633/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 634/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 635/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 636/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 637/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 638/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 639/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 640/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 641/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 642/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 643/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 644/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 645/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 646/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 647/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 648/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 649/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 650/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 651/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 652/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 653/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 654/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 655/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 656/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 657/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 658/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 659/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 660/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 661/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 662/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 663/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 664/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 665/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 666/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 667/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 668/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 669/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 670/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 671/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 672/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 673/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 674/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 675/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 676/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 677/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 678/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 679/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 680/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 681/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 682/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 683/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 684/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 685/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 686/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 687/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 688/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 689/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 690/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 691/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 692/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 693/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 694/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 695/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 696/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 697/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 698/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 699/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 700/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 701/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 702/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 703/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 704/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 705/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 706/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 707/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 708/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 709/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 710/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 711/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 712/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 713/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 714/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 715/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 716/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 717/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 718/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 719/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 720/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 721/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 722/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 723/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 724/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 725/5000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 726/5000\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0476 - rmse: 0.2183Restoring model weights from the end of the best epoch: 526.\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0476 - rmse: 0.2181 - lr: 1.0000e-08\n",
      "Epoch 726: early stopping\n"
     ]
    }
   ],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "start = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train, epochs=5000, shuffle=True,\n",
    "                    callbacks=[es, reduce_lr, checkpoint_cb])\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:06:51.748622\n"
     ]
    }
   ],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2)\n",
    "plt.title('Training loss (mean squared error)\\nAeroCNN-II', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "745feda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0476 - rmse: 0.2181\n"
     ]
    }
   ],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "test_results = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7078f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0467 - rmse: 0.2162\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f240f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "decoded_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e12e035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 2, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ccbbb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "#with mirrored_strategy.scope():\n",
    "decoded_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37220966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 2, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98c788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train_refrained = decoded_train[:,0,:]*(np.max(cl)+np.min(cl)) + np.min(cl)\n",
    "cl_test_refrained = decoded_test[:,0,:]*(np.max(cl)+np.min(cl)) + np.min(cl)\n",
    "cd_train_refrained = decoded_train[:,1,:]*(np.max(cl)+np.min(cl)) + np.min(cl)\n",
    "cd_test_refrained = decoded_test[:,1,:]*(np.max(cl)+np.min(cl)) + np.min(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a32573c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_train_refrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d822fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_train_refrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b357e033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_test_refrained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d8c182f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d5a4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = np.concatenate((cl_train_refrained.reshape((int(x_train.shape[0]/2),2,1)),\n",
    "                                cd_train_refrained.reshape((int(x_train.shape[0]/2),2,1))), axis=0)\n",
    "decoded_test = np.concatenate((cl_test_refrained.reshape((int(x_test.shape[0]/2),2,1)),\n",
    "                               cd_test_refrained.reshape((int(x_test.shape[0]/2),2,1))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = np.abs(decoded_train - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4c0dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_abs = np.abs(decoded_test - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec80e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_Cl_abs = np.abs(decoded_train[:,0,:] - y_train[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "028d78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_Cd_abs = np.abs(decoded_train[:,1,:] - y_train[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83cd596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_Cl_abs = np.abs(decoded_test[:,0,:] - y_test[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5148e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_Cd_abs = np.abs(decoded_test[:,1,:] - y_test[:,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6df80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\\\TrainedModels\\\\20221024\")\n",
    "model.save('AeroCNN-II_ClCd_nGrid128_100kernel_2by2MaxPooling_1CNNlayer_testSize0.05(normalized)(1x1convAdded).h5',\n",
    "           overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.341457293811594\n"
     ]
    }
   ],
   "source": [
    "l2_error_train = np.sqrt(np.sum((decoded_train - y_train)**2) / np.sum(y_train**2))\n",
    "print(l2_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3770434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.327337592329249\n"
     ]
    }
   ],
   "source": [
    "l2_error_test = np.sqrt(np.sum((decoded_test - y_test)**2) / np.sum(y_test**2))\n",
    "print(l2_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d893bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6623517216522457\n"
     ]
    }
   ],
   "source": [
    "l2_error_Cl_train = np.sqrt(np.sum((decoded_train[:,0,:] - y_train[:,0,:])**2) / np.sum(y_train[:,0,:]**2))\n",
    "print(l2_error_Cl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14eb3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.986024339376438\n"
     ]
    }
   ],
   "source": [
    "l2_error_Cd_train = np.sqrt(np.sum((decoded_train[:,1,:] - y_train[:,1,:])**2) / np.sum(y_train[:,1,:]**2))\n",
    "print(l2_error_Cd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58600c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_Cl_test = np.sqrt(np.sum((decoded_test[:,0,:] - y_test[:,0,:])**2) / np.sum(y_test[:,0,:]**2))\n",
    "print(l2_error_Cl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_Cd_test = np.sqrt(np.sum((decoded_test[:,1,:] - y_test[:,1,:])**2) / np.sum(y_test[:,1,:]**2))\n",
    "print(l2_error_Cd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(aa_train)):\n",
    "    l2_error_train_data = np.sqrt(np.sum((decoded_train[i] - y_train[i])**2) / np.sum(y_train[i]**2))\n",
    "    l2_error_train_list.append(l2_error_train_data)\n",
    "print(l2_error_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(aa_test)):\n",
    "    l2_error_test_data = np.sqrt(np.sum((decoded_test[i] - y_test[i])**2) / np.sum(y_test[i]**2))\n",
    "    l2_error_test_list.append(l2_error_test_data)\n",
    "print(l2_error_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_Cl_train_list = []\n",
    "for i in range(0, len(aa_train)):\n",
    "    l2_error_Cl_train_data = np.sqrt(np.sum((decoded_train[:,0,:][i] - y_train[:,0,:][i])**2) / np.sum(y_train[:,0,:][i]**2))\n",
    "    l2_error_Cl_train_list.append(l2_error_Cl_train_data)\n",
    "print(l2_error_Cl_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dba7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_Cd_train_list = []\n",
    "for i in range(0, len(aa_train)):\n",
    "    l2_error_Cd_train_data = np.sqrt(np.sum((decoded_train[:,1,:][i] - y_train[:,1,:][i])**2) / np.sum(y_train[:,1,:][i]**2))\n",
    "    l2_error_Cd_train_list.append(l2_error_Cd_train_data)\n",
    "print(l2_error_Cd_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b092e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((decoded_train[:,1,:][36] - y_train[:,1,:][36])**2) / np.sum(y_train[:,1,:][36]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e795fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_Cl_test_list = []\n",
    "for i in range(0, len(aa_test)):\n",
    "    l2_error_Cl_test_data = np.sqrt(np.sum((decoded_test[:,0,:][i] - y_test[:,0,:][i])**2) / np.sum(y_test[:,0,:][i]**2))\n",
    "    l2_error_Cl_test_list.append(l2_error_Cl_test_data)\n",
    "print(l2_error_Cl_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806455b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_Cd_test_list = []\n",
    "for i in range(0, len(aa_test)):\n",
    "    l2_error_Cd_test_data = np.sqrt(np.sum((decoded_test[:,1,:][i] - y_test[:,1,:][i])**2) / np.sum(y_test[:,1,:][i]**2))\n",
    "    l2_error_Cd_test_list.append(l2_error_Cd_test_data)\n",
    "print(l2_error_Cd_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd795141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_train.shape[0], aa_train.shape[0]),\n",
    "         l2_error_train*np.ones(aa_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_train.shape[0], aa_train.shape[0]), l2_error_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, training\\n100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, test\\n100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad363604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, test (log scale)\\n100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_train.shape[0], aa_train.shape[0]),\n",
    "         l2_error_Cl_train*np.ones(aa_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_train.shape[0], aa_train.shape[0]), l2_error_Cl_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, $C_l$ prediction, train\\n100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fd291",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_Cl_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_Cl_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, $C_l$ prediction, test\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d28db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_train.shape[0], aa_train.shape[0]),\n",
    "         l2_error_Cl_train*np.ones(aa_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_train.shape[0], aa_train.shape[0]), l2_error_Cl_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, $C_l$ prediction, train (log scale)\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f270230",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_Cl_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_Cl_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, $C_l$ prediction, test (log scale)\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_train.shape[0], aa_train.shape[0]),\n",
    "         l2_error_Cd_train*np.ones(aa_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_train.shape[0], aa_train.shape[0]), l2_error_Cd_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, $C_d$ prediction, train\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f55012",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_Cd_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_Cd_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.title('$L_2$ error norm variance - AeroCNN-II, $C_d$ prediction, test\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, decoded_train.shape[0], decoded_train.shape[0]), y_train[:,0,:], 'k',lw=0.5)\n",
    "plt.scatter(np.linspace(1, decoded_train.shape[0], decoded_train.shape[0]), decoded_train[:,0,:], c='b', s=15)\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.title('$C_l$ prediction, train\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, decoded_test.shape[0], decoded_test.shape[0]), y_test[:,0,:], 'k',lw=1)\n",
    "plt.scatter(np.linspace(1, decoded_test.shape[0], decoded_test.shape[0]), decoded_test[:,0,:], c='b', s=15)\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.title('$C_l$ prediction, test\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d671fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, decoded_train.shape[0], decoded_train.shape[0]), y_train[:,1,:], 'k',lw=0.5)\n",
    "plt.scatter(np.linspace(1, decoded_train.shape[0], decoded_train.shape[0]), decoded_train[:,1,:], c='b', s=15)\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.title('$C_d$ prediction, train\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860304c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, decoded_test.shape[0], decoded_test.shape[0]), y_test[:,1,:], 'k',lw=1)\n",
    "plt.scatter(np.linspace(1, decoded_test.shape[0], decoded_test.shape[0]), decoded_test[:,1,:], c='b', s=15)\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.title('$C_d$ prediction, test\\n1 CNN layers, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ef917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airfoiltest1_predict = decoded_test[16*0:16*1]\n",
    "\n",
    "airfoiltest1_cl=y_test[16*0:16*1,0,:]\n",
    "airfoiltest1_cd=y_test[16*0:16*1,1,:]\n",
    "\n",
    "epsilonCl = np.sqrt(np.sum((airfoiltest1_predict[:,0,:] - airfoiltest1_cl)**2) / np.sum(airfoiltest1_cl**2))\n",
    "epsilonCd = np.sqrt(np.sum((airfoiltest1_predict[:,1,:] - airfoiltest1_cd)**2) / np.sum(airfoiltest1_cd**2))\n",
    "\n",
    "plt.plot(alpha, airfoiltest1_cl.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest1_predict[:,0,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_l$ prediction - Airfoil 1 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[0*16][0])[2:-1], epsilonCl), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alpha, airfoiltest1_cd.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest1_predict[:,1,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_d$ prediction - Airfoil 1 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[0*16][0])[2:-1], epsilonCd), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "airfoiltest37_predict = decoded_test[16*1:16*2]\n",
    "\n",
    "airfoiltest37_cl=y_test[16*1:16*2,0,:]\n",
    "airfoiltest37_cd=y_test[16*1:16*2,1,:]\n",
    "\n",
    "epsilonCl = np.sqrt(np.sum((airfoiltest37_predict[:,0,:] - airfoiltest37_cl)**2) / np.sum(airfoiltest37_cl**2))\n",
    "epsilonCd = np.sqrt(np.sum((airfoiltest37_predict[:,1,:] - airfoiltest37_cd)**2) / np.sum(airfoiltest37_cd**2))\n",
    "\n",
    "plt.plot(alpha, airfoiltest37_cl.reshape(16,), 'r', marker='o',lw=1)\n",
    "plt.plot(alpha, airfoiltest37_predict[:,0,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_l$ prediction - Airfoil 2 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[1*16][0])[2:-1], epsilonCl), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alpha, airfoiltest37_cd.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest37_predict[:,1,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_d$ prediction - Airfoil 2 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[1*16][0])[2:-1], epsilonCd), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db3c090",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "airfoiltrain37_predict = decoded_train[16*36:16*37]\n",
    "\n",
    "airfoiltrain37_cl=y_train[16*36:16*37,0,:]\n",
    "airfoiltrain37_cd=y_train[16*36:16*37,1,:]\n",
    "\n",
    "epsilonCl = np.sqrt(np.sum((airfoiltrain37_predict[:,0,:] - airfoiltrain37_cl)**2) / np.sum(airfoiltrain37_cl**2))\n",
    "epsilonCd = np.sqrt(np.sum((airfoiltrain37_predict[:,1,:] - airfoiltrain37_cd)**2) / np.sum(airfoiltrain37_cd**2))\n",
    "\n",
    "plt.plot(alpha, airfoiltrain37_cl.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltrain37_predict[:,0,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title('$C_l$ prediction - Airfoil 37 (%s) (training set) $\\epsilon$=%.4f' % (str(geo_train[36*16][0])[2:-1], epsilonCl), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alpha, airfoiltrain37_cd.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltrain37_predict[:,1,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title('$C_d$ prediction - Airfoil 37 (%s) (training set) $\\epsilon$=%.4f' % (str(geo_train[36*16][0])[2:-1], epsilonCd), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "airfoiltrain45_predict = decoded_train[16*44:16*45]\n",
    "\n",
    "airfoiltrain45_cl=y_train[16*44:16*45,0,:]\n",
    "airfoiltrain45_cd=y_train[16*44:16*45,1,:]\n",
    "\n",
    "epsilonCl = np.sqrt(np.sum((airfoiltrain45_predict[:,0,:] - airfoiltrain45_cl)**2) / np.sum(airfoiltrain45_cl**2))\n",
    "epsilonCd = np.sqrt(np.sum((airfoiltrain45_predict[:,1,:] - airfoiltrain45_cd)**2) / np.sum(airfoiltrain45_cd**2))\n",
    "\n",
    "plt.plot(alpha, airfoiltrain45_cl.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltrain45_predict[:,0,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_l$ prediction - Airfoil 45 (%s) (training set) $\\epsilon$=%.4f' % (str(geo_train[44*16][0])[2:-1], epsilonCl),\n",
    "          fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alpha, airfoiltrain45_cd.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltrain45_predict[:,1,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_d$ prediction - Airfoil 45 (%s) (training set) $\\epsilon$=%.4f' % (str(geo_train[44*16][0])[2:-1], epsilonCd),\n",
    "          fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train[:,0,:], decoded_train[:,0,:], c='r', s=20)\n",
    "plt.scatter(y_test[:,0,:], decoded_test[:,0,:], c='g', s=15)\n",
    "plt.xlabel('Original $C_l$', fontsize=15)\n",
    "plt.ylabel('Predicted $C_l$', fontsize=15)\n",
    "plt.title('Overall training accuracy ($C_l$)\\n1 CNN layer, 100 kernels', fontsize=15)\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(['training', 'test'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382174c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train[:,1,:], decoded_train[:,1,:], c='r', s=20)\n",
    "plt.scatter(y_test[:,1,:], decoded_test[:,1,:], c='g', s=15)\n",
    "plt.xlabel('Original $C_d$', fontsize=15)\n",
    "plt.ylabel('Predicted $C_d$', fontsize=15)\n",
    "plt.title('Overall training accuracy ($C_d$)\\n1 CNN layer, 100 kernels', fontsize=15)\n",
    "plt.grid()\n",
    "plt.legend(['training', 'test'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65431d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "airfoiltest3_predict = decoded_test[16*2:16*3]\n",
    "\n",
    "airfoiltest3_cl=y_test[16*2:16*3,0,:]\n",
    "airfoiltest3_cd=y_test[16*2:16*3,1,:]\n",
    "\n",
    "epsilonCl = np.sqrt(np.sum((airfoiltest3_predict[:,0,:] - airfoiltest3_cl)**2) / np.sum(airfoiltest3_cl**2))\n",
    "epsilonCd = np.sqrt(np.sum((airfoiltest3_predict[:,1,:] - airfoiltest3_cd)**2) / np.sum(airfoiltest3_cd**2))\n",
    "\n",
    "plt.plot(alpha, airfoiltest3_cl.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest3_predict[:,0,:].reshape(16,), marker='s', c='b')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_l$ prediction - Airfoil 3 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[2*16][0])[2:-1], epsilonCl), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alpha, airfoiltest3_cd.reshape(16,), 'r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest3_predict[:,1,:].reshape(16,), marker='s',c='b')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_d$ prediction - Airfoil 3 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[2*16][0])[2:-1], epsilonCd), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9af217",
   "metadata": {},
   "outputs": [],
   "source": [
    "airfoiltest11_predict = decoded_test[16*5:16*6]\n",
    "\n",
    "airfoiltest11_cl=y_test[16*5:16*6,0,:]\n",
    "airfoiltest11_cd=y_test[16*5:16*6,1,:]\n",
    "\n",
    "epsilonCl = np.sqrt(np.sum((airfoiltest11_predict[:,0,:] - airfoiltest11_cl)**2) / np.sum(airfoiltest11_cl**2))\n",
    "epsilonCd = np.sqrt(np.sum((airfoiltest11_predict[:,1,:] - airfoiltest11_cd)**2) / np.sum(airfoiltest11_cd**2))\n",
    "\n",
    "plt.plot(alpha, airfoiltest11_cl.reshape(16,), c='r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest11_predict[:,0,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_l$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_l$ prediction - Airfoil 6 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[5*16][0])[2:-1], epsilonCl), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(alpha, airfoiltest11_cd.reshape(16,), c='r', marker='o', lw=1)\n",
    "plt.plot(alpha, airfoiltest11_predict[:,1,:].reshape(16,), c='b', marker='s')\n",
    "plt.xlabel(r'Angle of attack ($\\alpha$, degree)', fontsize=15)\n",
    "plt.ylabel('$C_d$', fontsize=15)\n",
    "plt.xticks(alpha, label=alpha)\n",
    "plt.title(r'$C_d$ prediction - Airfoil 6 (%s) (test set) $\\epsilon$=%.4f' % (str(geo_test[5*16][0])[2:-1], epsilonCd), fontsize=15)\n",
    "plt.legend(['True value', 'Predicted value'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d376d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
