{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc91fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AeroCNN-II\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1130c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernel=100\n",
    "l2Regularizer=1e-09\n",
    "kernel_size1 = 3\n",
    "kernel_size2 = 3\n",
    "#kernel_size3 = 5\n",
    "n_grid = 128\n",
    "strides1 = 1\n",
    "strides2 = 2\n",
    "lr = 5e-04\n",
    "val_rate=0.2\n",
    "test_rate=0.1\n",
    "input_size = 100\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d84b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = 'D:\\\\20221103aeroCNNII(-1to1)'\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b716a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_directory = 'offset0.25_validation'+str(val_rate)+'test'+str(test_rate)\n",
    "if not os.path.exists(case_directory):\n",
    "    os.makedirs(case_directory)\n",
    "    \n",
    "case_storage = main_directory+\"\\\\\"+case_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d7f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.linspace(-10,20,16).reshape((16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f0eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.zeros((16*133,1))\n",
    "for i in range(0, 133):\n",
    "    aa[16*i:16*(i+1), :] = alpha[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e191fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = aa.reshape((133*16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ba4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\AeroCNN2Inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = \"D:\\\\20221103aeroCNNII(-1to1)\\\\offset0.25\"\n",
    "origin_data = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\"\n",
    "origin_coord = \"D:\\\\AirfoilClCdCoordinates_out\\\\AirfoilClCdCoordinates_out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a9cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_orig = os.listdir(origin)\n",
    "folders = [file for file in folders_orig if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c16d796",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for j in range(0, alpha.shape[0]):\n",
    "        csv_file_name = origin + '\\\\airfoil' + str(i) + \"_alpha\"+ str(int(alpha[j])) + \"_.csv\"\n",
    "        data = pd.read_csv(csv_file_name, header=None)\n",
    "        image_df = pd.concat([image_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa448a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_np = image_df.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6d479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_np.reshape((133*16, 100, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438d1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 1-image/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d6b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\airfoilFlowField'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb0bd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = origin_data + \"\\\\AirfoilIndexList.xlsx\"\n",
    "airfoilName_df = pd.read_excel(file_name)\n",
    "geometry_orig = airfoilName_df.iloc[:, 0].values\n",
    "geometry_orig2 = airfoilName_df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b3225e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\airfoilFlowField\\airfoil1alpha-8_interpolated.csv\n"
     ]
    }
   ],
   "source": [
    "data_name = path + '\\\\' + str(geometry_orig[0]) + \"alpha\"+ str(int(alpha[1])) + \"_interpolated.csv\"\n",
    "print(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7049560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:\\\\rotatedInterpolation_pow2\\\\n_grid100\\\\velocityMagnitudeField'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa87b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmag_df = pd.DataFrame()\n",
    "for i in range(1, 134):\n",
    "    for j in range(0, alpha.shape[0]):\n",
    "        data_name = path + '\\\\' + str(geometry_orig[i-1]) + \"_alpha\"+ str(int(alpha[j])) + \"_.csv\"\n",
    "        data = pd.read_csv(data_name, header=None)\n",
    "        Vmag_df = pd.concat([Vmag_df, data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "997d7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imp = Vmag_df.iloc[:, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3152af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212800, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31449c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_imp.reshape((133*16, 100, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adb3ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetMax = np.max(y)\n",
    "targetMin = np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a19e4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nor = (y - targetMin)/(targetMax-targetMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5faa41b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NACA000834'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry_orig2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb3458bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = np.zeros((133*16,1))\n",
    "geometry = geometry.astype(np.string_)\n",
    "for i in geometry_orig2:\n",
    "    index_ = np.where(geometry_orig2==i)\n",
    "    for j in range(0,16):\n",
    "        geometry[16*index_[0]+j,:] = np.asarray(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e31070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2128, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geometry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec562b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all, x_test, aa_all, aa_test, geo_all, geo_test, y_all, y_test = train_test_split(\n",
    "    image, aa, geometry, y, test_size=test_rate, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c12849ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, aa_train, aa_val, geo_train, geo_val, y_train, y_val = train_test_split(\n",
    "    x_all, aa_all, geo_all, y_all, test_size=val_rate/(1-test_rate), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd86f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nor = (y_train-targetMin)/(targetMax-targetMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "088356a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_nor = (y_val-targetMin)/(targetMax-targetMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dade5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_nor = (y_test-targetMin)/(targetMax-targetMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82d60c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37290049",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.keras.Input(shape=(100, 100, 1))\n",
    "\n",
    "x_conv1 = tf.keras.layers.Conv2D(n_kernel, (kernel_size1, kernel_size1), strides=(strides1, strides1),\n",
    "                                 activation='relu', padding='same',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                 name='Conv2DLayer1')(input_image)\n",
    "x_maxpool1 = tf.keras.layers.MaxPooling2D((2,2))(x_conv1)\n",
    "x_conv2 = tf.keras.layers.Conv2D(n_kernel*2, (kernel_size1, kernel_size1), strides=(strides1, strides1),\n",
    "                                 activation='relu', padding='same',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                 name='Conv2DLayer2')(x_maxpool1)\n",
    "x_maxpool2 = tf.keras.layers.MaxPooling2D((2,2))(x_conv2)\n",
    "\n",
    "x_deconv1 = tf.keras.layers.Conv2DTranspose(n_kernel*2, (kernel_size1, kernel_size1),\n",
    "                                            strides = (strides2, strides2),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                            padding='same', activation='relu')(x_maxpool2)\n",
    "x_deconv2 = tf.keras.layers.Conv2DTranspose(n_kernel, (kernel_size1, kernel_size1),\n",
    "                                            strides = (strides2, strides2),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                            padding='same', activation='relu')(x_deconv1)\n",
    "\n",
    "output_impr = tf.keras.layers.Conv2D(1, (kernel_size1, kernel_size1), strides=(strides1, strides1),\n",
    "                                     activation='relu', padding='same',\n",
    "                                     kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer),\n",
    "                                     name='Conv2Doutput')(x_deconv2)\n",
    "x_flat = tf.keras.layers.Flatten()(output_impr)\n",
    "x_fc = tf.keras.layers.Dense(units=(n_grid+1)**2, activation='linear', name='outputLayer',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(l2Regularizer))(x_flat)\n",
    "output_data = tf.keras.layers.Reshape((n_grid+1, n_grid+1,1))(x_fc)\n",
    "# CNN autoencoder\n",
    "model = tf.keras.Model(input_image, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3c482f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " Conv2DLayer1 (Conv2D)       (None, 100, 100, 100)     1000      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 50, 100)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Conv2DLayer2 (Conv2D)       (None, 50, 50, 200)       180200    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 200)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 50, 50, 200)      360200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 100, 100, 100)    180100    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " Conv2Doutput (Conv2D)       (None, 100, 100, 1)       901       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10000)             0         \n",
      "                                                                 \n",
      " outputLayer (Dense)         (None, 16641)             166426641 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 129, 129, 1)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,149,042\n",
      "Trainable params: 167,149,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30f3abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf477620",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(case_storage)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100, min_delta=6e-7,\n",
    "                                      restore_best_weights=True, verbose=1)\n",
    "rp = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=70, factor=0.5,\n",
    "                                          min_delta = 1e-07, min_lr=1e-06,\n",
    "                                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17d6b26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 129 and 100 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model/reshape/Reshape, IteratorGetNext:1)' with input shapes: [?,129,129,1], [?,100,100,1].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_nor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_nor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filekhi_r_18.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\cfdML\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 129 and 100 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model/reshape/Reshape, IteratorGetNext:1)' with input shapes: [?,129,129,1], [?,100,100,1].\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "history = model.fit(x_train, y_train_nor, validation_data=[x_val, y_val_nor], batch_size=batch_size,\n",
    "                    epochs=5000, shuffle=True, callbacks=[es, rp])\n",
    "end = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79204ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = end - start\n",
    "print(\"Training time:\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "plt.plot(hist['loss'], lw=2)\n",
    "plt.plot(hist['val_loss'], lw=2)\n",
    "plt.title('Training loss (mean squared error)\\nCNN Autoencoder, offset=0.25', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "#plt.ylim([5e-5, 1e-1])\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.grid()\n",
    "saveName = case_storage + \"\\\\TrainingLoss_val\" + str(val_rate) + \"test\"+str(test_rate) + \"_offset0.25.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['rmse'], lw=2)\n",
    "plt.plot(hist['val_rmse'], lw=2)\n",
    "plt.title('Root Mean Squared Error\\nCNN Autoencoder, offset=0.25', size=15)\n",
    "plt.xlabel('Epoch', size=15)\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.legend(['Training RMSE', 'Validation RMSE'])\n",
    "plt.grid()\n",
    "saveName = case_storage + \"\\\\RMSE_val\" + str(val_rate) + \"test\"+str(test_rate) + \"_offset0.25.jpg\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc70d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745feda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train_nor = model.predict(x_train)\n",
    "decoded_val_nor = model.predict(x_val)\n",
    "decoded_test_nor = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94009de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_train = decoded_train_nor*(targetMax-targetMin) + targetMin\n",
    "decoded_val = decoded_val_nor*(targetMax-targetMin) + targetMin\n",
    "decoded_test = decoded_test_nor*(targetMax-targetMin) + targetMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d01da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\\\TrainedModels\\\\20221103\")\n",
    "model_name = \"20221103AeroCNN-II_FlowField_offset0.25_val\" + str(val_rate) + \"test\"+str(test_rate)+\".h5\"\n",
    "model.save(model_name, overwrite=True, include_optimizer=True, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_abs = np.abs(decoded_train - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_val_abs = np.abs(decoded_val - y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test_abs = np.abs(decoded_test - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_train = np.sqrt(np.sum((decoded_train - y_train)**2) / np.sum(y_train**2))\n",
    "print(l2_error_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc47280",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val = np.sqrt(np.sum((decoded_val - y_val)**2) / np.sum(y_val**2))\n",
    "print(l2_error_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3770434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_test = np.sqrt(np.sum((decoded_test - y_test)**2) / np.sum(y_test**2))\n",
    "print(l2_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9785cd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_train_list = []\n",
    "for i in range(0, len(aa_train)):\n",
    "    l2_error_train_data = np.sqrt(np.sum((decoded_train[i] - y_train[i])**2) / np.sum(y_train[i]**2))\n",
    "    l2_error_train_list.append(l2_error_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede607ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error_val_list = []\n",
    "for i in range(0, len(aa_val)):\n",
    "    l2_error_val_data = np.sqrt(np.sum((decoded_val[i] - y_val[i])**2) / np.sum(y_val[i]**2))\n",
    "    l2_error_val_list.append(l2_error_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6a696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l2_error_test_list = []\n",
    "for i in range(0, len(aa_test)):\n",
    "    l2_error_test_data = np.sqrt(np.sum((decoded_test[i] - y_test[i])**2) / np.sum(y_test[i]**2))\n",
    "    l2_error_test_list.append(l2_error_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd795141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_train.shape[0], aa_train.shape[0]),\n",
    "         l2_error_train*np.ones(aa_train.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_train.shape[0], aa_train.shape[0]), l2_error_train_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - AeroCNN-II, training (domainSize 1)\\nValidation {0}, test {1}, offset 0.25'.format(val_rate, test_rate), fontsize=15)\n",
    "plt.grid()\n",
    "saveName = case_storage + \"\\\\trainingErrorDistribution\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_val.shape[0], aa_val.shape[0]),\n",
    "         l2_error_val*np.ones(aa_val.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_val.shape[0], aa_val.shape[0]), l2_error_val_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - AeroCNN-II, validation (domainSize 1)\\nValidation {0}, test {1}, offset 0.25'.format(val_rate, test_rate), fontsize=15)\n",
    "plt.grid()\n",
    "saveName = case_storage + \"\\\\validationErrorDistribution\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, aa_test.shape[0], aa_test.shape[0]),\n",
    "         l2_error_test*np.ones(aa_test.shape[0],), 'k', lw=2.5)\n",
    "plt.scatter(np.linspace(1, aa_test.shape[0], aa_test.shape[0]), l2_error_test_list, c='b')\n",
    "plt.xlabel('Index', fontsize=15)\n",
    "plt.ylabel('$L_2$ error norm', fontsize=15)\n",
    "plt.yscale('log')\n",
    "plt.title('$L_2$ error norm distribution - AeroCNN-II, test (domainSize 1)\\nValidation {0}, test {1}, offset 0.25'.format(val_rate, test_rate), fontsize=15)\n",
    "plt.grid()\n",
    "saveName = case_storage + \"\\\\testErrorDistribution\"\n",
    "plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddbea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_grid =129\n",
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_test2_rotate = y_test[2*16+c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_test[2*16+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    xrange = np.linspace(-1, 1, n_grid)\n",
    "    yrange = np.linspace(-1, 1, n_grid)\n",
    "    xmesh, ymesh = np.meshgrid(xrange, yrange)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_test2_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Test dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_test[2*16+c])[3:-2], aa_test[2*16+c]),fontsize=20)\n",
    "    saveName = case_storage + \"\\\\testprediction\"+str(np.array2string(geo_test[2*16+c])[3:-2])+\"_alpha\"+str(aa_test[2*16+c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369c4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_test0_rotate = y_test[c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_test[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    xmesh, ymesh = np.meshgrid(xrange, yrange)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_test0_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Test dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_test[c])[3:-2], aa_test[c]),fontsize=20)\n",
    "    saveName = case_storage + \"\\\\testprediction\"+str(np.array2string(geo_test[c])[3:-2])+\"_alpha\"+str(aa_test[c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e49554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_train0_rotate = y_train[c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_train[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_train0_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Training dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_train[c])[3:-2], aa_train[c]),fontsize=20)\n",
    "    saveName = case_storage + \"\\\\trainingprediction\"+str(np.array2string(geo_train[c])[3:-2])+\"_alpha\"+str(aa_train[c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd7cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    y_train20_rotate = y_train[20*16+c].reshape(n_grid,n_grid)\n",
    "    decoded_rotate = decoded_train[20*16+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    a1 = plt.contourf(xmesh, ymesh, y_train20_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Original test image', fontsize=15)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    a2 = plt.contourf(xmesh, ymesh, decoded_rotate, vmin=targetMin, vmax=targetMax, levels=128, cmap='seismic')\n",
    "    ax.set_xlabel('$x$', fontsize=15)\n",
    "    ax.set_ylabel('$y$', fontsize=15)\n",
    "    ax.set_title('Reconstructed image', fontsize=15)\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(a1, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Velocity Magnitude', fontsize=15)\n",
    "    #cbar.set_ticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "    plt.suptitle(r'Training dataset (%s, $\\alpha$ = %d)' %(np.array2string(geo_train[20*16+c])[3:-2], aa_train[20*16+c]),fontsize=20)\n",
    "    saveName = case_storage + \"\\\\trainingprediction\"+str(np.array2string(geo_train[20*16+c])[3:-2])+\"_alpha\"+str(aa_train[20*16+c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_test_abs2_rotate = error_test_abs[2*16+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_test_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_test[2*16+c])[3:-2],\n",
    "                                                                       aa_test[2*16+c], l2_error_test_list[2*16+c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    saveName = case_storage+ \"\\\\testError\"+str(np.array2string(geo_test[2*16+c])[3:-2])+\"_alpha\"+str(aa_test[2*16+c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c85b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_test_abs2_rotate = error_test_abs[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_test_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_test[c])[3:-2],\n",
    "                                                                       aa_test[c], l2_error_test_list[c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "    \n",
    "    saveName = case_storage+ \"\\\\testError\"+str(np.array2string(geo_test[c])[3:-2])+\"_alpha\"+str(aa_test[c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_train_abs2_rotate = error_train_abs[c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_train_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_train[c])[3:-2],\n",
    "                                                                       aa_train[c], l2_error_train_list[c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    saveName = case_storage+ \"\\\\trainingError\"+str(np.array2string(geo_train[c])[3:-2])+\"_alpha\"+str(aa_train[c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,16):\n",
    "    error_train_abs2_rotate = error_train_abs[16*20+c].reshape(n_grid,n_grid)\n",
    "\n",
    "    fig5 = plt.figure(figsize = (8, 8))\n",
    "    ax5 = fig5.add_subplot(111)\n",
    "    mappable = ax5.contourf(xmesh, ymesh, error_train_abs2_rotate, levels=128, cmap='seismic')\n",
    "    ax5.set_title(r'Absolute error (%s, $\\alpha$ = %d, $\\epsilon$ = %.4f)' %(np.array2string(geo_train[16*20+c])[3:-2],\n",
    "                                                                       aa_train[16*20+c], l2_error_train_list[16*20+c]), fontsize=16)\n",
    "    ax5.set_xlabel('$y$', fontsize=15)\n",
    "    ax5.set_ylabel('$z$', fontsize=15)\n",
    "\n",
    "    cax = plt.axes([0.12, 0.005, 0.78, 0.05])\n",
    "    cbar = plt.colorbar(mappable, cax=cax, orientation=\"horizontal\")\n",
    "    cbar.set_label('Error', fontsize=15)\n",
    "\n",
    "    saveName = case_storage+ \"\\\\trainingError\"+str(np.array2string(geo_train[16*20+c])[3:-2])+\"_alpha\"+str(aa_train[16*20+c])+\".jpg\"\n",
    "    plt.savefig(saveName, dpi=300, bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7472bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
